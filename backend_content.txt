--- DIRECTORY TREE ---

Directory Tree for: /home/marcel/ShareYourSpace/shareyourspace-backend

├── ./
    ├── pyproject.toml
    ├── .gitignore
    ├── main.py
    ├── README.md
    ├── poetry.lock
    ├── Dockerfile
    ├── .env
    ├── docker-compose.yml
    ├── .dockerignore
    ├── alembic.ini
    ├── requirements.txt
    ├── test_db_connection.py
    ├── scripts/
        ├── seed.py
        ├── generate_embeddings_for_users.py
        ├── backfill_embeddings.py
    ├── app/
        ├── main.py
        ├── dependencies.py
        ├── __init__.py
        ├── security.py
        ├── socket_handlers.py
        ├── socket_instance.py
        ├── routers/
            ├── auth.py
            ├── users.py
            ├── organizations.py
            ├── member_requests.py
            ├── matching.py
            ├── notifications.py
            ├── __init__.py
            ├── uploads.py
            ├── connections.py
            ├── invitations.py
            ├── admin.py
            ├── spaces.py
            ├── agent.py
            ├── startup_actions.py
            ├── chat.py
        ├── utils/
            ├── email.py
            ├── security_utils.py
            ├── storage.py
            ├── embeddings.py
            ├── __pycache__/
                ├── security_utils.cpython-312.pyc
        ├── core/
            ├── __init__.py
            ├── config.py
            ├── __pycache__/
                ├── config.cpython-312.pyc
                ├── __init__.cpython-312.pyc
        ├── schemas/
            ├── message.py
            ├── auth.py
            ├── user.py
            ├── space.py
            ├── connection.py
            ├── organization.py
            ├── matching.py
            ├── __init__.py
            ├── token.py
            ├── verification_token.py
            ├── password_reset_token.py
            ├── admin.py
            ├── user_profile.py
            ├── notification.py
            ├── member_request.py
            ├── chat.py
            ├── invitation.py
            ├── __pycache__/
                ├── password_reset_token.cpython-312.pyc
                ├── verification_token.cpython-312.pyc
                ├── organization.cpython-312.pyc
                ├── user.cpython-312.pyc
                ├── token.cpython-312.pyc
                ├── auth.cpython-312.pyc
                ├── __init__.cpython-312.pyc
                ├── space.cpython-312.pyc
                ├── message.cpython-312.pyc
                ├── chat.cpython-312.pyc
                ├── user_profile.cpython-312.pyc
        ├── models/
            ├── user.py
            ├── space.py
            ├── connection.py
            ├── organization.py
            ├── profile.py
            ├── __init__.py
            ├── verification_token.py
            ├── password_reset_token.py
            ├── enums.py
            ├── notification.py
            ├── chat.py
            ├── invitation.py
            ├── __pycache__/
                ├── password_reset_token.cpython-312.pyc
                ├── connection.cpython-312.pyc
                ├── notification.cpython-312.pyc
                ├── invitation.cpython-312.pyc
                ├── enums.cpython-312.pyc
                ├── verification_token.cpython-312.pyc
                ├── organization.cpython-312.pyc
                ├── user.cpython-312.pyc
                ├── __init__.cpython-312.pyc
                ├── space.cpython-312.pyc
                ├── chat.cpython-312.pyc
                ├── user_profile.cpython-312.pyc
                ├── profile.cpython-312.pyc
        ├── crud/
            ├── crud_organization.py
            ├── crud_verification_token.py
            ├── crud_invitation.py
            ├── crud_space.py
            ├── crud_user.py
            ├── crud_password_reset_token.py
            ├── __init__.py
            ├── crud_connection.py
            ├── crud_user_profile.py
            ├── crud_chat.py
            ├── crud_notification.py
            ├── base.py
        ├── db/
            ├── session.py
            ├── base_class.py
            ├── __pycache__/
                ├── session.cpython-312.pyc
                ├── base_class.cpython-312.pyc
        ├── __pycache__/
            ├── __init__.cpython-312.pyc
    ├── alembic/
        ├── env.py
        ├── script.py.mako
        ├── README
        ├── versions/
            ├── 25802b79acda_add_message_reaction_table.py
            ├── 08eced71251f_add_last_read_at_to_.py
            ├── 9a0c9d66f8f4_create_connection_table.py
            ├── a9db281d289d_add_attachment_fields_to_chat_messages_.py
            ├── 6e42b588d2b7_add_user_profile_table_and_relationship.py
            ├── f6faaa54ca44_add_message_reactions_table.py
            ├── 835b07ae6f4e_add_approval_acceptance_to_invitations.py
            ├── 0581da68b2ba_change_connection_status_to_enum.py
            ├── 8c3a5a32e14b_add_verification_token_table.py
            ├── c5a8a53fefb7_add_revoked_fields_to_invitations.py
            ├── 5294db0e7af9_add_hnsw_index_on_profile_vector.py
            ├── 6584e07b26cc_add_space_id_to_users_table.py
            ├── 4560944864bf_add_updated_at_is_deleted_to_chatmessage.py
            ├── a0ea2f0b7b3a_add_decline_fields_to_invitations.py
            ├── 99e4b0bb221a_add_company_and_startup_models.py
            ├── 96604f2f7de6_create_user_table.py
            ├── a3cc12c29cbe_add_chat_models.py
            ├── a0f683693a70_create_invitations_table.py
            ├── a2d9934e5db7_add_user_profiles_table_with_profile_.py
            ├── 7bd0250369dc_create_notification_table.py
            ├── 43b26710d32d_update_invitationstatus_enum_and_values.py
            ├── 61285376d591_add_reference_and_link_to_notification.py
            ├── c92880be338c_add_missing_profile_fields_to_user_.py
            ├── c421022fb1a2_add_space_workstation_management_models_.py
            ├── 01fcfe2512a6_make_corporate_admin_id_nullable_in_.py
            ├── 2a94457f8436_add_space_id_to_startup_and_relationship.py
            ├── 362919f61f47_add_space_node_and_workstation_models.py
            ├── bd906d8dba40_create_password_reset_tokens_table.py
            ├── 6f81518f99df_create_user_table.py
            ├── __pycache__/
                ├── 61285376d591_add_reference_and_link_to_notification.cpython-312.pyc
                ├── c421022fb1a2_add_space_workstation_management_models_.cpython-312.pyc
                ├── bd906d8dba40_create_password_reset_tokens_table.cpython-312.pyc
                ├── 6f81518f99df_create_user_table.cpython-312.pyc
                ├── 08eced71251f_add_last_read_at_to_.cpython-312.pyc
                ├── 01fcfe2512a6_make_corporate_admin_id_nullable_in_.cpython-312.pyc
                ├── 2a94457f8436_add_space_id_to_startup_and_relationship.cpython-312.pyc
                ├── a0ea2f0b7b3a_add_decline_fields_to_invitations.cpython-312.pyc
                ├── a2d9934e5db7_add_user_profiles_table_with_profile_.cpython-312.pyc
                ├── 7bd0250369dc_create_notification_table.cpython-312.pyc
                ├── c5a8a53fefb7_add_revoked_fields_to_invitations.cpython-312.pyc
                ├── 0581da68b2ba_change_connection_status_to_enum.cpython-312.pyc
                ├── c92880be338c_add_missing_profile_fields_to_user_.cpython-312.pyc
                ├── 96604f2f7de6_create_user_table.cpython-312.pyc
                ├── a9db281d289d_add_attachment_fields_to_chat_messages_.cpython-312.pyc
                ├── 835b07ae6f4e_add_approval_acceptance_to_invitations.cpython-312.pyc
                ├── 25802b79acda_add_message_reaction_table.cpython-312.pyc
                ├── a0f683693a70_create_invitations_table.cpython-312.pyc
                ├── 5294db0e7af9_add_hnsw_index_on_profile_vector.cpython-312.pyc
                ├── 6e42b588d2b7_add_user_profile_table_and_relationship.cpython-312.pyc
                ├── 99e4b0bb221a_add_company_and_startup_models.cpython-312.pyc
                ├── 362919f61f47_add_space_node_and_workstation_models.cpython-312.pyc
                ├── 8c3a5a32e14b_add_verification_token_table.cpython-312.pyc
                ├── a3cc12c29cbe_add_chat_models.cpython-312.pyc
                ├── f6faaa54ca44_add_message_reactions_table.cpython-312.pyc
                ├── 9a0c9d66f8f4_create_connection_table.cpython-312.pyc
                ├── 4560944864bf_add_updated_at_is_deleted_to_chatmessage.cpython-312.pyc
                ├── 43b26710d32d_update_invitationstatus_enum_and_values.cpython-312.pyc
                ├── 6584e07b26cc_add_space_id_to_users_table.cpython-312.pyc
        ├── __pycache__/
            ├── env.cpython-312.pyc

================================================================================

--- START OF FILE: pyproject.toml ---

[tool.poetry]
name = "shareyourspace-backend"
version = "0.1.0"
description = ""
authors = ["Marcel Kueck <marcel@shareyourspace.app>"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.12"
fastapi = "^0.115.12"
uvicorn = {extras = ["standard"], version = "^0.34.2"}
pydantic-settings = "^2.8.1"
python-dotenv = "^1.1.0"
sqlalchemy = {extras = ["asyncio"], version = "^2.0.40"}
alembic = "^1.15.2"
asyncpg = "^0.30.0"
passlib = {extras = ["bcrypt"], version = "^1.7.4"}
python-jose = {extras = ["cryptography"], version = "^3.4.0"}
faker = "^37.1.0"
pydantic = {extras = ["email"], version = "^2.11.3"}
resend = "^2.7.0"
python-multipart = "^0.0.20"
google-cloud-storage = "^3.1.0"
pgvector = "^0.4.0"
google-generativeai = "^0.8.5"
python-socketio = "^5.13.0"
bcrypt = "4.0.1"


[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"


--- END OF FILE: pyproject.toml ---

================================================================================

--- START OF FILE: .gitignore ---

.env

--- END OF FILE: .gitignore ---

================================================================================

--- START OF FILE: main.py ---

import uvicorn
from dotenv import load_dotenv

# Load environment variables from .env file before importing the app
load_dotenv()

# Now it's safe to import the app and settings
from app.main import app

if __name__ == "__main__":
    # When running directly, use uvicorn to serve the app
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True) 

--- END OF FILE: main.py ---

================================================================================

--- START OF FILE: README.md ---



--- END OF FILE: README.md ---

================================================================================

--- START OF FILE: poetry.lock ---

# This file is automatically @generated by Poetry 1.8.2 and should not be changed by hand.

[[package]]
name = "alembic"
version = "1.16.1"
description = "A database migration tool for SQLAlchemy."
optional = false
python-versions = ">=3.9"
files = [
    {file = "alembic-1.16.1-py3-none-any.whl", hash = "sha256:0cdd48acada30d93aa1035767d67dff25702f8de74d7c3919f2e8492c8db2e67"},
    {file = "alembic-1.16.1.tar.gz", hash = "sha256:43d37ba24b3d17bc1eb1024fe0f51cd1dc95aeb5464594a02c6bb9ca9864bfa4"},
]

[package.dependencies]
Mako = "*"
SQLAlchemy = ">=1.4.0"
typing-extensions = ">=4.12"

[package.extras]
tz = ["tzdata"]

[[package]]
name = "annotated-types"
version = "0.7.0"
description = "Reusable constraint types to use with typing.Annotated"
optional = false
python-versions = ">=3.8"
files = [
    {file = "annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53"},
    {file = "annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89"},
]

[[package]]
name = "anyio"
version = "4.9.0"
description = "High level compatibility layer for multiple asynchronous event loop implementations"
optional = false
python-versions = ">=3.9"
files = [
    {file = "anyio-4.9.0-py3-none-any.whl", hash = "sha256:9f76d541cad6e36af7beb62e978876f3b41e3e04f2c1fbf0884604c0a9c4d93c"},
    {file = "anyio-4.9.0.tar.gz", hash = "sha256:673c0c244e15788651a4ff38710fea9675823028a6f08a5eda409e0c9840a028"},
]

[package.dependencies]
idna = ">=2.8"
sniffio = ">=1.1"
typing_extensions = {version = ">=4.5", markers = "python_version < \"3.13\""}

[package.extras]
doc = ["Sphinx (>=8.2,<9.0)", "packaging", "sphinx-autodoc-typehints (>=1.2.0)", "sphinx_rtd_theme"]
test = ["anyio[trio]", "blockbuster (>=1.5.23)", "coverage[toml] (>=7)", "exceptiongroup (>=1.2.0)", "hypothesis (>=4.0)", "psutil (>=5.9)", "pytest (>=7.0)", "trustme", "truststore (>=0.9.1)", "uvloop (>=0.21)"]
trio = ["trio (>=0.26.1)"]

[[package]]
name = "asyncpg"
version = "0.30.0"
description = "An asyncio PostgreSQL driver"
optional = false
python-versions = ">=3.8.0"
files = [
    {file = "asyncpg-0.30.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:bfb4dd5ae0699bad2b233672c8fc5ccbd9ad24b89afded02341786887e37927e"},
    {file = "asyncpg-0.30.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:dc1f62c792752a49f88b7e6f774c26077091b44caceb1983509edc18a2222ec0"},
    {file = "asyncpg-0.30.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3152fef2e265c9c24eec4ee3d22b4f4d2703d30614b0b6753e9ed4115c8a146f"},
    {file = "asyncpg-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c7255812ac85099a0e1ffb81b10dc477b9973345793776b128a23e60148dd1af"},
    {file = "asyncpg-0.30.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:578445f09f45d1ad7abddbff2a3c7f7c291738fdae0abffbeb737d3fc3ab8b75"},
    {file = "asyncpg-0.30.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:c42f6bb65a277ce4d93f3fba46b91a265631c8df7250592dd4f11f8b0152150f"},
    {file = "asyncpg-0.30.0-cp310-cp310-win32.whl", hash = "sha256:aa403147d3e07a267ada2ae34dfc9324e67ccc4cdca35261c8c22792ba2b10cf"},
    {file = "asyncpg-0.30.0-cp310-cp310-win_amd64.whl", hash = "sha256:fb622c94db4e13137c4c7f98834185049cc50ee01d8f657ef898b6407c7b9c50"},
    {file = "asyncpg-0.30.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:5e0511ad3dec5f6b4f7a9e063591d407eee66b88c14e2ea636f187da1dcfff6a"},
    {file = "asyncpg-0.30.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:915aeb9f79316b43c3207363af12d0e6fd10776641a7de8a01212afd95bdf0ed"},
    {file = "asyncpg-0.30.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1c198a00cce9506fcd0bf219a799f38ac7a237745e1d27f0e1f66d3707c84a5a"},
    {file = "asyncpg-0.30.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3326e6d7381799e9735ca2ec9fd7be4d5fef5dcbc3cb555d8a463d8460607956"},
    {file = "asyncpg-0.30.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:51da377487e249e35bd0859661f6ee2b81db11ad1f4fc036194bc9cb2ead5056"},
    {file = "asyncpg-0.30.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:bc6d84136f9c4d24d358f3b02be4b6ba358abd09f80737d1ac7c444f36108454"},
    {file = "asyncpg-0.30.0-cp311-cp311-win32.whl", hash = "sha256:574156480df14f64c2d76450a3f3aaaf26105869cad3865041156b38459e935d"},
    {file = "asyncpg-0.30.0-cp311-cp311-win_amd64.whl", hash = "sha256:3356637f0bd830407b5597317b3cb3571387ae52ddc3bca6233682be88bbbc1f"},
    {file = "asyncpg-0.30.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:c902a60b52e506d38d7e80e0dd5399f657220f24635fee368117b8b5fce1142e"},
    {file = "asyncpg-0.30.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:aca1548e43bbb9f0f627a04666fedaca23db0a31a84136ad1f868cb15deb6e3a"},
    {file = "asyncpg-0.30.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6c2a2ef565400234a633da0eafdce27e843836256d40705d83ab7ec42074efb3"},
    {file = "asyncpg-0.30.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1292b84ee06ac8a2ad8e51c7475aa309245874b61333d97411aab835c4a2f737"},
    {file = "asyncpg-0.30.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:0f5712350388d0cd0615caec629ad53c81e506b1abaaf8d14c93f54b35e3595a"},
    {file = "asyncpg-0.30.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:db9891e2d76e6f425746c5d2da01921e9a16b5a71a1c905b13f30e12a257c4af"},
    {file = "asyncpg-0.30.0-cp312-cp312-win32.whl", hash = "sha256:68d71a1be3d83d0570049cd1654a9bdfe506e794ecc98ad0873304a9f35e411e"},
    {file = "asyncpg-0.30.0-cp312-cp312-win_amd64.whl", hash = "sha256:9a0292c6af5c500523949155ec17b7fe01a00ace33b68a476d6b5059f9630305"},
    {file = "asyncpg-0.30.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:05b185ebb8083c8568ea8a40e896d5f7af4b8554b64d7719c0eaa1eb5a5c3a70"},
    {file = "asyncpg-0.30.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:c47806b1a8cbb0a0db896f4cd34d89942effe353a5035c62734ab13b9f938da3"},
    {file = "asyncpg-0.30.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9b6fde867a74e8c76c71e2f64f80c64c0f3163e687f1763cfaf21633ec24ec33"},
    {file = "asyncpg-0.30.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:46973045b567972128a27d40001124fbc821c87a6cade040cfcd4fa8a30bcdc4"},
    {file = "asyncpg-0.30.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:9110df111cabc2ed81aad2f35394a00cadf4f2e0635603db6ebbd0fc896f46a4"},
    {file = "asyncpg-0.30.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:04ff0785ae7eed6cc138e73fc67b8e51d54ee7a3ce9b63666ce55a0bf095f7ba"},
    {file = "asyncpg-0.30.0-cp313-cp313-win32.whl", hash = "sha256:ae374585f51c2b444510cdf3595b97ece4f233fde739aa14b50e0d64e8a7a590"},
    {file = "asyncpg-0.30.0-cp313-cp313-win_amd64.whl", hash = "sha256:f59b430b8e27557c3fb9869222559f7417ced18688375825f8f12302c34e915e"},
    {file = "asyncpg-0.30.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:29ff1fc8b5bf724273782ff8b4f57b0f8220a1b2324184846b39d1ab4122031d"},
    {file = "asyncpg-0.30.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:64e899bce0600871b55368b8483e5e3e7f1860c9482e7f12e0a771e747988168"},
    {file = "asyncpg-0.30.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5b290f4726a887f75dcd1b3006f484252db37602313f806e9ffc4e5996cfe5cb"},
    {file = "asyncpg-0.30.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f86b0e2cd3f1249d6fe6fd6cfe0cd4538ba994e2d8249c0491925629b9104d0f"},
    {file = "asyncpg-0.30.0-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:393af4e3214c8fa4c7b86da6364384c0d1b3298d45803375572f415b6f673f38"},
    {file = "asyncpg-0.30.0-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:fd4406d09208d5b4a14db9a9dbb311b6d7aeeab57bded7ed2f8ea41aeef39b34"},
    {file = "asyncpg-0.30.0-cp38-cp38-win32.whl", hash = "sha256:0b448f0150e1c3b96cb0438a0d0aa4871f1472e58de14a3ec320dbb2798fb0d4"},
    {file = "asyncpg-0.30.0-cp38-cp38-win_amd64.whl", hash = "sha256:f23b836dd90bea21104f69547923a02b167d999ce053f3d502081acea2fba15b"},
    {file = "asyncpg-0.30.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:6f4e83f067b35ab5e6371f8a4c93296e0439857b4569850b178a01385e82e9ad"},
    {file = "asyncpg-0.30.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:5df69d55add4efcd25ea2a3b02025b669a285b767bfbf06e356d68dbce4234ff"},
    {file = "asyncpg-0.30.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a3479a0d9a852c7c84e822c073622baca862d1217b10a02dd57ee4a7a081f708"},
    {file = "asyncpg-0.30.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:26683d3b9a62836fad771a18ecf4659a30f348a561279d6227dab96182f46144"},
    {file = "asyncpg-0.30.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:1b982daf2441a0ed314bd10817f1606f1c28b1136abd9e4f11335358c2c631cb"},
    {file = "asyncpg-0.30.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:1c06a3a50d014b303e5f6fc1e5f95eb28d2cee89cf58384b700da621e5d5e547"},
    {file = "asyncpg-0.30.0-cp39-cp39-win32.whl", hash = "sha256:1b11a555a198b08f5c4baa8f8231c74a366d190755aa4f99aacec5970afe929a"},
    {file = "asyncpg-0.30.0-cp39-cp39-win_amd64.whl", hash = "sha256:8b684a3c858a83cd876f05958823b68e8d14ec01bb0c0d14a6704c5bf9711773"},
    {file = "asyncpg-0.30.0.tar.gz", hash = "sha256:c551e9928ab6707602f44811817f82ba3c446e018bfe1d3abecc8ba5f3eac851"},
]

[package.extras]
docs = ["Sphinx (>=8.1.3,<8.2.0)", "sphinx-rtd-theme (>=1.2.2)"]
gssauth = ["gssapi", "sspilib"]
test = ["distro (>=1.9.0,<1.10.0)", "flake8 (>=6.1,<7.0)", "flake8-pyi (>=24.1.0,<24.2.0)", "gssapi", "k5test", "mypy (>=1.8.0,<1.9.0)", "sspilib", "uvloop (>=0.15.3)"]

[[package]]
name = "bcrypt"
version = "4.0.1"
description = "Modern password hashing for your software and your servers"
optional = false
python-versions = ">=3.6"
files = [
    {file = "bcrypt-4.0.1-cp36-abi3-macosx_10_10_universal2.whl", hash = "sha256:b1023030aec778185a6c16cf70f359cbb6e0c289fd564a7cfa29e727a1c38f8f"},
    {file = "bcrypt-4.0.1-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_24_aarch64.whl", hash = "sha256:08d2947c490093a11416df18043c27abe3921558d2c03e2076ccb28a116cb6d0"},
    {file = "bcrypt-4.0.1-cp36-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0eaa47d4661c326bfc9d08d16debbc4edf78778e6aaba29c1bc7ce67214d4410"},
    {file = "bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ae88eca3024bb34bb3430f964beab71226e761f51b912de5133470b649d82344"},
    {file = "bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl", hash = "sha256:a522427293d77e1c29e303fc282e2d71864579527a04ddcfda6d4f8396c6c36a"},
    {file = "bcrypt-4.0.1-cp36-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:fbdaec13c5105f0c4e5c52614d04f0bca5f5af007910daa8b6b12095edaa67b3"},
    {file = "bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:ca3204d00d3cb2dfed07f2d74a25f12fc12f73e606fcaa6975d1f7ae69cacbb2"},
    {file = "bcrypt-4.0.1-cp36-abi3-musllinux_1_1_aarch64.whl", hash = "sha256:089098effa1bc35dc055366740a067a2fc76987e8ec75349eb9484061c54f535"},
    {file = "bcrypt-4.0.1-cp36-abi3-musllinux_1_1_x86_64.whl", hash = "sha256:e9a51bbfe7e9802b5f3508687758b564069ba937748ad7b9e890086290d2f79e"},
    {file = "bcrypt-4.0.1-cp36-abi3-win32.whl", hash = "sha256:2caffdae059e06ac23fce178d31b4a702f2a3264c20bfb5ff541b338194d8fab"},
    {file = "bcrypt-4.0.1-cp36-abi3-win_amd64.whl", hash = "sha256:8a68f4341daf7522fe8d73874de8906f3a339048ba406be6ddc1b3ccb16fc0d9"},
    {file = "bcrypt-4.0.1-pp37-pypy37_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bf4fa8b2ca74381bb5442c089350f09a3f17797829d958fad058d6e44d9eb83c"},
    {file = "bcrypt-4.0.1-pp37-pypy37_pp73-manylinux_2_24_x86_64.whl", hash = "sha256:67a97e1c405b24f19d08890e7ae0c4f7ce1e56a712a016746c8b2d7732d65d4b"},
    {file = "bcrypt-4.0.1-pp37-pypy37_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:b3b85202d95dd568efcb35b53936c5e3b3600c7cdcc6115ba461df3a8e89f38d"},
    {file = "bcrypt-4.0.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cbb03eec97496166b704ed663a53680ab57c5084b2fc98ef23291987b525cb7d"},
    {file = "bcrypt-4.0.1-pp38-pypy38_pp73-manylinux_2_24_x86_64.whl", hash = "sha256:5ad4d32a28b80c5fa6671ccfb43676e8c1cc232887759d1cd7b6f56ea4355215"},
    {file = "bcrypt-4.0.1-pp38-pypy38_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:b57adba8a1444faf784394de3436233728a1ecaeb6e07e8c22c8848f179b893c"},
    {file = "bcrypt-4.0.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:705b2cea8a9ed3d55b4491887ceadb0106acf7c6387699fca771af56b1cdeeda"},
    {file = "bcrypt-4.0.1-pp39-pypy39_pp73-manylinux_2_24_x86_64.whl", hash = "sha256:2b3ac11cf45161628f1f3733263e63194f22664bf4d0c0f3ab34099c02134665"},
    {file = "bcrypt-4.0.1-pp39-pypy39_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:3100851841186c25f127731b9fa11909ab7b1df6fc4b9f8353f4f1fd952fbf71"},
    {file = "bcrypt-4.0.1.tar.gz", hash = "sha256:27d375903ac8261cfe4047f6709d16f7d18d39b1ec92aaf72af989552a650ebd"},
]

[package.extras]
tests = ["pytest (>=3.2.1,!=3.3.0)"]
typecheck = ["mypy"]

[[package]]
name = "bidict"
version = "0.23.1"
description = "The bidirectional mapping library for Python."
optional = false
python-versions = ">=3.8"
files = [
    {file = "bidict-0.23.1-py3-none-any.whl", hash = "sha256:5dae8d4d79b552a71cbabc7deb25dfe8ce710b17ff41711e13010ead2abfc3e5"},
    {file = "bidict-0.23.1.tar.gz", hash = "sha256:03069d763bc387bbd20e7d49914e75fc4132a41937fa3405417e1a5a2d006d71"},
]

[[package]]
name = "cachetools"
version = "5.5.2"
description = "Extensible memoizing collections and decorators"
optional = false
python-versions = ">=3.7"
files = [
    {file = "cachetools-5.5.2-py3-none-any.whl", hash = "sha256:d26a22bcc62eb95c3beabd9f1ee5e820d3d2704fe2967cbe350e20c8ffcd3f0a"},
    {file = "cachetools-5.5.2.tar.gz", hash = "sha256:1a661caa9175d26759571b2e19580f9d6393969e5dfca11fdb1f947a23e640d4"},
]

[[package]]
name = "certifi"
version = "2025.4.26"
description = "Python package for providing Mozilla's CA Bundle."
optional = false
python-versions = ">=3.6"
files = [
    {file = "certifi-2025.4.26-py3-none-any.whl", hash = "sha256:30350364dfe371162649852c63336a15c70c6510c2ad5015b21c2345311805f3"},
    {file = "certifi-2025.4.26.tar.gz", hash = "sha256:0a816057ea3cdefcef70270d2c515e4506bbc954f417fa5ade2021213bb8f0c6"},
]

[[package]]
name = "cffi"
version = "1.17.1"
description = "Foreign Function Interface for Python calling C code."
optional = false
python-versions = ">=3.8"
files = [
    {file = "cffi-1.17.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:df8b1c11f177bc2313ec4b2d46baec87a5f3e71fc8b45dab2ee7cae86d9aba14"},
    {file = "cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8f2cdc858323644ab277e9bb925ad72ae0e67f69e804f4898c070998d50b1a67"},
    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:edae79245293e15384b51f88b00613ba9f7198016a5948b5dddf4917d4d26382"},
    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:45398b671ac6d70e67da8e4224a065cec6a93541bb7aebe1b198a61b58c7b702"},
    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ad9413ccdeda48c5afdae7e4fa2192157e991ff761e7ab8fdd8926f40b160cc3"},
    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5da5719280082ac6bd9aa7becb3938dc9f9cbd57fac7d2871717b1feb0902ab6"},
    {file = "cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2bb1a08b8008b281856e5971307cc386a8e9c5b625ac297e853d36da6efe9c17"},
    {file = "cffi-1.17.1-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:045d61c734659cc045141be4bae381a41d89b741f795af1dd018bfb532fd0df8"},
    {file = "cffi-1.17.1-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:6883e737d7d9e4899a8a695e00ec36bd4e5e4f18fabe0aca0efe0a4b44cdb13e"},
    {file = "cffi-1.17.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:6b8b4a92e1c65048ff98cfe1f735ef8f1ceb72e3d5f0c25fdb12087a23da22be"},
    {file = "cffi-1.17.1-cp310-cp310-win32.whl", hash = "sha256:c9c3d058ebabb74db66e431095118094d06abf53284d9c81f27300d0e0d8bc7c"},
    {file = "cffi-1.17.1-cp310-cp310-win_amd64.whl", hash = "sha256:0f048dcf80db46f0098ccac01132761580d28e28bc0f78ae0d58048063317e15"},
    {file = "cffi-1.17.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:a45e3c6913c5b87b3ff120dcdc03f6131fa0065027d0ed7ee6190736a74cd401"},
    {file = "cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:30c5e0cb5ae493c04c8b42916e52ca38079f1b235c2f8ae5f4527b963c401caf"},
    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f75c7ab1f9e4aca5414ed4d8e5c0e303a34f4421f8a0d47a4d019ceff0ab6af4"},
    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a1ed2dd2972641495a3ec98445e09766f077aee98a1c896dcb4ad0d303628e41"},
    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:46bf43160c1a35f7ec506d254e5c890f3c03648a4dbac12d624e4490a7046cd1"},
    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a24ed04c8ffd54b0729c07cee15a81d964e6fee0e3d4d342a27b020d22959dc6"},
    {file = "cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:610faea79c43e44c71e1ec53a554553fa22321b65fae24889706c0a84d4ad86d"},
    {file = "cffi-1.17.1-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:a9b15d491f3ad5d692e11f6b71f7857e7835eb677955c00cc0aefcd0669adaf6"},
    {file = "cffi-1.17.1-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:de2ea4b5833625383e464549fec1bc395c1bdeeb5f25c4a3a82b5a8c756ec22f"},
    {file = "cffi-1.17.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:fc48c783f9c87e60831201f2cce7f3b2e4846bf4d8728eabe54d60700b318a0b"},
    {file = "cffi-1.17.1-cp311-cp311-win32.whl", hash = "sha256:85a950a4ac9c359340d5963966e3e0a94a676bd6245a4b55bc43949eee26a655"},
    {file = "cffi-1.17.1-cp311-cp311-win_amd64.whl", hash = "sha256:caaf0640ef5f5517f49bc275eca1406b0ffa6aa184892812030f04c2abf589a0"},
    {file = "cffi-1.17.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:805b4371bf7197c329fcb3ead37e710d1bca9da5d583f5073b799d5c5bd1eee4"},
    {file = "cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:733e99bc2df47476e3848417c5a4540522f234dfd4ef3ab7fafdf555b082ec0c"},
    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1257bdabf294dceb59f5e70c64a3e2f462c30c7ad68092d01bbbfb1c16b1ba36"},
    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:da95af8214998d77a98cc14e3a3bd00aa191526343078b530ceb0bd710fb48a5"},
    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d63afe322132c194cf832bfec0dc69a99fb9bb6bbd550f161a49e9e855cc78ff"},
    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f79fc4fc25f1c8698ff97788206bb3c2598949bfe0fef03d299eb1b5356ada99"},
    {file = "cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b62ce867176a75d03a665bad002af8e6d54644fad99a3c70905c543130e39d93"},
    {file = "cffi-1.17.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:386c8bf53c502fff58903061338ce4f4950cbdcb23e2902d86c0f722b786bbe3"},
    {file = "cffi-1.17.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ceb10419a9adf4460ea14cfd6bc43d08701f0835e979bf821052f1805850fe8"},
    {file = "cffi-1.17.1-cp312-cp312-win32.whl", hash = "sha256:a08d7e755f8ed21095a310a693525137cfe756ce62d066e53f502a83dc550f65"},
    {file = "cffi-1.17.1-cp312-cp312-win_amd64.whl", hash = "sha256:51392eae71afec0d0c8fb1a53b204dbb3bcabcb3c9b807eedf3e1e6ccf2de903"},
    {file = "cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f3a2b4222ce6b60e2e8b337bb9596923045681d71e5a082783484d845390938e"},
    {file = "cffi-1.17.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:0984a4925a435b1da406122d4d7968dd861c1385afe3b45ba82b750f229811e2"},
    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d01b12eeeb4427d3110de311e1774046ad344f5b1a7403101878976ecd7a10f3"},
    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:706510fe141c86a69c8ddc029c7910003a17353970cff3b904ff0686a5927683"},
    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:de55b766c7aa2e2a3092c51e0483d700341182f08e67c63630d5b6f200bb28e5"},
    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c59d6e989d07460165cc5ad3c61f9fd8f1b4796eacbd81cee78957842b834af4"},
    {file = "cffi-1.17.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dd398dbc6773384a17fe0d3e7eeb8d1a21c2200473ee6806bb5e6a8e62bb73dd"},
    {file = "cffi-1.17.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:3edc8d958eb099c634dace3c7e16560ae474aa3803a5df240542b305d14e14ed"},
    {file = "cffi-1.17.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:72e72408cad3d5419375fc87d289076ee319835bdfa2caad331e377589aebba9"},
    {file = "cffi-1.17.1-cp313-cp313-win32.whl", hash = "sha256:e03eab0a8677fa80d646b5ddece1cbeaf556c313dcfac435ba11f107ba117b5d"},
    {file = "cffi-1.17.1-cp313-cp313-win_amd64.whl", hash = "sha256:f6a16c31041f09ead72d69f583767292f750d24913dadacf5756b966aacb3f1a"},
    {file = "cffi-1.17.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:636062ea65bd0195bc012fea9321aca499c0504409f413dc88af450b57ffd03b"},
    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c7eac2ef9b63c79431bc4b25f1cd649d7f061a28808cbc6c47b534bd789ef964"},
    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e221cf152cff04059d011ee126477f0d9588303eb57e88923578ace7baad17f9"},
    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:31000ec67d4221a71bd3f67df918b1f88f676f1c3b535a7eb473255fdc0b83fc"},
    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6f17be4345073b0a7b8ea599688f692ac3ef23ce28e5df79c04de519dbc4912c"},
    {file = "cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0e2b1fac190ae3ebfe37b979cc1ce69c81f4e4fe5746bb401dca63a9062cdaf1"},
    {file = "cffi-1.17.1-cp38-cp38-win32.whl", hash = "sha256:7596d6620d3fa590f677e9ee430df2958d2d6d6de2feeae5b20e82c00b76fbf8"},
    {file = "cffi-1.17.1-cp38-cp38-win_amd64.whl", hash = "sha256:78122be759c3f8a014ce010908ae03364d00a1f81ab5c7f4a7a5120607ea56e1"},
    {file = "cffi-1.17.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:b2ab587605f4ba0bf81dc0cb08a41bd1c0a5906bd59243d56bad7668a6fc6c16"},
    {file = "cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:28b16024becceed8c6dfbc75629e27788d8a3f9030691a1dbf9821a128b22c36"},
    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1d599671f396c4723d016dbddb72fe8e0397082b0a77a4fab8028923bec050e8"},
    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ca74b8dbe6e8e8263c0ffd60277de77dcee6c837a3d0881d8c1ead7268c9e576"},
    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f7f5baafcc48261359e14bcd6d9bff6d4b28d9103847c9e136694cb0501aef87"},
    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:98e3969bcff97cae1b2def8ba499ea3d6f31ddfdb7635374834cf89a1a08ecf0"},
    {file = "cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cdf5ce3acdfd1661132f2a9c19cac174758dc2352bfe37d98aa7512c6b7178b3"},
    {file = "cffi-1.17.1-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:9755e4345d1ec879e3849e62222a18c7174d65a6a92d5b346b1863912168b595"},
    {file = "cffi-1.17.1-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:f1e22e8c4419538cb197e4dd60acc919d7696e5ef98ee4da4e01d3f8cfa4cc5a"},
    {file = "cffi-1.17.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:c03e868a0b3bc35839ba98e74211ed2b05d2119be4e8a0f224fba9384f1fe02e"},
    {file = "cffi-1.17.1-cp39-cp39-win32.whl", hash = "sha256:e31ae45bc2e29f6b2abd0de1cc3b9d5205aa847cafaecb8af1476a609a2f6eb7"},
    {file = "cffi-1.17.1-cp39-cp39-win_amd64.whl", hash = "sha256:d016c76bdd850f3c626af19b0542c9677ba156e4ee4fccfdd7848803533ef662"},
    {file = "cffi-1.17.1.tar.gz", hash = "sha256:1c39c6016c32bc48dd54561950ebd6836e1670f2ae46128f67cf49e789c52824"},
]

[package.dependencies]
pycparser = "*"

[[package]]
name = "charset-normalizer"
version = "3.4.2"
description = "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet."
optional = false
python-versions = ">=3.7"
files = [
    {file = "charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:7c48ed483eb946e6c04ccbe02c6b4d1d48e51944b6db70f697e089c193404941"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b2d318c11350e10662026ad0eb71bb51c7812fc8590825304ae0bdd4ac283acd"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:9cbfacf36cb0ec2897ce0ebc5d08ca44213af24265bd56eca54bee7923c48fd6"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:18dd2e350387c87dabe711b86f83c9c78af772c748904d372ade190b5c7c9d4d"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8075c35cd58273fee266c58c0c9b670947c19df5fb98e7b66710e04ad4e9ff86"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:5bf4545e3b962767e5c06fe1738f951f77d27967cb2caa64c28be7c4563e162c"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:7a6ab32f7210554a96cd9e33abe3ddd86732beeafc7a28e9955cdf22ffadbab0"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:b33de11b92e9f75a2b545d6e9b6f37e398d86c3e9e9653c4864eb7e89c5773ef"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:8755483f3c00d6c9a77f490c17e6ab0c8729e39e6390328e42521ef175380ae6"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:68a328e5f55ec37c57f19ebb1fdc56a248db2e3e9ad769919a58672958e8f366"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:21b2899062867b0e1fde9b724f8aecb1af14f2778d69aacd1a5a1853a597a5db"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-win32.whl", hash = "sha256:e8082b26888e2f8b36a042a58307d5b917ef2b1cacab921ad3323ef91901c71a"},
    {file = "charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl", hash = "sha256:f69a27e45c43520f5487f27627059b64aaf160415589230992cec34c5e18a509"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:be1e352acbe3c78727a16a455126d9ff83ea2dfdcbc83148d2982305a04714c2"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:aa88ca0b1932e93f2d961bf3addbb2db902198dca337d88c89e1559e066e7645"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d524ba3f1581b35c03cb42beebab4a13e6cdad7b36246bd22541fa585a56cccd"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:28a1005facc94196e1fb3e82a3d442a9d9110b8434fc1ded7a24a2983c9888d8"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fdb20a30fe1175ecabed17cbf7812f7b804b8a315a25f24678bcdf120a90077f"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0f5d9ed7f254402c9e7d35d2f5972c9bbea9040e99cd2861bd77dc68263277c7"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:efd387a49825780ff861998cd959767800d54f8308936b21025326de4b5a42b9"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:f0aa37f3c979cf2546b73e8222bbfa3dc07a641585340179d768068e3455e544"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:e70e990b2137b29dc5564715de1e12701815dacc1d056308e2b17e9095372a82"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:0c8c57f84ccfc871a48a47321cfa49ae1df56cd1d965a09abe84066f6853b9c0"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:6b66f92b17849b85cad91259efc341dce9c1af48e2173bf38a85c6329f1033e5"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-win32.whl", hash = "sha256:daac4765328a919a805fa5e2720f3e94767abd632ae410a9062dff5412bae65a"},
    {file = "charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl", hash = "sha256:e53efc7c7cee4c1e70661e2e112ca46a575f90ed9ae3fef200f2a25e954f4b28"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:0c29de6a1a95f24b9a1aa7aefd27d2487263f00dfd55a77719b530788f75cff7"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cddf7bd982eaa998934a91f69d182aec997c6c468898efe6679af88283b498d3"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:fcbe676a55d7445b22c10967bceaaf0ee69407fbe0ece4d032b6eb8d4565982a"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d41c4d287cfc69060fa91cae9683eacffad989f1a10811995fa309df656ec214"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4e594135de17ab3866138f496755f302b72157d115086d100c3f19370839dd3a"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:cf713fe9a71ef6fd5adf7a79670135081cd4431c2943864757f0fa3a65b1fafd"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:a370b3e078e418187da8c3674eddb9d983ec09445c99a3a263c2011993522981"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:a955b438e62efdf7e0b7b52a64dc5c3396e2634baa62471768a64bc2adb73d5c"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:7222ffd5e4de8e57e03ce2cef95a4c43c98fcb72ad86909abdfc2c17d227fc1b"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:bee093bf902e1d8fc0ac143c88902c3dfc8941f7ea1d6a8dd2bcb786d33db03d"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:dedb8adb91d11846ee08bec4c8236c8549ac721c245678282dcb06b221aab59f"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-win32.whl", hash = "sha256:db4c7bf0e07fc3b7d89ac2a5880a6a8062056801b83ff56d8464b70f65482b6c"},
    {file = "charset_normalizer-3.4.2-cp312-cp312-win_amd64.whl", hash = "sha256:5a9979887252a82fefd3d3ed2a8e3b937a7a809f65dcb1e068b090e165bbe99e"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:926ca93accd5d36ccdabd803392ddc3e03e6d4cd1cf17deff3b989ab8e9dbcf0"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:eba9904b0f38a143592d9fc0e19e2df0fa2e41c3c3745554761c5f6447eedabf"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:3fddb7e2c84ac87ac3a947cb4e66d143ca5863ef48e4a5ecb83bd48619e4634e"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:98f862da73774290f251b9df8d11161b6cf25b599a66baf087c1ffe340e9bfd1"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6c9379d65defcab82d07b2a9dfbfc2e95bc8fe0ebb1b176a3190230a3ef0e07c"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e635b87f01ebc977342e2697d05b56632f5f879a4f15955dfe8cef2448b51691"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:1c95a1e2902a8b722868587c0e1184ad5c55631de5afc0eb96bc4b0d738092c0"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:ef8de666d6179b009dce7bcb2ad4c4a779f113f12caf8dc77f0162c29d20490b"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:32fc0341d72e0f73f80acb0a2c94216bd704f4f0bce10aedea38f30502b271ff"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:289200a18fa698949d2b39c671c2cc7a24d44096784e76614899a7ccf2574b7b"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:4a476b06fbcf359ad25d34a057b7219281286ae2477cc5ff5e3f70a246971148"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-win32.whl", hash = "sha256:aaeeb6a479c7667fbe1099af9617c83aaca22182d6cf8c53966491a0f1b7ffb7"},
    {file = "charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl", hash = "sha256:aa6af9e7d59f9c12b33ae4e9450619cf2488e2bbe9b44030905877f0b2324980"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1cad5f45b3146325bb38d6855642f6fd609c3f7cad4dbaf75549bf3b904d3184"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b2680962a4848b3c4f155dc2ee64505a9c57186d0d56b43123b17ca3de18f0fa"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:36b31da18b8890a76ec181c3cf44326bf2c48e36d393ca1b72b3f484113ea344"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f4074c5a429281bf056ddd4c5d3b740ebca4d43ffffe2ef4bf4d2d05114299da"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c9e36a97bee9b86ef9a1cf7bb96747eb7a15c2f22bdb5b516434b00f2a599f02"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-musllinux_1_2_aarch64.whl", hash = "sha256:1b1bde144d98e446b056ef98e59c256e9294f6b74d7af6846bf5ffdafd687a7d"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-musllinux_1_2_i686.whl", hash = "sha256:915f3849a011c1f593ab99092f3cecfcb4d65d8feb4a64cf1bf2d22074dc0ec4"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-musllinux_1_2_ppc64le.whl", hash = "sha256:fb707f3e15060adf5b7ada797624a6c6e0138e2a26baa089df64c68ee98e040f"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-musllinux_1_2_s390x.whl", hash = "sha256:25a23ea5c7edc53e0f29bae2c44fcb5a1aa10591aae107f2a2b2583a9c5cbc64"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-musllinux_1_2_x86_64.whl", hash = "sha256:770cab594ecf99ae64c236bc9ee3439c3f46be49796e265ce0cc8bc17b10294f"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-win32.whl", hash = "sha256:6a0289e4589e8bdfef02a80478f1dfcb14f0ab696b5a00e1f4b8a14a307a3c58"},
    {file = "charset_normalizer-3.4.2-cp37-cp37m-win_amd64.whl", hash = "sha256:6fc1f5b51fa4cecaa18f2bd7a003f3dd039dd615cd69a2afd6d3b19aed6775f2"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:76af085e67e56c8816c3ccf256ebd136def2ed9654525348cfa744b6802b69eb"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e45ba65510e2647721e35323d6ef54c7974959f6081b58d4ef5d87c60c84919a"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:046595208aae0120559a67693ecc65dd75d46f7bf687f159127046628178dc45"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:75d10d37a47afee94919c4fab4c22b9bc2a8bf7d4f46f87363bcf0573f3ff4f5"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6333b3aa5a12c26b2a4d4e7335a28f1475e0e5e17d69d55141ee3cab736f66d1"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e8323a9b031aa0393768b87f04b4164a40037fb2a3c11ac06a03ffecd3618027"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:24498ba8ed6c2e0b56d4acbf83f2d989720a93b41d712ebd4f4979660db4417b"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:844da2b5728b5ce0e32d863af26f32b5ce61bc4273a9c720a9f3aa9df73b1455"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-musllinux_1_2_ppc64le.whl", hash = "sha256:65c981bdbd3f57670af8b59777cbfae75364b483fa8a9f420f08094531d54a01"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-musllinux_1_2_s390x.whl", hash = "sha256:3c21d4fca343c805a52c0c78edc01e3477f6dd1ad7c47653241cf2a206d4fc58"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:dc7039885fa1baf9be153a0626e337aa7ec8bf96b0128605fb0d77788ddc1681"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-win32.whl", hash = "sha256:8272b73e1c5603666618805fe821edba66892e2870058c94c53147602eab29c7"},
    {file = "charset_normalizer-3.4.2-cp38-cp38-win_amd64.whl", hash = "sha256:70f7172939fdf8790425ba31915bfbe8335030f05b9913d7ae00a87d4395620a"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:005fa3432484527f9732ebd315da8da8001593e2cf46a3d817669f062c3d9ed4"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e92fca20c46e9f5e1bb485887d074918b13543b1c2a1185e69bb8d17ab6236a7"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:50bf98d5e563b83cc29471fa114366e6806bc06bc7a25fd59641e41445327836"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:721c76e84fe669be19c5791da68232ca2e05ba5185575086e384352e2c309597"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:82d8fd25b7f4675d0c47cf95b594d4e7b158aca33b76aa63d07186e13c0e0ab7"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b3daeac64d5b371dea99714f08ffc2c208522ec6b06fbc7866a450dd446f5c0f"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:dccab8d5fa1ef9bfba0590ecf4d46df048d18ffe3eec01eeb73a42e0d9e7a8ba"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:aaf27faa992bfee0264dc1f03f4c75e9fcdda66a519db6b957a3f826e285cf12"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-musllinux_1_2_ppc64le.whl", hash = "sha256:eb30abc20df9ab0814b5a2524f23d75dcf83cde762c161917a2b4b7b55b1e518"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-musllinux_1_2_s390x.whl", hash = "sha256:c72fbbe68c6f32f251bdc08b8611c7b3060612236e960ef848e0a517ddbe76c5"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:982bb1e8b4ffda883b3d0a521e23abcd6fd17418f6d2c4118d257a10199c0ce3"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-win32.whl", hash = "sha256:43e0933a0eff183ee85833f341ec567c0980dae57c464d8a508e1b2ceb336471"},
    {file = "charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl", hash = "sha256:d11b54acf878eef558599658b0ffca78138c8c3655cf4f3a4a673c437e67732e"},
    {file = "charset_normalizer-3.4.2-py3-none-any.whl", hash = "sha256:7f56930ab0abd1c45cd15be65cc741c28b1c9a34876ce8c17a2fa107810c0af0"},
    {file = "charset_normalizer-3.4.2.tar.gz", hash = "sha256:5baececa9ecba31eff645232d59845c07aa030f0c81ee70184a90d35099a0e63"},
]

[[package]]
name = "click"
version = "8.2.1"
description = "Composable command line interface toolkit"
optional = false
python-versions = ">=3.10"
files = [
    {file = "click-8.2.1-py3-none-any.whl", hash = "sha256:61a3265b914e850b85317d0b3109c7f8cd35a670f963866005d6ef1d5175a12b"},
    {file = "click-8.2.1.tar.gz", hash = "sha256:27c491cc05d968d271d5a1db13e3b5a184636d9d930f148c50b038f0d0646202"},
]

[package.dependencies]
colorama = {version = "*", markers = "platform_system == \"Windows\""}

[[package]]
name = "colorama"
version = "0.4.6"
description = "Cross-platform colored terminal text."
optional = false
python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7"
files = [
    {file = "colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6"},
    {file = "colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44"},
]

[[package]]
name = "cryptography"
version = "45.0.2"
description = "cryptography is a package which provides cryptographic recipes and primitives to Python developers."
optional = false
python-versions = "!=3.9.0,!=3.9.1,>=3.7"
files = [
    {file = "cryptography-45.0.2-cp311-abi3-macosx_10_9_universal2.whl", hash = "sha256:61a8b1bbddd9332917485b2453d1de49f142e6334ce1d97b7916d5a85d179c84"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4cc31c66411e14dd70e2f384a9204a859dc25b05e1f303df0f5326691061b839"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:463096533acd5097f8751115bc600b0b64620c4aafcac10c6d0041e6e68f88fe"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:cdafb86eb673c3211accffbffdb3cdffa3aaafacd14819e0898d23696d18e4d3"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:05c2385b1f5c89a17df19900cfb1345115a77168f5ed44bdf6fd3de1ce5cc65b"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:e9e4bdcd70216b08801e267c0b563316b787f957a46e215249921f99288456f9"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:b2de529027579e43b6dc1f805f467b102fb7d13c1e54c334f1403ee2b37d0059"},
    {file = "cryptography-45.0.2-cp311-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:10d68763892a7b19c22508ab57799c4423c7c8cd61d7eee4c5a6a55a46511949"},
    {file = "cryptography-45.0.2-cp311-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:d2a90ce2f0f5b695e4785ac07c19a58244092f3c85d57db6d8eb1a2b26d2aad6"},
    {file = "cryptography-45.0.2-cp311-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:59c0c8f043dd376bbd9d4f636223836aed50431af4c5a467ed9bf61520294627"},
    {file = "cryptography-45.0.2-cp311-abi3-win32.whl", hash = "sha256:80303ee6a02ef38c4253160446cbeb5c400c07e01d4ddbd4ff722a89b736d95a"},
    {file = "cryptography-45.0.2-cp311-abi3-win_amd64.whl", hash = "sha256:7429936146063bd1b2cfc54f0e04016b90ee9b1c908a7bed0800049cbace70eb"},
    {file = "cryptography-45.0.2-cp37-abi3-macosx_10_9_universal2.whl", hash = "sha256:e86c8d54cd19a13e9081898b3c24351683fd39d726ecf8e774aaa9d8d96f5f3a"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e328357b6bbf79928363dbf13f4635b7aac0306afb7e5ad24d21d0c5761c3253"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:49af56491473231159c98c2c26f1a8f3799a60e5cf0e872d00745b858ddac9d2"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:f169469d04a23282de9d0be349499cb6683b6ff1b68901210faacac9b0c24b7d"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:9cfd1399064b13043082c660ddd97a0358e41c8b0dc7b77c1243e013d305c344"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:18f8084b7ca3ce1b8d38bdfe33c48116edf9a08b4d056ef4a96dceaa36d8d965"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:2cb03a944a1a412724d15a7c051d50e63a868031f26b6a312f2016965b661942"},
    {file = "cryptography-45.0.2-cp37-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:a9727a21957d3327cf6b7eb5ffc9e4b663909a25fea158e3fcbc49d4cdd7881b"},
    {file = "cryptography-45.0.2-cp37-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:ddb8d01aa900b741d6b7cc585a97aff787175f160ab975e21f880e89d810781a"},
    {file = "cryptography-45.0.2-cp37-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:c0c000c1a09f069632d8a9eb3b610ac029fcc682f1d69b758e625d6ee713f4ed"},
    {file = "cryptography-45.0.2-cp37-abi3-win32.whl", hash = "sha256:08281de408e7eb71ba3cd5098709a356bfdf65eebd7ee7633c3610f0aa80d79b"},
    {file = "cryptography-45.0.2-cp37-abi3-win_amd64.whl", hash = "sha256:48caa55c528617fa6db1a9c3bf2e37ccb31b73e098ac2b71408d1f2db551dde4"},
    {file = "cryptography-45.0.2-pp310-pypy310_pp73-macosx_10_9_x86_64.whl", hash = "sha256:a8ec324711596fbf21837d3a5db543937dd84597d364769b46e0102250023f77"},
    {file = "cryptography-45.0.2-pp310-pypy310_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:965611880c3fa8e504b7458484c0697e00ae6e937279cd6734fdaa2bc954dc49"},
    {file = "cryptography-45.0.2-pp310-pypy310_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:d891942592789fa0ab71b502550bbadb12f540d7413d7d7c4cef4b02af0f5bc6"},
    {file = "cryptography-45.0.2-pp310-pypy310_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:b19f4b28dd2ef2e6d600307fee656c00825a2980c4356a7080bd758d633c3a6f"},
    {file = "cryptography-45.0.2-pp310-pypy310_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:7c73968fbb7698a4c5d6160859db560d3aac160edde89c751edd5a8bc6560c88"},
    {file = "cryptography-45.0.2-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:501de1296b2041dccf2115e3c7d4947430585601b251b140970ce255c5cfb985"},
    {file = "cryptography-45.0.2-pp311-pypy311_pp73-macosx_10_9_x86_64.whl", hash = "sha256:1655d3a76e3dedb683c982a6c3a2cbfae2d08f47a48ec5a3d58db52b3d29ea6f"},
    {file = "cryptography-45.0.2-pp311-pypy311_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:dc7693573f16535428183de8fd27f0ca1ca37a51baa0b41dc5ed7b3d68fe80e2"},
    {file = "cryptography-45.0.2-pp311-pypy311_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:614bca7c6ed0d8ad1dce683a6289afae1f880675b4090878a0136c3da16bc693"},
    {file = "cryptography-45.0.2-pp311-pypy311_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:4142e20c29224cec63e9e32eb1e6014fb285fe39b7be66b3564ca978a3a8afe9"},
    {file = "cryptography-45.0.2-pp311-pypy311_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:9a900036b42f7324df7c7ad9569eb92ba0b613cf699160dd9c2154b24fd02f8e"},
    {file = "cryptography-45.0.2-pp311-pypy311_pp73-win_amd64.whl", hash = "sha256:057723b79752a142efbc609e90b0dff27b0361ccbee3bd48312d70f5cdf53b78"},
    {file = "cryptography-45.0.2.tar.gz", hash = "sha256:d784d57b958ffd07e9e226d17272f9af0c41572557604ca7554214def32c26bf"},
]

[package.dependencies]
cffi = {version = ">=1.14", markers = "platform_python_implementation != \"PyPy\""}

[package.extras]
docs = ["sphinx (>=5.3.0)", "sphinx-inline-tabs", "sphinx-rtd-theme (>=3.0.0)"]
docstest = ["pyenchant (>=3)", "readme-renderer (>=30.0)", "sphinxcontrib-spelling (>=7.3.1)"]
nox = ["nox (>=2024.4.15)", "nox[uv] (>=2024.3.2)"]
pep8test = ["check-sdist", "click (>=8.0.1)", "mypy (>=1.4)", "ruff (>=0.3.6)"]
sdist = ["build (>=1.0.0)"]
ssh = ["bcrypt (>=3.1.5)"]
test = ["certifi (>=2024)", "cryptography-vectors (==45.0.2)", "pretend (>=0.7)", "pytest (>=7.4.0)", "pytest-benchmark (>=4.0)", "pytest-cov (>=2.10.1)", "pytest-xdist (>=3.5.0)"]
test-randomorder = ["pytest-randomly"]

[[package]]
name = "dnspython"
version = "2.7.0"
description = "DNS toolkit"
optional = false
python-versions = ">=3.9"
files = [
    {file = "dnspython-2.7.0-py3-none-any.whl", hash = "sha256:b4c34b7d10b51bcc3a5071e7b8dee77939f1e878477eeecc965e9835f63c6c86"},
    {file = "dnspython-2.7.0.tar.gz", hash = "sha256:ce9c432eda0dc91cf618a5cedf1a4e142651196bbcd2c80e89ed5a907e5cfaf1"},
]

[package.extras]
dev = ["black (>=23.1.0)", "coverage (>=7.0)", "flake8 (>=7)", "hypercorn (>=0.16.0)", "mypy (>=1.8)", "pylint (>=3)", "pytest (>=7.4)", "pytest-cov (>=4.1.0)", "quart-trio (>=0.11.0)", "sphinx (>=7.2.0)", "sphinx-rtd-theme (>=2.0.0)", "twine (>=4.0.0)", "wheel (>=0.42.0)"]
dnssec = ["cryptography (>=43)"]
doh = ["h2 (>=4.1.0)", "httpcore (>=1.0.0)", "httpx (>=0.26.0)"]
doq = ["aioquic (>=1.0.0)"]
idna = ["idna (>=3.7)"]
trio = ["trio (>=0.23)"]
wmi = ["wmi (>=1.5.1)"]

[[package]]
name = "ecdsa"
version = "0.19.1"
description = "ECDSA cryptographic signature library (pure python)"
optional = false
python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,>=2.6"
files = [
    {file = "ecdsa-0.19.1-py2.py3-none-any.whl", hash = "sha256:30638e27cf77b7e15c4c4cc1973720149e1033827cfd00661ca5c8cc0cdb24c3"},
    {file = "ecdsa-0.19.1.tar.gz", hash = "sha256:478cba7b62555866fcb3bb3fe985e06decbdb68ef55713c4e5ab98c57d508e61"},
]

[package.dependencies]
six = ">=1.9.0"

[package.extras]
gmpy = ["gmpy"]
gmpy2 = ["gmpy2"]

[[package]]
name = "email-validator"
version = "2.2.0"
description = "A robust email address syntax and deliverability validation library."
optional = false
python-versions = ">=3.8"
files = [
    {file = "email_validator-2.2.0-py3-none-any.whl", hash = "sha256:561977c2d73ce3611850a06fa56b414621e0c8faa9d66f2611407d87465da631"},
    {file = "email_validator-2.2.0.tar.gz", hash = "sha256:cb690f344c617a714f22e66ae771445a1ceb46821152df8e165c5f9a364582b7"},
]

[package.dependencies]
dnspython = ">=2.0.0"
idna = ">=2.0.0"

[[package]]
name = "faker"
version = "37.3.0"
description = "Faker is a Python package that generates fake data for you."
optional = false
python-versions = ">=3.9"
files = [
    {file = "faker-37.3.0-py3-none-any.whl", hash = "sha256:48c94daa16a432f2d2bc803c7ff602509699fca228d13e97e379cd860a7e216e"},
    {file = "faker-37.3.0.tar.gz", hash = "sha256:77b79e7a2228d57175133af0bbcdd26dc623df81db390ee52f5104d46c010f2f"},
]

[package.dependencies]
tzdata = "*"

[[package]]
name = "fastapi"
version = "0.115.12"
description = "FastAPI framework, high performance, easy to learn, fast to code, ready for production"
optional = false
python-versions = ">=3.8"
files = [
    {file = "fastapi-0.115.12-py3-none-any.whl", hash = "sha256:e94613d6c05e27be7ffebdd6ea5f388112e5e430c8f7d6494a9d1d88d43e814d"},
    {file = "fastapi-0.115.12.tar.gz", hash = "sha256:1e2c2a2646905f9e83d32f04a3f86aff4a286669c6c950ca95b5fd68c2602681"},
]

[package.dependencies]
pydantic = ">=1.7.4,<1.8 || >1.8,<1.8.1 || >1.8.1,<2.0.0 || >2.0.0,<2.0.1 || >2.0.1,<2.1.0 || >2.1.0,<3.0.0"
starlette = ">=0.40.0,<0.47.0"
typing-extensions = ">=4.8.0"

[package.extras]
all = ["email-validator (>=2.0.0)", "fastapi-cli[standard] (>=0.0.5)", "httpx (>=0.23.0)", "itsdangerous (>=1.1.0)", "jinja2 (>=3.1.5)", "orjson (>=3.2.1)", "pydantic-extra-types (>=2.0.0)", "pydantic-settings (>=2.0.0)", "python-multipart (>=0.0.18)", "pyyaml (>=5.3.1)", "ujson (>=4.0.1,!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0)", "uvicorn[standard] (>=0.12.0)"]
standard = ["email-validator (>=2.0.0)", "fastapi-cli[standard] (>=0.0.5)", "httpx (>=0.23.0)", "jinja2 (>=3.1.5)", "python-multipart (>=0.0.18)", "uvicorn[standard] (>=0.12.0)"]

[[package]]
name = "google-ai-generativelanguage"
version = "0.6.15"
description = "Google Ai Generativelanguage API client library"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_ai_generativelanguage-0.6.15-py3-none-any.whl", hash = "sha256:5a03ef86377aa184ffef3662ca28f19eeee158733e45d7947982eb953c6ebb6c"},
    {file = "google_ai_generativelanguage-0.6.15.tar.gz", hash = "sha256:8f6d9dc4c12b065fe2d0289026171acea5183ebf2d0b11cefe12f3821e159ec3"},
]

[package.dependencies]
google-api-core = {version = ">=1.34.1,<2.0.dev0 || >=2.11.dev0,<3.0.0dev", extras = ["grpc"]}
google-auth = ">=2.14.1,<2.24.0 || >2.24.0,<2.25.0 || >2.25.0,<3.0.0dev"
proto-plus = [
    {version = ">=1.25.0,<2.0.0dev", markers = "python_version >= \"3.13\""},
    {version = ">=1.22.3,<2.0.0dev", markers = "python_version < \"3.13\""},
]
protobuf = ">=3.20.2,<4.21.0 || >4.21.0,<4.21.1 || >4.21.1,<4.21.2 || >4.21.2,<4.21.3 || >4.21.3,<4.21.4 || >4.21.4,<4.21.5 || >4.21.5,<6.0.0dev"

[[package]]
name = "google-api-core"
version = "2.24.2"
description = "Google API client core library"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_api_core-2.24.2-py3-none-any.whl", hash = "sha256:810a63ac95f3c441b7c0e43d344e372887f62ce9071ba972eacf32672e072de9"},
    {file = "google_api_core-2.24.2.tar.gz", hash = "sha256:81718493daf06d96d6bc76a91c23874dbf2fac0adbbf542831b805ee6e974696"},
]

[package.dependencies]
google-auth = ">=2.14.1,<3.0.0"
googleapis-common-protos = ">=1.56.2,<2.0.0"
grpcio = {version = ">=1.49.1,<2.0dev", optional = true, markers = "python_version >= \"3.11\" and extra == \"grpc\""}
grpcio-status = {version = ">=1.49.1,<2.0.dev0", optional = true, markers = "python_version >= \"3.11\" and extra == \"grpc\""}
proto-plus = [
    {version = ">=1.25.0,<2.0.0", markers = "python_version >= \"3.13\""},
    {version = ">=1.22.3,<2.0.0", markers = "python_version < \"3.13\""},
]
protobuf = ">=3.19.5,<3.20.0 || >3.20.0,<3.20.1 || >3.20.1,<4.21.0 || >4.21.0,<4.21.1 || >4.21.1,<4.21.2 || >4.21.2,<4.21.3 || >4.21.3,<4.21.4 || >4.21.4,<4.21.5 || >4.21.5,<7.0.0"
requests = ">=2.18.0,<3.0.0"

[package.extras]
async-rest = ["google-auth[aiohttp] (>=2.35.0,<3.0.dev0)"]
grpc = ["grpcio (>=1.33.2,<2.0dev)", "grpcio (>=1.49.1,<2.0dev)", "grpcio-status (>=1.33.2,<2.0.dev0)", "grpcio-status (>=1.49.1,<2.0.dev0)"]
grpcgcp = ["grpcio-gcp (>=0.2.2,<1.0.dev0)"]
grpcio-gcp = ["grpcio-gcp (>=0.2.2,<1.0.dev0)"]

[[package]]
name = "google-api-python-client"
version = "2.170.0"
description = "Google API Client Library for Python"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_api_python_client-2.170.0-py3-none-any.whl", hash = "sha256:7bf518a0527ad23322f070fa69f4f24053170d5c766821dc970ff0571ec22748"},
    {file = "google_api_python_client-2.170.0.tar.gz", hash = "sha256:75f3a1856f11418ea3723214e0abc59d9b217fd7ed43dcf743aab7f06ab9e2b1"},
]

[package.dependencies]
google-api-core = ">=1.31.5,<2.0.dev0 || >2.3.0,<3.0.0"
google-auth = ">=1.32.0,<2.24.0 || >2.24.0,<2.25.0 || >2.25.0,<3.0.0"
google-auth-httplib2 = ">=0.2.0,<1.0.0"
httplib2 = ">=0.19.0,<1.0.0"
uritemplate = ">=3.0.1,<5"

[[package]]
name = "google-auth"
version = "2.40.2"
description = "Google Authentication Library"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_auth-2.40.2-py2.py3-none-any.whl", hash = "sha256:f7e568d42eedfded58734f6a60c58321896a621f7c116c411550a4b4a13da90b"},
    {file = "google_auth-2.40.2.tar.gz", hash = "sha256:a33cde547a2134273226fa4b853883559947ebe9207521f7afc707efbf690f58"},
]

[package.dependencies]
cachetools = ">=2.0.0,<6.0"
pyasn1-modules = ">=0.2.1"
rsa = ">=3.1.4,<5"

[package.extras]
aiohttp = ["aiohttp (>=3.6.2,<4.0.0)", "requests (>=2.20.0,<3.0.0)"]
enterprise-cert = ["cryptography", "pyopenssl"]
pyjwt = ["cryptography (<39.0.0)", "cryptography (>=38.0.3)", "pyjwt (>=2.0)"]
pyopenssl = ["cryptography (<39.0.0)", "cryptography (>=38.0.3)", "pyopenssl (>=20.0.0)"]
reauth = ["pyu2f (>=0.1.5)"]
requests = ["requests (>=2.20.0,<3.0.0)"]
testing = ["aiohttp (<3.10.0)", "aiohttp (>=3.6.2,<4.0.0)", "aioresponses", "cryptography (<39.0.0)", "cryptography (>=38.0.3)", "flask", "freezegun", "grpcio", "mock", "oauth2client", "packaging", "pyjwt (>=2.0)", "pyopenssl (<24.3.0)", "pyopenssl (>=20.0.0)", "pytest", "pytest-asyncio", "pytest-cov", "pytest-localserver", "pyu2f (>=0.1.5)", "requests (>=2.20.0,<3.0.0)", "responses", "urllib3"]
urllib3 = ["packaging", "urllib3"]

[[package]]
name = "google-auth-httplib2"
version = "0.2.0"
description = "Google Authentication Library: httplib2 transport"
optional = false
python-versions = "*"
files = [
    {file = "google-auth-httplib2-0.2.0.tar.gz", hash = "sha256:38aa7badf48f974f1eb9861794e9c0cb2a0511a4ec0679b1f886d108f5640e05"},
    {file = "google_auth_httplib2-0.2.0-py2.py3-none-any.whl", hash = "sha256:b65a0a2123300dd71281a7bf6e64d65a0759287df52729bdd1ae2e47dc311a3d"},
]

[package.dependencies]
google-auth = "*"
httplib2 = ">=0.19.0"

[[package]]
name = "google-cloud-core"
version = "2.4.3"
description = "Google Cloud API client core library"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_cloud_core-2.4.3-py2.py3-none-any.whl", hash = "sha256:5130f9f4c14b4fafdff75c79448f9495cfade0d8775facf1b09c3bf67e027f6e"},
    {file = "google_cloud_core-2.4.3.tar.gz", hash = "sha256:1fab62d7102844b278fe6dead3af32408b1df3eb06f5c7e8634cbd40edc4da53"},
]

[package.dependencies]
google-api-core = ">=1.31.6,<2.0.dev0 || >2.3.0,<3.0.0dev"
google-auth = ">=1.25.0,<3.0dev"

[package.extras]
grpc = ["grpcio (>=1.38.0,<2.0dev)", "grpcio-status (>=1.38.0,<2.0.dev0)"]

[[package]]
name = "google-cloud-storage"
version = "3.1.0"
description = "Google Cloud Storage API client library"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_cloud_storage-3.1.0-py2.py3-none-any.whl", hash = "sha256:eaf36966b68660a9633f03b067e4a10ce09f1377cae3ff9f2c699f69a81c66c6"},
    {file = "google_cloud_storage-3.1.0.tar.gz", hash = "sha256:944273179897c7c8a07ee15f2e6466a02da0c7c4b9ecceac2a26017cb2972049"},
]

[package.dependencies]
google-api-core = ">=2.15.0,<3.0.0dev"
google-auth = ">=2.26.1,<3.0dev"
google-cloud-core = ">=2.4.2,<3.0dev"
google-crc32c = ">=1.0,<2.0dev"
google-resumable-media = ">=2.7.2"
requests = ">=2.18.0,<3.0.0dev"

[package.extras]
protobuf = ["protobuf (<6.0.0dev)"]
tracing = ["opentelemetry-api (>=1.1.0)"]

[[package]]
name = "google-crc32c"
version = "1.7.1"
description = "A python wrapper of the C library 'Google CRC32C'"
optional = false
python-versions = ">=3.9"
files = [
    {file = "google_crc32c-1.7.1-cp310-cp310-macosx_12_0_arm64.whl", hash = "sha256:b07d48faf8292b4db7c3d64ab86f950c2e94e93a11fd47271c28ba458e4a0d76"},
    {file = "google_crc32c-1.7.1-cp310-cp310-macosx_12_0_x86_64.whl", hash = "sha256:7cc81b3a2fbd932a4313eb53cc7d9dde424088ca3a0337160f35d91826880c1d"},
    {file = "google_crc32c-1.7.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:1c67ca0a1f5b56162951a9dae987988679a7db682d6f97ce0f6381ebf0fbea4c"},
    {file = "google_crc32c-1.7.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fc5319db92daa516b653600794d5b9f9439a9a121f3e162f94b0e1891c7933cb"},
    {file = "google_crc32c-1.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dcdf5a64adb747610140572ed18d011896e3b9ae5195f2514b7ff678c80f1603"},
    {file = "google_crc32c-1.7.1-cp310-cp310-win_amd64.whl", hash = "sha256:754561c6c66e89d55754106739e22fdaa93fafa8da7221b29c8b8e8270c6ec8a"},
    {file = "google_crc32c-1.7.1-cp311-cp311-macosx_12_0_arm64.whl", hash = "sha256:6fbab4b935989e2c3610371963ba1b86afb09537fd0c633049be82afe153ac06"},
    {file = "google_crc32c-1.7.1-cp311-cp311-macosx_12_0_x86_64.whl", hash = "sha256:ed66cbe1ed9cbaaad9392b5259b3eba4a9e565420d734e6238813c428c3336c9"},
    {file = "google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ee6547b657621b6cbed3562ea7826c3e11cab01cd33b74e1f677690652883e77"},
    {file = "google_crc32c-1.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d68e17bad8f7dd9a49181a1f5a8f4b251c6dbc8cc96fb79f1d321dfd57d66f53"},
    {file = "google_crc32c-1.7.1-cp311-cp311-win_amd64.whl", hash = "sha256:6335de12921f06e1f774d0dd1fbea6bf610abe0887a1638f64d694013138be5d"},
    {file = "google_crc32c-1.7.1-cp312-cp312-macosx_12_0_arm64.whl", hash = "sha256:2d73a68a653c57281401871dd4aeebbb6af3191dcac751a76ce430df4d403194"},
    {file = "google_crc32c-1.7.1-cp312-cp312-macosx_12_0_x86_64.whl", hash = "sha256:22beacf83baaf59f9d3ab2bbb4db0fb018da8e5aebdce07ef9f09fce8220285e"},
    {file = "google_crc32c-1.7.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:19eafa0e4af11b0a4eb3974483d55d2d77ad1911e6cf6f832e1574f6781fd337"},
    {file = "google_crc32c-1.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b6d86616faaea68101195c6bdc40c494e4d76f41e07a37ffdef270879c15fb65"},
    {file = "google_crc32c-1.7.1-cp312-cp312-win_amd64.whl", hash = "sha256:b7491bdc0c7564fcf48c0179d2048ab2f7c7ba36b84ccd3a3e1c3f7a72d3bba6"},
    {file = "google_crc32c-1.7.1-cp313-cp313-macosx_12_0_arm64.whl", hash = "sha256:df8b38bdaf1629d62d51be8bdd04888f37c451564c2042d36e5812da9eff3c35"},
    {file = "google_crc32c-1.7.1-cp313-cp313-macosx_12_0_x86_64.whl", hash = "sha256:e42e20a83a29aa2709a0cf271c7f8aefaa23b7ab52e53b322585297bb94d4638"},
    {file = "google_crc32c-1.7.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:905a385140bf492ac300026717af339790921f411c0dfd9aa5a9e69a08ed32eb"},
    {file = "google_crc32c-1.7.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6b211ddaf20f7ebeec5c333448582c224a7c90a9d98826fbab82c0ddc11348e6"},
    {file = "google_crc32c-1.7.1-cp313-cp313-win_amd64.whl", hash = "sha256:0f99eaa09a9a7e642a61e06742856eec8b19fc0037832e03f941fe7cf0c8e4db"},
    {file = "google_crc32c-1.7.1-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:32d1da0d74ec5634a05f53ef7df18fc646666a25efaaca9fc7dcfd4caf1d98c3"},
    {file = "google_crc32c-1.7.1-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e10554d4abc5238823112c2ad7e4560f96c7bf3820b202660373d769d9e6e4c9"},
    {file = "google_crc32c-1.7.1-cp39-cp39-macosx_12_0_arm64.whl", hash = "sha256:9fc196f0b8d8bd2789352c6a522db03f89e83a0ed6b64315923c396d7a932315"},
    {file = "google_crc32c-1.7.1-cp39-cp39-macosx_12_0_x86_64.whl", hash = "sha256:bb5e35dcd8552f76eed9461a23de1030920a3c953c1982f324be8f97946e7127"},
    {file = "google_crc32c-1.7.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:f2226b6a8da04f1d9e61d3e357f2460b9551c5e6950071437e122c958a18ae14"},
    {file = "google_crc32c-1.7.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f2b3522222746fff0e04a9bd0a23ea003ba3cccc8cf21385c564deb1f223242"},
    {file = "google_crc32c-1.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3bda0fcb632d390e3ea8b6b07bf6b4f4a66c9d02dcd6fbf7ba00a197c143f582"},
    {file = "google_crc32c-1.7.1-cp39-cp39-win_amd64.whl", hash = "sha256:713121af19f1a617054c41f952294764e0c5443d5a5d9034b2cd60f5dd7e0349"},
    {file = "google_crc32c-1.7.1-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a8e9afc74168b0b2232fb32dd202c93e46b7d5e4bf03e66ba5dc273bb3559589"},
    {file = "google_crc32c-1.7.1-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fa8136cc14dd27f34a3221c0f16fd42d8a40e4778273e61a3c19aedaa44daf6b"},
    {file = "google_crc32c-1.7.1-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:85fef7fae11494e747c9fd1359a527e5970fc9603c90764843caabd3a16a0a48"},
    {file = "google_crc32c-1.7.1-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6efb97eb4369d52593ad6f75e7e10d053cf00c48983f7a973105bc70b0ac4d82"},
    {file = "google_crc32c-1.7.1.tar.gz", hash = "sha256:2bff2305f98846f3e825dbeec9ee406f89da7962accdb29356e4eadc251bd472"},
]

[package.extras]
testing = ["pytest"]

[[package]]
name = "google-generativeai"
version = "0.8.5"
description = "Google Generative AI High level API client library and tools."
optional = false
python-versions = ">=3.9"
files = [
    {file = "google_generativeai-0.8.5-py3-none-any.whl", hash = "sha256:22b420817fb263f8ed520b33285f45976d5b21e904da32b80d4fd20c055123a2"},
]

[package.dependencies]
google-ai-generativelanguage = "0.6.15"
google-api-core = "*"
google-api-python-client = "*"
google-auth = ">=2.15.0"
protobuf = "*"
pydantic = "*"
tqdm = "*"
typing-extensions = "*"

[package.extras]
dev = ["Pillow", "absl-py", "black", "ipython", "nose2", "pandas", "pytype", "pyyaml"]

[[package]]
name = "google-resumable-media"
version = "2.7.2"
description = "Utilities for Google Media Downloads and Resumable Uploads"
optional = false
python-versions = ">=3.7"
files = [
    {file = "google_resumable_media-2.7.2-py2.py3-none-any.whl", hash = "sha256:3ce7551e9fe6d99e9a126101d2536612bb73486721951e9562fee0f90c6ababa"},
    {file = "google_resumable_media-2.7.2.tar.gz", hash = "sha256:5280aed4629f2b60b847b0d42f9857fd4935c11af266744df33d8074cae92fe0"},
]

[package.dependencies]
google-crc32c = ">=1.0,<2.0dev"

[package.extras]
aiohttp = ["aiohttp (>=3.6.2,<4.0.0dev)", "google-auth (>=1.22.0,<2.0dev)"]
requests = ["requests (>=2.18.0,<3.0.0dev)"]

[[package]]
name = "googleapis-common-protos"
version = "1.70.0"
description = "Common protobufs used in Google APIs"
optional = false
python-versions = ">=3.7"
files = [
    {file = "googleapis_common_protos-1.70.0-py3-none-any.whl", hash = "sha256:b8bfcca8c25a2bb253e0e0b0adaf8c00773e5e6af6fd92397576680b807e0fd8"},
    {file = "googleapis_common_protos-1.70.0.tar.gz", hash = "sha256:0e1b44e0ea153e6594f9f394fef15193a68aaaea2d843f83e2742717ca753257"},
]

[package.dependencies]
protobuf = ">=3.20.2,<4.21.1 || >4.21.1,<4.21.2 || >4.21.2,<4.21.3 || >4.21.3,<4.21.4 || >4.21.4,<4.21.5 || >4.21.5,<7.0.0"

[package.extras]
grpc = ["grpcio (>=1.44.0,<2.0.0)"]

[[package]]
name = "greenlet"
version = "3.2.2"
description = "Lightweight in-process concurrent programming"
optional = false
python-versions = ">=3.9"
files = [
    {file = "greenlet-3.2.2-cp310-cp310-macosx_11_0_universal2.whl", hash = "sha256:c49e9f7c6f625507ed83a7485366b46cbe325717c60837f7244fc99ba16ba9d6"},
    {file = "greenlet-3.2.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c3cc1a3ed00ecfea8932477f729a9f616ad7347a5e55d50929efa50a86cb7be7"},
    {file = "greenlet-3.2.2-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:7c9896249fbef2c615853b890ee854f22c671560226c9221cfd27c995db97e5c"},
    {file = "greenlet-3.2.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7409796591d879425997a518138889d8d17e63ada7c99edc0d7a1c22007d4907"},
    {file = "greenlet-3.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7791dcb496ec53d60c7f1c78eaa156c21f402dda38542a00afc3e20cae0f480f"},
    {file = "greenlet-3.2.2-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:d8009ae46259e31bc73dc183e402f548e980c96f33a6ef58cc2e7865db012e13"},
    {file = "greenlet-3.2.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:fd9fb7c941280e2c837b603850efc93c999ae58aae2b40765ed682a6907ebbc5"},
    {file = "greenlet-3.2.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:00cd814b8959b95a546e47e8d589610534cfb71f19802ea8a2ad99d95d702057"},
    {file = "greenlet-3.2.2-cp310-cp310-win_amd64.whl", hash = "sha256:d0cb7d47199001de7658c213419358aa8937df767936506db0db7ce1a71f4a2f"},
    {file = "greenlet-3.2.2-cp311-cp311-macosx_11_0_universal2.whl", hash = "sha256:dcb9cebbf3f62cb1e5afacae90761ccce0effb3adaa32339a0670fe7805d8068"},
    {file = "greenlet-3.2.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bf3fc9145141250907730886b031681dfcc0de1c158f3cc51c092223c0f381ce"},
    {file = "greenlet-3.2.2-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:efcdfb9df109e8a3b475c016f60438fcd4be68cd13a365d42b35914cdab4bb2b"},
    {file = "greenlet-3.2.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:4bd139e4943547ce3a56ef4b8b1b9479f9e40bb47e72cc906f0f66b9d0d5cab3"},
    {file = "greenlet-3.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:71566302219b17ca354eb274dfd29b8da3c268e41b646f330e324e3967546a74"},
    {file = "greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:3091bc45e6b0c73f225374fefa1536cd91b1e987377b12ef5b19129b07d93ebe"},
    {file = "greenlet-3.2.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:44671c29da26539a5f142257eaba5110f71887c24d40df3ac87f1117df589e0e"},
    {file = "greenlet-3.2.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:c23ea227847c9dbe0b3910f5c0dd95658b607137614eb821e6cbaecd60d81cc6"},
    {file = "greenlet-3.2.2-cp311-cp311-win_amd64.whl", hash = "sha256:0a16fb934fcabfdfacf21d79e6fed81809d8cd97bc1be9d9c89f0e4567143d7b"},
    {file = "greenlet-3.2.2-cp312-cp312-macosx_11_0_universal2.whl", hash = "sha256:df4d1509efd4977e6a844ac96d8be0b9e5aa5d5c77aa27ca9f4d3f92d3fcf330"},
    {file = "greenlet-3.2.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:da956d534a6d1b9841f95ad0f18ace637668f680b1339ca4dcfb2c1837880a0b"},
    {file = "greenlet-3.2.2-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:9c7b15fb9b88d9ee07e076f5a683027bc3befd5bb5d25954bb633c385d8b737e"},
    {file = "greenlet-3.2.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:752f0e79785e11180ebd2e726c8a88109ded3e2301d40abced2543aa5d164275"},
    {file = "greenlet-3.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9ae572c996ae4b5e122331e12bbb971ea49c08cc7c232d1bd43150800a2d6c65"},
    {file = "greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:02f5972ff02c9cf615357c17ab713737cccfd0eaf69b951084a9fd43f39833d3"},
    {file = "greenlet-3.2.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:4fefc7aa68b34b9224490dfda2e70ccf2131368493add64b4ef2d372955c207e"},
    {file = "greenlet-3.2.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:a31ead8411a027c2c4759113cf2bd473690517494f3d6e4bf67064589afcd3c5"},
    {file = "greenlet-3.2.2-cp312-cp312-win_amd64.whl", hash = "sha256:b24c7844c0a0afc3ccbeb0b807adeefb7eff2b5599229ecedddcfeb0ef333bec"},
    {file = "greenlet-3.2.2-cp313-cp313-macosx_11_0_universal2.whl", hash = "sha256:3ab7194ee290302ca15449f601036007873028712e92ca15fc76597a0aeb4c59"},
    {file = "greenlet-3.2.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2dc5c43bb65ec3669452af0ab10729e8fdc17f87a1f2ad7ec65d4aaaefabf6bf"},
    {file = "greenlet-3.2.2-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:decb0658ec19e5c1f519faa9a160c0fc85a41a7e6654b3ce1b44b939f8bf1325"},
    {file = "greenlet-3.2.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6fadd183186db360b61cb34e81117a096bff91c072929cd1b529eb20dd46e6c5"},
    {file = "greenlet-3.2.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1919cbdc1c53ef739c94cf2985056bcc0838c1f217b57647cbf4578576c63825"},
    {file = "greenlet-3.2.2-cp313-cp313-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:3885f85b61798f4192d544aac7b25a04ece5fe2704670b4ab73c2d2c14ab740d"},
    {file = "greenlet-3.2.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:85f3e248507125bf4af607a26fd6cb8578776197bd4b66e35229cdf5acf1dfbf"},
    {file = "greenlet-3.2.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:1e76106b6fc55fa3d6fe1c527f95ee65e324a13b62e243f77b48317346559708"},
    {file = "greenlet-3.2.2-cp313-cp313-win_amd64.whl", hash = "sha256:fe46d4f8e94e637634d54477b0cfabcf93c53f29eedcbdeecaf2af32029b4421"},
    {file = "greenlet-3.2.2-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ba30e88607fb6990544d84caf3c706c4b48f629e18853fc6a646f82db9629418"},
    {file = "greenlet-3.2.2-cp313-cp313t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:055916fafad3e3388d27dd68517478933a97edc2fc54ae79d3bec827de2c64c4"},
    {file = "greenlet-3.2.2-cp313-cp313t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2593283bf81ca37d27d110956b79e8723f9aa50c4bcdc29d3c0543d4743d2763"},
    {file = "greenlet-3.2.2-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:89c69e9a10670eb7a66b8cef6354c24671ba241f46152dd3eed447f79c29fb5b"},
    {file = "greenlet-3.2.2-cp313-cp313t-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:02a98600899ca1ca5d3a2590974c9e3ec259503b2d6ba6527605fcd74e08e207"},
    {file = "greenlet-3.2.2-cp313-cp313t-musllinux_1_1_aarch64.whl", hash = "sha256:b50a8c5c162469c3209e5ec92ee4f95c8231b11db6a04db09bbe338176723bb8"},
    {file = "greenlet-3.2.2-cp313-cp313t-musllinux_1_1_x86_64.whl", hash = "sha256:45f9f4853fb4cc46783085261c9ec4706628f3b57de3e68bae03e8f8b3c0de51"},
    {file = "greenlet-3.2.2-cp314-cp314-macosx_11_0_universal2.whl", hash = "sha256:9ea5231428af34226c05f927e16fc7f6fa5e39e3ad3cd24ffa48ba53a47f4240"},
    {file = "greenlet-3.2.2-cp39-cp39-macosx_11_0_universal2.whl", hash = "sha256:1e4747712c4365ef6765708f948acc9c10350719ca0545e362c24ab973017370"},
    {file = "greenlet-3.2.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:782743700ab75716650b5238a4759f840bb2dcf7bff56917e9ffdf9f1f23ec59"},
    {file = "greenlet-3.2.2-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:354f67445f5bed6604e493a06a9a49ad65675d3d03477d38a4db4a427e9aad0e"},
    {file = "greenlet-3.2.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3aeca9848d08ce5eb653cf16e15bb25beeab36e53eb71cc32569f5f3afb2a3aa"},
    {file = "greenlet-3.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8cb8553ee954536500d88a1a2f58fcb867e45125e600e80f586ade399b3f8819"},
    {file = "greenlet-3.2.2-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:1592a615b598643dbfd566bac8467f06c8c8ab6e56f069e573832ed1d5d528cc"},
    {file = "greenlet-3.2.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:1f72667cc341c95184f1c68f957cb2d4fc31eef81646e8e59358a10ce6689457"},
    {file = "greenlet-3.2.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:a8fa80665b1a29faf76800173ff5325095f3e66a78e62999929809907aca5659"},
    {file = "greenlet-3.2.2-cp39-cp39-win32.whl", hash = "sha256:6629311595e3fe7304039c67f00d145cd1d38cf723bb5b99cc987b23c1433d61"},
    {file = "greenlet-3.2.2-cp39-cp39-win_amd64.whl", hash = "sha256:eeb27bece45c0c2a5842ac4c5a1b5c2ceaefe5711078eed4e8043159fa05c834"},
    {file = "greenlet-3.2.2.tar.gz", hash = "sha256:ad053d34421a2debba45aa3cc39acf454acbcd025b3fc1a9f8a0dee237abd485"},
]

[package.extras]
docs = ["Sphinx", "furo"]
test = ["objgraph", "psutil"]

[[package]]
name = "grpcio"
version = "1.71.0"
description = "HTTP/2-based RPC framework"
optional = false
python-versions = ">=3.9"
files = [
    {file = "grpcio-1.71.0-cp310-cp310-linux_armv7l.whl", hash = "sha256:c200cb6f2393468142eb50ab19613229dcc7829b5ccee8b658a36005f6669fdd"},
    {file = "grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl", hash = "sha256:b2266862c5ad664a380fbbcdbdb8289d71464c42a8c29053820ee78ba0119e5d"},
    {file = "grpcio-1.71.0-cp310-cp310-manylinux_2_17_aarch64.whl", hash = "sha256:0ab8b2864396663a5b0b0d6d79495657ae85fa37dcb6498a2669d067c65c11ea"},
    {file = "grpcio-1.71.0-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c30f393f9d5ff00a71bb56de4aa75b8fe91b161aeb61d39528db6b768d7eac69"},
    {file = "grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f250ff44843d9a0615e350c77f890082102a0318d66a99540f54769c8766ab73"},
    {file = "grpcio-1.71.0-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:e6d8de076528f7c43a2f576bc311799f89d795aa6c9b637377cc2b1616473804"},
    {file = "grpcio-1.71.0-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:9b91879d6da1605811ebc60d21ab6a7e4bae6c35f6b63a061d61eb818c8168f6"},
    {file = "grpcio-1.71.0-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:f71574afdf944e6652203cd1badcda195b2a27d9c83e6d88dc1ce3cfb73b31a5"},
    {file = "grpcio-1.71.0-cp310-cp310-win32.whl", hash = "sha256:8997d6785e93308f277884ee6899ba63baafa0dfb4729748200fcc537858a509"},
    {file = "grpcio-1.71.0-cp310-cp310-win_amd64.whl", hash = "sha256:7d6ac9481d9d0d129224f6d5934d5832c4b1cddb96b59e7eba8416868909786a"},
    {file = "grpcio-1.71.0-cp311-cp311-linux_armv7l.whl", hash = "sha256:d6aa986318c36508dc1d5001a3ff169a15b99b9f96ef5e98e13522c506b37eef"},
    {file = "grpcio-1.71.0-cp311-cp311-macosx_10_14_universal2.whl", hash = "sha256:d2c170247315f2d7e5798a22358e982ad6eeb68fa20cf7a820bb74c11f0736e7"},
    {file = "grpcio-1.71.0-cp311-cp311-manylinux_2_17_aarch64.whl", hash = "sha256:e6f83a583ed0a5b08c5bc7a3fe860bb3c2eac1f03f1f63e0bc2091325605d2b7"},
    {file = "grpcio-1.71.0-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4be74ddeeb92cc87190e0e376dbc8fc7736dbb6d3d454f2fa1f5be1dee26b9d7"},
    {file = "grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4dd0dfbe4d5eb1fcfec9490ca13f82b089a309dc3678e2edabc144051270a66e"},
    {file = "grpcio-1.71.0-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:a2242d6950dc892afdf9e951ed7ff89473aaf744b7d5727ad56bdaace363722b"},
    {file = "grpcio-1.71.0-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:0fa05ee31a20456b13ae49ad2e5d585265f71dd19fbd9ef983c28f926d45d0a7"},
    {file = "grpcio-1.71.0-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:3d081e859fb1ebe176de33fc3adb26c7d46b8812f906042705346b314bde32c3"},
    {file = "grpcio-1.71.0-cp311-cp311-win32.whl", hash = "sha256:d6de81c9c00c8a23047136b11794b3584cdc1460ed7cbc10eada50614baa1444"},
    {file = "grpcio-1.71.0-cp311-cp311-win_amd64.whl", hash = "sha256:24e867651fc67717b6f896d5f0cac0ec863a8b5fb7d6441c2ab428f52c651c6b"},
    {file = "grpcio-1.71.0-cp312-cp312-linux_armv7l.whl", hash = "sha256:0ff35c8d807c1c7531d3002be03221ff9ae15712b53ab46e2a0b4bb271f38537"},
    {file = "grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl", hash = "sha256:b78a99cd1ece4be92ab7c07765a0b038194ded2e0a26fd654591ee136088d8d7"},
    {file = "grpcio-1.71.0-cp312-cp312-manylinux_2_17_aarch64.whl", hash = "sha256:dc1a1231ed23caac1de9f943d031f1bc38d0f69d2a3b243ea0d664fc1fbd7fec"},
    {file = "grpcio-1.71.0-cp312-cp312-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e6beeea5566092c5e3c4896c6d1d307fb46b1d4bdf3e70c8340b190a69198594"},
    {file = "grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d5170929109450a2c031cfe87d6716f2fae39695ad5335d9106ae88cc32dc84c"},
    {file = "grpcio-1.71.0-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:5b08d03ace7aca7b2fadd4baf291139b4a5f058805a8327bfe9aece7253b6d67"},
    {file = "grpcio-1.71.0-cp312-cp312-musllinux_1_1_i686.whl", hash = "sha256:f903017db76bf9cc2b2d8bdd37bf04b505bbccad6be8a81e1542206875d0e9db"},
    {file = "grpcio-1.71.0-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:469f42a0b410883185eab4689060a20488a1a0a00f8bbb3cbc1061197b4c5a79"},
    {file = "grpcio-1.71.0-cp312-cp312-win32.whl", hash = "sha256:ad9f30838550695b5eb302add33f21f7301b882937460dd24f24b3cc5a95067a"},
    {file = "grpcio-1.71.0-cp312-cp312-win_amd64.whl", hash = "sha256:652350609332de6dac4ece254e5d7e1ff834e203d6afb769601f286886f6f3a8"},
    {file = "grpcio-1.71.0-cp313-cp313-linux_armv7l.whl", hash = "sha256:cebc1b34ba40a312ab480ccdb396ff3c529377a2fce72c45a741f7215bfe8379"},
    {file = "grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl", hash = "sha256:85da336e3649a3d2171e82f696b5cad2c6231fdd5bad52616476235681bee5b3"},
    {file = "grpcio-1.71.0-cp313-cp313-manylinux_2_17_aarch64.whl", hash = "sha256:f9a412f55bb6e8f3bb000e020dbc1e709627dcb3a56f6431fa7076b4c1aab0db"},
    {file = "grpcio-1.71.0-cp313-cp313-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:47be9584729534660416f6d2a3108aaeac1122f6b5bdbf9fd823e11fe6fbaa29"},
    {file = "grpcio-1.71.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7c9c80ac6091c916db81131d50926a93ab162a7e97e4428ffc186b6e80d6dda4"},
    {file = "grpcio-1.71.0-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:789d5e2a3a15419374b7b45cd680b1e83bbc1e52b9086e49308e2c0b5bbae6e3"},
    {file = "grpcio-1.71.0-cp313-cp313-musllinux_1_1_i686.whl", hash = "sha256:1be857615e26a86d7363e8a163fade914595c81fec962b3d514a4b1e8760467b"},
    {file = "grpcio-1.71.0-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:a76d39b5fafd79ed604c4be0a869ec3581a172a707e2a8d7a4858cb05a5a7637"},
    {file = "grpcio-1.71.0-cp313-cp313-win32.whl", hash = "sha256:74258dce215cb1995083daa17b379a1a5a87d275387b7ffe137f1d5131e2cfbb"},
    {file = "grpcio-1.71.0-cp313-cp313-win_amd64.whl", hash = "sha256:22c3bc8d488c039a199f7a003a38cb7635db6656fa96437a8accde8322ce2366"},
    {file = "grpcio-1.71.0-cp39-cp39-linux_armv7l.whl", hash = "sha256:c6a0a28450c16809f94e0b5bfe52cabff63e7e4b97b44123ebf77f448534d07d"},
    {file = "grpcio-1.71.0-cp39-cp39-macosx_10_14_universal2.whl", hash = "sha256:a371e6b6a5379d3692cc4ea1cb92754d2a47bdddeee755d3203d1f84ae08e03e"},
    {file = "grpcio-1.71.0-cp39-cp39-manylinux_2_17_aarch64.whl", hash = "sha256:39983a9245d37394fd59de71e88c4b295eb510a3555e0a847d9965088cdbd033"},
    {file = "grpcio-1.71.0-cp39-cp39-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:9182e0063112e55e74ee7584769ec5a0b4f18252c35787f48738627e23a62b97"},
    {file = "grpcio-1.71.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:693bc706c031aeb848849b9d1c6b63ae6bcc64057984bb91a542332b75aa4c3d"},
    {file = "grpcio-1.71.0-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:20e8f653abd5ec606be69540f57289274c9ca503ed38388481e98fa396ed0b41"},
    {file = "grpcio-1.71.0-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:8700a2a57771cc43ea295296330daaddc0d93c088f0a35cc969292b6db959bf3"},
    {file = "grpcio-1.71.0-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:d35a95f05a8a2cbe8e02be137740138b3b2ea5f80bd004444e4f9a1ffc511e32"},
    {file = "grpcio-1.71.0-cp39-cp39-win32.whl", hash = "sha256:f9c30c464cb2ddfbc2ddf9400287701270fdc0f14be5f08a1e3939f1e749b455"},
    {file = "grpcio-1.71.0-cp39-cp39-win_amd64.whl", hash = "sha256:63e41b91032f298b3e973b3fa4093cbbc620c875e2da7b93e249d4728b54559a"},
    {file = "grpcio-1.71.0.tar.gz", hash = "sha256:2b85f7820475ad3edec209d3d89a7909ada16caab05d3f2e08a7e8ae3200a55c"},
]

[package.extras]
protobuf = ["grpcio-tools (>=1.71.0)"]

[[package]]
name = "grpcio-status"
version = "1.71.0"
description = "Status proto mapping for gRPC"
optional = false
python-versions = ">=3.9"
files = [
    {file = "grpcio_status-1.71.0-py3-none-any.whl", hash = "sha256:843934ef8c09e3e858952887467f8256aac3910c55f077a359a65b2b3cde3e68"},
    {file = "grpcio_status-1.71.0.tar.gz", hash = "sha256:11405fed67b68f406b3f3c7c5ae5104a79d2d309666d10d61b152e91d28fb968"},
]

[package.dependencies]
googleapis-common-protos = ">=1.5.5"
grpcio = ">=1.71.0"
protobuf = ">=5.26.1,<6.0dev"

[[package]]
name = "h11"
version = "0.16.0"
description = "A pure-Python, bring-your-own-I/O implementation of HTTP/1.1"
optional = false
python-versions = ">=3.8"
files = [
    {file = "h11-0.16.0-py3-none-any.whl", hash = "sha256:63cf8bbe7522de3bf65932fda1d9c2772064ffb3dae62d55932da54b31cb6c86"},
    {file = "h11-0.16.0.tar.gz", hash = "sha256:4e35b956cf45792e4caa5885e69fba00bdbc6ffafbfa020300e549b208ee5ff1"},
]

[[package]]
name = "httplib2"
version = "0.22.0"
description = "A comprehensive HTTP client library."
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"
files = [
    {file = "httplib2-0.22.0-py3-none-any.whl", hash = "sha256:14ae0a53c1ba8f3d37e9e27cf37eabb0fb9980f435ba405d546948b009dd64dc"},
    {file = "httplib2-0.22.0.tar.gz", hash = "sha256:d7a10bc5ef5ab08322488bde8c726eeee5c8618723fdb399597ec58f3d82df81"},
]

[package.dependencies]
pyparsing = {version = ">=2.4.2,<3.0.0 || >3.0.0,<3.0.1 || >3.0.1,<3.0.2 || >3.0.2,<3.0.3 || >3.0.3,<4", markers = "python_version > \"3.0\""}

[[package]]
name = "httptools"
version = "0.6.4"
description = "A collection of framework independent HTTP protocol utils."
optional = false
python-versions = ">=3.8.0"
files = [
    {file = "httptools-0.6.4-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:3c73ce323711a6ffb0d247dcd5a550b8babf0f757e86a52558fe5b86d6fefcc0"},
    {file = "httptools-0.6.4-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:345c288418f0944a6fe67be8e6afa9262b18c7626c3ef3c28adc5eabc06a68da"},
    {file = "httptools-0.6.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:deee0e3343f98ee8047e9f4c5bc7cedbf69f5734454a94c38ee829fb2d5fa3c1"},
    {file = "httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ca80b7485c76f768a3bc83ea58373f8db7b015551117375e4918e2aa77ea9b50"},
    {file = "httptools-0.6.4-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:90d96a385fa941283ebd231464045187a31ad932ebfa541be8edf5b3c2328959"},
    {file = "httptools-0.6.4-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:59e724f8b332319e2875efd360e61ac07f33b492889284a3e05e6d13746876f4"},
    {file = "httptools-0.6.4-cp310-cp310-win_amd64.whl", hash = "sha256:c26f313951f6e26147833fc923f78f95604bbec812a43e5ee37f26dc9e5a686c"},
    {file = "httptools-0.6.4-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:f47f8ed67cc0ff862b84a1189831d1d33c963fb3ce1ee0c65d3b0cbe7b711069"},
    {file = "httptools-0.6.4-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:0614154d5454c21b6410fdf5262b4a3ddb0f53f1e1721cfd59d55f32138c578a"},
    {file = "httptools-0.6.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f8787367fbdfccae38e35abf7641dafc5310310a5987b689f4c32cc8cc3ee975"},
    {file = "httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:40b0f7fe4fd38e6a507bdb751db0379df1e99120c65fbdc8ee6c1d044897a636"},
    {file = "httptools-0.6.4-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:40a5ec98d3f49904b9fe36827dcf1aadfef3b89e2bd05b0e35e94f97c2b14721"},
    {file = "httptools-0.6.4-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:dacdd3d10ea1b4ca9df97a0a303cbacafc04b5cd375fa98732678151643d4988"},
    {file = "httptools-0.6.4-cp311-cp311-win_amd64.whl", hash = "sha256:288cd628406cc53f9a541cfaf06041b4c71d751856bab45e3702191f931ccd17"},
    {file = "httptools-0.6.4-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:df017d6c780287d5c80601dafa31f17bddb170232d85c066604d8558683711a2"},
    {file = "httptools-0.6.4-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:85071a1e8c2d051b507161f6c3e26155b5c790e4e28d7f236422dbacc2a9cc44"},
    {file = "httptools-0.6.4-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:69422b7f458c5af875922cdb5bd586cc1f1033295aa9ff63ee196a87519ac8e1"},
    {file = "httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:16e603a3bff50db08cd578d54f07032ca1631450ceb972c2f834c2b860c28ea2"},
    {file = "httptools-0.6.4-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:ec4f178901fa1834d4a060320d2f3abc5c9e39766953d038f1458cb885f47e81"},
    {file = "httptools-0.6.4-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:f9eb89ecf8b290f2e293325c646a211ff1c2493222798bb80a530c5e7502494f"},
    {file = "httptools-0.6.4-cp312-cp312-win_amd64.whl", hash = "sha256:db78cb9ca56b59b016e64b6031eda5653be0589dba2b1b43453f6e8b405a0970"},
    {file = "httptools-0.6.4-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:ade273d7e767d5fae13fa637f4d53b6e961fb7fd93c7797562663f0171c26660"},
    {file = "httptools-0.6.4-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:856f4bc0478ae143bad54a4242fccb1f3f86a6e1be5548fecfd4102061b3a083"},
    {file = "httptools-0.6.4-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:322d20ea9cdd1fa98bd6a74b77e2ec5b818abdc3d36695ab402a0de8ef2865a3"},
    {file = "httptools-0.6.4-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4d87b29bd4486c0093fc64dea80231f7c7f7eb4dc70ae394d70a495ab8436071"},
    {file = "httptools-0.6.4-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:342dd6946aa6bda4b8f18c734576106b8a31f2fe31492881a9a160ec84ff4bd5"},
    {file = "httptools-0.6.4-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:4b36913ba52008249223042dca46e69967985fb4051951f94357ea681e1f5dc0"},
    {file = "httptools-0.6.4-cp313-cp313-win_amd64.whl", hash = "sha256:28908df1b9bb8187393d5b5db91435ccc9c8e891657f9cbb42a2541b44c82fc8"},
    {file = "httptools-0.6.4-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:d3f0d369e7ffbe59c4b6116a44d6a8eb4783aae027f2c0b366cf0aa964185dba"},
    {file = "httptools-0.6.4-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:94978a49b8f4569ad607cd4946b759d90b285e39c0d4640c6b36ca7a3ddf2efc"},
    {file = "httptools-0.6.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:40dc6a8e399e15ea525305a2ddba998b0af5caa2566bcd79dcbe8948181eeaff"},
    {file = "httptools-0.6.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ab9ba8dcf59de5181f6be44a77458e45a578fc99c31510b8c65b7d5acc3cf490"},
    {file = "httptools-0.6.4-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:fc411e1c0a7dcd2f902c7c48cf079947a7e65b5485dea9decb82b9105ca71a43"},
    {file = "httptools-0.6.4-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:d54efd20338ac52ba31e7da78e4a72570cf729fac82bc31ff9199bedf1dc7440"},
    {file = "httptools-0.6.4-cp38-cp38-win_amd64.whl", hash = "sha256:df959752a0c2748a65ab5387d08287abf6779ae9165916fe053e68ae1fbdc47f"},
    {file = "httptools-0.6.4-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:85797e37e8eeaa5439d33e556662cc370e474445d5fab24dcadc65a8ffb04003"},
    {file = "httptools-0.6.4-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:db353d22843cf1028f43c3651581e4bb49374d85692a85f95f7b9a130e1b2cab"},
    {file = "httptools-0.6.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d1ffd262a73d7c28424252381a5b854c19d9de5f56f075445d33919a637e3547"},
    {file = "httptools-0.6.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:703c346571fa50d2e9856a37d7cd9435a25e7fd15e236c397bf224afaa355fe9"},
    {file = "httptools-0.6.4-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:aafe0f1918ed07b67c1e838f950b1c1fabc683030477e60b335649b8020e1076"},
    {file = "httptools-0.6.4-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:0e563e54979e97b6d13f1bbc05a96109923e76b901f786a5eae36e99c01237bd"},
    {file = "httptools-0.6.4-cp39-cp39-win_amd64.whl", hash = "sha256:b799de31416ecc589ad79dd85a0b2657a8fe39327944998dea368c1d4c9e55e6"},
    {file = "httptools-0.6.4.tar.gz", hash = "sha256:4e93eee4add6493b59a5c514da98c939b244fce4a0d8879cd3f466562f4b7d5c"},
]

[package.extras]
test = ["Cython (>=0.29.24)"]

[[package]]
name = "idna"
version = "3.10"
description = "Internationalized Domain Names in Applications (IDNA)"
optional = false
python-versions = ">=3.6"
files = [
    {file = "idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3"},
    {file = "idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9"},
]

[package.extras]
all = ["flake8 (>=7.1.1)", "mypy (>=1.11.2)", "pytest (>=8.3.2)", "ruff (>=0.6.2)"]

[[package]]
name = "mako"
version = "1.3.10"
description = "A super-fast templating language that borrows the best ideas from the existing templating languages."
optional = false
python-versions = ">=3.8"
files = [
    {file = "mako-1.3.10-py3-none-any.whl", hash = "sha256:baef24a52fc4fc514a0887ac600f9f1cff3d82c61d4d700a1fa84d597b88db59"},
    {file = "mako-1.3.10.tar.gz", hash = "sha256:99579a6f39583fa7e5630a28c3c1f440e4e97a414b80372649c0ce338da2ea28"},
]

[package.dependencies]
MarkupSafe = ">=0.9.2"

[package.extras]
babel = ["Babel"]
lingua = ["lingua"]
testing = ["pytest"]

[[package]]
name = "markupsafe"
version = "3.0.2"
description = "Safely add untrusted strings to HTML/XML markup."
optional = false
python-versions = ">=3.9"
files = [
    {file = "MarkupSafe-3.0.2-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:7e94c425039cde14257288fd61dcfb01963e658efbc0ff54f5306b06054700f8"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:9e2d922824181480953426608b81967de705c3cef4d1af983af849d7bd619158"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:38a9ef736c01fccdd6600705b09dc574584b89bea478200c5fbf112a6b0d5579"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bbcb445fa71794da8f178f0f6d66789a28d7319071af7a496d4d507ed566270d"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:57cb5a3cf367aeb1d316576250f65edec5bb3be939e9247ae594b4bcbc317dfb"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:3809ede931876f5b2ec92eef964286840ed3540dadf803dd570c3b7e13141a3b"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:e07c3764494e3776c602c1e78e298937c3315ccc9043ead7e685b7f2b8d47b3c"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:b424c77b206d63d500bcb69fa55ed8d0e6a3774056bdc4839fc9298a7edca171"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-win32.whl", hash = "sha256:fcabf5ff6eea076f859677f5f0b6b5c1a51e70a376b0579e0eadef8db48c6b50"},
    {file = "MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl", hash = "sha256:6af100e168aa82a50e186c82875a5893c5597a0c1ccdb0d8b40240b1f28b969a"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:9025b4018f3a1314059769c7bf15441064b2207cb3f065e6ea1e7359cb46db9d"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:93335ca3812df2f366e80509ae119189886b0f3c2b81325d39efdb84a1e2ae93"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2cb8438c3cbb25e220c2ab33bb226559e7afb3baec11c4f218ffa7308603c832"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a123e330ef0853c6e822384873bef7507557d8e4a082961e1defa947aa59ba84"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1e084f686b92e5b83186b07e8a17fc09e38fff551f3602b249881fec658d3eca"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:d8213e09c917a951de9d09ecee036d5c7d36cb6cb7dbaece4c71a60d79fb9798"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:5b02fb34468b6aaa40dfc198d813a641e3a63b98c2b05a16b9f80b7ec314185e"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:0bff5e0ae4ef2e1ae4fdf2dfd5b76c75e5c2fa4132d05fc1b0dabcd20c7e28c4"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-win32.whl", hash = "sha256:6c89876f41da747c8d3677a2b540fb32ef5715f97b66eeb0c6b66f5e3ef6f59d"},
    {file = "MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl", hash = "sha256:70a87b411535ccad5ef2f1df5136506a10775d267e197e4cf531ced10537bd6b"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:9778bd8ab0a994ebf6f84c2b949e65736d5575320a17ae8984a77fab08db94cf"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:846ade7b71e3536c4e56b386c2a47adf5741d2d8b94ec9dc3e92e5e1ee1e2225"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1c99d261bd2d5f6b59325c92c73df481e05e57f19837bdca8413b9eac4bd8028"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e17c96c14e19278594aa4841ec148115f9c7615a47382ecb6b82bd8fea3ab0c8"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:88416bd1e65dcea10bc7569faacb2c20ce071dd1f87539ca2ab364bf6231393c"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:2181e67807fc2fa785d0592dc2d6206c019b9502410671cc905d132a92866557"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:52305740fe773d09cffb16f8ed0427942901f00adedac82ec8b67752f58a1b22"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:ad10d3ded218f1039f11a75f8091880239651b52e9bb592ca27de44eed242a48"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-win32.whl", hash = "sha256:0f4ca02bea9a23221c0182836703cbf8930c5e9454bacce27e767509fa286a30"},
    {file = "MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:8e06879fc22a25ca47312fbe7c8264eb0b662f6db27cb2d3bbbc74b1df4b9b87"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:ba9527cdd4c926ed0760bc301f6728ef34d841f405abf9d4f959c478421e4efd"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:f8b3d067f2e40fe93e1ccdd6b2e1d16c43140e76f02fb1319a05cf2b79d99430"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:569511d3b58c8791ab4c2e1285575265991e6d8f8700c7be0e88f86cb0672094"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:15ab75ef81add55874e7ab7055e9c397312385bd9ced94920f2802310c930396"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f3818cb119498c0678015754eba762e0d61e5b52d34c8b13d770f0719f7b1d79"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:cdb82a876c47801bb54a690c5ae105a46b392ac6099881cdfb9f6e95e4014c6a"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:cabc348d87e913db6ab4aa100f01b08f481097838bdddf7c7a84b7575b7309ca"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:444dcda765c8a838eaae23112db52f1efaf750daddb2d9ca300bcae1039adc5c"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-win32.whl", hash = "sha256:bcf3e58998965654fdaff38e58584d8937aa3096ab5354d493c77d1fdd66d7a1"},
    {file = "MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:e6a2a455bd412959b57a172ce6328d2dd1f01cb2135efda2e4576e8a23fa3b0f"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:b5a6b3ada725cea8a5e634536b1b01c30bcdcd7f9c6fff4151548d5bf6b3a36c"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:a904af0a6162c73e3edcb969eeeb53a63ceeb5d8cf642fade7d39e7963a22ddb"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4aa4e5faecf353ed117801a068ebab7b7e09ffb6e1d5e412dc852e0da018126c"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c0ef13eaeee5b615fb07c9a7dadb38eac06a0608b41570d8ade51c56539e509d"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d16a81a06776313e817c951135cf7340a3e91e8c1ff2fac444cfd75fffa04afe"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:6381026f158fdb7c72a168278597a5e3a5222e83ea18f543112b2662a9b699c5"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:3d79d162e7be8f996986c064d1c7c817f6df3a77fe3d6859f6f9e7be4b8c213a"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:131a3c7689c85f5ad20f9f6fb1b866f402c445b220c19fe4308c0b147ccd2ad9"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-win32.whl", hash = "sha256:ba8062ed2cf21c07a9e295d5b8a2a5ce678b913b45fdf68c32d95d6c1291e0b6"},
    {file = "MarkupSafe-3.0.2-cp313-cp313t-win_amd64.whl", hash = "sha256:e444a31f8db13eb18ada366ab3cf45fd4b31e4db1236a4448f68778c1d1a5a2f"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:eaa0a10b7f72326f1372a713e73c3f739b524b3af41feb43e4921cb529f5929a"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:48032821bbdf20f5799ff537c7ac3d1fba0ba032cfc06194faffa8cda8b560ff"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1a9d3f5f0901fdec14d8d2f66ef7d035f2157240a433441719ac9a3fba440b13"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:88b49a3b9ff31e19998750c38e030fc7bb937398b1f78cfa599aaef92d693144"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:cfad01eed2c2e0c01fd0ecd2ef42c492f7f93902e39a42fc9ee1692961443a29"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:1225beacc926f536dc82e45f8a4d68502949dc67eea90eab715dea3a21c1b5f0"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:3169b1eefae027567d1ce6ee7cae382c57fe26e82775f460f0b2778beaad66c0"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:eb7972a85c54febfb25b5c4b4f3af4dcc731994c7da0d8a0b4a6eb0640e1d178"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-win32.whl", hash = "sha256:8c4e8c3ce11e1f92f6536ff07154f9d49677ebaaafc32db9db4620bc11ed480f"},
    {file = "MarkupSafe-3.0.2-cp39-cp39-win_amd64.whl", hash = "sha256:6e296a513ca3d94054c2c881cc913116e90fd030ad1c656b3869762b754f5f8a"},
    {file = "markupsafe-3.0.2.tar.gz", hash = "sha256:ee55d3edf80167e48ea11a923c7386f4669df67d7994554387f84e7d8b0a2bf0"},
]

[[package]]
name = "numpy"
version = "2.2.6"
description = "Fundamental package for array computing in Python"
optional = false
python-versions = ">=3.10"
files = [
    {file = "numpy-2.2.6-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:b412caa66f72040e6d268491a59f2c43bf03eb6c96dd8f0307829feb7fa2b6fb"},
    {file = "numpy-2.2.6-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8e41fd67c52b86603a91c1a505ebaef50b3314de0213461c7a6e99c9a3beff90"},
    {file = "numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl", hash = "sha256:37e990a01ae6ec7fe7fa1c26c55ecb672dd98b19c3d0e1d1f326fa13cb38d163"},
    {file = "numpy-2.2.6-cp310-cp310-macosx_14_0_x86_64.whl", hash = "sha256:5a6429d4be8ca66d889b7cf70f536a397dc45ba6faeb5f8c5427935d9592e9cf"},
    {file = "numpy-2.2.6-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:efd28d4e9cd7d7a8d39074a4d44c63eda73401580c5c76acda2ce969e0a38e83"},
    {file = "numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fc7b73d02efb0e18c000e9ad8b83480dfcd5dfd11065997ed4c6747470ae8915"},
    {file = "numpy-2.2.6-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:74d4531beb257d2c3f4b261bfb0fc09e0f9ebb8842d82a7b4209415896adc680"},
    {file = "numpy-2.2.6-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:8fc377d995680230e83241d8a96def29f204b5782f371c532579b4f20607a289"},
    {file = "numpy-2.2.6-cp310-cp310-win32.whl", hash = "sha256:b093dd74e50a8cba3e873868d9e93a85b78e0daf2e98c6797566ad8044e8363d"},
    {file = "numpy-2.2.6-cp310-cp310-win_amd64.whl", hash = "sha256:f0fd6321b839904e15c46e0d257fdd101dd7f530fe03fd6359c1ea63738703f3"},
    {file = "numpy-2.2.6-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:f9f1adb22318e121c5c69a09142811a201ef17ab257a1e66ca3025065b7f53ae"},
    {file = "numpy-2.2.6-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:c820a93b0255bc360f53eca31a0e676fd1101f673dda8da93454a12e23fc5f7a"},
    {file = "numpy-2.2.6-cp311-cp311-macosx_14_0_arm64.whl", hash = "sha256:3d70692235e759f260c3d837193090014aebdf026dfd167834bcba43e30c2a42"},
    {file = "numpy-2.2.6-cp311-cp311-macosx_14_0_x86_64.whl", hash = "sha256:481b49095335f8eed42e39e8041327c05b0f6f4780488f61286ed3c01368d491"},
    {file = "numpy-2.2.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b64d8d4d17135e00c8e346e0a738deb17e754230d7e0810ac5012750bbd85a5a"},
    {file = "numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ba10f8411898fc418a521833e014a77d3ca01c15b0c6cdcce6a0d2897e6dbbdf"},
    {file = "numpy-2.2.6-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:bd48227a919f1bafbdda0583705e547892342c26fb127219d60a5c36882609d1"},
    {file = "numpy-2.2.6-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:9551a499bf125c1d4f9e250377c1ee2eddd02e01eac6644c080162c0c51778ab"},
    {file = "numpy-2.2.6-cp311-cp311-win32.whl", hash = "sha256:0678000bb9ac1475cd454c6b8c799206af8107e310843532b04d49649c717a47"},
    {file = "numpy-2.2.6-cp311-cp311-win_amd64.whl", hash = "sha256:e8213002e427c69c45a52bbd94163084025f533a55a59d6f9c5b820774ef3303"},
    {file = "numpy-2.2.6-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:41c5a21f4a04fa86436124d388f6ed60a9343a6f767fced1a8a71c3fbca038ff"},
    {file = "numpy-2.2.6-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:de749064336d37e340f640b05f24e9e3dd678c57318c7289d222a8a2f543e90c"},
    {file = "numpy-2.2.6-cp312-cp312-macosx_14_0_arm64.whl", hash = "sha256:894b3a42502226a1cac872f840030665f33326fc3dac8e57c607905773cdcde3"},
    {file = "numpy-2.2.6-cp312-cp312-macosx_14_0_x86_64.whl", hash = "sha256:71594f7c51a18e728451bb50cc60a3ce4e6538822731b2933209a1f3614e9282"},
    {file = "numpy-2.2.6-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f2618db89be1b4e05f7a1a847a9c1c0abd63e63a1607d892dd54668dd92faf87"},
    {file = "numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fd83c01228a688733f1ded5201c678f0c53ecc1006ffbc404db9f7a899ac6249"},
    {file = "numpy-2.2.6-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:37c0ca431f82cd5fa716eca9506aefcabc247fb27ba69c5062a6d3ade8cf8f49"},
    {file = "numpy-2.2.6-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:fe27749d33bb772c80dcd84ae7e8df2adc920ae8297400dabec45f0dedb3f6de"},
    {file = "numpy-2.2.6-cp312-cp312-win32.whl", hash = "sha256:4eeaae00d789f66c7a25ac5f34b71a7035bb474e679f410e5e1a94deb24cf2d4"},
    {file = "numpy-2.2.6-cp312-cp312-win_amd64.whl", hash = "sha256:c1f9540be57940698ed329904db803cf7a402f3fc200bfe599334c9bd84a40b2"},
    {file = "numpy-2.2.6-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:0811bb762109d9708cca4d0b13c4f67146e3c3b7cf8d34018c722adb2d957c84"},
    {file = "numpy-2.2.6-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:287cc3162b6f01463ccd86be154f284d0893d2b3ed7292439ea97eafa8170e0b"},
    {file = "numpy-2.2.6-cp313-cp313-macosx_14_0_arm64.whl", hash = "sha256:f1372f041402e37e5e633e586f62aa53de2eac8d98cbfb822806ce4bbefcb74d"},
    {file = "numpy-2.2.6-cp313-cp313-macosx_14_0_x86_64.whl", hash = "sha256:55a4d33fa519660d69614a9fad433be87e5252f4b03850642f88993f7b2ca566"},
    {file = "numpy-2.2.6-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f92729c95468a2f4f15e9bb94c432a9229d0d50de67304399627a943201baa2f"},
    {file = "numpy-2.2.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1bc23a79bfabc5d056d106f9befb8d50c31ced2fbc70eedb8155aec74a45798f"},
    {file = "numpy-2.2.6-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:e3143e4451880bed956e706a3220b4e5cf6172ef05fcc397f6f36a550b1dd868"},
    {file = "numpy-2.2.6-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:b4f13750ce79751586ae2eb824ba7e1e8dba64784086c98cdbbcc6a42112ce0d"},
    {file = "numpy-2.2.6-cp313-cp313-win32.whl", hash = "sha256:5beb72339d9d4fa36522fc63802f469b13cdbe4fdab4a288f0c441b74272ebfd"},
    {file = "numpy-2.2.6-cp313-cp313-win_amd64.whl", hash = "sha256:b0544343a702fa80c95ad5d3d608ea3599dd54d4632df855e4c8d24eb6ecfa1c"},
    {file = "numpy-2.2.6-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:0bca768cd85ae743b2affdc762d617eddf3bcf8724435498a1e80132d04879e6"},
    {file = "numpy-2.2.6-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:fc0c5673685c508a142ca65209b4e79ed6740a4ed6b2267dbba90f34b0b3cfda"},
    {file = "numpy-2.2.6-cp313-cp313t-macosx_14_0_arm64.whl", hash = "sha256:5bd4fc3ac8926b3819797a7c0e2631eb889b4118a9898c84f585a54d475b7e40"},
    {file = "numpy-2.2.6-cp313-cp313t-macosx_14_0_x86_64.whl", hash = "sha256:fee4236c876c4e8369388054d02d0e9bb84821feb1a64dd59e137e6511a551f8"},
    {file = "numpy-2.2.6-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e1dda9c7e08dc141e0247a5b8f49cf05984955246a327d4c48bda16821947b2f"},
    {file = "numpy-2.2.6-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f447e6acb680fd307f40d3da4852208af94afdfab89cf850986c3ca00562f4fa"},
    {file = "numpy-2.2.6-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:389d771b1623ec92636b0786bc4ae56abafad4a4c513d36a55dce14bd9ce8571"},
    {file = "numpy-2.2.6-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:8e9ace4a37db23421249ed236fdcdd457d671e25146786dfc96835cd951aa7c1"},
    {file = "numpy-2.2.6-cp313-cp313t-win32.whl", hash = "sha256:038613e9fb8c72b0a41f025a7e4c3f0b7a1b5d768ece4796b674c8f3fe13efff"},
    {file = "numpy-2.2.6-cp313-cp313t-win_amd64.whl", hash = "sha256:6031dd6dfecc0cf9f668681a37648373bddd6421fff6c66ec1624eed0180ee06"},
    {file = "numpy-2.2.6-pp310-pypy310_pp73-macosx_10_15_x86_64.whl", hash = "sha256:0b605b275d7bd0c640cad4e5d30fa701a8d59302e127e5f79138ad62762c3e3d"},
    {file = "numpy-2.2.6-pp310-pypy310_pp73-macosx_14_0_x86_64.whl", hash = "sha256:7befc596a7dc9da8a337f79802ee8adb30a552a94f792b9c9d18c840055907db"},
    {file = "numpy-2.2.6-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ce47521a4754c8f4593837384bd3424880629f718d87c5d44f8ed763edd63543"},
    {file = "numpy-2.2.6-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:d042d24c90c41b54fd506da306759e06e568864df8ec17ccc17e9e884634fd00"},
    {file = "numpy-2.2.6.tar.gz", hash = "sha256:e29554e2bef54a90aa5cc07da6ce955accb83f21ab5de01a62c8478897b264fd"},
]

[[package]]
name = "passlib"
version = "1.7.4"
description = "comprehensive password hashing framework supporting over 30 schemes"
optional = false
python-versions = "*"
files = [
    {file = "passlib-1.7.4-py2.py3-none-any.whl", hash = "sha256:aa6bca462b8d8bda89c70b382f0c298a20b5560af6cbfa2dce410c0a2fb669f1"},
    {file = "passlib-1.7.4.tar.gz", hash = "sha256:defd50f72b65c5402ab2c573830a6978e5f202ad0d984793c8dde2c4152ebe04"},
]

[package.dependencies]
bcrypt = {version = ">=3.1.0", optional = true, markers = "extra == \"bcrypt\""}

[package.extras]
argon2 = ["argon2-cffi (>=18.2.0)"]
bcrypt = ["bcrypt (>=3.1.0)"]
build-docs = ["cloud-sptheme (>=1.10.1)", "sphinx (>=1.6)", "sphinxcontrib-fulltoc (>=1.2.0)"]
totp = ["cryptography"]

[[package]]
name = "pgvector"
version = "0.4.1"
description = "pgvector support for Python"
optional = false
python-versions = ">=3.9"
files = [
    {file = "pgvector-0.4.1-py3-none-any.whl", hash = "sha256:34bb4e99e1b13d08a2fe82dda9f860f15ddcd0166fbb25bffe15821cbfeb7362"},
    {file = "pgvector-0.4.1.tar.gz", hash = "sha256:83d3a1c044ff0c2f1e95d13dfb625beb0b65506cfec0941bfe81fd0ad44f4003"},
]

[package.dependencies]
numpy = "*"

[[package]]
name = "proto-plus"
version = "1.26.1"
description = "Beautiful, Pythonic protocol buffers"
optional = false
python-versions = ">=3.7"
files = [
    {file = "proto_plus-1.26.1-py3-none-any.whl", hash = "sha256:13285478c2dcf2abb829db158e1047e2f1e8d63a077d94263c2b88b043c75a66"},
    {file = "proto_plus-1.26.1.tar.gz", hash = "sha256:21a515a4c4c0088a773899e23c7bbade3d18f9c66c73edd4c7ee3816bc96a012"},
]

[package.dependencies]
protobuf = ">=3.19.0,<7.0.0"

[package.extras]
testing = ["google-api-core (>=1.31.5)"]

[[package]]
name = "protobuf"
version = "5.29.4"
description = ""
optional = false
python-versions = ">=3.8"
files = [
    {file = "protobuf-5.29.4-cp310-abi3-win32.whl", hash = "sha256:13eb236f8eb9ec34e63fc8b1d6efd2777d062fa6aaa68268fb67cf77f6839ad7"},
    {file = "protobuf-5.29.4-cp310-abi3-win_amd64.whl", hash = "sha256:bcefcdf3976233f8a502d265eb65ea740c989bacc6c30a58290ed0e519eb4b8d"},
    {file = "protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl", hash = "sha256:307ecba1d852ec237e9ba668e087326a67564ef83e45a0189a772ede9e854dd0"},
    {file = "protobuf-5.29.4-cp38-abi3-manylinux2014_aarch64.whl", hash = "sha256:aec4962f9ea93c431d5714ed1be1c93f13e1a8618e70035ba2b0564d9e633f2e"},
    {file = "protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl", hash = "sha256:d7d3f7d1d5a66ed4942d4fefb12ac4b14a29028b209d4bfb25c68ae172059922"},
    {file = "protobuf-5.29.4-cp38-cp38-win32.whl", hash = "sha256:1832f0515b62d12d8e6ffc078d7e9eb06969aa6dc13c13e1036e39d73bebc2de"},
    {file = "protobuf-5.29.4-cp38-cp38-win_amd64.whl", hash = "sha256:476cb7b14914c780605a8cf62e38c2a85f8caff2e28a6a0bad827ec7d6c85d68"},
    {file = "protobuf-5.29.4-cp39-cp39-win32.whl", hash = "sha256:fd32223020cb25a2cc100366f1dedc904e2d71d9322403224cdde5fdced0dabe"},
    {file = "protobuf-5.29.4-cp39-cp39-win_amd64.whl", hash = "sha256:678974e1e3a9b975b8bc2447fca458db5f93a2fb6b0c8db46b6675b5b5346812"},
    {file = "protobuf-5.29.4-py3-none-any.whl", hash = "sha256:3fde11b505e1597f71b875ef2fc52062b6a9740e5f7c8997ce878b6009145862"},
    {file = "protobuf-5.29.4.tar.gz", hash = "sha256:4f1dfcd7997b31ef8f53ec82781ff434a28bf71d9102ddde14d076adcfc78c99"},
]

[[package]]
name = "pyasn1"
version = "0.4.8"
description = "ASN.1 types and codecs"
optional = false
python-versions = "*"
files = [
    {file = "pyasn1-0.4.8-py2.py3-none-any.whl", hash = "sha256:39c7e2ec30515947ff4e87fb6f456dfc6e84857d34be479c9d4a4ba4bf46aa5d"},
    {file = "pyasn1-0.4.8.tar.gz", hash = "sha256:aef77c9fb94a3ac588e87841208bdec464471d9871bd5050a287cc9a475cd0ba"},
]

[[package]]
name = "pyasn1-modules"
version = "0.4.1"
description = "A collection of ASN.1-based protocols modules"
optional = false
python-versions = ">=3.8"
files = [
    {file = "pyasn1_modules-0.4.1-py3-none-any.whl", hash = "sha256:49bfa96b45a292b711e986f222502c1c9a5e1f4e568fc30e2574a6c7d07838fd"},
    {file = "pyasn1_modules-0.4.1.tar.gz", hash = "sha256:c28e2dbf9c06ad61c71a075c7e0f9fd0f1b0bb2d2ad4377f240d33ac2ab60a7c"},
]

[package.dependencies]
pyasn1 = ">=0.4.6,<0.7.0"

[[package]]
name = "pycparser"
version = "2.22"
description = "C parser in Python"
optional = false
python-versions = ">=3.8"
files = [
    {file = "pycparser-2.22-py3-none-any.whl", hash = "sha256:c3702b6d3dd8c7abc1afa565d7e63d53a1d0bd86cdc24edd75470f4de499cfcc"},
    {file = "pycparser-2.22.tar.gz", hash = "sha256:491c8be9c040f5390f5bf44a5b07752bd07f56edf992381b05c701439eec10f6"},
]

[[package]]
name = "pydantic"
version = "2.11.5"
description = "Data validation using Python type hints"
optional = false
python-versions = ">=3.9"
files = [
    {file = "pydantic-2.11.5-py3-none-any.whl", hash = "sha256:f9c26ba06f9747749ca1e5c94d6a85cb84254577553c8785576fd38fa64dc0f7"},
    {file = "pydantic-2.11.5.tar.gz", hash = "sha256:7f853db3d0ce78ce8bbb148c401c2cdd6431b3473c0cdff2755c7690952a7b7a"},
]

[package.dependencies]
annotated-types = ">=0.6.0"
email-validator = {version = ">=2.0.0", optional = true, markers = "extra == \"email\""}
pydantic-core = "2.33.2"
typing-extensions = ">=4.12.2"
typing-inspection = ">=0.4.0"

[package.extras]
email = ["email-validator (>=2.0.0)"]
timezone = ["tzdata"]

[[package]]
name = "pydantic-core"
version = "2.33.2"
description = "Core functionality for Pydantic validation and serialization"
optional = false
python-versions = ">=3.9"
files = [
    {file = "pydantic_core-2.33.2-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:2b3d326aaef0c0399d9afffeb6367d5e26ddc24d351dbc9c636840ac355dc5d8"},
    {file = "pydantic_core-2.33.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:0e5b2671f05ba48b94cb90ce55d8bdcaaedb8ba00cc5359f6810fc918713983d"},
    {file = "pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0069c9acc3f3981b9ff4cdfaf088e98d83440a4c7ea1bc07460af3d4dc22e72d"},
    {file = "pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:d53b22f2032c42eaaf025f7c40c2e3b94568ae077a606f006d206a463bc69572"},
    {file = "pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:0405262705a123b7ce9f0b92f123334d67b70fd1f20a9372b907ce1080c7ba02"},
    {file = "pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:4b25d91e288e2c4e0662b8038a28c6a07eaac3e196cfc4ff69de4ea3db992a1b"},
    {file = "pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6bdfe4b3789761f3bcb4b1ddf33355a71079858958e3a552f16d5af19768fef2"},
    {file = "pydantic_core-2.33.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:efec8db3266b76ef9607c2c4c419bdb06bf335ae433b80816089ea7585816f6a"},
    {file = "pydantic_core-2.33.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:031c57d67ca86902726e0fae2214ce6770bbe2f710dc33063187a68744a5ecac"},
    {file = "pydantic_core-2.33.2-cp310-cp310-musllinux_1_1_armv7l.whl", hash = "sha256:f8de619080e944347f5f20de29a975c2d815d9ddd8be9b9b7268e2e3ef68605a"},
    {file = "pydantic_core-2.33.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:73662edf539e72a9440129f231ed3757faab89630d291b784ca99237fb94db2b"},
    {file = "pydantic_core-2.33.2-cp310-cp310-win32.whl", hash = "sha256:0a39979dcbb70998b0e505fb1556a1d550a0781463ce84ebf915ba293ccb7e22"},
    {file = "pydantic_core-2.33.2-cp310-cp310-win_amd64.whl", hash = "sha256:b0379a2b24882fef529ec3b4987cb5d003b9cda32256024e6fe1586ac45fc640"},
    {file = "pydantic_core-2.33.2-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:4c5b0a576fb381edd6d27f0a85915c6daf2f8138dc5c267a57c08a62900758c7"},
    {file = "pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:e799c050df38a639db758c617ec771fd8fb7a5f8eaaa4b27b101f266b216a246"},
    {file = "pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:dc46a01bf8d62f227d5ecee74178ffc448ff4e5197c756331f71efcc66dc980f"},
    {file = "pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:a144d4f717285c6d9234a66778059f33a89096dfb9b39117663fd8413d582dcc"},
    {file = "pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:73cf6373c21bc80b2e0dc88444f41ae60b2f070ed02095754eb5a01df12256de"},
    {file = "pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3dc625f4aa79713512d1976fe9f0bc99f706a9dee21dfd1810b4bbbf228d0e8a"},
    {file = "pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:881b21b5549499972441da4758d662aeea93f1923f953e9cbaff14b8b9565aef"},
    {file = "pydantic_core-2.33.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:bdc25f3681f7b78572699569514036afe3c243bc3059d3942624e936ec93450e"},
    {file = "pydantic_core-2.33.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:fe5b32187cbc0c862ee201ad66c30cf218e5ed468ec8dc1cf49dec66e160cc4d"},
    {file = "pydantic_core-2.33.2-cp311-cp311-musllinux_1_1_armv7l.whl", hash = "sha256:bc7aee6f634a6f4a95676fcb5d6559a2c2a390330098dba5e5a5f28a2e4ada30"},
    {file = "pydantic_core-2.33.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:235f45e5dbcccf6bd99f9f472858849f73d11120d76ea8707115415f8e5ebebf"},
    {file = "pydantic_core-2.33.2-cp311-cp311-win32.whl", hash = "sha256:6368900c2d3ef09b69cb0b913f9f8263b03786e5b2a387706c5afb66800efd51"},
    {file = "pydantic_core-2.33.2-cp311-cp311-win_amd64.whl", hash = "sha256:1e063337ef9e9820c77acc768546325ebe04ee38b08703244c1309cccc4f1bab"},
    {file = "pydantic_core-2.33.2-cp311-cp311-win_arm64.whl", hash = "sha256:6b99022f1d19bc32a4c2a0d544fc9a76e3be90f0b3f4af413f87d38749300e65"},
    {file = "pydantic_core-2.33.2-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:a7ec89dc587667f22b6a0b6579c249fca9026ce7c333fc142ba42411fa243cdc"},
    {file = "pydantic_core-2.33.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:3c6db6e52c6d70aa0d00d45cdb9b40f0433b96380071ea80b09277dba021ddf7"},
    {file = "pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4e61206137cbc65e6d5256e1166f88331d3b6238e082d9f74613b9b765fb9025"},
    {file = "pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:eb8c529b2819c37140eb51b914153063d27ed88e3bdc31b71198a198e921e011"},
    {file = "pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:c52b02ad8b4e2cf14ca7b3d918f3eb0ee91e63b3167c32591e57c4317e134f8f"},
    {file = "pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:96081f1605125ba0855dfda83f6f3df5ec90c61195421ba72223de35ccfb2f88"},
    {file = "pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8f57a69461af2a5fa6e6bbd7a5f60d3b7e6cebb687f55106933188e79ad155c1"},
    {file = "pydantic_core-2.33.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:572c7e6c8bb4774d2ac88929e3d1f12bc45714ae5ee6d9a788a9fb35e60bb04b"},
    {file = "pydantic_core-2.33.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:db4b41f9bd95fbe5acd76d89920336ba96f03e149097365afe1cb092fceb89a1"},
    {file = "pydantic_core-2.33.2-cp312-cp312-musllinux_1_1_armv7l.whl", hash = "sha256:fa854f5cf7e33842a892e5c73f45327760bc7bc516339fda888c75ae60edaeb6"},
    {file = "pydantic_core-2.33.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:5f483cfb75ff703095c59e365360cb73e00185e01aaea067cd19acffd2ab20ea"},
    {file = "pydantic_core-2.33.2-cp312-cp312-win32.whl", hash = "sha256:9cb1da0f5a471435a7bc7e439b8a728e8b61e59784b2af70d7c169f8dd8ae290"},
    {file = "pydantic_core-2.33.2-cp312-cp312-win_amd64.whl", hash = "sha256:f941635f2a3d96b2973e867144fde513665c87f13fe0e193c158ac51bfaaa7b2"},
    {file = "pydantic_core-2.33.2-cp312-cp312-win_arm64.whl", hash = "sha256:cca3868ddfaccfbc4bfb1d608e2ccaaebe0ae628e1416aeb9c4d88c001bb45ab"},
    {file = "pydantic_core-2.33.2-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:1082dd3e2d7109ad8b7da48e1d4710c8d06c253cbc4a27c1cff4fbcaa97a9e3f"},
    {file = "pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:f517ca031dfc037a9c07e748cefd8d96235088b83b4f4ba8939105d20fa1dcd6"},
    {file = "pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0a9f2c9dd19656823cb8250b0724ee9c60a82f3cdf68a080979d13092a3b0fef"},
    {file = "pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:2b0a451c263b01acebe51895bfb0e1cc842a5c666efe06cdf13846c7418caa9a"},
    {file = "pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1ea40a64d23faa25e62a70ad163571c0b342b8bf66d5fa612ac0dec4f069d916"},
    {file = "pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:0fb2d542b4d66f9470e8065c5469ec676978d625a8b7a363f07d9a501a9cb36a"},
    {file = "pydantic_core-2.33.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9fdac5d6ffa1b5a83bca06ffe7583f5576555e6c8b3a91fbd25ea7780f825f7d"},
    {file = "pydantic_core-2.33.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:04a1a413977ab517154eebb2d326da71638271477d6ad87a769102f7c2488c56"},
    {file = "pydantic_core-2.33.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:c8e7af2f4e0194c22b5b37205bfb293d166a7344a5b0d0eaccebc376546d77d5"},
    {file = "pydantic_core-2.33.2-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:5c92edd15cd58b3c2d34873597a1e20f13094f59cf88068adb18947df5455b4e"},
    {file = "pydantic_core-2.33.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:65132b7b4a1c0beded5e057324b7e16e10910c106d43675d9bd87d4f38dde162"},
    {file = "pydantic_core-2.33.2-cp313-cp313-win32.whl", hash = "sha256:52fb90784e0a242bb96ec53f42196a17278855b0f31ac7c3cc6f5c1ec4811849"},
    {file = "pydantic_core-2.33.2-cp313-cp313-win_amd64.whl", hash = "sha256:c083a3bdd5a93dfe480f1125926afcdbf2917ae714bdb80b36d34318b2bec5d9"},
    {file = "pydantic_core-2.33.2-cp313-cp313-win_arm64.whl", hash = "sha256:e80b087132752f6b3d714f041ccf74403799d3b23a72722ea2e6ba2e892555b9"},
    {file = "pydantic_core-2.33.2-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:61c18fba8e5e9db3ab908620af374db0ac1baa69f0f32df4f61ae23f15e586ac"},
    {file = "pydantic_core-2.33.2-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:95237e53bb015f67b63c91af7518a62a8660376a6a0db19b89acc77a4d6199f5"},
    {file = "pydantic_core-2.33.2-cp313-cp313t-win_amd64.whl", hash = "sha256:c2fc0a768ef76c15ab9238afa6da7f69895bb5d1ee83aeea2e3509af4472d0b9"},
    {file = "pydantic_core-2.33.2-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:a2b911a5b90e0374d03813674bf0a5fbbb7741570dcd4b4e85a2e48d17def29d"},
    {file = "pydantic_core-2.33.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:6fa6dfc3e4d1f734a34710f391ae822e0a8eb8559a85c6979e14e65ee6ba2954"},
    {file = "pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c54c939ee22dc8e2d545da79fc5381f1c020d6d3141d3bd747eab59164dc89fb"},
    {file = "pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:53a57d2ed685940a504248187d5685e49eb5eef0f696853647bf37c418c538f7"},
    {file = "pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:09fb9dd6571aacd023fe6aaca316bd01cf60ab27240d7eb39ebd66a3a15293b4"},
    {file = "pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:0e6116757f7959a712db11f3e9c0a99ade00a5bbedae83cb801985aa154f071b"},
    {file = "pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8d55ab81c57b8ff8548c3e4947f119551253f4e3787a7bbc0b6b3ca47498a9d3"},
    {file = "pydantic_core-2.33.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:c20c462aa4434b33a2661701b861604913f912254e441ab8d78d30485736115a"},
    {file = "pydantic_core-2.33.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:44857c3227d3fb5e753d5fe4a3420d6376fa594b07b621e220cd93703fe21782"},
    {file = "pydantic_core-2.33.2-cp39-cp39-musllinux_1_1_armv7l.whl", hash = "sha256:eb9b459ca4df0e5c87deb59d37377461a538852765293f9e6ee834f0435a93b9"},
    {file = "pydantic_core-2.33.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:9fcd347d2cc5c23b06de6d3b7b8275be558a0c90549495c699e379a80bf8379e"},
    {file = "pydantic_core-2.33.2-cp39-cp39-win32.whl", hash = "sha256:83aa99b1285bc8f038941ddf598501a86f1536789740991d7d8756e34f1e74d9"},
    {file = "pydantic_core-2.33.2-cp39-cp39-win_amd64.whl", hash = "sha256:f481959862f57f29601ccced557cc2e817bce7533ab8e01a797a48b49c9692b3"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:5c4aa4e82353f65e548c476b37e64189783aa5384903bfea4f41580f255fddfa"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:d946c8bf0d5c24bf4fe333af284c59a19358aa3ec18cb3dc4370080da1e8ad29"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:87b31b6846e361ef83fedb187bb5b4372d0da3f7e28d85415efa92d6125d6e6d"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:aa9d91b338f2df0508606f7009fde642391425189bba6d8c653afd80fd6bb64e"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:2058a32994f1fde4ca0480ab9d1e75a0e8c87c22b53a3ae66554f9af78f2fe8c"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:0e03262ab796d986f978f79c943fc5f620381be7287148b8010b4097f79a39ec"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:1a8695a8d00c73e50bff9dfda4d540b7dee29ff9b8053e38380426a85ef10052"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:fa754d1850735a0b0e03bcffd9d4b4343eb417e47196e4485d9cca326073a42c"},
    {file = "pydantic_core-2.33.2-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:a11c8d26a50bfab49002947d3d237abe4d9e4b5bdc8846a63537b6488e197808"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-macosx_10_12_x86_64.whl", hash = "sha256:dd14041875d09cc0f9308e37a6f8b65f5585cf2598a53aa0123df8b129d481f8"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-macosx_11_0_arm64.whl", hash = "sha256:d87c561733f66531dced0da6e864f44ebf89a8fba55f31407b00c2f7f9449593"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2f82865531efd18d6e07a04a17331af02cb7a651583c418df8266f17a63c6612"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2bfb5112df54209d820d7bf9317c7a6c9025ea52e49f46b6a2060104bba37de7"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:64632ff9d614e5eecfb495796ad51b0ed98c453e447a76bcbeeb69615079fc7e"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:f889f7a40498cc077332c7ab6b4608d296d852182211787d4f3ee377aaae66e8"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:de4b83bb311557e439b9e186f733f6c645b9417c84e2eb8203f3f820a4b988bf"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:82f68293f055f51b51ea42fafc74b6aad03e70e191799430b90c13d643059ebb"},
    {file = "pydantic_core-2.33.2-pp311-pypy311_pp73-win_amd64.whl", hash = "sha256:329467cecfb529c925cf2bbd4d60d2c509bc2fb52a20c1045bf09bb70971a9c1"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-macosx_10_12_x86_64.whl", hash = "sha256:87acbfcf8e90ca885206e98359d7dca4bcbb35abdc0ff66672a293e1d7a19101"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:7f92c15cd1e97d4b12acd1cc9004fa092578acfa57b67ad5e43a197175d01a64"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d3f26877a748dc4251cfcfda9dfb5f13fcb034f5308388066bcfe9031b63ae7d"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dac89aea9af8cd672fa7b510e7b8c33b0bba9a43186680550ccf23020f32d535"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:970919794d126ba8645f3837ab6046fb4e72bbc057b3709144066204c19a455d"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:3eb3fe62804e8f859c49ed20a8451342de53ed764150cb14ca71357c765dc2a6"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:3abcd9392a36025e3bd55f9bd38d908bd17962cc49bc6da8e7e96285336e2bca"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:3a1c81334778f9e3af2f8aeb7a960736e5cab1dfebfb26aabca09afd2906c039"},
    {file = "pydantic_core-2.33.2-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:2807668ba86cb38c6817ad9bc66215ab8584d1d304030ce4f0887336f28a5e27"},
    {file = "pydantic_core-2.33.2.tar.gz", hash = "sha256:7cb8bc3605c29176e1b105350d2e6474142d7c1bd1d9327c4a9bdb46bf827acc"},
]

[package.dependencies]
typing-extensions = ">=4.6.0,<4.7.0 || >4.7.0"

[[package]]
name = "pydantic-settings"
version = "2.9.1"
description = "Settings management using Pydantic"
optional = false
python-versions = ">=3.9"
files = [
    {file = "pydantic_settings-2.9.1-py3-none-any.whl", hash = "sha256:59b4f431b1defb26fe620c71a7d3968a710d719f5f4cdbbdb7926edeb770f6ef"},
    {file = "pydantic_settings-2.9.1.tar.gz", hash = "sha256:c509bf79d27563add44e8446233359004ed85066cd096d8b510f715e6ef5d268"},
]

[package.dependencies]
pydantic = ">=2.7.0"
python-dotenv = ">=0.21.0"
typing-inspection = ">=0.4.0"

[package.extras]
aws-secrets-manager = ["boto3 (>=1.35.0)", "boto3-stubs[secretsmanager]"]
azure-key-vault = ["azure-identity (>=1.16.0)", "azure-keyvault-secrets (>=4.8.0)"]
gcp-secret-manager = ["google-cloud-secret-manager (>=2.23.1)"]
toml = ["tomli (>=2.0.1)"]
yaml = ["pyyaml (>=6.0.1)"]

[[package]]
name = "pyparsing"
version = "3.2.3"
description = "pyparsing module - Classes and methods to define and execute parsing grammars"
optional = false
python-versions = ">=3.9"
files = [
    {file = "pyparsing-3.2.3-py3-none-any.whl", hash = "sha256:a749938e02d6fd0b59b356ca504a24982314bb090c383e3cf201c95ef7e2bfcf"},
    {file = "pyparsing-3.2.3.tar.gz", hash = "sha256:b9c13f1ab8b3b542f72e28f634bad4de758ab3ce4546e4301970ad6fa77c38be"},
]

[package.extras]
diagrams = ["jinja2", "railroad-diagrams"]

[[package]]
name = "python-dotenv"
version = "1.1.0"
description = "Read key-value pairs from a .env file and set them as environment variables"
optional = false
python-versions = ">=3.9"
files = [
    {file = "python_dotenv-1.1.0-py3-none-any.whl", hash = "sha256:d7c01d9e2293916c18baf562d95698754b0dbbb5e74d457c45d4f6561fb9d55d"},
    {file = "python_dotenv-1.1.0.tar.gz", hash = "sha256:41f90bc6f5f177fb41f53e87666db362025010eb28f60a01c9143bfa33a2b2d5"},
]

[package.extras]
cli = ["click (>=5.0)"]

[[package]]
name = "python-engineio"
version = "4.12.1"
description = "Engine.IO server and client for Python"
optional = false
python-versions = ">=3.6"
files = [
    {file = "python_engineio-4.12.1-py3-none-any.whl", hash = "sha256:9ec20d7900def0886fb9621f86fd1f05140d407f8d4e6a51bef0cfba2d112ff7"},
    {file = "python_engineio-4.12.1.tar.gz", hash = "sha256:9f2b5a645c416208a9c727254316d487252493de52bee0ff70dc29ca9210397e"},
]

[package.dependencies]
simple-websocket = ">=0.10.0"

[package.extras]
asyncio-client = ["aiohttp (>=3.4)"]
client = ["requests (>=2.21.0)", "websocket-client (>=0.54.0)"]
docs = ["sphinx"]

[[package]]
name = "python-jose"
version = "3.4.0"
description = "JOSE implementation in Python"
optional = false
python-versions = "*"
files = [
    {file = "python-jose-3.4.0.tar.gz", hash = "sha256:9a9a40f418ced8ecaf7e3b28d69887ceaa76adad3bcaa6dae0d9e596fec1d680"},
    {file = "python_jose-3.4.0-py2.py3-none-any.whl", hash = "sha256:9c9f616819652d109bd889ecd1e15e9a162b9b94d682534c9c2146092945b78f"},
]

[package.dependencies]
cryptography = {version = ">=3.4.0", optional = true, markers = "extra == \"cryptography\""}
ecdsa = "!=0.15"
pyasn1 = ">=0.4.1,<0.5.0"
rsa = ">=4.0,<4.1.1 || >4.1.1,<4.4 || >4.4,<5.0"

[package.extras]
cryptography = ["cryptography (>=3.4.0)"]
pycrypto = ["pycrypto (>=2.6.0,<2.7.0)"]
pycryptodome = ["pycryptodome (>=3.3.1,<4.0.0)"]
test = ["pytest", "pytest-cov"]

[[package]]
name = "python-multipart"
version = "0.0.20"
description = "A streaming multipart parser for Python"
optional = false
python-versions = ">=3.8"
files = [
    {file = "python_multipart-0.0.20-py3-none-any.whl", hash = "sha256:8a62d3a8335e06589fe01f2a3e178cdcc632f3fbe0d492ad9ee0ec35aab1f104"},
    {file = "python_multipart-0.0.20.tar.gz", hash = "sha256:8dd0cab45b8e23064ae09147625994d090fa46f5b0d1e13af944c331a7fa9d13"},
]

[[package]]
name = "python-socketio"
version = "5.13.0"
description = "Socket.IO server and client for Python"
optional = false
python-versions = ">=3.8"
files = [
    {file = "python_socketio-5.13.0-py3-none-any.whl", hash = "sha256:51f68d6499f2df8524668c24bcec13ba1414117cfb3a90115c559b601ab10caf"},
    {file = "python_socketio-5.13.0.tar.gz", hash = "sha256:ac4e19a0302ae812e23b712ec8b6427ca0521f7c582d6abb096e36e24a263029"},
]

[package.dependencies]
bidict = ">=0.21.0"
python-engineio = ">=4.11.0"

[package.extras]
asyncio-client = ["aiohttp (>=3.4)"]
client = ["requests (>=2.21.0)", "websocket-client (>=0.54.0)"]
docs = ["sphinx"]

[[package]]
name = "pyyaml"
version = "6.0.2"
description = "YAML parser and emitter for Python"
optional = false
python-versions = ">=3.8"
files = [
    {file = "PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086"},
    {file = "PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:29717114e51c84ddfba879543fb232a6ed60086602313ca38cce623c1d62cfbf"},
    {file = "PyYAML-6.0.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8824b5a04a04a047e72eea5cec3bc266db09e35de6bdfe34c9436ac5ee27d237"},
    {file = "PyYAML-6.0.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7c36280e6fb8385e520936c3cb3b8042851904eba0e58d277dca80a5cfed590b"},
    {file = "PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ec031d5d2feb36d1d1a24380e4db6d43695f3748343d99434e6f5f9156aaa2ed"},
    {file = "PyYAML-6.0.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:936d68689298c36b53b29f23c6dbb74de12b4ac12ca6cfe0e047bedceea56180"},
    {file = "PyYAML-6.0.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:23502f431948090f597378482b4812b0caae32c22213aecf3b55325e049a6c68"},
    {file = "PyYAML-6.0.2-cp310-cp310-win32.whl", hash = "sha256:2e99c6826ffa974fe6e27cdb5ed0021786b03fc98e5ee3c5bfe1fd5015f42b99"},
    {file = "PyYAML-6.0.2-cp310-cp310-win_amd64.whl", hash = "sha256:a4d3091415f010369ae4ed1fc6b79def9416358877534caf6a0fdd2146c87a3e"},
    {file = "PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:cc1c1159b3d456576af7a3e4d1ba7e6924cb39de8f67111c735f6fc832082774"},
    {file = "PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:1e2120ef853f59c7419231f3bf4e7021f1b936f6ebd222406c3b60212205d2ee"},
    {file = "PyYAML-6.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5d225db5a45f21e78dd9358e58a98702a0302f2659a3c6cd320564b75b86f47c"},
    {file = "PyYAML-6.0.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5ac9328ec4831237bec75defaf839f7d4564be1e6b25ac710bd1a96321cc8317"},
    {file = "PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3ad2a3decf9aaba3d29c8f537ac4b243e36bef957511b4766cb0057d32b0be85"},
    {file = "PyYAML-6.0.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:ff3824dc5261f50c9b0dfb3be22b4567a6f938ccce4587b38952d85fd9e9afe4"},
    {file = "PyYAML-6.0.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:797b4f722ffa07cc8d62053e4cff1486fa6dc094105d13fea7b1de7d8bf71c9e"},
    {file = "PyYAML-6.0.2-cp311-cp311-win32.whl", hash = "sha256:11d8f3dd2b9c1207dcaf2ee0bbbfd5991f571186ec9cc78427ba5bd32afae4b5"},
    {file = "PyYAML-6.0.2-cp311-cp311-win_amd64.whl", hash = "sha256:e10ce637b18caea04431ce14fabcf5c64a1c61ec9c56b071a4b7ca131ca52d44"},
    {file = "PyYAML-6.0.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:c70c95198c015b85feafc136515252a261a84561b7b1d51e3384e0655ddf25ab"},
    {file = "PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:ce826d6ef20b1bc864f0a68340c8b3287705cae2f8b4b1d932177dcc76721725"},
    {file = "PyYAML-6.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f71ea527786de97d1a0cc0eacd1defc0985dcf6b3f17bb77dcfc8c34bec4dc5"},
    {file = "PyYAML-6.0.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9b22676e8097e9e22e36d6b7bda33190d0d400f345f23d4065d48f4ca7ae0425"},
    {file = "PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:80bab7bfc629882493af4aa31a4cfa43a4c57c83813253626916b8c7ada83476"},
    {file = "PyYAML-6.0.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48"},
    {file = "PyYAML-6.0.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:8b9c7197f7cb2738065c481a0461e50ad02f18c78cd75775628afb4d7137fb3b"},
    {file = "PyYAML-6.0.2-cp312-cp312-win32.whl", hash = "sha256:ef6107725bd54b262d6dedcc2af448a266975032bc85ef0172c5f059da6325b4"},
    {file = "PyYAML-6.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:7e7401d0de89a9a855c839bc697c079a4af81cf878373abd7dc625847d25cbd8"},
    {file = "PyYAML-6.0.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:efdca5630322a10774e8e98e1af481aad470dd62c3170801852d752aa7a783ba"},
    {file = "PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:50187695423ffe49e2deacb8cd10510bc361faac997de9efef88badc3bb9e2d1"},
    {file = "PyYAML-6.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0ffe8360bab4910ef1b9e87fb812d8bc0a308b0d0eef8c8f44e0254ab3b07133"},
    {file = "PyYAML-6.0.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:17e311b6c678207928d649faa7cb0d7b4c26a0ba73d41e99c4fff6b6c3276484"},
    {file = "PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:70b189594dbe54f75ab3a1acec5f1e3faa7e8cf2f1e08d9b561cb41b845f69d5"},
    {file = "PyYAML-6.0.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:41e4e3953a79407c794916fa277a82531dd93aad34e29c2a514c2c0c5fe971cc"},
    {file = "PyYAML-6.0.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:68ccc6023a3400877818152ad9a1033e3db8625d899c72eacb5a668902e4d652"},
    {file = "PyYAML-6.0.2-cp313-cp313-win32.whl", hash = "sha256:bc2fa7c6b47d6bc618dd7fb02ef6fdedb1090ec036abab80d4681424b84c1183"},
    {file = "PyYAML-6.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:8388ee1976c416731879ac16da0aff3f63b286ffdd57cdeb95f3f2e085687563"},
    {file = "PyYAML-6.0.2-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:24471b829b3bf607e04e88d79542a9d48bb037c2267d7927a874e6c205ca7e9a"},
    {file = "PyYAML-6.0.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d7fded462629cfa4b685c5416b949ebad6cec74af5e2d42905d41e257e0869f5"},
    {file = "PyYAML-6.0.2-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d84a1718ee396f54f3a086ea0a66d8e552b2ab2017ef8b420e92edbc841c352d"},
    {file = "PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9056c1ecd25795207ad294bcf39f2db3d845767be0ea6e6a34d856f006006083"},
    {file = "PyYAML-6.0.2-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:82d09873e40955485746739bcb8b4586983670466c23382c19cffecbf1fd8706"},
    {file = "PyYAML-6.0.2-cp38-cp38-win32.whl", hash = "sha256:43fa96a3ca0d6b1812e01ced1044a003533c47f6ee8aca31724f78e93ccc089a"},
    {file = "PyYAML-6.0.2-cp38-cp38-win_amd64.whl", hash = "sha256:01179a4a8559ab5de078078f37e5c1a30d76bb88519906844fd7bdea1b7729ff"},
    {file = "PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:688ba32a1cffef67fd2e9398a2efebaea461578b0923624778664cc1c914db5d"},
    {file = "PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a8786accb172bd8afb8be14490a16625cbc387036876ab6ba70912730faf8e1f"},
    {file = "PyYAML-6.0.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d8e03406cac8513435335dbab54c0d385e4a49e4945d2909a581c83647ca0290"},
    {file = "PyYAML-6.0.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f753120cb8181e736c57ef7636e83f31b9c0d1722c516f7e86cf15b7aa57ff12"},
    {file = "PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3b1fdb9dc17f5a7677423d508ab4f243a726dea51fa5e70992e59a7411c89d19"},
    {file = "PyYAML-6.0.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:0b69e4ce7a131fe56b7e4d770c67429700908fc0752af059838b1cfb41960e4e"},
    {file = "PyYAML-6.0.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:a9f8c2e67970f13b16084e04f134610fd1d374bf477b17ec1599185cf611d725"},
    {file = "PyYAML-6.0.2-cp39-cp39-win32.whl", hash = "sha256:6395c297d42274772abc367baaa79683958044e5d3835486c16da75d2a694631"},
    {file = "PyYAML-6.0.2-cp39-cp39-win_amd64.whl", hash = "sha256:39693e1f8320ae4f43943590b49779ffb98acb81f788220ea932a6b6c51004d8"},
    {file = "pyyaml-6.0.2.tar.gz", hash = "sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e"},
]

[[package]]
name = "requests"
version = "2.32.3"
description = "Python HTTP for Humans."
optional = false
python-versions = ">=3.8"
files = [
    {file = "requests-2.32.3-py3-none-any.whl", hash = "sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6"},
    {file = "requests-2.32.3.tar.gz", hash = "sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760"},
]

[package.dependencies]
certifi = ">=2017.4.17"
charset-normalizer = ">=2,<4"
idna = ">=2.5,<4"
urllib3 = ">=1.21.1,<3"

[package.extras]
socks = ["PySocks (>=1.5.6,!=1.5.7)"]
use-chardet-on-py3 = ["chardet (>=3.0.2,<6)"]

[[package]]
name = "resend"
version = "2.10.0"
description = "Resend Python SDK"
optional = false
python-versions = ">=3.7"
files = [
    {file = "resend-2.10.0-py2.py3-none-any.whl", hash = "sha256:1d65a36b032522d5eb738e08956ca29cbaa217a270efbe915a071eb72c0d6956"},
    {file = "resend-2.10.0.tar.gz", hash = "sha256:f9091f487f0d878095bb7a744549969c624815413b7ac82ba92039e2d0804b75"},
]

[package.dependencies]
requests = ">=2.31.0"
typing-extensions = ">=4.4.0"

[[package]]
name = "rsa"
version = "4.9.1"
description = "Pure-Python RSA implementation"
optional = false
python-versions = "<4,>=3.6"
files = [
    {file = "rsa-4.9.1-py3-none-any.whl", hash = "sha256:68635866661c6836b8d39430f97a996acbd61bfa49406748ea243539fe239762"},
    {file = "rsa-4.9.1.tar.gz", hash = "sha256:e7bdbfdb5497da4c07dfd35530e1a902659db6ff241e39d9953cad06ebd0ae75"},
]

[package.dependencies]
pyasn1 = ">=0.1.3"

[[package]]
name = "simple-websocket"
version = "1.1.0"
description = "Simple WebSocket server and client for Python"
optional = false
python-versions = ">=3.6"
files = [
    {file = "simple_websocket-1.1.0-py3-none-any.whl", hash = "sha256:4af6069630a38ed6c561010f0e11a5bc0d4ca569b36306eb257cd9a192497c8c"},
    {file = "simple_websocket-1.1.0.tar.gz", hash = "sha256:7939234e7aa067c534abdab3a9ed933ec9ce4691b0713c78acb195560aa52ae4"},
]

[package.dependencies]
wsproto = "*"

[package.extras]
dev = ["flake8", "pytest", "pytest-cov", "tox"]
docs = ["sphinx"]

[[package]]
name = "six"
version = "1.17.0"
description = "Python 2 and 3 compatibility utilities"
optional = false
python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,>=2.7"
files = [
    {file = "six-1.17.0-py2.py3-none-any.whl", hash = "sha256:4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274"},
    {file = "six-1.17.0.tar.gz", hash = "sha256:ff70335d468e7eb6ec65b95b99d3a2836546063f63acc5171de367e834932a81"},
]

[[package]]
name = "sniffio"
version = "1.3.1"
description = "Sniff out which async library your code is running under"
optional = false
python-versions = ">=3.7"
files = [
    {file = "sniffio-1.3.1-py3-none-any.whl", hash = "sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2"},
    {file = "sniffio-1.3.1.tar.gz", hash = "sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc"},
]

[[package]]
name = "sqlalchemy"
version = "2.0.41"
description = "Database Abstraction Library"
optional = false
python-versions = ">=3.7"
files = [
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-macosx_10_9_x86_64.whl", hash = "sha256:6854175807af57bdb6425e47adbce7d20a4d79bbfd6f6d6519cd10bb7109a7f8"},
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:05132c906066142103b83d9c250b60508af556982a385d96c4eaa9fb9720ac2b"},
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8b4af17bda11e907c51d10686eda89049f9ce5669b08fbe71a29747f1e876036"},
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-musllinux_1_2_aarch64.whl", hash = "sha256:c0b0e5e1b5d9f3586601048dd68f392dc0cc99a59bb5faf18aab057ce00d00b2"},
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-musllinux_1_2_x86_64.whl", hash = "sha256:0b3dbf1e7e9bc95f4bac5e2fb6d3fb2f083254c3fdd20a1789af965caf2d2348"},
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-win32.whl", hash = "sha256:1e3f196a0c59b0cae9a0cd332eb1a4bda4696e863f4f1cf84ab0347992c548c2"},
    {file = "SQLAlchemy-2.0.41-cp37-cp37m-win_amd64.whl", hash = "sha256:6ab60a5089a8f02009f127806f777fca82581c49e127f08413a66056bd9166dd"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:b1f09b6821406ea1f94053f346f28f8215e293344209129a9c0fcc3578598d7b"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:1936af879e3db023601196a1684d28e12f19ccf93af01bf3280a3262c4b6b4e5"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b2ac41acfc8d965fb0c464eb8f44995770239668956dc4cdf502d1b1ffe0d747"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:81c24e0c0fde47a9723c81d5806569cddef103aebbf79dbc9fcbb617153dea30"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:23a8825495d8b195c4aa9ff1c430c28f2c821e8c5e2d98089228af887e5d7e29"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:60c578c45c949f909a4026b7807044e7e564adf793537fc762b2489d522f3d11"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-win32.whl", hash = "sha256:118c16cd3f1b00c76d69343e38602006c9cfb9998fa4f798606d28d63f23beda"},
    {file = "sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl", hash = "sha256:7492967c3386df69f80cf67efd665c0f667cee67032090fe01d7d74b0e19bb08"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:6375cd674fe82d7aa9816d1cb96ec592bac1726c11e0cafbf40eeee9a4516b5f"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:9f8c9fdd15a55d9465e590a402f42082705d66b05afc3ffd2d2eb3c6ba919560"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:32f9dc8c44acdee06c8fc6440db9eae8b4af8b01e4b1aee7bdd7241c22edff4f"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:90c11ceb9a1f482c752a71f203a81858625d8df5746d787a4786bca4ffdf71c6"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:911cc493ebd60de5f285bcae0491a60b4f2a9f0f5c270edd1c4dbaef7a38fc04"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:03968a349db483936c249f4d9cd14ff2c296adfa1290b660ba6516f973139582"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-win32.whl", hash = "sha256:293cd444d82b18da48c9f71cd7005844dbbd06ca19be1ccf6779154439eec0b8"},
    {file = "sqlalchemy-2.0.41-cp311-cp311-win_amd64.whl", hash = "sha256:3d3549fc3e40667ec7199033a4e40a2f669898a00a7b18a931d3efb4c7900504"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:81f413674d85cfd0dfcd6512e10e0f33c19c21860342a4890c3a2b59479929f9"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:598d9ebc1e796431bbd068e41e4de4dc34312b7aa3292571bb3674a0cb415dd1"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a104c5694dfd2d864a6f91b0956eb5d5883234119cb40010115fd45a16da5e70"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6145afea51ff0af7f2564a05fa95eb46f542919e6523729663a5d285ecb3cf5e"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:b46fa6eae1cd1c20e6e6f44e19984d438b6b2d8616d21d783d150df714f44078"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:41836fe661cc98abfae476e14ba1906220f92c4e528771a8a3ae6a151242d2ae"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-win32.whl", hash = "sha256:a8808d5cf866c781150d36a3c8eb3adccfa41a8105d031bf27e92c251e3969d6"},
    {file = "sqlalchemy-2.0.41-cp312-cp312-win_amd64.whl", hash = "sha256:5b14e97886199c1f52c14629c11d90c11fbb09e9334fa7bb5f6d068d9ced0ce0"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:4eeb195cdedaf17aab6b247894ff2734dcead6c08f748e617bfe05bd5a218443"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:d4ae769b9c1c7757e4ccce94b0641bc203bbdf43ba7a2413ab2523d8d047d8dc"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a62448526dd9ed3e3beedc93df9bb6b55a436ed1474db31a2af13b313a70a7e1"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dc56c9788617b8964ad02e8fcfeed4001c1f8ba91a9e1f31483c0dffb207002a"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:c153265408d18de4cc5ded1941dcd8315894572cddd3c58df5d5b5705b3fa28d"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:4f67766965996e63bb46cfbf2ce5355fc32d9dd3b8ad7e536a920ff9ee422e23"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-win32.whl", hash = "sha256:bfc9064f6658a3d1cadeaa0ba07570b83ce6801a1314985bf98ec9b95d74e15f"},
    {file = "sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl", hash = "sha256:82ca366a844eb551daff9d2e6e7a9e5e76d2612c8564f58db6c19a726869c1df"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:90144d3b0c8b139408da50196c5cad2a6909b51b23df1f0538411cd23ffa45d3"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:023b3ee6169969beea3bb72312e44d8b7c27c75b347942d943cf49397b7edeb5"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:725875a63abf7c399d4548e686debb65cdc2549e1825437096a0af1f7e374814"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:81965cc20848ab06583506ef54e37cf15c83c7e619df2ad16807c03100745dea"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:dd5ec3aa6ae6e4d5b5de9357d2133c07be1aff6405b136dad753a16afb6717dd"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:ff8e80c4c4932c10493ff97028decfdb622de69cae87e0f127a7ebe32b4069c6"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-win32.whl", hash = "sha256:4d44522480e0bf34c3d63167b8cfa7289c1c54264c2950cc5fc26e7850967e45"},
    {file = "sqlalchemy-2.0.41-cp38-cp38-win_amd64.whl", hash = "sha256:81eedafa609917040d39aa9332e25881a8e7a0862495fcdf2023a9667209deda"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:9a420a91913092d1e20c86a2f5f1fc85c1a8924dbcaf5e0586df8aceb09c9cc2"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:906e6b0d7d452e9a98e5ab8507c0da791856b2380fdee61b765632bb8698026f"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a373a400f3e9bac95ba2a06372c4fd1412a7cee53c37fc6c05f829bf672b8769"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:087b6b52de812741c27231b5a3586384d60c353fbd0e2f81405a814b5591dc8b"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:34ea30ab3ec98355235972dadc497bb659cc75f8292b760394824fab9cf39826"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:8280856dd7c6a68ab3a164b4a4b1c51f7691f6d04af4d4ca23d6ecf2261b7923"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-win32.whl", hash = "sha256:b50eab9994d64f4a823ff99a0ed28a6903224ddbe7fef56a6dd865eec9243440"},
    {file = "sqlalchemy-2.0.41-cp39-cp39-win_amd64.whl", hash = "sha256:5e22575d169529ac3e0a120cf050ec9daa94b6a9597993d1702884f6954a7d71"},
    {file = "sqlalchemy-2.0.41-py3-none-any.whl", hash = "sha256:57df5dc6fdb5ed1a88a1ed2195fd31927e705cad62dedd86b46972752a80f576"},
    {file = "sqlalchemy-2.0.41.tar.gz", hash = "sha256:edba70118c4be3c2b1f90754d308d0b79c6fe2c0fdc52d8ddf603916f83f4db9"},
]

[package.dependencies]
greenlet = {version = ">=1", optional = true, markers = "python_version < \"3.14\" and (platform_machine == \"aarch64\" or platform_machine == \"ppc64le\" or platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\" or platform_machine == \"win32\" or platform_machine == \"WIN32\") or extra == \"asyncio\""}
typing-extensions = ">=4.6.0"

[package.extras]
aiomysql = ["aiomysql (>=0.2.0)", "greenlet (>=1)"]
aioodbc = ["aioodbc", "greenlet (>=1)"]
aiosqlite = ["aiosqlite", "greenlet (>=1)", "typing_extensions (!=3.10.0.1)"]
asyncio = ["greenlet (>=1)"]
asyncmy = ["asyncmy (>=0.2.3,!=0.2.4,!=0.2.6)", "greenlet (>=1)"]
mariadb-connector = ["mariadb (>=1.0.1,!=1.1.2,!=1.1.5,!=1.1.10)"]
mssql = ["pyodbc"]
mssql-pymssql = ["pymssql"]
mssql-pyodbc = ["pyodbc"]
mypy = ["mypy (>=0.910)"]
mysql = ["mysqlclient (>=1.4.0)"]
mysql-connector = ["mysql-connector-python"]
oracle = ["cx_oracle (>=8)"]
oracle-oracledb = ["oracledb (>=1.0.1)"]
postgresql = ["psycopg2 (>=2.7)"]
postgresql-asyncpg = ["asyncpg", "greenlet (>=1)"]
postgresql-pg8000 = ["pg8000 (>=1.29.1)"]
postgresql-psycopg = ["psycopg (>=3.0.7)"]
postgresql-psycopg2binary = ["psycopg2-binary"]
postgresql-psycopg2cffi = ["psycopg2cffi"]
postgresql-psycopgbinary = ["psycopg[binary] (>=3.0.7)"]
pymysql = ["pymysql"]
sqlcipher = ["sqlcipher3_binary"]

[[package]]
name = "starlette"
version = "0.46.2"
description = "The little ASGI library that shines."
optional = false
python-versions = ">=3.9"
files = [
    {file = "starlette-0.46.2-py3-none-any.whl", hash = "sha256:595633ce89f8ffa71a015caed34a5b2dc1c0cdb3f0f1fbd1e69339cf2abeec35"},
    {file = "starlette-0.46.2.tar.gz", hash = "sha256:7f7361f34eed179294600af672f565727419830b54b7b084efe44bb82d2fccd5"},
]

[package.dependencies]
anyio = ">=3.6.2,<5"

[package.extras]
full = ["httpx (>=0.27.0,<0.29.0)", "itsdangerous", "jinja2", "python-multipart (>=0.0.18)", "pyyaml"]

[[package]]
name = "tqdm"
version = "4.67.1"
description = "Fast, Extensible Progress Meter"
optional = false
python-versions = ">=3.7"
files = [
    {file = "tqdm-4.67.1-py3-none-any.whl", hash = "sha256:26445eca388f82e72884e0d580d5464cd801a3ea01e63e5601bdff9ba6a48de2"},
    {file = "tqdm-4.67.1.tar.gz", hash = "sha256:f8aef9c52c08c13a65f30ea34f4e5aac3fd1a34959879d7e59e63027286627f2"},
]

[package.dependencies]
colorama = {version = "*", markers = "platform_system == \"Windows\""}

[package.extras]
dev = ["nbval", "pytest (>=6)", "pytest-asyncio (>=0.24)", "pytest-cov", "pytest-timeout"]
discord = ["requests"]
notebook = ["ipywidgets (>=6)"]
slack = ["slack-sdk"]
telegram = ["requests"]

[[package]]
name = "typing-extensions"
version = "4.13.2"
description = "Backported and Experimental Type Hints for Python 3.8+"
optional = false
python-versions = ">=3.8"
files = [
    {file = "typing_extensions-4.13.2-py3-none-any.whl", hash = "sha256:a439e7c04b49fec3e5d3e2beaa21755cadbbdc391694e28ccdd36ca4a1408f8c"},
    {file = "typing_extensions-4.13.2.tar.gz", hash = "sha256:e6c81219bd689f51865d9e372991c540bda33a0379d5573cddb9a3a23f7caaef"},
]

[[package]]
name = "typing-inspection"
version = "0.4.1"
description = "Runtime typing introspection tools"
optional = false
python-versions = ">=3.9"
files = [
    {file = "typing_inspection-0.4.1-py3-none-any.whl", hash = "sha256:389055682238f53b04f7badcb49b989835495a96700ced5dab2d8feae4b26f51"},
    {file = "typing_inspection-0.4.1.tar.gz", hash = "sha256:6ae134cc0203c33377d43188d4064e9b357dba58cff3185f22924610e70a9d28"},
]

[package.dependencies]
typing-extensions = ">=4.12.0"

[[package]]
name = "tzdata"
version = "2025.2"
description = "Provider of IANA time zone data"
optional = false
python-versions = ">=2"
files = [
    {file = "tzdata-2025.2-py2.py3-none-any.whl", hash = "sha256:1a403fada01ff9221ca8044d701868fa132215d84beb92242d9acd2147f667a8"},
    {file = "tzdata-2025.2.tar.gz", hash = "sha256:b60a638fcc0daffadf82fe0f57e53d06bdec2f36c4df66280ae79bce6bd6f2b9"},
]

[[package]]
name = "uritemplate"
version = "4.1.1"
description = "Implementation of RFC 6570 URI Templates"
optional = false
python-versions = ">=3.6"
files = [
    {file = "uritemplate-4.1.1-py2.py3-none-any.whl", hash = "sha256:830c08b8d99bdd312ea4ead05994a38e8936266f84b9a7878232db50b044e02e"},
    {file = "uritemplate-4.1.1.tar.gz", hash = "sha256:4346edfc5c3b79f694bccd6d6099a322bbeb628dbf2cd86eea55a456ce5124f0"},
]

[[package]]
name = "urllib3"
version = "2.4.0"
description = "HTTP library with thread-safe connection pooling, file post, and more."
optional = false
python-versions = ">=3.9"
files = [
    {file = "urllib3-2.4.0-py3-none-any.whl", hash = "sha256:4e16665048960a0900c702d4a66415956a584919c03361cac9f1df5c5dd7e813"},
    {file = "urllib3-2.4.0.tar.gz", hash = "sha256:414bc6535b787febd7567804cc015fee39daab8ad86268f1310a9250697de466"},
]

[package.extras]
brotli = ["brotli (>=1.0.9)", "brotlicffi (>=0.8.0)"]
h2 = ["h2 (>=4,<5)"]
socks = ["pysocks (>=1.5.6,!=1.5.7,<2.0)"]
zstd = ["zstandard (>=0.18.0)"]

[[package]]
name = "uvicorn"
version = "0.34.2"
description = "The lightning-fast ASGI server."
optional = false
python-versions = ">=3.9"
files = [
    {file = "uvicorn-0.34.2-py3-none-any.whl", hash = "sha256:deb49af569084536d269fe0a6d67e3754f104cf03aba7c11c40f01aadf33c403"},
    {file = "uvicorn-0.34.2.tar.gz", hash = "sha256:0e929828f6186353a80b58ea719861d2629d766293b6d19baf086ba31d4f3328"},
]

[package.dependencies]
click = ">=7.0"
colorama = {version = ">=0.4", optional = true, markers = "sys_platform == \"win32\" and extra == \"standard\""}
h11 = ">=0.8"
httptools = {version = ">=0.6.3", optional = true, markers = "extra == \"standard\""}
python-dotenv = {version = ">=0.13", optional = true, markers = "extra == \"standard\""}
pyyaml = {version = ">=5.1", optional = true, markers = "extra == \"standard\""}
uvloop = {version = ">=0.14.0,<0.15.0 || >0.15.0,<0.15.1 || >0.15.1", optional = true, markers = "(sys_platform != \"win32\" and sys_platform != \"cygwin\") and platform_python_implementation != \"PyPy\" and extra == \"standard\""}
watchfiles = {version = ">=0.13", optional = true, markers = "extra == \"standard\""}
websockets = {version = ">=10.4", optional = true, markers = "extra == \"standard\""}

[package.extras]
standard = ["colorama (>=0.4)", "httptools (>=0.6.3)", "python-dotenv (>=0.13)", "pyyaml (>=5.1)", "uvloop (>=0.14.0,!=0.15.0,!=0.15.1)", "watchfiles (>=0.13)", "websockets (>=10.4)"]

[[package]]
name = "uvloop"
version = "0.21.0"
description = "Fast implementation of asyncio event loop on top of libuv"
optional = false
python-versions = ">=3.8.0"
files = [
    {file = "uvloop-0.21.0-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:ec7e6b09a6fdded42403182ab6b832b71f4edaf7f37a9a0e371a01db5f0cb45f"},
    {file = "uvloop-0.21.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:196274f2adb9689a289ad7d65700d37df0c0930fd8e4e743fa4834e850d7719d"},
    {file = "uvloop-0.21.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f38b2e090258d051d68a5b14d1da7203a3c3677321cf32a95a6f4db4dd8b6f26"},
    {file = "uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:87c43e0f13022b998eb9b973b5e97200c8b90823454d4bc06ab33829e09fb9bb"},
    {file = "uvloop-0.21.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:10d66943def5fcb6e7b37310eb6b5639fd2ccbc38df1177262b0640c3ca68c1f"},
    {file = "uvloop-0.21.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:67dd654b8ca23aed0a8e99010b4c34aca62f4b7fce88f39d452ed7622c94845c"},
    {file = "uvloop-0.21.0-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:c0f3fa6200b3108919f8bdabb9a7f87f20e7097ea3c543754cabc7d717d95cf8"},
    {file = "uvloop-0.21.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:0878c2640cf341b269b7e128b1a5fed890adc4455513ca710d77d5e93aa6d6a0"},
    {file = "uvloop-0.21.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b9fb766bb57b7388745d8bcc53a359b116b8a04c83a2288069809d2b3466c37e"},
    {file = "uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8a375441696e2eda1c43c44ccb66e04d61ceeffcd76e4929e527b7fa401b90fb"},
    {file = "uvloop-0.21.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:baa0e6291d91649c6ba4ed4b2f982f9fa165b5bbd50a9e203c416a2797bab3c6"},
    {file = "uvloop-0.21.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:4509360fcc4c3bd2c70d87573ad472de40c13387f5fda8cb58350a1d7475e58d"},
    {file = "uvloop-0.21.0-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:359ec2c888397b9e592a889c4d72ba3d6befba8b2bb01743f72fffbde663b59c"},
    {file = "uvloop-0.21.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:f7089d2dc73179ce5ac255bdf37c236a9f914b264825fdaacaded6990a7fb4c2"},
    {file = "uvloop-0.21.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:baa4dcdbd9ae0a372f2167a207cd98c9f9a1ea1188a8a526431eef2f8116cc8d"},
    {file = "uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:86975dca1c773a2c9864f4c52c5a55631038e387b47eaf56210f873887b6c8dc"},
    {file = "uvloop-0.21.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:461d9ae6660fbbafedd07559c6a2e57cd553b34b0065b6550685f6653a98c1cb"},
    {file = "uvloop-0.21.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:183aef7c8730e54c9a3ee3227464daed66e37ba13040bb3f350bc2ddc040f22f"},
    {file = "uvloop-0.21.0-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:bfd55dfcc2a512316e65f16e503e9e450cab148ef11df4e4e679b5e8253a5281"},
    {file = "uvloop-0.21.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:787ae31ad8a2856fc4e7c095341cccc7209bd657d0e71ad0dc2ea83c4a6fa8af"},
    {file = "uvloop-0.21.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5ee4d4ef48036ff6e5cfffb09dd192c7a5027153948d85b8da7ff705065bacc6"},
    {file = "uvloop-0.21.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f3df876acd7ec037a3d005b3ab85a7e4110422e4d9c1571d4fc89b0fc41b6816"},
    {file = "uvloop-0.21.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:bd53ecc9a0f3d87ab847503c2e1552b690362e005ab54e8a48ba97da3924c0dc"},
    {file = "uvloop-0.21.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:a5c39f217ab3c663dc699c04cbd50c13813e31d917642d459fdcec07555cc553"},
    {file = "uvloop-0.21.0-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:17df489689befc72c39a08359efac29bbee8eee5209650d4b9f34df73d22e414"},
    {file = "uvloop-0.21.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:bc09f0ff191e61c2d592a752423c767b4ebb2986daa9ed62908e2b1b9a9ae206"},
    {file = "uvloop-0.21.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f0ce1b49560b1d2d8a2977e3ba4afb2414fb46b86a1b64056bc4ab929efdafbe"},
    {file = "uvloop-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e678ad6fe52af2c58d2ae3c73dc85524ba8abe637f134bf3564ed07f555c5e79"},
    {file = "uvloop-0.21.0-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:460def4412e473896ef179a1671b40c039c7012184b627898eea5072ef6f017a"},
    {file = "uvloop-0.21.0-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:10da8046cc4a8f12c91a1c39d1dd1585c41162a15caaef165c2174db9ef18bdc"},
    {file = "uvloop-0.21.0-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:c097078b8031190c934ed0ebfee8cc5f9ba9642e6eb88322b9958b649750f72b"},
    {file = "uvloop-0.21.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:46923b0b5ee7fc0020bef24afe7836cb068f5050ca04caf6b487c513dc1a20b2"},
    {file = "uvloop-0.21.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:53e420a3afe22cdcf2a0f4846e377d16e718bc70103d7088a4f7623567ba5fb0"},
    {file = "uvloop-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:88cb67cdbc0e483da00af0b2c3cdad4b7c61ceb1ee0f33fe00e09c81e3a6cb75"},
    {file = "uvloop-0.21.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:221f4f2a1f46032b403bf3be628011caf75428ee3cc204a22addf96f586b19fd"},
    {file = "uvloop-0.21.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:2d1f581393673ce119355d56da84fe1dd9d2bb8b3d13ce792524e1607139feff"},
    {file = "uvloop-0.21.0.tar.gz", hash = "sha256:3bf12b0fda68447806a7ad847bfa591613177275d35b6724b1ee573faa3704e3"},
]

[package.extras]
dev = ["Cython (>=3.0,<4.0)", "setuptools (>=60)"]
docs = ["Sphinx (>=4.1.2,<4.2.0)", "sphinx-rtd-theme (>=0.5.2,<0.6.0)", "sphinxcontrib-asyncio (>=0.3.0,<0.4.0)"]
test = ["aiohttp (>=3.10.5)", "flake8 (>=5.0,<6.0)", "mypy (>=0.800)", "psutil", "pyOpenSSL (>=23.0.0,<23.1.0)", "pycodestyle (>=2.9.0,<2.10.0)"]

[[package]]
name = "watchfiles"
version = "1.0.5"
description = "Simple, modern and high performance file watching and code reload in python."
optional = false
python-versions = ">=3.9"
files = [
    {file = "watchfiles-1.0.5-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:5c40fe7dd9e5f81e0847b1ea64e1f5dd79dd61afbedb57759df06767ac719b40"},
    {file = "watchfiles-1.0.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8c0db396e6003d99bb2d7232c957b5f0b5634bbd1b24e381a5afcc880f7373fb"},
    {file = "watchfiles-1.0.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b551d4fb482fc57d852b4541f911ba28957d051c8776e79c3b4a51eb5e2a1b11"},
    {file = "watchfiles-1.0.5-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:830aa432ba5c491d52a15b51526c29e4a4b92bf4f92253787f9726fe01519487"},
    {file = "watchfiles-1.0.5-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a16512051a822a416b0d477d5f8c0e67b67c1a20d9acecb0aafa3aa4d6e7d256"},
    {file = "watchfiles-1.0.5-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:bfe0cbc787770e52a96c6fda6726ace75be7f840cb327e1b08d7d54eadc3bc85"},
    {file = "watchfiles-1.0.5-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d363152c5e16b29d66cbde8fa614f9e313e6f94a8204eaab268db52231fe5358"},
    {file = "watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7ee32c9a9bee4d0b7bd7cbeb53cb185cf0b622ac761efaa2eba84006c3b3a614"},
    {file = "watchfiles-1.0.5-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:29c7fd632ccaf5517c16a5188e36f6612d6472ccf55382db6c7fe3fcccb7f59f"},
    {file = "watchfiles-1.0.5-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:8e637810586e6fe380c8bc1b3910accd7f1d3a9a7262c8a78d4c8fb3ba6a2b3d"},
    {file = "watchfiles-1.0.5-cp310-cp310-win32.whl", hash = "sha256:cd47d063fbeabd4c6cae1d4bcaa38f0902f8dc5ed168072874ea11d0c7afc1ff"},
    {file = "watchfiles-1.0.5-cp310-cp310-win_amd64.whl", hash = "sha256:86c0df05b47a79d80351cd179893f2f9c1b1cae49d96e8b3290c7f4bd0ca0a92"},
    {file = "watchfiles-1.0.5-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:237f9be419e977a0f8f6b2e7b0475ababe78ff1ab06822df95d914a945eac827"},
    {file = "watchfiles-1.0.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:e0da39ff917af8b27a4bdc5a97ac577552a38aac0d260a859c1517ea3dc1a7c4"},
    {file = "watchfiles-1.0.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2cfcb3952350e95603f232a7a15f6c5f86c5375e46f0bd4ae70d43e3e063c13d"},
    {file = "watchfiles-1.0.5-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:68b2dddba7a4e6151384e252a5632efcaa9bc5d1c4b567f3cb621306b2ca9f63"},
    {file = "watchfiles-1.0.5-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:95cf944fcfc394c5f9de794ce581914900f82ff1f855326f25ebcf24d5397418"},
    {file = "watchfiles-1.0.5-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ecf6cd9f83d7c023b1aba15d13f705ca7b7d38675c121f3cc4a6e25bd0857ee9"},
    {file = "watchfiles-1.0.5-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:852de68acd6212cd6d33edf21e6f9e56e5d98c6add46f48244bd479d97c967c6"},
    {file = "watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d5730f3aa35e646103b53389d5bc77edfbf578ab6dab2e005142b5b80a35ef25"},
    {file = "watchfiles-1.0.5-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:18b3bd29954bc4abeeb4e9d9cf0b30227f0f206c86657674f544cb032296acd5"},
    {file = "watchfiles-1.0.5-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:ba5552a1b07c8edbf197055bc9d518b8f0d98a1c6a73a293bc0726dce068ed01"},
    {file = "watchfiles-1.0.5-cp311-cp311-win32.whl", hash = "sha256:2f1fefb2e90e89959447bc0420fddd1e76f625784340d64a2f7d5983ef9ad246"},
    {file = "watchfiles-1.0.5-cp311-cp311-win_amd64.whl", hash = "sha256:b6e76ceb1dd18c8e29c73f47d41866972e891fc4cc7ba014f487def72c1cf096"},
    {file = "watchfiles-1.0.5-cp311-cp311-win_arm64.whl", hash = "sha256:266710eb6fddc1f5e51843c70e3bebfb0f5e77cf4f27129278c70554104d19ed"},
    {file = "watchfiles-1.0.5-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:b5eb568c2aa6018e26da9e6c86f3ec3fd958cee7f0311b35c2630fa4217d17f2"},
    {file = "watchfiles-1.0.5-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:0a04059f4923ce4e856b4b4e5e783a70f49d9663d22a4c3b3298165996d1377f"},
    {file = "watchfiles-1.0.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3e380c89983ce6e6fe2dd1e1921b9952fb4e6da882931abd1824c092ed495dec"},
    {file = "watchfiles-1.0.5-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:fe43139b2c0fdc4a14d4f8d5b5d967f7a2777fd3d38ecf5b1ec669b0d7e43c21"},
    {file = "watchfiles-1.0.5-cp312-cp312-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ee0822ce1b8a14fe5a066f93edd20aada932acfe348bede8aa2149f1a4489512"},
    {file = "watchfiles-1.0.5-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:a0dbcb1c2d8f2ab6e0a81c6699b236932bd264d4cef1ac475858d16c403de74d"},
    {file = "watchfiles-1.0.5-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a2014a2b18ad3ca53b1f6c23f8cd94a18ce930c1837bd891262c182640eb40a6"},
    {file = "watchfiles-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:10f6ae86d5cb647bf58f9f655fcf577f713915a5d69057a0371bc257e2553234"},
    {file = "watchfiles-1.0.5-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:1a7bac2bde1d661fb31f4d4e8e539e178774b76db3c2c17c4bb3e960a5de07a2"},
    {file = "watchfiles-1.0.5-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ab626da2fc1ac277bbf752446470b367f84b50295264d2d313e28dc4405d663"},
    {file = "watchfiles-1.0.5-cp312-cp312-win32.whl", hash = "sha256:9f4571a783914feda92018ef3901dab8caf5b029325b5fe4558c074582815249"},
    {file = "watchfiles-1.0.5-cp312-cp312-win_amd64.whl", hash = "sha256:360a398c3a19672cf93527f7e8d8b60d8275119c5d900f2e184d32483117a705"},
    {file = "watchfiles-1.0.5-cp312-cp312-win_arm64.whl", hash = "sha256:1a2902ede862969077b97523987c38db28abbe09fb19866e711485d9fbf0d417"},
    {file = "watchfiles-1.0.5-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:0b289572c33a0deae62daa57e44a25b99b783e5f7aed81b314232b3d3c81a11d"},
    {file = "watchfiles-1.0.5-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:a056c2f692d65bf1e99c41045e3bdcaea3cb9e6b5a53dcaf60a5f3bd95fc9763"},
    {file = "watchfiles-1.0.5-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b9dca99744991fc9850d18015c4f0438865414e50069670f5f7eee08340d8b40"},
    {file = "watchfiles-1.0.5-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:894342d61d355446d02cd3988a7326af344143eb33a2fd5d38482a92072d9563"},
    {file = "watchfiles-1.0.5-cp313-cp313-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ab44e1580924d1ffd7b3938e02716d5ad190441965138b4aa1d1f31ea0877f04"},
    {file = "watchfiles-1.0.5-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d6f9367b132078b2ceb8d066ff6c93a970a18c3029cea37bfd7b2d3dd2e5db8f"},
    {file = "watchfiles-1.0.5-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f2e55a9b162e06e3f862fb61e399fe9f05d908d019d87bf5b496a04ef18a970a"},
    {file = "watchfiles-1.0.5-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0125f91f70e0732a9f8ee01e49515c35d38ba48db507a50c5bdcad9503af5827"},
    {file = "watchfiles-1.0.5-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:13bb21f8ba3248386337c9fa51c528868e6c34a707f729ab041c846d52a0c69a"},
    {file = "watchfiles-1.0.5-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:839ebd0df4a18c5b3c1b890145b5a3f5f64063c2a0d02b13c76d78fe5de34936"},
    {file = "watchfiles-1.0.5-cp313-cp313-win32.whl", hash = "sha256:4a8ec1e4e16e2d5bafc9ba82f7aaecfeec990ca7cd27e84fb6f191804ed2fcfc"},
    {file = "watchfiles-1.0.5-cp313-cp313-win_amd64.whl", hash = "sha256:f436601594f15bf406518af922a89dcaab416568edb6f65c4e5bbbad1ea45c11"},
    {file = "watchfiles-1.0.5-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:2cfb371be97d4db374cba381b9f911dd35bb5f4c58faa7b8b7106c8853e5d225"},
    {file = "watchfiles-1.0.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a3904d88955fda461ea2531fcf6ef73584ca921415d5cfa44457a225f4a42bc1"},
    {file = "watchfiles-1.0.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2b7a21715fb12274a71d335cff6c71fe7f676b293d322722fe708a9ec81d91f5"},
    {file = "watchfiles-1.0.5-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:dfd6ae1c385ab481766b3c61c44aca2b3cd775f6f7c0fa93d979ddec853d29d5"},
    {file = "watchfiles-1.0.5-cp39-cp39-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b659576b950865fdad31fa491d31d37cf78b27113a7671d39f919828587b429b"},
    {file = "watchfiles-1.0.5-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1909e0a9cd95251b15bff4261de5dd7550885bd172e3536824bf1cf6b121e200"},
    {file = "watchfiles-1.0.5-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:832ccc221927c860e7286c55c9b6ebcc0265d5e072f49c7f6456c7798d2b39aa"},
    {file = "watchfiles-1.0.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:85fbb6102b3296926d0c62cfc9347f6237fb9400aecd0ba6bbda94cae15f2b3b"},
    {file = "watchfiles-1.0.5-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:15ac96dd567ad6c71c71f7b2c658cb22b7734901546cd50a475128ab557593ca"},
    {file = "watchfiles-1.0.5-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:4b6227351e11c57ae997d222e13f5b6f1f0700d84b8c52304e8675d33a808382"},
    {file = "watchfiles-1.0.5-cp39-cp39-win32.whl", hash = "sha256:974866e0db748ebf1eccab17862bc0f0303807ed9cda465d1324625b81293a18"},
    {file = "watchfiles-1.0.5-cp39-cp39-win_amd64.whl", hash = "sha256:9848b21ae152fe79c10dd0197304ada8f7b586d3ebc3f27f43c506e5a52a863c"},
    {file = "watchfiles-1.0.5-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:f59b870db1f1ae5a9ac28245707d955c8721dd6565e7f411024fa374b5362d1d"},
    {file = "watchfiles-1.0.5-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:9475b0093767e1475095f2aeb1d219fb9664081d403d1dff81342df8cd707034"},
    {file = "watchfiles-1.0.5-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fc533aa50664ebd6c628b2f30591956519462f5d27f951ed03d6c82b2dfd9965"},
    {file = "watchfiles-1.0.5-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fed1cd825158dcaae36acce7b2db33dcbfd12b30c34317a88b8ed80f0541cc57"},
    {file = "watchfiles-1.0.5-pp39-pypy39_pp73-macosx_10_12_x86_64.whl", hash = "sha256:554389562c29c2c182e3908b149095051f81d28c2fec79ad6c8997d7d63e0009"},
    {file = "watchfiles-1.0.5-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:a74add8d7727e6404d5dc4dcd7fac65d4d82f95928bbee0cf5414c900e86773e"},
    {file = "watchfiles-1.0.5-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cb1489f25b051a89fae574505cc26360c8e95e227a9500182a7fe0afcc500ce0"},
    {file = "watchfiles-1.0.5-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c0901429650652d3f0da90bad42bdafc1f9143ff3605633c455c999a2d786cac"},
    {file = "watchfiles-1.0.5.tar.gz", hash = "sha256:b7529b5dcc114679d43827d8c35a07c493ad6f083633d573d81c660abc5979e9"},
]

[package.dependencies]
anyio = ">=3.0.0"

[[package]]
name = "websockets"
version = "15.0.1"
description = "An implementation of the WebSocket Protocol (RFC 6455 & 7692)"
optional = false
python-versions = ">=3.9"
files = [
    {file = "websockets-15.0.1-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:d63efaa0cd96cf0c5fe4d581521d9fa87744540d4bc999ae6e08595a1014b45b"},
    {file = "websockets-15.0.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:ac60e3b188ec7574cb761b08d50fcedf9d77f1530352db4eef1707fe9dee7205"},
    {file = "websockets-15.0.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:5756779642579d902eed757b21b0164cd6fe338506a8083eb58af5c372e39d9a"},
    {file = "websockets-15.0.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0fdfe3e2a29e4db3659dbd5bbf04560cea53dd9610273917799f1cde46aa725e"},
    {file = "websockets-15.0.1-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4c2529b320eb9e35af0fa3016c187dffb84a3ecc572bcee7c3ce302bfeba52bf"},
    {file = "websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ac1e5c9054fe23226fb11e05a6e630837f074174c4c2f0fe442996112a6de4fb"},
    {file = "websockets-15.0.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:5df592cd503496351d6dc14f7cdad49f268d8e618f80dce0cd5a36b93c3fc08d"},
    {file = "websockets-15.0.1-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:0a34631031a8f05657e8e90903e656959234f3a04552259458aac0b0f9ae6fd9"},
    {file = "websockets-15.0.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:3d00075aa65772e7ce9e990cab3ff1de702aa09be3940d1dc88d5abf1ab8a09c"},
    {file = "websockets-15.0.1-cp310-cp310-win32.whl", hash = "sha256:1234d4ef35db82f5446dca8e35a7da7964d02c127b095e172e54397fb6a6c256"},
    {file = "websockets-15.0.1-cp310-cp310-win_amd64.whl", hash = "sha256:39c1fec2c11dc8d89bba6b2bf1556af381611a173ac2b511cf7231622058af41"},
    {file = "websockets-15.0.1-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:823c248b690b2fd9303ba00c4f66cd5e2d8c3ba4aa968b2779be9532a4dad431"},
    {file = "websockets-15.0.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:678999709e68425ae2593acf2e3ebcbcf2e69885a5ee78f9eb80e6e371f1bf57"},
    {file = "websockets-15.0.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:d50fd1ee42388dcfb2b3676132c78116490976f1300da28eb629272d5d93e905"},
    {file = "websockets-15.0.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d99e5546bf73dbad5bf3547174cd6cb8ba7273062a23808ffea025ecb1cf8562"},
    {file = "websockets-15.0.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:66dd88c918e3287efc22409d426c8f729688d89a0c587c88971a0faa2c2f3792"},
    {file = "websockets-15.0.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8dd8327c795b3e3f219760fa603dcae1dcc148172290a8ab15158cf85a953413"},
    {file = "websockets-15.0.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:8fdc51055e6ff4adeb88d58a11042ec9a5eae317a0a53d12c062c8a8865909e8"},
    {file = "websockets-15.0.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:693f0192126df6c2327cce3baa7c06f2a117575e32ab2308f7f8216c29d9e2e3"},
    {file = "websockets-15.0.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:54479983bd5fb469c38f2f5c7e3a24f9a4e70594cd68cd1fa6b9340dadaff7cf"},
    {file = "websockets-15.0.1-cp311-cp311-win32.whl", hash = "sha256:16b6c1b3e57799b9d38427dda63edcbe4926352c47cf88588c0be4ace18dac85"},
    {file = "websockets-15.0.1-cp311-cp311-win_amd64.whl", hash = "sha256:27ccee0071a0e75d22cb35849b1db43f2ecd3e161041ac1ee9d2352ddf72f065"},
    {file = "websockets-15.0.1-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:3e90baa811a5d73f3ca0bcbf32064d663ed81318ab225ee4f427ad4e26e5aff3"},
    {file = "websockets-15.0.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:592f1a9fe869c778694f0aa806ba0374e97648ab57936f092fd9d87f8bc03665"},
    {file = "websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:0701bc3cfcb9164d04a14b149fd74be7347a530ad3bbf15ab2c678a2cd3dd9a2"},
    {file = "websockets-15.0.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e8b56bdcdb4505c8078cb6c7157d9811a85790f2f2b3632c7d1462ab5783d215"},
    {file = "websockets-15.0.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0af68c55afbd5f07986df82831c7bff04846928ea8d1fd7f30052638788bc9b5"},
    {file = "websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:64dee438fed052b52e4f98f76c5790513235efaa1ef7f3f2192c392cd7c91b65"},
    {file = "websockets-15.0.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:d5f6b181bb38171a8ad1d6aa58a67a6aa9d4b38d0f8c5f496b9e42561dfc62fe"},
    {file = "websockets-15.0.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:5d54b09eba2bada6011aea5375542a157637b91029687eb4fdb2dab11059c1b4"},
    {file = "websockets-15.0.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:3be571a8b5afed347da347bfcf27ba12b069d9d7f42cb8c7028b5e98bbb12597"},
    {file = "websockets-15.0.1-cp312-cp312-win32.whl", hash = "sha256:c338ffa0520bdb12fbc527265235639fb76e7bc7faafbb93f6ba80d9c06578a9"},
    {file = "websockets-15.0.1-cp312-cp312-win_amd64.whl", hash = "sha256:fcd5cf9e305d7b8338754470cf69cf81f420459dbae8a3b40cee57417f4614a7"},
    {file = "websockets-15.0.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:ee443ef070bb3b6ed74514f5efaa37a252af57c90eb33b956d35c8e9c10a1931"},
    {file = "websockets-15.0.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:5a939de6b7b4e18ca683218320fc67ea886038265fd1ed30173f5ce3f8e85675"},
    {file = "websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:746ee8dba912cd6fc889a8147168991d50ed70447bf18bcda7039f7d2e3d9151"},
    {file = "websockets-15.0.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:595b6c3969023ecf9041b2936ac3827e4623bfa3ccf007575f04c5a6aa318c22"},
    {file = "websockets-15.0.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:3c714d2fc58b5ca3e285461a4cc0c9a66bd0e24c5da9911e30158286c9b5be7f"},
    {file = "websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0f3c1e2ab208db911594ae5b4f79addeb3501604a165019dd221c0bdcabe4db8"},
    {file = "websockets-15.0.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:229cf1d3ca6c1804400b0a9790dc66528e08a6a1feec0d5040e8b9eb14422375"},
    {file = "websockets-15.0.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:756c56e867a90fb00177d530dca4b097dd753cde348448a1012ed6c5131f8b7d"},
    {file = "websockets-15.0.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:558d023b3df0bffe50a04e710bc87742de35060580a293c2a984299ed83bc4e4"},
    {file = "websockets-15.0.1-cp313-cp313-win32.whl", hash = "sha256:ba9e56e8ceeeedb2e080147ba85ffcd5cd0711b89576b83784d8605a7df455fa"},
    {file = "websockets-15.0.1-cp313-cp313-win_amd64.whl", hash = "sha256:e09473f095a819042ecb2ab9465aee615bd9c2028e4ef7d933600a8401c79561"},
    {file = "websockets-15.0.1-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:5f4c04ead5aed67c8a1a20491d54cdfba5884507a48dd798ecaf13c74c4489f5"},
    {file = "websockets-15.0.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:abdc0c6c8c648b4805c5eacd131910d2a7f6455dfd3becab248ef108e89ab16a"},
    {file = "websockets-15.0.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a625e06551975f4b7ea7102bc43895b90742746797e2e14b70ed61c43a90f09b"},
    {file = "websockets-15.0.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d591f8de75824cbb7acad4e05d2d710484f15f29d4a915092675ad3456f11770"},
    {file = "websockets-15.0.1-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:47819cea040f31d670cc8d324bb6435c6f133b8c7a19ec3d61634e62f8d8f9eb"},
    {file = "websockets-15.0.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ac017dd64572e5c3bd01939121e4d16cf30e5d7e110a119399cf3133b63ad054"},
    {file = "websockets-15.0.1-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:4a9fac8e469d04ce6c25bb2610dc535235bd4aa14996b4e6dbebf5e007eba5ee"},
    {file = "websockets-15.0.1-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:363c6f671b761efcb30608d24925a382497c12c506b51661883c3e22337265ed"},
    {file = "websockets-15.0.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:2034693ad3097d5355bfdacfffcbd3ef5694f9718ab7f29c29689a9eae841880"},
    {file = "websockets-15.0.1-cp39-cp39-win32.whl", hash = "sha256:3b1ac0d3e594bf121308112697cf4b32be538fb1444468fb0a6ae4feebc83411"},
    {file = "websockets-15.0.1-cp39-cp39-win_amd64.whl", hash = "sha256:b7643a03db5c95c799b89b31c036d5f27eeb4d259c798e878d6937d71832b1e4"},
    {file = "websockets-15.0.1-pp310-pypy310_pp73-macosx_10_15_x86_64.whl", hash = "sha256:0c9e74d766f2818bb95f84c25be4dea09841ac0f734d1966f415e4edfc4ef1c3"},
    {file = "websockets-15.0.1-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:1009ee0c7739c08a0cd59de430d6de452a55e42d6b522de7aa15e6f67db0b8e1"},
    {file = "websockets-15.0.1-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:76d1f20b1c7a2fa82367e04982e708723ba0e7b8d43aa643d3dcd404d74f1475"},
    {file = "websockets-15.0.1-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f29d80eb9a9263b8d109135351caf568cc3f80b9928bccde535c235de55c22d9"},
    {file = "websockets-15.0.1-pp310-pypy310_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b359ed09954d7c18bbc1680f380c7301f92c60bf924171629c5db97febb12f04"},
    {file = "websockets-15.0.1-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:cad21560da69f4ce7658ca2cb83138fb4cf695a2ba3e475e0559e05991aa8122"},
    {file = "websockets-15.0.1-pp39-pypy39_pp73-macosx_10_15_x86_64.whl", hash = "sha256:7f493881579c90fc262d9cdbaa05a6b54b3811c2f300766748db79f098db9940"},
    {file = "websockets-15.0.1-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:47b099e1f4fbc95b701b6e85768e1fcdaf1630f3cbe4765fa216596f12310e2e"},
    {file = "websockets-15.0.1-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:67f2b6de947f8c757db2db9c71527933ad0019737ec374a8a6be9a956786aaf9"},
    {file = "websockets-15.0.1-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d08eb4c2b7d6c41da6ca0600c077e93f5adcfd979cd777d747e9ee624556da4b"},
    {file = "websockets-15.0.1-pp39-pypy39_pp73-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4b826973a4a2ae47ba357e4e82fa44a463b8f168e1ca775ac64521442b19e87f"},
    {file = "websockets-15.0.1-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:21c1fa28a6a7e3cbdc171c694398b6df4744613ce9b36b1a498e816787e28123"},
    {file = "websockets-15.0.1-py3-none-any.whl", hash = "sha256:f7a866fbc1e97b5c617ee4116daaa09b722101d4a3c170c787450ba409f9736f"},
    {file = "websockets-15.0.1.tar.gz", hash = "sha256:82544de02076bafba038ce055ee6412d68da13ab47f0c60cab827346de828dee"},
]

[[package]]
name = "wsproto"
version = "1.2.0"
description = "WebSockets state-machine based protocol implementation"
optional = false
python-versions = ">=3.7.0"
files = [
    {file = "wsproto-1.2.0-py3-none-any.whl", hash = "sha256:b9acddd652b585d75b20477888c56642fdade28bdfd3579aa24a4d2c037dd736"},
    {file = "wsproto-1.2.0.tar.gz", hash = "sha256:ad565f26ecb92588a3e43bc3d96164de84cd9902482b130d0ddbaa9664a85065"},
]

[package.dependencies]
h11 = ">=0.9.0,<1"

[metadata]
lock-version = "2.0"
python-versions = "^3.12"
content-hash = "3201611cea990614500ced9e55ad12ee0e73d37acd6ce35aec4dbc2e680bcd8f"


--- END OF FILE: poetry.lock ---

================================================================================

--- START OF FILE: Dockerfile ---

# Use an official Python base image
FROM python:3.12-slim as base

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    # Add any other system dependencies needed here
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install poetry

# Set the working directory
WORKDIR /app

# Copy only dependency files to leverage Docker cache
COPY poetry.lock pyproject.toml ./

# Install project dependencies
# --no-root: Don't install the project itself, only dependencies
# --only main: Install only the main dependencies (excluding dev, etc.)
RUN poetry install --no-root --only main --no-interaction --no-ansi

# Copy the rest of the application code
COPY ./app ./app
COPY ./scripts ./scripts
COPY ./main.py ./main.py
# Copy alembic files if migrations are run inside the container start script
COPY ./alembic.ini ./alembic.ini
COPY ./alembic ./alembic

# Expose the port the app runs on
EXPOSE 8000

# Command to run the application using uvicorn via poetry
# Ensure your FastAPI app instance is correctly referenced (e.g., app.main:app)
CMD ["poetry", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"] 

--- END OF FILE: Dockerfile ---

================================================================================

--- START OF FILE: .env ---

# Database URL for the application to connect to the Docker container
DATABASE_URL=postgresql+asyncpg://admin:changethis@db:5432/shareyourspacedb
SECRET_KEY=your_very_secret_key_here_please_change
ALGORITHM=HS256
# Add other secrets later (Resend API Key, Stripe Keys, OAuth Keys, Google AI Key)
RESEND_API_KEY=re_RZ6f3YBY_DU8JHpWc2DVCX4BzzAUYPdqJ
STRIPE_SECRET_KEY=
STRIPE_PUBLISHABLE_KEY=
STRIPE_WEBHOOK_SECRET=
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
LINKEDIN_CLIENT_ID=
LINKEDIN_CLIENT_SECRET=
APPLE_CLIENT_ID=
APPLE_TEAM_ID=
APPLE_KEY_ID=
APPLE_PRIVATE_KEY=
GOOGLE_AI_API_KEY=AIzaSyBr3PQP4MDuDwT-pcHOAPs00Zb7GlUXGGc
# PostgreSQL Environment Variables for Docker Compose DB container initialization
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=db
# Frontend URL (used for constructing verification links, etc.)
FRONTEND_URL=http://localhost:3000

# Google Cloud Storage Bucket Name
GCS_BUCKET_NAME=shareyourspace-profile-pics

# Google Cloud Project ID (Needed for GCS client library)
GOOGLE_CLOUD_PROJECT=shareyourspace-457108

# Ensure ADC user credentials mount path is USED when using impersonation
# Point to the Service Account Key file within the container (COMMENTED OUT - using impersonation)
# GOOGLE_APPLICATION_CREDENTIALS=/app/gcs-service-account-key.json

# Email address of the Service Account the backend should impersonate
TARGET_SERVICE_ACCOUNT_EMAIL=shareyourspace-backend-sa@shareyourspace-457108.iam.gserviceaccount.com

# Ensure ADC user credentials mount path is NOT used when using a key file

--- END OF FILE: .env ---

================================================================================

--- START OF FILE: docker-compose.yml ---

version: "3.8"

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: shareyourspace-backend-backend-1
    ports:
      - "8000:8000"
    volumes:
      # Mount the app directory for live code changes during development
      - ./app:/app/app
      # Add other potential volume mounts if needed (e.g., scripts)
      - ./scripts:/app/scripts
      - ./main.py:/app/main.py
      - ./alembic.ini:/app/alembic.ini
      - ./alembic:/app/alembic
      # Mount the host's ADC file into the container for local development authentication
      - ~/.config/gcloud/application_default_credentials.json:/root/.config/gcloud/application_default_credentials.json:ro
    env_file:
      - .env
    environment:
      - DATABASE_URL=postgresql+asyncpg://admin:changethis@db:5432/shareyourspacedb
      - SECRET_KEY=your_super_secret_key_please_change_this_in_docker_compose
      - GCS_BUCKET_NAME=your_gcs_bucket_name_please_change_this_in_docker_compose
      # Add other required env vars from your config.py here if they don't have defaults
      # For example, if TARGET_SERVICE_ACCOUNT_EMAIL is strictly required by your app logic:
      # - TARGET_SERVICE_ACCOUNT_EMAIL=your_sa_email@example.com
    dns:
      - 8.8.8.8 # Added public DNS as a test
    depends_on:
      db:
        condition: service_healthy
    command: poetry run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  db:
    image: pgvector/pgvector:pg16
    container_name: shareyourspace-backend-db-1
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: changethis
      POSTGRES_DB: shareyourspacedb
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

volumes:
  postgres_data:


--- END OF FILE: docker-compose.yml ---

================================================================================

--- START OF FILE: .dockerignore ---

# Git files
.git
.gitignore

# Python cache files
__pycache__/
*.pyc
*.pyo
*.pyd

# Virtual environment
.venv/
venv/
env/

# IDE and Tooling Cache
.idea/
.vscode/
.mypy_cache/
.pytest_cache/

# Build artifacts
dist/
build/
*.egg-info/

# Logs
*.log

# Environment variables file
.env

# OS generated files
.DS_Store
Thumbs.db

# Test files (if tests are not run inside the container)
tests/

# Alembic versions (usually applied via command, not copied)
# alembic/versions/* 

--- END OF FILE: .dockerignore ---

================================================================================

--- START OF FILE: alembic.ini ---

# A generic, single database configuration.

[alembic]
# path to migration scripts
# Use forward slashes (/) also on windows to provide an os agnostic path
script_location = alembic

# template used to generate migration file names; The default value is %%(rev)s_%%(slug)s
# Uncomment the line below if you want the files to be prepended with date and time
# see https://alembic.sqlalchemy.org/en/latest/tutorial.html#editing-the-ini-file
# for all available tokens
# file_template = %%(year)d_%%(month).2d_%%(day).2d_%%(hour).2d%%(minute).2d-%%(rev)s_%%(slug)s

# sys.path path, will be prepended to sys.path if present.
# defaults to the current working directory.
prepend_sys_path = .

# timezone to use when rendering the date within the migration file
# as well as the filename.
# If specified, requires the python>=3.9 or backports.zoneinfo library and tzdata library.
# Any required deps can installed by adding `alembic[tz]` to the pip requirements
# string value is passed to ZoneInfo()
# leave blank for localtime
# timezone =

# max length of characters to apply to the "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; This defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path.
# The path separator used here should be the separator specified by "version_path_separator" below.
# version_locations = %(here)s/bar:%(here)s/bat:alembic/versions

# version path separator; As mentioned above, this is the character used to split
# version_locations. The default within new alembic.ini files is "os", which uses os.pathsep.
# If this key is omitted entirely, it falls back to the legacy behavior of splitting on spaces and/or commas.
# Valid values for version_path_separator are:
#
# version_path_separator = :
# version_path_separator = ;
# version_path_separator = space
# version_path_separator = newline
#
# Use os.pathsep. Default configuration used for new projects.
version_path_separator = os

# set to 'true' to search source files recursively
# in each "version_locations" directory
# new in Alembic version 1.10
# recursive_version_locations = false

# the output encoding used when dealing with database server messages.
# psycopg2 default is 'utf-8'.
# output_encoding = utf-8

# Set the database URL.
# Make sure this matches the DATABASE_URL in your .env file.
# The env.py script should read directly from settings, so this line
# should typically be commented out to avoid conflicts.
# sqlalchemy.url = postgresql+asyncpg://user:password@host:port/db

# the underlying database driver dialect for sqlalchemy
# If you are using asyncpg, make sure it's configured correctly
# sqlalchemy.url = driver://user:pass@localhost/dbname
sqlalchemy.url = %(DATABASE_URL)s

[post_write_hooks]
# post_write_hooks defines scripts or Python functions that are run
# on newly generated revision scripts.  See the documentation for further
# detail and examples

# format using "black" - use the console_scripts runner, against the "black" entrypoint
# hooks = black
# black.type = console_scripts
# black.entrypoint = black
# black.options = -l 79 REVISION_SCRIPT_FILENAME

# lint with attempts to fix using "ruff" - use the exec runner, execute a binary
# hooks = ruff
# ruff.type = exec
# ruff.executable = %(here)s/.venv/bin/ruff
# ruff.options = check --fix REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARNING
handlers = console
qualname =

[logger_sqlalchemy]
level = WARNING
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S


--- END OF FILE: alembic.ini ---

================================================================================

--- START OF FILE: requirements.txt ---

alembic==1.15.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:1c72391bbdeffccfe317eefba686cb9a3c078005478885413b95c3b26c57a8a7 \
    --hash=sha256:2e76bd916d547f6900ec4bb5a90aeac1485d2c92536923d0b138c02b126edc53
annotated-types==0.7.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53 \
    --hash=sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89
anyio==4.9.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:673c0c244e15788651a4ff38710fea9675823028a6f08a5eda409e0c9840a028 \
    --hash=sha256:9f76d541cad6e36af7beb62e978876f3b41e3e04f2c1fbf0884604c0a9c4d93c
asyncpg==0.30.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:04ff0785ae7eed6cc138e73fc67b8e51d54ee7a3ce9b63666ce55a0bf095f7ba \
    --hash=sha256:05b185ebb8083c8568ea8a40e896d5f7af4b8554b64d7719c0eaa1eb5a5c3a70 \
    --hash=sha256:0b448f0150e1c3b96cb0438a0d0aa4871f1472e58de14a3ec320dbb2798fb0d4 \
    --hash=sha256:0f5712350388d0cd0615caec629ad53c81e506b1abaaf8d14c93f54b35e3595a \
    --hash=sha256:1292b84ee06ac8a2ad8e51c7475aa309245874b61333d97411aab835c4a2f737 \
    --hash=sha256:1b11a555a198b08f5c4baa8f8231c74a366d190755aa4f99aacec5970afe929a \
    --hash=sha256:1b982daf2441a0ed314bd10817f1606f1c28b1136abd9e4f11335358c2c631cb \
    --hash=sha256:1c06a3a50d014b303e5f6fc1e5f95eb28d2cee89cf58384b700da621e5d5e547 \
    --hash=sha256:1c198a00cce9506fcd0bf219a799f38ac7a237745e1d27f0e1f66d3707c84a5a \
    --hash=sha256:26683d3b9a62836fad771a18ecf4659a30f348a561279d6227dab96182f46144 \
    --hash=sha256:29ff1fc8b5bf724273782ff8b4f57b0f8220a1b2324184846b39d1ab4122031d \
    --hash=sha256:3152fef2e265c9c24eec4ee3d22b4f4d2703d30614b0b6753e9ed4115c8a146f \
    --hash=sha256:3326e6d7381799e9735ca2ec9fd7be4d5fef5dcbc3cb555d8a463d8460607956 \
    --hash=sha256:3356637f0bd830407b5597317b3cb3571387ae52ddc3bca6233682be88bbbc1f \
    --hash=sha256:393af4e3214c8fa4c7b86da6364384c0d1b3298d45803375572f415b6f673f38 \
    --hash=sha256:46973045b567972128a27d40001124fbc821c87a6cade040cfcd4fa8a30bcdc4 \
    --hash=sha256:51da377487e249e35bd0859661f6ee2b81db11ad1f4fc036194bc9cb2ead5056 \
    --hash=sha256:574156480df14f64c2d76450a3f3aaaf26105869cad3865041156b38459e935d \
    --hash=sha256:578445f09f45d1ad7abddbff2a3c7f7c291738fdae0abffbeb737d3fc3ab8b75 \
    --hash=sha256:5b290f4726a887f75dcd1b3006f484252db37602313f806e9ffc4e5996cfe5cb \
    --hash=sha256:5df69d55add4efcd25ea2a3b02025b669a285b767bfbf06e356d68dbce4234ff \
    --hash=sha256:5e0511ad3dec5f6b4f7a9e063591d407eee66b88c14e2ea636f187da1dcfff6a \
    --hash=sha256:64e899bce0600871b55368b8483e5e3e7f1860c9482e7f12e0a771e747988168 \
    --hash=sha256:68d71a1be3d83d0570049cd1654a9bdfe506e794ecc98ad0873304a9f35e411e \
    --hash=sha256:6c2a2ef565400234a633da0eafdce27e843836256d40705d83ab7ec42074efb3 \
    --hash=sha256:6f4e83f067b35ab5e6371f8a4c93296e0439857b4569850b178a01385e82e9ad \
    --hash=sha256:8b684a3c858a83cd876f05958823b68e8d14ec01bb0c0d14a6704c5bf9711773 \
    --hash=sha256:9110df111cabc2ed81aad2f35394a00cadf4f2e0635603db6ebbd0fc896f46a4 \
    --hash=sha256:915aeb9f79316b43c3207363af12d0e6fd10776641a7de8a01212afd95bdf0ed \
    --hash=sha256:9a0292c6af5c500523949155ec17b7fe01a00ace33b68a476d6b5059f9630305 \
    --hash=sha256:9b6fde867a74e8c76c71e2f64f80c64c0f3163e687f1763cfaf21633ec24ec33 \
    --hash=sha256:a3479a0d9a852c7c84e822c073622baca862d1217b10a02dd57ee4a7a081f708 \
    --hash=sha256:aa403147d3e07a267ada2ae34dfc9324e67ccc4cdca35261c8c22792ba2b10cf \
    --hash=sha256:aca1548e43bbb9f0f627a04666fedaca23db0a31a84136ad1f868cb15deb6e3a \
    --hash=sha256:ae374585f51c2b444510cdf3595b97ece4f233fde739aa14b50e0d64e8a7a590 \
    --hash=sha256:bc6d84136f9c4d24d358f3b02be4b6ba358abd09f80737d1ac7c444f36108454 \
    --hash=sha256:bfb4dd5ae0699bad2b233672c8fc5ccbd9ad24b89afded02341786887e37927e \
    --hash=sha256:c42f6bb65a277ce4d93f3fba46b91a265631c8df7250592dd4f11f8b0152150f \
    --hash=sha256:c47806b1a8cbb0a0db896f4cd34d89942effe353a5035c62734ab13b9f938da3 \
    --hash=sha256:c551e9928ab6707602f44811817f82ba3c446e018bfe1d3abecc8ba5f3eac851 \
    --hash=sha256:c7255812ac85099a0e1ffb81b10dc477b9973345793776b128a23e60148dd1af \
    --hash=sha256:c902a60b52e506d38d7e80e0dd5399f657220f24635fee368117b8b5fce1142e \
    --hash=sha256:db9891e2d76e6f425746c5d2da01921e9a16b5a71a1c905b13f30e12a257c4af \
    --hash=sha256:dc1f62c792752a49f88b7e6f774c26077091b44caceb1983509edc18a2222ec0 \
    --hash=sha256:f23b836dd90bea21104f69547923a02b167d999ce053f3d502081acea2fba15b \
    --hash=sha256:f59b430b8e27557c3fb9869222559f7417ced18688375825f8f12302c34e915e \
    --hash=sha256:f86b0e2cd3f1249d6fe6fd6cfe0cd4538ba994e2d8249c0491925629b9104d0f \
    --hash=sha256:fb622c94db4e13137c4c7f98834185049cc50ee01d8f657ef898b6407c7b9c50 \
    --hash=sha256:fd4406d09208d5b4a14db9a9dbb311b6d7aeeab57bded7ed2f8ea41aeef39b34
bcrypt==4.3.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0042b2e342e9ae3d2ed22727c1262f76cc4f345683b5c1715f0250cf4277294f \
    --hash=sha256:0142b2cb84a009f8452c8c5a33ace5e3dfec4159e7735f5afe9a4d50a8ea722d \
    --hash=sha256:08bacc884fd302b611226c01014eca277d48f0a05187666bca23aac0dad6fe24 \
    --hash=sha256:0d3efb1157edebfd9128e4e46e2ac1a64e0c1fe46fb023158a407c7892b0f8c3 \
    --hash=sha256:0e30e5e67aed0187a1764911af023043b4542e70a7461ad20e837e94d23e1d6c \
    --hash=sha256:107d53b5c67e0bbc3f03ebf5b030e0403d24dda980f8e244795335ba7b4a027d \
    --hash=sha256:12fa6ce40cde3f0b899729dbd7d5e8811cb892d31b6f7d0334a1f37748b789fd \
    --hash=sha256:17a854d9a7a476a89dcef6c8bd119ad23e0f82557afbd2c442777a16408e614f \
    --hash=sha256:191354ebfe305e84f344c5964c7cd5f924a3bfc5d405c75ad07f232b6dffb49f \
    --hash=sha256:2ef6630e0ec01376f59a006dc72918b1bf436c3b571b80fa1968d775fa02fe7d \
    --hash=sha256:3004df1b323d10021fda07a813fd33e0fd57bef0e9a480bb143877f6cba996fe \
    --hash=sha256:335a420cfd63fc5bc27308e929bee231c15c85cc4c496610ffb17923abf7f231 \
    --hash=sha256:33752b1ba962ee793fa2b6321404bf20011fe45b9afd2a842139de3011898fef \
    --hash=sha256:3a3fd2204178b6d2adcf09cb4f6426ffef54762577a7c9b54c159008cb288c18 \
    --hash=sha256:3b8d62290ebefd49ee0b3ce7500f5dbdcf13b81402c05f6dafab9a1e1b27212f \
    --hash=sha256:3e36506d001e93bffe59754397572f21bb5dc7c83f54454c990c74a468cd589e \
    --hash=sha256:41261d64150858eeb5ff43c753c4b216991e0ae16614a308a15d909503617732 \
    --hash=sha256:50e6e80a4bfd23a25f5c05b90167c19030cf9f87930f7cb2eacb99f45d1c3304 \
    --hash=sha256:531457e5c839d8caea9b589a1bcfe3756b0547d7814e9ce3d437f17da75c32b0 \
    --hash=sha256:55a935b8e9a1d2def0626c4269db3fcd26728cbff1e84f0341465c31c4ee56d8 \
    --hash=sha256:57967b7a28d855313a963aaea51bf6df89f833db4320da458e5b3c5ab6d4c938 \
    --hash=sha256:584027857bc2843772114717a7490a37f68da563b3620f78a849bcb54dc11e62 \
    --hash=sha256:59e1aa0e2cd871b08ca146ed08445038f42ff75968c7ae50d2fdd7860ade2180 \
    --hash=sha256:5bd3cca1f2aa5dbcf39e2aa13dd094ea181f48959e1071265de49cc2b82525af \
    --hash=sha256:5c1949bf259a388863ced887c7861da1df681cb2388645766c89fdfd9004c669 \
    --hash=sha256:62f26585e8b219cdc909b6a0069efc5e4267e25d4a3770a364ac58024f62a761 \
    --hash=sha256:67a561c4d9fb9465ec866177e7aebcad08fe23aaf6fbd692a6fab69088abfc51 \
    --hash=sha256:6fb1fd3ab08c0cbc6826a2e0447610c6f09e983a281b919ed721ad32236b8b23 \
    --hash=sha256:74a8d21a09f5e025a9a23e7c0fd2c7fe8e7503e4d356c0a2c1486ba010619f09 \
    --hash=sha256:79e70b8342a33b52b55d93b3a59223a844962bef479f6a0ea318ebbcadf71505 \
    --hash=sha256:7a4be4cbf241afee43f1c3969b9103a41b40bcb3a3f467ab19f891d9bc4642e4 \
    --hash=sha256:7c03296b85cb87db865d91da79bf63d5609284fc0cab9472fdd8367bbd830753 \
    --hash=sha256:842d08d75d9fe9fb94b18b071090220697f9f184d4547179b60734846461ed59 \
    --hash=sha256:864f8f19adbe13b7de11ba15d85d4a428c7e2f344bac110f667676a0ff84924b \
    --hash=sha256:97eea7408db3a5bcce4a55d13245ab3fa566e23b4c67cd227062bb49e26c585d \
    --hash=sha256:a839320bf27d474e52ef8cb16449bb2ce0ba03ca9f44daba6d93fa1d8828e48a \
    --hash=sha256:afe327968aaf13fc143a56a3360cb27d4ad0345e34da12c7290f1b00b8fe9a8b \
    --hash=sha256:b4d4e57f0a63fd0b358eb765063ff661328f69a04494427265950c71b992a39a \
    --hash=sha256:b6354d3760fcd31994a14c89659dee887f1351a06e5dac3c1142307172a79f90 \
    --hash=sha256:b693dbb82b3c27a1604a3dff5bfc5418a7e6a781bb795288141e5f80cf3a3492 \
    --hash=sha256:bdc6a24e754a555d7316fa4774e64c6c3997d27ed2d1964d55920c7c227bc4ce \
    --hash=sha256:beeefe437218a65322fbd0069eb437e7c98137e08f22c4660ac2dc795c31f8bb \
    --hash=sha256:c5eeac541cefd0bb887a371ef73c62c3cd78535e4887b310626036a7c0a817bb \
    --hash=sha256:c950d682f0952bafcceaf709761da0a32a942272fad381081b51096ffa46cea1 \
    --hash=sha256:d9af79d322e735b1fc33404b5765108ae0ff232d4b54666d46730f8ac1a43676 \
    --hash=sha256:e53e074b120f2877a35cc6c736b8eb161377caae8925c17688bd46ba56daaa5b \
    --hash=sha256:e965a9c1e9a393b8005031ff52583cedc15b7884fce7deb8b0346388837d6cfe \
    --hash=sha256:f01e060f14b6b57bbb72fc5b4a83ac21c443c9a2ee708e04a10e9192f90a6281 \
    --hash=sha256:f1e3ffa1365e8702dc48c8b360fef8d7afeca482809c5e45e653af82ccd088c1 \
    --hash=sha256:f6746e6fec103fcd509b96bacdfdaa2fbde9a553245dbada284435173a6f1aef \
    --hash=sha256:f81b0ed2639568bf14749112298f9e4e2b28853dab50a8b357e31798686a036d
cachetools==5.5.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:1a661caa9175d26759571b2e19580f9d6393969e5dfca11fdb1f947a23e640d4 \
    --hash=sha256:d26a22bcc62eb95c3beabd9f1ee5e820d3d2704fe2967cbe350e20c8ffcd3f0a
certifi==2025.1.31 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:3d5da6925056f6f18f119200434a4780a94263f10d1c21d032a6f6b2baa20651 \
    --hash=sha256:ca78db4565a652026a4db2bcdf68f2fb589ea80d0be70e03929ed730746b84fe
cffi==1.17.1 ; python_version >= "3.12" and python_version < "4.0" and platform_python_implementation != "PyPy" \
    --hash=sha256:045d61c734659cc045141be4bae381a41d89b741f795af1dd018bfb532fd0df8 \
    --hash=sha256:0984a4925a435b1da406122d4d7968dd861c1385afe3b45ba82b750f229811e2 \
    --hash=sha256:0e2b1fac190ae3ebfe37b979cc1ce69c81f4e4fe5746bb401dca63a9062cdaf1 \
    --hash=sha256:0f048dcf80db46f0098ccac01132761580d28e28bc0f78ae0d58048063317e15 \
    --hash=sha256:1257bdabf294dceb59f5e70c64a3e2f462c30c7ad68092d01bbbfb1c16b1ba36 \
    --hash=sha256:1c39c6016c32bc48dd54561950ebd6836e1670f2ae46128f67cf49e789c52824 \
    --hash=sha256:1d599671f396c4723d016dbddb72fe8e0397082b0a77a4fab8028923bec050e8 \
    --hash=sha256:28b16024becceed8c6dfbc75629e27788d8a3f9030691a1dbf9821a128b22c36 \
    --hash=sha256:2bb1a08b8008b281856e5971307cc386a8e9c5b625ac297e853d36da6efe9c17 \
    --hash=sha256:30c5e0cb5ae493c04c8b42916e52ca38079f1b235c2f8ae5f4527b963c401caf \
    --hash=sha256:31000ec67d4221a71bd3f67df918b1f88f676f1c3b535a7eb473255fdc0b83fc \
    --hash=sha256:386c8bf53c502fff58903061338ce4f4950cbdcb23e2902d86c0f722b786bbe3 \
    --hash=sha256:3edc8d958eb099c634dace3c7e16560ae474aa3803a5df240542b305d14e14ed \
    --hash=sha256:45398b671ac6d70e67da8e4224a065cec6a93541bb7aebe1b198a61b58c7b702 \
    --hash=sha256:46bf43160c1a35f7ec506d254e5c890f3c03648a4dbac12d624e4490a7046cd1 \
    --hash=sha256:4ceb10419a9adf4460ea14cfd6bc43d08701f0835e979bf821052f1805850fe8 \
    --hash=sha256:51392eae71afec0d0c8fb1a53b204dbb3bcabcb3c9b807eedf3e1e6ccf2de903 \
    --hash=sha256:5da5719280082ac6bd9aa7becb3938dc9f9cbd57fac7d2871717b1feb0902ab6 \
    --hash=sha256:610faea79c43e44c71e1ec53a554553fa22321b65fae24889706c0a84d4ad86d \
    --hash=sha256:636062ea65bd0195bc012fea9321aca499c0504409f413dc88af450b57ffd03b \
    --hash=sha256:6883e737d7d9e4899a8a695e00ec36bd4e5e4f18fabe0aca0efe0a4b44cdb13e \
    --hash=sha256:6b8b4a92e1c65048ff98cfe1f735ef8f1ceb72e3d5f0c25fdb12087a23da22be \
    --hash=sha256:6f17be4345073b0a7b8ea599688f692ac3ef23ce28e5df79c04de519dbc4912c \
    --hash=sha256:706510fe141c86a69c8ddc029c7910003a17353970cff3b904ff0686a5927683 \
    --hash=sha256:72e72408cad3d5419375fc87d289076ee319835bdfa2caad331e377589aebba9 \
    --hash=sha256:733e99bc2df47476e3848417c5a4540522f234dfd4ef3ab7fafdf555b082ec0c \
    --hash=sha256:7596d6620d3fa590f677e9ee430df2958d2d6d6de2feeae5b20e82c00b76fbf8 \
    --hash=sha256:78122be759c3f8a014ce010908ae03364d00a1f81ab5c7f4a7a5120607ea56e1 \
    --hash=sha256:805b4371bf7197c329fcb3ead37e710d1bca9da5d583f5073b799d5c5bd1eee4 \
    --hash=sha256:85a950a4ac9c359340d5963966e3e0a94a676bd6245a4b55bc43949eee26a655 \
    --hash=sha256:8f2cdc858323644ab277e9bb925ad72ae0e67f69e804f4898c070998d50b1a67 \
    --hash=sha256:9755e4345d1ec879e3849e62222a18c7174d65a6a92d5b346b1863912168b595 \
    --hash=sha256:98e3969bcff97cae1b2def8ba499ea3d6f31ddfdb7635374834cf89a1a08ecf0 \
    --hash=sha256:a08d7e755f8ed21095a310a693525137cfe756ce62d066e53f502a83dc550f65 \
    --hash=sha256:a1ed2dd2972641495a3ec98445e09766f077aee98a1c896dcb4ad0d303628e41 \
    --hash=sha256:a24ed04c8ffd54b0729c07cee15a81d964e6fee0e3d4d342a27b020d22959dc6 \
    --hash=sha256:a45e3c6913c5b87b3ff120dcdc03f6131fa0065027d0ed7ee6190736a74cd401 \
    --hash=sha256:a9b15d491f3ad5d692e11f6b71f7857e7835eb677955c00cc0aefcd0669adaf6 \
    --hash=sha256:ad9413ccdeda48c5afdae7e4fa2192157e991ff761e7ab8fdd8926f40b160cc3 \
    --hash=sha256:b2ab587605f4ba0bf81dc0cb08a41bd1c0a5906bd59243d56bad7668a6fc6c16 \
    --hash=sha256:b62ce867176a75d03a665bad002af8e6d54644fad99a3c70905c543130e39d93 \
    --hash=sha256:c03e868a0b3bc35839ba98e74211ed2b05d2119be4e8a0f224fba9384f1fe02e \
    --hash=sha256:c59d6e989d07460165cc5ad3c61f9fd8f1b4796eacbd81cee78957842b834af4 \
    --hash=sha256:c7eac2ef9b63c79431bc4b25f1cd649d7f061a28808cbc6c47b534bd789ef964 \
    --hash=sha256:c9c3d058ebabb74db66e431095118094d06abf53284d9c81f27300d0e0d8bc7c \
    --hash=sha256:ca74b8dbe6e8e8263c0ffd60277de77dcee6c837a3d0881d8c1ead7268c9e576 \
    --hash=sha256:caaf0640ef5f5517f49bc275eca1406b0ffa6aa184892812030f04c2abf589a0 \
    --hash=sha256:cdf5ce3acdfd1661132f2a9c19cac174758dc2352bfe37d98aa7512c6b7178b3 \
    --hash=sha256:d016c76bdd850f3c626af19b0542c9677ba156e4ee4fccfdd7848803533ef662 \
    --hash=sha256:d01b12eeeb4427d3110de311e1774046ad344f5b1a7403101878976ecd7a10f3 \
    --hash=sha256:d63afe322132c194cf832bfec0dc69a99fb9bb6bbd550f161a49e9e855cc78ff \
    --hash=sha256:da95af8214998d77a98cc14e3a3bd00aa191526343078b530ceb0bd710fb48a5 \
    --hash=sha256:dd398dbc6773384a17fe0d3e7eeb8d1a21c2200473ee6806bb5e6a8e62bb73dd \
    --hash=sha256:de2ea4b5833625383e464549fec1bc395c1bdeeb5f25c4a3a82b5a8c756ec22f \
    --hash=sha256:de55b766c7aa2e2a3092c51e0483d700341182f08e67c63630d5b6f200bb28e5 \
    --hash=sha256:df8b1c11f177bc2313ec4b2d46baec87a5f3e71fc8b45dab2ee7cae86d9aba14 \
    --hash=sha256:e03eab0a8677fa80d646b5ddece1cbeaf556c313dcfac435ba11f107ba117b5d \
    --hash=sha256:e221cf152cff04059d011ee126477f0d9588303eb57e88923578ace7baad17f9 \
    --hash=sha256:e31ae45bc2e29f6b2abd0de1cc3b9d5205aa847cafaecb8af1476a609a2f6eb7 \
    --hash=sha256:edae79245293e15384b51f88b00613ba9f7198016a5948b5dddf4917d4d26382 \
    --hash=sha256:f1e22e8c4419538cb197e4dd60acc919d7696e5ef98ee4da4e01d3f8cfa4cc5a \
    --hash=sha256:f3a2b4222ce6b60e2e8b337bb9596923045681d71e5a082783484d845390938e \
    --hash=sha256:f6a16c31041f09ead72d69f583767292f750d24913dadacf5756b966aacb3f1a \
    --hash=sha256:f75c7ab1f9e4aca5414ed4d8e5c0e303a34f4421f8a0d47a4d019ceff0ab6af4 \
    --hash=sha256:f79fc4fc25f1c8698ff97788206bb3c2598949bfe0fef03d299eb1b5356ada99 \
    --hash=sha256:f7f5baafcc48261359e14bcd6d9bff6d4b28d9103847c9e136694cb0501aef87 \
    --hash=sha256:fc48c783f9c87e60831201f2cce7f3b2e4846bf4d8728eabe54d60700b318a0b
charset-normalizer==3.4.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0167ddc8ab6508fe81860a57dd472b2ef4060e8d378f0cc555707126830f2537 \
    --hash=sha256:01732659ba9b5b873fc117534143e4feefecf3b2078b0a6a2e925271bb6f4cfa \
    --hash=sha256:01ad647cdd609225c5350561d084b42ddf732f4eeefe6e678765636791e78b9a \
    --hash=sha256:04432ad9479fa40ec0f387795ddad4437a2b50417c69fa275e212933519ff294 \
    --hash=sha256:0907f11d019260cdc3f94fbdb23ff9125f6b5d1039b76003b5b0ac9d6a6c9d5b \
    --hash=sha256:0924e81d3d5e70f8126529951dac65c1010cdf117bb75eb02dd12339b57749dd \
    --hash=sha256:09b26ae6b1abf0d27570633b2b078a2a20419c99d66fb2823173d73f188ce601 \
    --hash=sha256:09b5e6733cbd160dcc09589227187e242a30a49ca5cefa5a7edd3f9d19ed53fd \
    --hash=sha256:0af291f4fe114be0280cdd29d533696a77b5b49cfde5467176ecab32353395c4 \
    --hash=sha256:0f55e69f030f7163dffe9fd0752b32f070566451afe180f99dbeeb81f511ad8d \
    --hash=sha256:1a2bc9f351a75ef49d664206d51f8e5ede9da246602dc2d2726837620ea034b2 \
    --hash=sha256:22e14b5d70560b8dd51ec22863f370d1e595ac3d024cb8ad7d308b4cd95f8313 \
    --hash=sha256:234ac59ea147c59ee4da87a0c0f098e9c8d169f4dc2a159ef720f1a61bbe27cd \
    --hash=sha256:2369eea1ee4a7610a860d88f268eb39b95cb588acd7235e02fd5a5601773d4fa \
    --hash=sha256:237bdbe6159cff53b4f24f397d43c6336c6b0b42affbe857970cefbb620911c8 \
    --hash=sha256:28bf57629c75e810b6ae989f03c0828d64d6b26a5e205535585f96093e405ed1 \
    --hash=sha256:2967f74ad52c3b98de4c3b32e1a44e32975e008a9cd2a8cc8966d6a5218c5cb2 \
    --hash=sha256:2a75d49014d118e4198bcee5ee0a6f25856b29b12dbf7cd012791f8a6cc5c496 \
    --hash=sha256:2bdfe3ac2e1bbe5b59a1a63721eb3b95fc9b6817ae4a46debbb4e11f6232428d \
    --hash=sha256:2d074908e1aecee37a7635990b2c6d504cd4766c7bc9fc86d63f9c09af3fa11b \
    --hash=sha256:2fb9bd477fdea8684f78791a6de97a953c51831ee2981f8e4f583ff3b9d9687e \
    --hash=sha256:311f30128d7d333eebd7896965bfcfbd0065f1716ec92bd5638d7748eb6f936a \
    --hash=sha256:329ce159e82018d646c7ac45b01a430369d526569ec08516081727a20e9e4af4 \
    --hash=sha256:345b0426edd4e18138d6528aed636de7a9ed169b4aaf9d61a8c19e39d26838ca \
    --hash=sha256:363e2f92b0f0174b2f8238240a1a30142e3db7b957a5dd5689b0e75fb717cc78 \
    --hash=sha256:3a3bd0dcd373514dcec91c411ddb9632c0d7d92aed7093b8c3bbb6d69ca74408 \
    --hash=sha256:3bed14e9c89dcb10e8f3a29f9ccac4955aebe93c71ae803af79265c9ca5644c5 \
    --hash=sha256:44251f18cd68a75b56585dd00dae26183e102cd5e0f9f1466e6df5da2ed64ea3 \
    --hash=sha256:44ecbf16649486d4aebafeaa7ec4c9fed8b88101f4dd612dcaf65d5e815f837f \
    --hash=sha256:4532bff1b8421fd0a320463030c7520f56a79c9024a4e88f01c537316019005a \
    --hash=sha256:49402233c892a461407c512a19435d1ce275543138294f7ef013f0b63d5d3765 \
    --hash=sha256:4c0907b1928a36d5a998d72d64d8eaa7244989f7aaaf947500d3a800c83a3fd6 \
    --hash=sha256:4d86f7aff21ee58f26dcf5ae81a9addbd914115cdebcbb2217e4f0ed8982e146 \
    --hash=sha256:5777ee0881f9499ed0f71cc82cf873d9a0ca8af166dfa0af8ec4e675b7df48e6 \
    --hash=sha256:5df196eb874dae23dcfb968c83d4f8fdccb333330fe1fc278ac5ceeb101003a9 \
    --hash=sha256:619a609aa74ae43d90ed2e89bdd784765de0a25ca761b93e196d938b8fd1dbbd \
    --hash=sha256:6e27f48bcd0957c6d4cb9d6fa6b61d192d0b13d5ef563e5f2ae35feafc0d179c \
    --hash=sha256:6ff8a4a60c227ad87030d76e99cd1698345d4491638dfa6673027c48b3cd395f \
    --hash=sha256:73d94b58ec7fecbc7366247d3b0b10a21681004153238750bb67bd9012414545 \
    --hash=sha256:7461baadb4dc00fd9e0acbe254e3d7d2112e7f92ced2adc96e54ef6501c5f176 \
    --hash=sha256:75832c08354f595c760a804588b9357d34ec00ba1c940c15e31e96d902093770 \
    --hash=sha256:7709f51f5f7c853f0fb938bcd3bc59cdfdc5203635ffd18bf354f6967ea0f824 \
    --hash=sha256:78baa6d91634dfb69ec52a463534bc0df05dbd546209b79a3880a34487f4b84f \
    --hash=sha256:7974a0b5ecd505609e3b19742b60cee7aa2aa2fb3151bc917e6e2646d7667dcf \
    --hash=sha256:7a4f97a081603d2050bfaffdefa5b02a9ec823f8348a572e39032caa8404a487 \
    --hash=sha256:7b1bef6280950ee6c177b326508f86cad7ad4dff12454483b51d8b7d673a2c5d \
    --hash=sha256:7d053096f67cd1241601111b698f5cad775f97ab25d81567d3f59219b5f1adbd \
    --hash=sha256:804a4d582ba6e5b747c625bf1255e6b1507465494a40a2130978bda7b932c90b \
    --hash=sha256:807f52c1f798eef6cf26beb819eeb8819b1622ddfeef9d0977a8502d4db6d534 \
    --hash=sha256:80ed5e856eb7f30115aaf94e4a08114ccc8813e6ed1b5efa74f9f82e8509858f \
    --hash=sha256:8417cb1f36cc0bc7eaba8ccb0e04d55f0ee52df06df3ad55259b9a323555fc8b \
    --hash=sha256:8436c508b408b82d87dc5f62496973a1805cd46727c34440b0d29d8a2f50a6c9 \
    --hash=sha256:89149166622f4db9b4b6a449256291dc87a99ee53151c74cbd82a53c8c2f6ccd \
    --hash=sha256:8bfa33f4f2672964266e940dd22a195989ba31669bd84629f05fab3ef4e2d125 \
    --hash=sha256:8c60ca7339acd497a55b0ea5d506b2a2612afb2826560416f6894e8b5770d4a9 \
    --hash=sha256:91b36a978b5ae0ee86c394f5a54d6ef44db1de0815eb43de826d41d21e4af3de \
    --hash=sha256:955f8851919303c92343d2f66165294848d57e9bba6cf6e3625485a70a038d11 \
    --hash=sha256:97f68b8d6831127e4787ad15e6757232e14e12060bec17091b85eb1486b91d8d \
    --hash=sha256:9b23ca7ef998bc739bf6ffc077c2116917eabcc901f88da1b9856b210ef63f35 \
    --hash=sha256:9f0b8b1c6d84c8034a44893aba5e767bf9c7a211e313a9605d9c617d7083829f \
    --hash=sha256:aabfa34badd18f1da5ec1bc2715cadc8dca465868a4e73a0173466b688f29dda \
    --hash=sha256:ab36c8eb7e454e34e60eb55ca5d241a5d18b2c6244f6827a30e451c42410b5f7 \
    --hash=sha256:b010a7a4fd316c3c484d482922d13044979e78d1861f0e0650423144c616a46a \
    --hash=sha256:b1ac5992a838106edb89654e0aebfc24f5848ae2547d22c2c3f66454daa11971 \
    --hash=sha256:b7b2d86dd06bfc2ade3312a83a5c364c7ec2e3498f8734282c6c3d4b07b346b8 \
    --hash=sha256:b97e690a2118911e39b4042088092771b4ae3fc3aa86518f84b8cf6888dbdb41 \
    --hash=sha256:bc2722592d8998c870fa4e290c2eec2c1569b87fe58618e67d38b4665dfa680d \
    --hash=sha256:c0429126cf75e16c4f0ad00ee0eae4242dc652290f940152ca8c75c3a4b6ee8f \
    --hash=sha256:c30197aa96e8eed02200a83fba2657b4c3acd0f0aa4bdc9f6c1af8e8962e0757 \
    --hash=sha256:c4c3e6da02df6fa1410a7680bd3f63d4f710232d3139089536310d027950696a \
    --hash=sha256:c75cb2a3e389853835e84a2d8fb2b81a10645b503eca9bcb98df6b5a43eb8886 \
    --hash=sha256:c96836c97b1238e9c9e3fe90844c947d5afbf4f4c92762679acfe19927d81d77 \
    --hash=sha256:d7f50a1f8c450f3925cb367d011448c39239bb3eb4117c36a6d354794de4ce76 \
    --hash=sha256:d973f03c0cb71c5ed99037b870f2be986c3c05e63622c017ea9816881d2dd247 \
    --hash=sha256:d98b1668f06378c6dbefec3b92299716b931cd4e6061f3c875a71ced1780ab85 \
    --hash=sha256:d9c3cdf5390dcd29aa8056d13e8e99526cda0305acc038b96b30352aff5ff2bb \
    --hash=sha256:dad3e487649f498dd991eeb901125411559b22e8d7ab25d3aeb1af367df5efd7 \
    --hash=sha256:dccbe65bd2f7f7ec22c4ff99ed56faa1e9f785482b9bbd7c717e26fd723a1d1e \
    --hash=sha256:dd78cfcda14a1ef52584dbb008f7ac81c1328c0f58184bf9a84c49c605002da6 \
    --hash=sha256:e218488cd232553829be0664c2292d3af2eeeb94b32bea483cf79ac6a694e037 \
    --hash=sha256:e358e64305fe12299a08e08978f51fc21fac060dcfcddd95453eabe5b93ed0e1 \
    --hash=sha256:ea0d8d539afa5eb2728aa1932a988a9a7af94f18582ffae4bc10b3fbdad0626e \
    --hash=sha256:eab677309cdb30d047996b36d34caeda1dc91149e4fdca0b1a039b3f79d9a807 \
    --hash=sha256:eb8178fe3dba6450a3e024e95ac49ed3400e506fd4e9e5c32d30adda88cbd407 \
    --hash=sha256:ecddf25bee22fe4fe3737a399d0d177d72bc22be6913acfab364b40bce1ba83c \
    --hash=sha256:eea6ee1db730b3483adf394ea72f808b6e18cf3cb6454b4d86e04fa8c4327a12 \
    --hash=sha256:f08ff5e948271dc7e18a35641d2f11a4cd8dfd5634f55228b691e62b37125eb3 \
    --hash=sha256:f30bf9fd9be89ecb2360c7d94a711f00c09b976258846efe40db3d05828e8089 \
    --hash=sha256:fa88b843d6e211393a37219e6a1c1df99d35e8fd90446f1118f4216e307e48cd \
    --hash=sha256:fc54db6c8593ef7d4b2a331b58653356cf04f67c960f584edb7c3d8c97e8f39e \
    --hash=sha256:fd4ec41f914fa74ad1b8304bbc634b3de73d2a0889bd32076342a573e0779e00 \
    --hash=sha256:ffc9202a29ab3920fa812879e95a9e78b2465fd10be7fcbd042899695d75e616
click==8.1.8 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:63c132bbbed01578a06712a2d1f497bb62d9c1c0d329b7903a866228027263b2 \
    --hash=sha256:ed53c9d8990d83c2a27deae68e4ee337473f6330c040a31d4225c9574d16096a
colorama==0.4.6 ; python_version >= "3.12" and python_version < "4.0" and (sys_platform == "win32" or platform_system == "Windows") \
    --hash=sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44 \
    --hash=sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6
cryptography==44.0.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:04abd71114848aa25edb28e225ab5f268096f44cf0127f3d36975bdf1bdf3390 \
    --hash=sha256:0529b1d5a0105dd3731fa65680b45ce49da4d8115ea76e9da77a875396727b41 \
    --hash=sha256:1bc312dfb7a6e5d66082c87c34c8a62176e684b6fe3d90fcfe1568de675e6688 \
    --hash=sha256:268e4e9b177c76d569e8a145a6939eca9a5fec658c932348598818acf31ae9a5 \
    --hash=sha256:29ecec49f3ba3f3849362854b7253a9f59799e3763b0c9d0826259a88efa02f1 \
    --hash=sha256:2bf7bf75f7df9715f810d1b038870309342bff3069c5bd8c6b96128cb158668d \
    --hash=sha256:3b721b8b4d948b218c88cb8c45a01793483821e709afe5f622861fc6182b20a7 \
    --hash=sha256:3c00b6b757b32ce0f62c574b78b939afab9eecaf597c4d624caca4f9e71e7843 \
    --hash=sha256:3dc62975e31617badc19a906481deacdeb80b4bb454394b4098e3f2525a488c5 \
    --hash=sha256:4973da6ca3db4405c54cd0b26d328be54c7747e89e284fcff166132eb7bccc9c \
    --hash=sha256:4e389622b6927d8133f314949a9812972711a111d577a5d1f4bee5e58736b80a \
    --hash=sha256:51e4de3af4ec3899d6d178a8c005226491c27c4ba84101bfb59c901e10ca9f79 \
    --hash=sha256:5f6f90b72d8ccadb9c6e311c775c8305381db88374c65fa1a68250aa8a9cb3a6 \
    --hash=sha256:6210c05941994290f3f7f175a4a57dbbb2afd9273657614c506d5976db061181 \
    --hash=sha256:6f101b1f780f7fc613d040ca4bdf835c6ef3b00e9bd7125a4255ec574c7916e4 \
    --hash=sha256:7bdcd82189759aba3816d1f729ce42ffded1ac304c151d0a8e89b9996ab863d5 \
    --hash=sha256:7ca25849404be2f8e4b3c59483d9d3c51298a22c1c61a0e84415104dacaf5562 \
    --hash=sha256:81276f0ea79a208d961c433a947029e1a15948966658cf6710bbabb60fcc2639 \
    --hash=sha256:8cadc6e3b5a1f144a039ea08a0bdb03a2a92e19c46be3285123d32029f40a922 \
    --hash=sha256:8e0ddd63e6bf1161800592c71ac794d3fb8001f2caebe0966e77c5234fa9efc3 \
    --hash=sha256:909c97ab43a9c0c0b0ada7a1281430e4e5ec0458e6d9244c0e821bbf152f061d \
    --hash=sha256:96e7a5e9d6e71f9f4fca8eebfd603f8e86c5225bb18eb621b2c1e50b290a9471 \
    --hash=sha256:9a1e657c0f4ea2a23304ee3f964db058c9e9e635cc7019c4aa21c330755ef6fd \
    --hash=sha256:9eb9d22b0a5d8fd9925a7764a054dca914000607dff201a24c791ff5c799e1fa \
    --hash=sha256:af4ff3e388f2fa7bff9f7f2b31b87d5651c45731d3e8cfa0944be43dff5cfbdb \
    --hash=sha256:b042d2a275c8cee83a4b7ae30c45a15e6a4baa65a179a0ec2d78ebb90e4f6699 \
    --hash=sha256:bc821e161ae88bfe8088d11bb39caf2916562e0a2dc7b6d56714a48b784ef0bb \
    --hash=sha256:c505d61b6176aaf982c5717ce04e87da5abc9a36a5b39ac03905c4aafe8de7aa \
    --hash=sha256:c63454aa261a0cf0c5b4718349629793e9e634993538db841165b3df74f37ec0 \
    --hash=sha256:c7362add18b416b69d58c910caa217f980c5ef39b23a38a0880dfd87bdf8cd23 \
    --hash=sha256:d03806036b4f89e3b13b6218fefea8d5312e450935b1a2d55f0524e2ed7c59d9 \
    --hash=sha256:d1b3031093a366ac767b3feb8bcddb596671b3aaff82d4050f984da0c248b615 \
    --hash=sha256:d1c3572526997b36f245a96a2b1713bf79ce99b271bbcf084beb6b9b075f29ea \
    --hash=sha256:efcfe97d1b3c79e486554efddeb8f6f53a4cdd4cf6086642784fa31fc384e1d7 \
    --hash=sha256:f514ef4cd14bb6fb484b4a60203e912cfcb64f2ab139e88c2274511514bf7308
dnspython==2.7.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:b4c34b7d10b51bcc3a5071e7b8dee77939f1e878477eeecc965e9835f63c6c86 \
    --hash=sha256:ce9c432eda0dc91cf618a5cedf1a4e142651196bbcd2c80e89ed5a907e5cfaf1
ecdsa==0.19.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:30638e27cf77b7e15c4c4cc1973720149e1033827cfd00661ca5c8cc0cdb24c3 \
    --hash=sha256:478cba7b62555866fcb3bb3fe985e06decbdb68ef55713c4e5ab98c57d508e61
email-validator==2.2.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:561977c2d73ce3611850a06fa56b414621e0c8faa9d66f2611407d87465da631 \
    --hash=sha256:cb690f344c617a714f22e66ae771445a1ceb46821152df8e165c5f9a364582b7
faker==37.1.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:ad9dc66a3b84888b837ca729e85299a96b58fdaef0323ed0baace93c9614af06 \
    --hash=sha256:dc2f730be71cb770e9c715b13374d80dbcee879675121ab51f9683d262ae9a1c
fastapi==0.115.12 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:1e2c2a2646905f9e83d32f04a3f86aff4a286669c6c950ca95b5fd68c2602681 \
    --hash=sha256:e94613d6c05e27be7ffebdd6ea5f388112e5e430c8f7d6494a9d1d88d43e814d
google-api-core==2.24.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:810a63ac95f3c441b7c0e43d344e372887f62ce9071ba972eacf32672e072de9 \
    --hash=sha256:81718493daf06d96d6bc76a91c23874dbf2fac0adbbf542831b805ee6e974696
google-auth==2.39.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0150b6711e97fb9f52fe599f55648950cc4540015565d8fbb31be2ad6e1548a2 \
    --hash=sha256:73222d43cdc35a3aeacbfdcaf73142a97839f10de930550d89ebfe1d0a00cde7
google-cloud-core==2.4.3 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:1fab62d7102844b278fe6dead3af32408b1df3eb06f5c7e8634cbd40edc4da53 \
    --hash=sha256:5130f9f4c14b4fafdff75c79448f9495cfade0d8775facf1b09c3bf67e027f6e
google-cloud-storage==3.1.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:944273179897c7c8a07ee15f2e6466a02da0c7c4b9ecceac2a26017cb2972049 \
    --hash=sha256:eaf36966b68660a9633f03b067e4a10ce09f1377cae3ff9f2c699f69a81c66c6
google-crc32c==1.7.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0f99eaa09a9a7e642a61e06742856eec8b19fc0037832e03f941fe7cf0c8e4db \
    --hash=sha256:19eafa0e4af11b0a4eb3974483d55d2d77ad1911e6cf6f832e1574f6781fd337 \
    --hash=sha256:1c67ca0a1f5b56162951a9dae987988679a7db682d6f97ce0f6381ebf0fbea4c \
    --hash=sha256:1f2b3522222746fff0e04a9bd0a23ea003ba3cccc8cf21385c564deb1f223242 \
    --hash=sha256:22beacf83baaf59f9d3ab2bbb4db0fb018da8e5aebdce07ef9f09fce8220285e \
    --hash=sha256:2bff2305f98846f3e825dbeec9ee406f89da7962accdb29356e4eadc251bd472 \
    --hash=sha256:2d73a68a653c57281401871dd4aeebbb6af3191dcac751a76ce430df4d403194 \
    --hash=sha256:32d1da0d74ec5634a05f53ef7df18fc646666a25efaaca9fc7dcfd4caf1d98c3 \
    --hash=sha256:3bda0fcb632d390e3ea8b6b07bf6b4f4a66c9d02dcd6fbf7ba00a197c143f582 \
    --hash=sha256:6335de12921f06e1f774d0dd1fbea6bf610abe0887a1638f64d694013138be5d \
    --hash=sha256:6b211ddaf20f7ebeec5c333448582c224a7c90a9d98826fbab82c0ddc11348e6 \
    --hash=sha256:6efb97eb4369d52593ad6f75e7e10d053cf00c48983f7a973105bc70b0ac4d82 \
    --hash=sha256:6fbab4b935989e2c3610371963ba1b86afb09537fd0c633049be82afe153ac06 \
    --hash=sha256:713121af19f1a617054c41f952294764e0c5443d5a5d9034b2cd60f5dd7e0349 \
    --hash=sha256:754561c6c66e89d55754106739e22fdaa93fafa8da7221b29c8b8e8270c6ec8a \
    --hash=sha256:7cc81b3a2fbd932a4313eb53cc7d9dde424088ca3a0337160f35d91826880c1d \
    --hash=sha256:85fef7fae11494e747c9fd1359a527e5970fc9603c90764843caabd3a16a0a48 \
    --hash=sha256:905a385140bf492ac300026717af339790921f411c0dfd9aa5a9e69a08ed32eb \
    --hash=sha256:9fc196f0b8d8bd2789352c6a522db03f89e83a0ed6b64315923c396d7a932315 \
    --hash=sha256:a8e9afc74168b0b2232fb32dd202c93e46b7d5e4bf03e66ba5dc273bb3559589 \
    --hash=sha256:b07d48faf8292b4db7c3d64ab86f950c2e94e93a11fd47271c28ba458e4a0d76 \
    --hash=sha256:b6d86616faaea68101195c6bdc40c494e4d76f41e07a37ffdef270879c15fb65 \
    --hash=sha256:b7491bdc0c7564fcf48c0179d2048ab2f7c7ba36b84ccd3a3e1c3f7a72d3bba6 \
    --hash=sha256:bb5e35dcd8552f76eed9461a23de1030920a3c953c1982f324be8f97946e7127 \
    --hash=sha256:d68e17bad8f7dd9a49181a1f5a8f4b251c6dbc8cc96fb79f1d321dfd57d66f53 \
    --hash=sha256:dcdf5a64adb747610140572ed18d011896e3b9ae5195f2514b7ff678c80f1603 \
    --hash=sha256:df8b38bdaf1629d62d51be8bdd04888f37c451564c2042d36e5812da9eff3c35 \
    --hash=sha256:e10554d4abc5238823112c2ad7e4560f96c7bf3820b202660373d769d9e6e4c9 \
    --hash=sha256:e42e20a83a29aa2709a0cf271c7f8aefaa23b7ab52e53b322585297bb94d4638 \
    --hash=sha256:ed66cbe1ed9cbaaad9392b5259b3eba4a9e565420d734e6238813c428c3336c9 \
    --hash=sha256:ee6547b657621b6cbed3562ea7826c3e11cab01cd33b74e1f677690652883e77 \
    --hash=sha256:f2226b6a8da04f1d9e61d3e357f2460b9551c5e6950071437e122c958a18ae14 \
    --hash=sha256:fa8136cc14dd27f34a3221c0f16fd42d8a40e4778273e61a3c19aedaa44daf6b \
    --hash=sha256:fc5319db92daa516b653600794d5b9f9439a9a121f3e162f94b0e1891c7933cb
google-resumable-media==2.7.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:3ce7551e9fe6d99e9a126101d2536612bb73486721951e9562fee0f90c6ababa \
    --hash=sha256:5280aed4629f2b60b847b0d42f9857fd4935c11af266744df33d8074cae92fe0
googleapis-common-protos==1.70.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0e1b44e0ea153e6594f9f394fef15193a68aaaea2d843f83e2742717ca753257 \
    --hash=sha256:b8bfcca8c25a2bb253e0e0b0adaf8c00773e5e6af6fd92397576680b807e0fd8
greenlet==3.2.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0010e928e1901d36625f21d008618273f9dda26b516dbdecf873937d39c9dff0 \
    --hash=sha256:04e781447a4722e30b4861af728cb878d73a3df79509dc19ea498090cea5d204 \
    --hash=sha256:0e14541f9024a280adb9645143d6a0a51fda6f7c5695fd96cb4d542bb563442f \
    --hash=sha256:144283ad88ed77f3ebd74710dd419b55dd15d18704b0ae05935766a93f5671c5 \
    --hash=sha256:17fd241c0d50bacb7ce8ff77a30f94a2d0ca69434ba2e0187cf95a5414aeb7e1 \
    --hash=sha256:18adc14ab154ca6e53eecc9dc50ff17aeb7ba70b7e14779b26e16d71efa90038 \
    --hash=sha256:199453d64b02d0c9d139e36d29681efd0e407ed8e2c0bf89d88878d6a787c28f \
    --hash=sha256:1cf89e2d92bae0d7e2d6093ce0bed26feeaf59a5d588e3984e35fcd46fc41090 \
    --hash=sha256:1d2d43bd711a43db8d9b9187500e6432ddb4fafe112d082ffabca8660a9e01a7 \
    --hash=sha256:1dcb1108449b55ff6bc0edac9616468f71db261a4571f27c47ccf3530a7f8b97 \
    --hash=sha256:211a9721f540e454a02e62db7956263e9a28a6cf776d4b9a7213844e36426333 \
    --hash=sha256:23f56a0103deb5570c8d6a0bb4ddf8a7a28931973ad7ed7a883460a67e599b32 \
    --hash=sha256:2688b3bd3198cc4bad7a79648a95fee088c24a0f6abd05d3639e6c3040ded015 \
    --hash=sha256:2919b126eeb63ca5fa971501cd20cd6cdb5522369a8e39548bbc73a3e10b8b41 \
    --hash=sha256:29449a2b82ed7ce11f8668c31ef20d31e9d88cd8329eb933098fab5a8608a93a \
    --hash=sha256:2b986f1a6467710e7ffeeeac1777da0318c95bbfcc467acbd0bd35abc775f558 \
    --hash=sha256:33ea7e7269d6f7275ce31f593d6dcfedd97539c01f63fbdc8d84e493e20b1b2c \
    --hash=sha256:397b6bbda06f8fe895893d96218cd6f6d855a6701dc45012ebe12262423cec8b \
    --hash=sha256:39801e633a978c3f829f21022501e7b0c3872683d7495c1850558d1a6fb95ed0 \
    --hash=sha256:4174fa6fa214e8924cedf332b6f2395ba2b9879f250dacd3c361b2fca86f58af \
    --hash=sha256:430cba962c85e339767235a93450a6aaffed6f9c567e73874ea2075f5aae51e1 \
    --hash=sha256:47aeadd1e8fbdef8fdceb8fb4edc0cbb398a57568d56fd68f2bc00d0d809e6b6 \
    --hash=sha256:58ef3d637c54e2f079064ca936556c4af3989144e4154d80cfd4e2a59fc3769c \
    --hash=sha256:598da3bd464c2cc411b723e3d4afc27b13c219ac077ba897bac88443ae45f5ec \
    --hash=sha256:5be69cd50994b8465c3ad1467f9e63001f76e53a89440ad4440d1b6d52591280 \
    --hash=sha256:5e57ff52315bfc0c5493917f328b8ba3ae0c0515d94524453c4d24e7638cbb53 \
    --hash=sha256:6005f7a86de836a1dc4b8d824a2339cdd5a1ca7cb1af55ea92575401f9952f4c \
    --hash=sha256:6017a4d430fad5229e397ad464db504ae70cb7b903757c4688cee6c25d6ce8d8 \
    --hash=sha256:60e77242e38e99ecaede853755bbd8165e0b20a2f1f3abcaa6f0dceb826a7411 \
    --hash=sha256:6fad8a9ca98b37951a053d7d2d2553569b151cd8c4ede744806b94d50d7f8f73 \
    --hash=sha256:7154b13ef87a8b62fc05419f12d75532d7783586ad016c57b5de8a1c6feeb517 \
    --hash=sha256:78b721dfadc60e3639141c0e1f19d23953c5b4b98bfcaf04ce40f79e4f01751c \
    --hash=sha256:7b162de2fb61b4c7f4b5d749408bf3280cae65db9b5a6aaf7f922ac829faa67c \
    --hash=sha256:7b17a26abc6a1890bf77d5d6b71c0999705386b00060d15c10b8182679ff2790 \
    --hash=sha256:7d08b88ee8d506ca1f5b2a58744e934d33c6a1686dd83b81e7999dfc704a912f \
    --hash=sha256:7f163d04f777e7bd229a50b937ecc1ae2a5b25296e6001445e5433e4f51f5191 \
    --hash=sha256:7fee6f518868e8206c617f4084a83ad4d7a3750b541bf04e692dfa02e52e805d \
    --hash=sha256:82a68a25a08f51fc8b66b113d1d9863ee123cdb0e8f1439aed9fc795cd6f85cf \
    --hash=sha256:844acfd479ee380f3810415e682c9ee941725fb90b45e139bb7fd6f85c6c9a30 \
    --hash=sha256:8a8940a8d301828acd8b9f3f85db23069a692ff2933358861b19936e29946b95 \
    --hash=sha256:8b3538711e7c0efd5f7a8fc1096c4db9598d6ed99dc87286b31e4ce9f8a8da67 \
    --hash=sha256:8fd2583024ff6cd5d4f842d446d001de4c4fe1264fdb5f28ddea28f6488866df \
    --hash=sha256:a0bc5776ac2831c022e029839bf1b9d3052332dcf5f431bb88c8503e27398e31 \
    --hash=sha256:b2392cc41eeed4055978c6b52549ccd9effd263bb780ffd639c0e1e7e2055ab0 \
    --hash=sha256:b7a7b7f2bad3ca72eb2fa14643f1c4ca11d115614047299d89bc24a3b11ddd09 \
    --hash=sha256:b86a3ccc865ae601f446af042707b749eebc297928ea7bd0c5f60c56525850be \
    --hash=sha256:b99de16560097b9984409ded0032f101f9555e1ab029440fc6a8b5e76dbba7ac \
    --hash=sha256:cd37273dc7ca1d5da149b58c8b3ce0711181672ba1b09969663905a765affe21 \
    --hash=sha256:ce531d7c424ef327a391de7a9777a6c93a38e1f89e18efa903a1c4ba11f85905 \
    --hash=sha256:d3f32d7c70b1c26844fd0e4e56a1da852b493e4e1c30df7b07274a1e5a9b599e \
    --hash=sha256:d97bc1be4bad83b70d8b8627ada6724091af41139616696e59b7088f358583b9 \
    --hash=sha256:e61d426969b68b2170a9f853cc36d5318030494576e9ec0bfe2dc2e2afa15a68 \
    --hash=sha256:e8622b33d8694ec373ad55050c3d4e49818132b44852158442e1931bb02af336 \
    --hash=sha256:e8ac9a2c20fbff3d0b853e9ef705cdedb70d9276af977d1ec1cde86a87a4c821 \
    --hash=sha256:ee59db626760f1ca8da697a086454210d36a19f7abecc9922a2374c04b47735b
h11==0.14.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d \
    --hash=sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761
httptools==0.6.4 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0614154d5454c21b6410fdf5262b4a3ddb0f53f1e1721cfd59d55f32138c578a \
    --hash=sha256:0e563e54979e97b6d13f1bbc05a96109923e76b901f786a5eae36e99c01237bd \
    --hash=sha256:16e603a3bff50db08cd578d54f07032ca1631450ceb972c2f834c2b860c28ea2 \
    --hash=sha256:288cd628406cc53f9a541cfaf06041b4c71d751856bab45e3702191f931ccd17 \
    --hash=sha256:28908df1b9bb8187393d5b5db91435ccc9c8e891657f9cbb42a2541b44c82fc8 \
    --hash=sha256:322d20ea9cdd1fa98bd6a74b77e2ec5b818abdc3d36695ab402a0de8ef2865a3 \
    --hash=sha256:342dd6946aa6bda4b8f18c734576106b8a31f2fe31492881a9a160ec84ff4bd5 \
    --hash=sha256:345c288418f0944a6fe67be8e6afa9262b18c7626c3ef3c28adc5eabc06a68da \
    --hash=sha256:3c73ce323711a6ffb0d247dcd5a550b8babf0f757e86a52558fe5b86d6fefcc0 \
    --hash=sha256:40a5ec98d3f49904b9fe36827dcf1aadfef3b89e2bd05b0e35e94f97c2b14721 \
    --hash=sha256:40b0f7fe4fd38e6a507bdb751db0379df1e99120c65fbdc8ee6c1d044897a636 \
    --hash=sha256:40dc6a8e399e15ea525305a2ddba998b0af5caa2566bcd79dcbe8948181eeaff \
    --hash=sha256:4b36913ba52008249223042dca46e69967985fb4051951f94357ea681e1f5dc0 \
    --hash=sha256:4d87b29bd4486c0093fc64dea80231f7c7f7eb4dc70ae394d70a495ab8436071 \
    --hash=sha256:4e93eee4add6493b59a5c514da98c939b244fce4a0d8879cd3f466562f4b7d5c \
    --hash=sha256:59e724f8b332319e2875efd360e61ac07f33b492889284a3e05e6d13746876f4 \
    --hash=sha256:69422b7f458c5af875922cdb5bd586cc1f1033295aa9ff63ee196a87519ac8e1 \
    --hash=sha256:703c346571fa50d2e9856a37d7cd9435a25e7fd15e236c397bf224afaa355fe9 \
    --hash=sha256:85071a1e8c2d051b507161f6c3e26155b5c790e4e28d7f236422dbacc2a9cc44 \
    --hash=sha256:856f4bc0478ae143bad54a4242fccb1f3f86a6e1be5548fecfd4102061b3a083 \
    --hash=sha256:85797e37e8eeaa5439d33e556662cc370e474445d5fab24dcadc65a8ffb04003 \
    --hash=sha256:90d96a385fa941283ebd231464045187a31ad932ebfa541be8edf5b3c2328959 \
    --hash=sha256:94978a49b8f4569ad607cd4946b759d90b285e39c0d4640c6b36ca7a3ddf2efc \
    --hash=sha256:aafe0f1918ed07b67c1e838f950b1c1fabc683030477e60b335649b8020e1076 \
    --hash=sha256:ab9ba8dcf59de5181f6be44a77458e45a578fc99c31510b8c65b7d5acc3cf490 \
    --hash=sha256:ade273d7e767d5fae13fa637f4d53b6e961fb7fd93c7797562663f0171c26660 \
    --hash=sha256:b799de31416ecc589ad79dd85a0b2657a8fe39327944998dea368c1d4c9e55e6 \
    --hash=sha256:c26f313951f6e26147833fc923f78f95604bbec812a43e5ee37f26dc9e5a686c \
    --hash=sha256:ca80b7485c76f768a3bc83ea58373f8db7b015551117375e4918e2aa77ea9b50 \
    --hash=sha256:d1ffd262a73d7c28424252381a5b854c19d9de5f56f075445d33919a637e3547 \
    --hash=sha256:d3f0d369e7ffbe59c4b6116a44d6a8eb4783aae027f2c0b366cf0aa964185dba \
    --hash=sha256:d54efd20338ac52ba31e7da78e4a72570cf729fac82bc31ff9199bedf1dc7440 \
    --hash=sha256:dacdd3d10ea1b4ca9df97a0a303cbacafc04b5cd375fa98732678151643d4988 \
    --hash=sha256:db353d22843cf1028f43c3651581e4bb49374d85692a85f95f7b9a130e1b2cab \
    --hash=sha256:db78cb9ca56b59b016e64b6031eda5653be0589dba2b1b43453f6e8b405a0970 \
    --hash=sha256:deee0e3343f98ee8047e9f4c5bc7cedbf69f5734454a94c38ee829fb2d5fa3c1 \
    --hash=sha256:df017d6c780287d5c80601dafa31f17bddb170232d85c066604d8558683711a2 \
    --hash=sha256:df959752a0c2748a65ab5387d08287abf6779ae9165916fe053e68ae1fbdc47f \
    --hash=sha256:ec4f178901fa1834d4a060320d2f3abc5c9e39766953d038f1458cb885f47e81 \
    --hash=sha256:f47f8ed67cc0ff862b84a1189831d1d33c963fb3ce1ee0c65d3b0cbe7b711069 \
    --hash=sha256:f8787367fbdfccae38e35abf7641dafc5310310a5987b689f4c32cc8cc3ee975 \
    --hash=sha256:f9eb89ecf8b290f2e293325c646a211ff1c2493222798bb80a530c5e7502494f \
    --hash=sha256:fc411e1c0a7dcd2f902c7c48cf079947a7e65b5485dea9decb82b9105ca71a43
idna==3.10 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9 \
    --hash=sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3
mako==1.3.10 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:99579a6f39583fa7e5630a28c3c1f440e4e97a414b80372649c0ce338da2ea28 \
    --hash=sha256:baef24a52fc4fc514a0887ac600f9f1cff3d82c61d4d700a1fa84d597b88db59
markupsafe==3.0.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0bff5e0ae4ef2e1ae4fdf2dfd5b76c75e5c2fa4132d05fc1b0dabcd20c7e28c4 \
    --hash=sha256:0f4ca02bea9a23221c0182836703cbf8930c5e9454bacce27e767509fa286a30 \
    --hash=sha256:1225beacc926f536dc82e45f8a4d68502949dc67eea90eab715dea3a21c1b5f0 \
    --hash=sha256:131a3c7689c85f5ad20f9f6fb1b866f402c445b220c19fe4308c0b147ccd2ad9 \
    --hash=sha256:15ab75ef81add55874e7ab7055e9c397312385bd9ced94920f2802310c930396 \
    --hash=sha256:1a9d3f5f0901fdec14d8d2f66ef7d035f2157240a433441719ac9a3fba440b13 \
    --hash=sha256:1c99d261bd2d5f6b59325c92c73df481e05e57f19837bdca8413b9eac4bd8028 \
    --hash=sha256:1e084f686b92e5b83186b07e8a17fc09e38fff551f3602b249881fec658d3eca \
    --hash=sha256:2181e67807fc2fa785d0592dc2d6206c019b9502410671cc905d132a92866557 \
    --hash=sha256:2cb8438c3cbb25e220c2ab33bb226559e7afb3baec11c4f218ffa7308603c832 \
    --hash=sha256:3169b1eefae027567d1ce6ee7cae382c57fe26e82775f460f0b2778beaad66c0 \
    --hash=sha256:3809ede931876f5b2ec92eef964286840ed3540dadf803dd570c3b7e13141a3b \
    --hash=sha256:38a9ef736c01fccdd6600705b09dc574584b89bea478200c5fbf112a6b0d5579 \
    --hash=sha256:3d79d162e7be8f996986c064d1c7c817f6df3a77fe3d6859f6f9e7be4b8c213a \
    --hash=sha256:444dcda765c8a838eaae23112db52f1efaf750daddb2d9ca300bcae1039adc5c \
    --hash=sha256:48032821bbdf20f5799ff537c7ac3d1fba0ba032cfc06194faffa8cda8b560ff \
    --hash=sha256:4aa4e5faecf353ed117801a068ebab7b7e09ffb6e1d5e412dc852e0da018126c \
    --hash=sha256:52305740fe773d09cffb16f8ed0427942901f00adedac82ec8b67752f58a1b22 \
    --hash=sha256:569511d3b58c8791ab4c2e1285575265991e6d8f8700c7be0e88f86cb0672094 \
    --hash=sha256:57cb5a3cf367aeb1d316576250f65edec5bb3be939e9247ae594b4bcbc317dfb \
    --hash=sha256:5b02fb34468b6aaa40dfc198d813a641e3a63b98c2b05a16b9f80b7ec314185e \
    --hash=sha256:6381026f158fdb7c72a168278597a5e3a5222e83ea18f543112b2662a9b699c5 \
    --hash=sha256:6af100e168aa82a50e186c82875a5893c5597a0c1ccdb0d8b40240b1f28b969a \
    --hash=sha256:6c89876f41da747c8d3677a2b540fb32ef5715f97b66eeb0c6b66f5e3ef6f59d \
    --hash=sha256:6e296a513ca3d94054c2c881cc913116e90fd030ad1c656b3869762b754f5f8a \
    --hash=sha256:70a87b411535ccad5ef2f1df5136506a10775d267e197e4cf531ced10537bd6b \
    --hash=sha256:7e94c425039cde14257288fd61dcfb01963e658efbc0ff54f5306b06054700f8 \
    --hash=sha256:846ade7b71e3536c4e56b386c2a47adf5741d2d8b94ec9dc3e92e5e1ee1e2225 \
    --hash=sha256:88416bd1e65dcea10bc7569faacb2c20ce071dd1f87539ca2ab364bf6231393c \
    --hash=sha256:88b49a3b9ff31e19998750c38e030fc7bb937398b1f78cfa599aaef92d693144 \
    --hash=sha256:8c4e8c3ce11e1f92f6536ff07154f9d49677ebaaafc32db9db4620bc11ed480f \
    --hash=sha256:8e06879fc22a25ca47312fbe7c8264eb0b662f6db27cb2d3bbbc74b1df4b9b87 \
    --hash=sha256:9025b4018f3a1314059769c7bf15441064b2207cb3f065e6ea1e7359cb46db9d \
    --hash=sha256:93335ca3812df2f366e80509ae119189886b0f3c2b81325d39efdb84a1e2ae93 \
    --hash=sha256:9778bd8ab0a994ebf6f84c2b949e65736d5575320a17ae8984a77fab08db94cf \
    --hash=sha256:9e2d922824181480953426608b81967de705c3cef4d1af983af849d7bd619158 \
    --hash=sha256:a123e330ef0853c6e822384873bef7507557d8e4a082961e1defa947aa59ba84 \
    --hash=sha256:a904af0a6162c73e3edcb969eeeb53a63ceeb5d8cf642fade7d39e7963a22ddb \
    --hash=sha256:ad10d3ded218f1039f11a75f8091880239651b52e9bb592ca27de44eed242a48 \
    --hash=sha256:b424c77b206d63d500bcb69fa55ed8d0e6a3774056bdc4839fc9298a7edca171 \
    --hash=sha256:b5a6b3ada725cea8a5e634536b1b01c30bcdcd7f9c6fff4151548d5bf6b3a36c \
    --hash=sha256:ba8062ed2cf21c07a9e295d5b8a2a5ce678b913b45fdf68c32d95d6c1291e0b6 \
    --hash=sha256:ba9527cdd4c926ed0760bc301f6728ef34d841f405abf9d4f959c478421e4efd \
    --hash=sha256:bbcb445fa71794da8f178f0f6d66789a28d7319071af7a496d4d507ed566270d \
    --hash=sha256:bcf3e58998965654fdaff38e58584d8937aa3096ab5354d493c77d1fdd66d7a1 \
    --hash=sha256:c0ef13eaeee5b615fb07c9a7dadb38eac06a0608b41570d8ade51c56539e509d \
    --hash=sha256:cabc348d87e913db6ab4aa100f01b08f481097838bdddf7c7a84b7575b7309ca \
    --hash=sha256:cdb82a876c47801bb54a690c5ae105a46b392ac6099881cdfb9f6e95e4014c6a \
    --hash=sha256:cfad01eed2c2e0c01fd0ecd2ef42c492f7f93902e39a42fc9ee1692961443a29 \
    --hash=sha256:d16a81a06776313e817c951135cf7340a3e91e8c1ff2fac444cfd75fffa04afe \
    --hash=sha256:d8213e09c917a951de9d09ecee036d5c7d36cb6cb7dbaece4c71a60d79fb9798 \
    --hash=sha256:e07c3764494e3776c602c1e78e298937c3315ccc9043ead7e685b7f2b8d47b3c \
    --hash=sha256:e17c96c14e19278594aa4841ec148115f9c7615a47382ecb6b82bd8fea3ab0c8 \
    --hash=sha256:e444a31f8db13eb18ada366ab3cf45fd4b31e4db1236a4448f68778c1d1a5a2f \
    --hash=sha256:e6a2a455bd412959b57a172ce6328d2dd1f01cb2135efda2e4576e8a23fa3b0f \
    --hash=sha256:eaa0a10b7f72326f1372a713e73c3f739b524b3af41feb43e4921cb529f5929a \
    --hash=sha256:eb7972a85c54febfb25b5c4b4f3af4dcc731994c7da0d8a0b4a6eb0640e1d178 \
    --hash=sha256:ee55d3edf80167e48ea11a923c7386f4669df67d7994554387f84e7d8b0a2bf0 \
    --hash=sha256:f3818cb119498c0678015754eba762e0d61e5b52d34c8b13d770f0719f7b1d79 \
    --hash=sha256:f8b3d067f2e40fe93e1ccdd6b2e1d16c43140e76f02fb1319a05cf2b79d99430 \
    --hash=sha256:fcabf5ff6eea076f859677f5f0b6b5c1a51e70a376b0579e0eadef8db48c6b50
numpy==2.2.5 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0255732338c4fdd00996c0421884ea8a3651eea555c3a56b84892b66f696eb70 \
    --hash=sha256:02f226baeefa68f7d579e213d0f3493496397d8f1cff5e2b222af274c86a552a \
    --hash=sha256:059b51b658f4414fff78c6d7b1b4e18283ab5fa56d270ff212d5ba0c561846f4 \
    --hash=sha256:0bcb1d057b7571334139129b7f941588f69ce7c4ed15a9d6162b2ea54ded700c \
    --hash=sha256:0cd48122a6b7eab8f06404805b1bd5856200e3ed6f8a1b9a194f9d9054631beb \
    --hash=sha256:19f4718c9012e3baea91a7dba661dcab2451cda2550678dc30d53acb91a7290f \
    --hash=sha256:1a161c2c79ab30fe4501d5a2bbfe8b162490757cf90b7f05be8b80bc02f7bb8e \
    --hash=sha256:1f4a922da1729f4c40932b2af4fe84909c7a6e167e6e99f71838ce3a29f3fe26 \
    --hash=sha256:261a1ef047751bb02f29dfe337230b5882b54521ca121fc7f62668133cb119c9 \
    --hash=sha256:262d23f383170f99cd9191a7c85b9a50970fe9069b2f8ab5d786eca8a675d60b \
    --hash=sha256:2ba321813a00e508d5421104464510cc962a6f791aa2fca1c97b1e65027da80d \
    --hash=sha256:2c1a1c6ccce4022383583a6ded7bbcda22fc635eb4eb1e0a053336425ed36dfa \
    --hash=sha256:352d330048c055ea6db701130abc48a21bec690a8d38f8284e00fab256dc1376 \
    --hash=sha256:369e0d4647c17c9363244f3468f2227d557a74b6781cb62ce57cf3ef5cc7c610 \
    --hash=sha256:36ab5b23915887543441efd0417e6a3baa08634308894316f446027611b53bf1 \
    --hash=sha256:37e32e985f03c06206582a7323ef926b4e78bdaa6915095ef08070471865b906 \
    --hash=sha256:3a801fef99668f309b88640e28d261991bfad9617c27beda4a3aec4f217ea073 \
    --hash=sha256:3d14b17b9be5f9c9301f43d2e2a4886a33b53f4e6fdf9ca2f4cc60aeeee76372 \
    --hash=sha256:422cc684f17bc963da5f59a31530b3936f57c95a29743056ef7a7903a5dbdf88 \
    --hash=sha256:4520caa3807c1ceb005d125a75e715567806fed67e315cea619d5ec6e75a4191 \
    --hash=sha256:47834cde750d3c9f4e52c6ca28a7361859fcaf52695c7dc3cc1a720b8922683e \
    --hash=sha256:47f9ed103af0bc63182609044b0490747e03bd20a67e391192dde119bf43d52f \
    --hash=sha256:498815b96f67dc347e03b719ef49c772589fb74b8ee9ea2c37feae915ad6ebda \
    --hash=sha256:54088a5a147ab71a8e7fdfd8c3601972751ded0739c6b696ad9cb0343e21ab73 \
    --hash=sha256:55f09e00d4dccd76b179c0f18a44f041e5332fd0e022886ba1c0bbf3ea4a18d0 \
    --hash=sha256:5a0ac90e46fdb5649ab6369d1ab6104bfe5854ab19b645bf5cda0127a13034ae \
    --hash=sha256:6411f744f7f20081b1b4e7112e0f4c9c5b08f94b9f086e6f0adf3645f85d3a4d \
    --hash=sha256:6413d48a9be53e183eb06495d8e3b006ef8f87c324af68241bbe7a39e8ff54c3 \
    --hash=sha256:7451f92eddf8503c9b8aa4fe6aa7e87fd51a29c2cfc5f7dbd72efde6c65acf57 \
    --hash=sha256:8b4c0773b6ada798f51f0f8e30c054d32304ccc6e9c5d93d46cb26f3d385ab19 \
    --hash=sha256:8dfa94b6a4374e7851bbb6f35e6ded2120b752b063e6acdd3157e4d2bb922eba \
    --hash=sha256:97c8425d4e26437e65e1d189d22dff4a079b747ff9c2788057bfb8114ce1e133 \
    --hash=sha256:9d75f338f5f79ee23548b03d801d28a505198297534f62416391857ea0479571 \
    --hash=sha256:9de6832228f617c9ef45d948ec1cd8949c482238d68b2477e6f642c33a7b0a54 \
    --hash=sha256:a4cbdef3ddf777423060c6f81b5694bad2dc9675f110c4b2a60dc0181543fac7 \
    --hash=sha256:a9c0d994680cd991b1cb772e8b297340085466a6fe964bc9d4e80f5e2f43c291 \
    --hash=sha256:aa70fdbdc3b169d69e8c59e65c07a1c9351ceb438e627f0fdcd471015cd956be \
    --hash=sha256:abe38cd8381245a7f49967a6010e77dbf3680bd3627c0fe4362dd693b404c7f8 \
    --hash=sha256:b13f04968b46ad705f7c8a80122a42ae8f620536ea38cf4bdd374302926424dd \
    --hash=sha256:b4ea7e1cff6784e58fe281ce7e7f05036b3e1c89c6f922a6bfbc0a7e8768adbe \
    --hash=sha256:b6f91524d31b34f4a5fee24f5bc16dcd1491b668798b6d85585d836c1e633a6a \
    --hash=sha256:c26843fd58f65da9491165072da2cccc372530681de481ef670dcc8e27cfb066 \
    --hash=sha256:c42365005c7a6c42436a54d28c43fe0e01ca11eb2ac3cefe796c25a5f98e5e9b \
    --hash=sha256:c8b82a55ef86a2d8e81b63da85e55f5537d2157165be1cb2ce7cfa57b6aef38b \
    --hash=sha256:ced69262a8278547e63409b2653b372bf4baff0870c57efa76c5703fd6543282 \
    --hash=sha256:d2e3bdadaba0e040d1e7ab39db73e0afe2c74ae277f5614dad53eadbecbbb169 \
    --hash=sha256:d403c84991b5ad291d3809bace5e85f4bbf44a04bdc9a88ed2bb1807b3360bb8 \
    --hash=sha256:d7543263084a85fbc09c704b515395398d31d6395518446237eac219eab9e55e \
    --hash=sha256:d8882a829fd779f0f43998e931c466802a77ca1ee0fe25a3abe50278616b1471 \
    --hash=sha256:e4f0b035d9d0ed519c813ee23e0a733db81ec37d2e9503afbb6e54ccfdee0fa7 \
    --hash=sha256:e8b025c351b9f0e8b5436cf28a07fa4ac0204d67b38f01433ac7f9b870fa38c6 \
    --hash=sha256:eb7fd5b184e5d277afa9ec0ad5e4eb562ecff541e7f60e69ee69c8d59e9aeaba \
    --hash=sha256:ec31367fd6a255dc8de4772bd1658c3e926d8e860a0b6e922b615e532d320ddc \
    --hash=sha256:ee461a4eaab4f165b68780a6a1af95fb23a29932be7569b9fab666c407969051 \
    --hash=sha256:f5045039100ed58fa817a6227a356240ea1b9a1bc141018864c306c1a16d4175
passlib[bcrypt]==1.7.4 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:aa6bca462b8d8bda89c70b382f0c298a20b5560af6cbfa2dce410c0a2fb669f1 \
    --hash=sha256:defd50f72b65c5402ab2c573830a6978e5f202ad0d984793c8dde2c4152ebe04
pgvector==0.4.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:9d3e0c27f676c61d2fd4270ac1bc520d39b947b199200babe4a56d6d00c74a07 \
    --hash=sha256:f909f8e8081b57fb8a2442c36c3a1e521228d0d4ad66100c28c674806ff62688
proto-plus==1.26.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:13285478c2dcf2abb829db158e1047e2f1e8d63a077d94263c2b88b043c75a66 \
    --hash=sha256:21a515a4c4c0088a773899e23c7bbade3d18f9c66c73edd4c7ee3816bc96a012
protobuf==6.30.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0eb523c550a66a09a0c20f86dd554afbf4d32b02af34ae53d93268c1f73bc65b \
    --hash=sha256:35c859ae076d8c56054c25b59e5e59638d86545ed6e2b6efac6be0b6ea3ba048 \
    --hash=sha256:4f6c687ae8efae6cf6093389a596548214467778146b7245e886f35e1485315d \
    --hash=sha256:50f32cc9fd9cb09c783ebc275611b4f19dfdfb68d1ee55d2f0c7fa040df96815 \
    --hash=sha256:524afedc03b31b15586ca7f64d877a98b184f007180ce25183d1a5cb230ee72b \
    --hash=sha256:7653c99774f73fe6b9301b87da52af0e69783a2e371e8b599b3e9cb4da4b12b9 \
    --hash=sha256:acec579c39c88bd8fbbacab1b8052c793efe83a0a5bd99db4a31423a25c0a0e2 \
    --hash=sha256:ae86b030e69a98e08c77beab574cbcb9fff6d031d57209f574a5aea1445f4b51 \
    --hash=sha256:b12ef7df7b9329886e66404bef5e9ce6a26b54069d7f7436a0853ccdeb91c103
pyasn1-modules==0.4.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:49bfa96b45a292b711e986f222502c1c9a5e1f4e568fc30e2574a6c7d07838fd \
    --hash=sha256:c28e2dbf9c06ad61c71a075c7e0f9fd0f1b0bb2d2ad4377f240d33ac2ab60a7c
pyasn1==0.4.8 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:39c7e2ec30515947ff4e87fb6f456dfc6e84857d34be479c9d4a4ba4bf46aa5d \
    --hash=sha256:aef77c9fb94a3ac588e87841208bdec464471d9871bd5050a287cc9a475cd0ba
pycparser==2.22 ; python_version >= "3.12" and python_version < "4.0" and platform_python_implementation != "PyPy" \
    --hash=sha256:491c8be9c040f5390f5bf44a5b07752bd07f56edf992381b05c701439eec10f6 \
    --hash=sha256:c3702b6d3dd8c7abc1afa565d7e63d53a1d0bd86cdc24edd75470f4de499cfcc
pydantic-core==2.33.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0483847fa9ad5e3412265c1bd72aad35235512d9ce9d27d81a56d935ef489672 \
    --hash=sha256:048831bd363490be79acdd3232f74a0e9951b11b2b4cc058aeb72b22fdc3abe1 \
    --hash=sha256:048c01eee07d37cbd066fc512b9d8b5ea88ceeb4e629ab94b3e56965ad655add \
    --hash=sha256:049e0de24cf23766f12cc5cc71d8abc07d4a9deb9061b334b62093dedc7cb068 \
    --hash=sha256:08530b8ac922003033f399128505f513e30ca770527cc8bbacf75a84fcc2c74b \
    --hash=sha256:0fb935c5591573ae3201640579f30128ccc10739b45663f93c06796854405505 \
    --hash=sha256:1293d7febb995e9d3ec3ea09caf1a26214eec45b0f29f6074abb004723fc1de8 \
    --hash=sha256:177d50460bc976a0369920b6c744d927b0ecb8606fb56858ff542560251b19e5 \
    --hash=sha256:1a28239037b3d6f16916a4c831a5a0eadf856bdd6d2e92c10a0da3a59eadcf3e \
    --hash=sha256:1b30d92c9412beb5ac6b10a3eb7ef92ccb14e3f2a8d7732e2d739f58b3aa7544 \
    --hash=sha256:1c607801d85e2e123357b3893f82c97a42856192997b95b4d8325deb1cd0c5f4 \
    --hash=sha256:1d20eb4861329bb2484c021b9d9a977566ab16d84000a57e28061151c62b349a \
    --hash=sha256:1dfae24cf9921875ca0ca6a8ecb4bb2f13c855794ed0d468d6abbec6e6dcd44a \
    --hash=sha256:25626fb37b3c543818c14821afe0fd3830bc327a43953bc88db924b68c5723f1 \
    --hash=sha256:282b3fe1bbbe5ae35224a0dbd05aed9ccabccd241e8e6b60370484234b456266 \
    --hash=sha256:2ea62419ba8c397e7da28a9170a16219d310d2cf4970dbc65c32faf20d828c83 \
    --hash=sha256:2f593494876eae852dc98c43c6f260f45abdbfeec9e4324e31a481d948214764 \
    --hash=sha256:2f9284e11c751b003fd4215ad92d325d92c9cb19ee6729ebd87e3250072cdcde \
    --hash=sha256:3077cfdb6125cc8dab61b155fdd714663e401f0e6883f9632118ec12cf42df26 \
    --hash=sha256:32cd11c5914d1179df70406427097c7dcde19fddf1418c787540f4b730289896 \
    --hash=sha256:338ea9b73e6e109f15ab439e62cb3b78aa752c7fd9536794112e14bee02c8d18 \
    --hash=sha256:35a5ec3fa8c2fe6c53e1b2ccc2454398f95d5393ab398478f53e1afbbeb4d939 \
    --hash=sha256:398a38d323f37714023be1e0285765f0a27243a8b1506b7b7de87b647b517e48 \
    --hash=sha256:3a371dc00282c4b84246509a5ddc808e61b9864aa1eae9ecc92bb1268b82db4a \
    --hash=sha256:3a64e81e8cba118e108d7126362ea30e021291b7805d47e4896e52c791be2761 \
    --hash=sha256:3ab2d36e20fbfcce8f02d73c33a8a7362980cff717926bbae030b93ae46b56c7 \
    --hash=sha256:3f1fdb790440a34f6ecf7679e1863b825cb5ffde858a9197f851168ed08371e5 \
    --hash=sha256:3f2648b9262607a7fb41d782cc263b48032ff7a03a835581abbf7a3bec62bcf5 \
    --hash=sha256:401d7b76e1000d0dd5538e6381d28febdcacb097c8d340dde7d7fc6e13e9f95d \
    --hash=sha256:495bc156026efafd9ef2d82372bd38afce78ddd82bf28ef5276c469e57c0c83e \
    --hash=sha256:4b315e596282bbb5822d0c7ee9d255595bd7506d1cb20c2911a4da0b970187d3 \
    --hash=sha256:5183e4f6a2d468787243ebcd70cf4098c247e60d73fb7d68d5bc1e1beaa0c4db \
    --hash=sha256:5277aec8d879f8d05168fdd17ae811dd313b8ff894aeeaf7cd34ad28b4d77e33 \
    --hash=sha256:52928d8c1b6bda03cc6d811e8923dffc87a2d3c8b3bfd2ce16471c7147a24850 \
    --hash=sha256:549150be302428b56fdad0c23c2741dcdb5572413776826c965619a25d9c6bde \
    --hash=sha256:5773da0ee2d17136b1f1c6fbde543398d452a6ad2a7b54ea1033e2daa739b8d2 \
    --hash=sha256:5ab77f45d33d264de66e1884fca158bc920cb5e27fd0764a72f72f5756ae8bdb \
    --hash=sha256:5c834f54f8f4640fd7e4b193f80eb25a0602bba9e19b3cd2fc7ffe8199f5ae02 \
    --hash=sha256:5ccd429694cf26af7997595d627dd2637e7932214486f55b8a357edaac9dae8c \
    --hash=sha256:681d65e9011f7392db5aa002b7423cc442d6a673c635668c227c6c8d0e5a4f77 \
    --hash=sha256:694ad99a7f6718c1a498dc170ca430687a39894a60327f548e02a9c7ee4b6504 \
    --hash=sha256:6dd8ecfde08d8bfadaea669e83c63939af76f4cf5538a72597016edfa3fad516 \
    --hash=sha256:6e966fc3caaf9f1d96b349b0341c70c8d6573bf1bac7261f7b0ba88f96c56c24 \
    --hash=sha256:70af6a21237b53d1fe7b9325b20e65cbf2f0a848cf77bed492b029139701e66a \
    --hash=sha256:723c5630c4259400818b4ad096735a829074601805d07f8cafc366d95786d331 \
    --hash=sha256:7965c13b3967909a09ecc91f21d09cfc4576bf78140b988904e94f130f188396 \
    --hash=sha256:7aeb055a42d734c0255c9e489ac67e75397d59c6fbe60d155851e9782f276a9c \
    --hash=sha256:7edbc454a29fc6aeae1e1eecba4f07b63b8d76e76a748532233c4c167b4cb9ea \
    --hash=sha256:7fb66263e9ba8fea2aa85e1e5578980d127fb37d7f2e292773e7bc3a38fb0c7b \
    --hash=sha256:87d3776f0001b43acebfa86f8c64019c043b55cc5a6a2e313d728b5c95b46969 \
    --hash=sha256:8ab581d3530611897d863d1a649fb0644b860286b4718db919bfd51ece41f10b \
    --hash=sha256:8d13f0276806ee722e70a1c93da19748594f19ac4299c7e41237fc791d1861ea \
    --hash=sha256:8ffab8b2908d152e74862d276cf5017c81a2f3719f14e8e3e8d6b83fda863927 \
    --hash=sha256:902dbc832141aa0ec374f4310f1e4e7febeebc3256f00dc359a9ac3f264a45dc \
    --hash=sha256:9097b9f17f91eea659b9ec58148c0747ec354a42f7389b9d50701610d86f812e \
    --hash=sha256:91815221101ad3c6b507804178a7bb5cb7b2ead9ecd600041669c8d805ebd595 \
    --hash=sha256:948b73114f47fd7016088e5186d13faf5e1b2fe83f5e320e371f035557fd264d \
    --hash=sha256:99b56acd433386c8f20be5c4000786d1e7ca0523c8eefc995d14d79c7a081498 \
    --hash=sha256:9d3da303ab5f378a268fa7d45f37d7d85c3ec19769f28d2cc0c61826a8de21fe \
    --hash=sha256:9f466e8bf0a62dc43e068c12166281c2eca72121dd2adc1040f3aa1e21ef8599 \
    --hash=sha256:9fea9c1869bb4742d174a57b4700c6dadea951df8b06de40c2fedb4f02931c2e \
    --hash=sha256:a0d5f3acc81452c56895e90643a625302bd6be351e7010664151cc55b7b97f89 \
    --hash=sha256:a3edde68d1a1f9af1273b2fe798997b33f90308fb6d44d8550c89fc6a3647cf6 \
    --hash=sha256:a62c3c3ef6a7e2c45f7853b10b5bc4ddefd6ee3cd31024754a1a5842da7d598d \
    --hash=sha256:aa687a23d4b7871a00e03ca96a09cad0f28f443690d300500603bd0adba4b523 \
    --hash=sha256:ab0277cedb698749caada82e5d099dc9fed3f906a30d4c382d1a21725777a1e5 \
    --hash=sha256:ad05b683963f69a1d5d2c2bdab1274a31221ca737dbbceaa32bcb67359453cdd \
    --hash=sha256:b172f7b9d2f3abc0efd12e3386f7e48b576ef309544ac3a63e5e9cdd2e24585d \
    --hash=sha256:b1caa0bc2741b043db7823843e1bde8aaa58a55a58fda06083b0569f8b45693a \
    --hash=sha256:bae370459da6a5466978c0eacf90690cb57ec9d533f8e63e564ef3822bfa04fe \
    --hash=sha256:bcc9c6fdb0ced789245b02b7d6603e17d1563064ddcfc36f046b61c0c05dd9df \
    --hash=sha256:bdc84017d28459c00db6f918a7272a5190bec3090058334e43a76afb279eac7c \
    --hash=sha256:bfd0adeee563d59c598ceabddf2c92eec77abcb3f4a391b19aa7366170bd9e30 \
    --hash=sha256:c566dd9c5f63d22226409553531f89de0cac55397f2ab8d97d6f06cfce6d947e \
    --hash=sha256:c91dbb0ab683fa0cd64a6e81907c8ff41d6497c346890e26b23de7ee55353f96 \
    --hash=sha256:c964fd24e6166420d18fb53996d8c9fd6eac9bf5ae3ec3d03015be4414ce497f \
    --hash=sha256:cc77ec5b7e2118b152b0d886c7514a4653bcb58c6b1d760134a9fab915f777b3 \
    --hash=sha256:d100e3ae783d2167782391e0c1c7a20a31f55f8015f3293647544df3f9c67824 \
    --hash=sha256:d3a07fadec2a13274a8d861d3d37c61e97a816beae717efccaa4b36dfcaadcde \
    --hash=sha256:d5e3d15245b08fa4a84cefc6c9222e6f37c98111c8679fbd94aa145f9a0ae23d \
    --hash=sha256:de9e06abe3cc5ec6a2d5f75bc99b0bdca4f5c719a5b34026f8c57efbdecd2ee3 \
    --hash=sha256:df6a94bf9452c6da9b5d76ed229a5683d0306ccb91cca8e1eea883189780d568 \
    --hash=sha256:e100c52f7355a48413e2999bfb4e139d2977a904495441b374f3d4fb4a170961 \
    --hash=sha256:e11f3864eb516af21b01e25fac915a82e9ddad3bb0fb9e95a246067398b435a4 \
    --hash=sha256:e14f369c98a7c15772b9da98987f58e2b509a93235582838bd0d1d8c08b68fda \
    --hash=sha256:e3de2777e3b9f4d603112f78006f4ae0acb936e95f06da6cb1a45fbad6bdb4b5 \
    --hash=sha256:e7aaba1b4b03aaea7bb59e1b5856d734be011d3e6d98f5bcaa98cb30f375f2ad \
    --hash=sha256:ec259f62538e8bf364903a7d0d0239447059f9434b284f5536e8402b7dd198db \
    --hash=sha256:ec79de2a8680b1a67a07490bddf9636d5c2fab609ba8c57597e855fa5fa4dacd \
    --hash=sha256:ed3eb16d51257c763539bde21e011092f127a2202692afaeaccb50db55a31383 \
    --hash=sha256:ede9b407e39949d2afc46385ce6bd6e11588660c26f80576c11c958e6647bc40 \
    --hash=sha256:ee12a7be1742f81b8a65b36c6921022301d466b82d80315d215c4c691724986f \
    --hash=sha256:ef99779001d7ac2e2461d8ab55d3373fe7315caefdbecd8ced75304ae5a6fc6b \
    --hash=sha256:f59295ecc75a1788af8ba92f2e8c6eeaa5a94c22fc4d151e8d9638814f85c8fc \
    --hash=sha256:f995719707e0e29f0f41a8aa3bcea6e761a36c9136104d3189eafb83f5cec5e5 \
    --hash=sha256:f99aeda58dce827f76963ee87a0ebe75e648c72ff9ba1174a253f6744f518f65 \
    --hash=sha256:fc6bf8869e193855e8d91d91f6bf59699a5cdfaa47a404e278e776dd7f168b39 \
    --hash=sha256:fc903512177361e868bc1f5b80ac8c8a6e05fcdd574a5fb5ffeac5a9982b9e89 \
    --hash=sha256:fe44d56aa0b00d66640aa84a3cbe80b7a3ccdc6f0b1ca71090696a6d4777c091
pydantic-settings==2.8.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:81942d5ac3d905f7f3ee1a70df5dfb62d5569c12f51a5a647defc1c3d9ee2e9c \
    --hash=sha256:d5c663dfbe9db9d5e1c646b2e161da12f0d734d422ee56f567d0ea2cee4e8585
pydantic==2.11.3 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:7471657138c16adad9322fe3070c0116dd6c3ad8d649300e3cbdfe91f4db4ec3 \
    --hash=sha256:a082753436a07f9ba1289c6ffa01cd93db3548776088aa917cc43b63f68fa60f
pydantic[email]==2.11.3 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:7471657138c16adad9322fe3070c0116dd6c3ad8d649300e3cbdfe91f4db4ec3 \
    --hash=sha256:a082753436a07f9ba1289c6ffa01cd93db3548776088aa917cc43b63f68fa60f
python-dotenv==1.1.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:41f90bc6f5f177fb41f53e87666db362025010eb28f60a01c9143bfa33a2b2d5 \
    --hash=sha256:d7c01d9e2293916c18baf562d95698754b0dbbb5e74d457c45d4f6561fb9d55d
python-jose[cryptography]==3.4.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:9a9a40f418ced8ecaf7e3b28d69887ceaa76adad3bcaa6dae0d9e596fec1d680 \
    --hash=sha256:9c9f616819652d109bd889ecd1e15e9a162b9b94d682534c9c2146092945b78f
python-multipart==0.0.20 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:8a62d3a8335e06589fe01f2a3e178cdcc632f3fbe0d492ad9ee0ec35aab1f104 \
    --hash=sha256:8dd0cab45b8e23064ae09147625994d090fa46f5b0d1e13af944c331a7fa9d13
pyyaml==6.0.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:01179a4a8559ab5de078078f37e5c1a30d76bb88519906844fd7bdea1b7729ff \
    --hash=sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48 \
    --hash=sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086 \
    --hash=sha256:0b69e4ce7a131fe56b7e4d770c67429700908fc0752af059838b1cfb41960e4e \
    --hash=sha256:0ffe8360bab4910ef1b9e87fb812d8bc0a308b0d0eef8c8f44e0254ab3b07133 \
    --hash=sha256:11d8f3dd2b9c1207dcaf2ee0bbbfd5991f571186ec9cc78427ba5bd32afae4b5 \
    --hash=sha256:17e311b6c678207928d649faa7cb0d7b4c26a0ba73d41e99c4fff6b6c3276484 \
    --hash=sha256:1e2120ef853f59c7419231f3bf4e7021f1b936f6ebd222406c3b60212205d2ee \
    --hash=sha256:1f71ea527786de97d1a0cc0eacd1defc0985dcf6b3f17bb77dcfc8c34bec4dc5 \
    --hash=sha256:23502f431948090f597378482b4812b0caae32c22213aecf3b55325e049a6c68 \
    --hash=sha256:24471b829b3bf607e04e88d79542a9d48bb037c2267d7927a874e6c205ca7e9a \
    --hash=sha256:29717114e51c84ddfba879543fb232a6ed60086602313ca38cce623c1d62cfbf \
    --hash=sha256:2e99c6826ffa974fe6e27cdb5ed0021786b03fc98e5ee3c5bfe1fd5015f42b99 \
    --hash=sha256:39693e1f8320ae4f43943590b49779ffb98acb81f788220ea932a6b6c51004d8 \
    --hash=sha256:3ad2a3decf9aaba3d29c8f537ac4b243e36bef957511b4766cb0057d32b0be85 \
    --hash=sha256:3b1fdb9dc17f5a7677423d508ab4f243a726dea51fa5e70992e59a7411c89d19 \
    --hash=sha256:41e4e3953a79407c794916fa277a82531dd93aad34e29c2a514c2c0c5fe971cc \
    --hash=sha256:43fa96a3ca0d6b1812e01ced1044a003533c47f6ee8aca31724f78e93ccc089a \
    --hash=sha256:50187695423ffe49e2deacb8cd10510bc361faac997de9efef88badc3bb9e2d1 \
    --hash=sha256:5ac9328ec4831237bec75defaf839f7d4564be1e6b25ac710bd1a96321cc8317 \
    --hash=sha256:5d225db5a45f21e78dd9358e58a98702a0302f2659a3c6cd320564b75b86f47c \
    --hash=sha256:6395c297d42274772abc367baaa79683958044e5d3835486c16da75d2a694631 \
    --hash=sha256:688ba32a1cffef67fd2e9398a2efebaea461578b0923624778664cc1c914db5d \
    --hash=sha256:68ccc6023a3400877818152ad9a1033e3db8625d899c72eacb5a668902e4d652 \
    --hash=sha256:70b189594dbe54f75ab3a1acec5f1e3faa7e8cf2f1e08d9b561cb41b845f69d5 \
    --hash=sha256:797b4f722ffa07cc8d62053e4cff1486fa6dc094105d13fea7b1de7d8bf71c9e \
    --hash=sha256:7c36280e6fb8385e520936c3cb3b8042851904eba0e58d277dca80a5cfed590b \
    --hash=sha256:7e7401d0de89a9a855c839bc697c079a4af81cf878373abd7dc625847d25cbd8 \
    --hash=sha256:80bab7bfc629882493af4aa31a4cfa43a4c57c83813253626916b8c7ada83476 \
    --hash=sha256:82d09873e40955485746739bcb8b4586983670466c23382c19cffecbf1fd8706 \
    --hash=sha256:8388ee1976c416731879ac16da0aff3f63b286ffdd57cdeb95f3f2e085687563 \
    --hash=sha256:8824b5a04a04a047e72eea5cec3bc266db09e35de6bdfe34c9436ac5ee27d237 \
    --hash=sha256:8b9c7197f7cb2738065c481a0461e50ad02f18c78cd75775628afb4d7137fb3b \
    --hash=sha256:9056c1ecd25795207ad294bcf39f2db3d845767be0ea6e6a34d856f006006083 \
    --hash=sha256:936d68689298c36b53b29f23c6dbb74de12b4ac12ca6cfe0e047bedceea56180 \
    --hash=sha256:9b22676e8097e9e22e36d6b7bda33190d0d400f345f23d4065d48f4ca7ae0425 \
    --hash=sha256:a4d3091415f010369ae4ed1fc6b79def9416358877534caf6a0fdd2146c87a3e \
    --hash=sha256:a8786accb172bd8afb8be14490a16625cbc387036876ab6ba70912730faf8e1f \
    --hash=sha256:a9f8c2e67970f13b16084e04f134610fd1d374bf477b17ec1599185cf611d725 \
    --hash=sha256:bc2fa7c6b47d6bc618dd7fb02ef6fdedb1090ec036abab80d4681424b84c1183 \
    --hash=sha256:c70c95198c015b85feafc136515252a261a84561b7b1d51e3384e0655ddf25ab \
    --hash=sha256:cc1c1159b3d456576af7a3e4d1ba7e6924cb39de8f67111c735f6fc832082774 \
    --hash=sha256:ce826d6ef20b1bc864f0a68340c8b3287705cae2f8b4b1d932177dcc76721725 \
    --hash=sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e \
    --hash=sha256:d7fded462629cfa4b685c5416b949ebad6cec74af5e2d42905d41e257e0869f5 \
    --hash=sha256:d84a1718ee396f54f3a086ea0a66d8e552b2ab2017ef8b420e92edbc841c352d \
    --hash=sha256:d8e03406cac8513435335dbab54c0d385e4a49e4945d2909a581c83647ca0290 \
    --hash=sha256:e10ce637b18caea04431ce14fabcf5c64a1c61ec9c56b071a4b7ca131ca52d44 \
    --hash=sha256:ec031d5d2feb36d1d1a24380e4db6d43695f3748343d99434e6f5f9156aaa2ed \
    --hash=sha256:ef6107725bd54b262d6dedcc2af448a266975032bc85ef0172c5f059da6325b4 \
    --hash=sha256:efdca5630322a10774e8e98e1af481aad470dd62c3170801852d752aa7a783ba \
    --hash=sha256:f753120cb8181e736c57ef7636e83f31b9c0d1722c516f7e86cf15b7aa57ff12 \
    --hash=sha256:ff3824dc5261f50c9b0dfb3be22b4567a6f938ccce4587b38952d85fd9e9afe4
requests==2.32.3 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760 \
    --hash=sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6
resend==2.7.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:104b34d3781b42593299633839e709e88056949e62fbcc915a937f5aad0678b2 \
    --hash=sha256:b419cd9125a0c180bb8e60453ee524e04cb1d067b14ad63ae53ee2e3886ead02
rsa==4.9.1 ; python_version >= "3.12" and python_version < "4" \
    --hash=sha256:68635866661c6836b8d39430f97a996acbd61bfa49406748ea243539fe239762 \
    --hash=sha256:e7bdbfdb5497da4c07dfd35530e1a902659db6ff241e39d9953cad06ebd0ae75
six==1.17.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274 \
    --hash=sha256:ff70335d468e7eb6ec65b95b99d3a2836546063f63acc5171de367e834932a81
sniffio==1.3.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2 \
    --hash=sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc
sqlalchemy==2.0.40 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:00a494ea6f42a44c326477b5bee4e0fc75f6a80c01570a32b57e89cf0fbef85a \
    --hash=sha256:0bb933a650323e476a2e4fbef8997a10d0003d4da996aad3fd7873e962fdde4d \
    --hash=sha256:110179728e442dae85dd39591beb74072ae4ad55a44eda2acc6ec98ead80d5f2 \
    --hash=sha256:15d08d5ef1b779af6a0909b97be6c1fd4298057504eb6461be88bd1696cb438e \
    --hash=sha256:16d325ea898f74b26ffcd1cf8c593b0beed8714f0317df2bed0d8d1de05a8f26 \
    --hash=sha256:1abb387710283fc5983d8a1209d9696a4eae9db8d7ac94b402981fe2fe2e39ad \
    --hash=sha256:1ffdf9c91428e59744f8e6f98190516f8e1d05eec90e936eb08b257332c5e870 \
    --hash=sha256:2be94d75ee06548d2fc591a3513422b873490efb124048f50556369a834853b0 \
    --hash=sha256:2cbafc8d39ff1abdfdda96435f38fab141892dc759a2165947d1a8fffa7ef596 \
    --hash=sha256:2ee5f9999a5b0e9689bed96e60ee53c3384f1a05c2dd8068cc2e8361b0df5b7a \
    --hash=sha256:32587e2e1e359276957e6fe5dad089758bc042a971a8a09ae8ecf7a8fe23d07a \
    --hash=sha256:35904d63412db21088739510216e9349e335f142ce4a04b69e2528020ee19ed4 \
    --hash=sha256:37a5c21ab099a83d669ebb251fddf8f5cee4d75ea40a5a1653d9c43d60e20867 \
    --hash=sha256:37f7a0f506cf78c80450ed1e816978643d3969f99c4ac6b01104a6fe95c5490a \
    --hash=sha256:46628ebcec4f23a1584fb52f2abe12ddb00f3bb3b7b337618b80fc1b51177aff \
    --hash=sha256:4a4c5a2905a9ccdc67a8963e24abd2f7afcd4348829412483695c59e0af9a705 \
    --hash=sha256:4aeb939bcac234b88e2d25d5381655e8353fe06b4e50b1c55ecffe56951d18c2 \
    --hash=sha256:50f5885bbed261fc97e2e66c5156244f9704083a674b8d17f24c72217d29baf5 \
    --hash=sha256:519624685a51525ddaa7d8ba8265a1540442a2ec71476f0e75241eb8263d6f51 \
    --hash=sha256:5434223b795be5c5ef8244e5ac98056e290d3a99bdcc539b916e282b160dda00 \
    --hash=sha256:55028d7a3ebdf7ace492fab9895cbc5270153f75442a0472d8516e03159ab364 \
    --hash=sha256:5654d1ac34e922b6c5711631f2da497d3a7bffd6f9f87ac23b35feea56098011 \
    --hash=sha256:574aea2c54d8f1dd1699449f332c7d9b71c339e04ae50163a3eb5ce4c4325ee4 \
    --hash=sha256:5cfa124eda500ba4b0d3afc3e91ea27ed4754e727c7f025f293a22f512bcd4c9 \
    --hash=sha256:5ea9181284754d37db15156eb7be09c86e16e50fbe77610e9e7bee09291771a1 \
    --hash=sha256:641ee2e0834812d657862f3a7de95e0048bdcb6c55496f39c6fa3d435f6ac6ad \
    --hash=sha256:650490653b110905c10adac69408380688cefc1f536a137d0d69aca1069dc1d1 \
    --hash=sha256:6959738971b4745eea16f818a2cd086fb35081383b078272c35ece2b07012716 \
    --hash=sha256:6cfedff6878b0e0d1d0a50666a817ecd85051d12d56b43d9d425455e608b5ba0 \
    --hash=sha256:7e0505719939e52a7b0c65d20e84a6044eb3712bb6f239c6b1db77ba8e173a37 \
    --hash=sha256:8b6b28d303b9d57c17a5164eb1fd2d5119bb6ff4413d5894e74873280483eeb5 \
    --hash=sha256:8bb131ffd2165fae48162c7bbd0d97c84ab961deea9b8bab16366543deeab625 \
    --hash=sha256:915866fd50dd868fdcc18d61d8258db1bf9ed7fbd6dfec960ba43365952f3b01 \
    --hash=sha256:9408fd453d5f8990405cc9def9af46bfbe3183e6110401b407c2d073c3388f47 \
    --hash=sha256:957f8d85d5e834397ef78a6109550aeb0d27a53b5032f7a57f2451e1adc37e98 \
    --hash=sha256:9c7a80ed86d6aaacb8160a1caef6680d4ddd03c944d985aecee940d168c411d1 \
    --hash=sha256:9d3b31d0a1c44b74d3ae27a3de422dfccd2b8f0b75e51ecb2faa2bf65ab1ba0d \
    --hash=sha256:a669cbe5be3c63f75bcbee0b266779706f1a54bcb1000f302685b87d1b8c1500 \
    --hash=sha256:a8aae085ea549a1eddbc9298b113cffb75e514eadbb542133dd2b99b5fb3b6af \
    --hash=sha256:ae9597cab738e7cc823f04a704fb754a9249f0b6695a6aeb63b74055cd417a96 \
    --hash=sha256:afe63b208153f3a7a2d1a5b9df452b0673082588933e54e7c8aac457cf35e758 \
    --hash=sha256:b5a5bbe29c10c5bfd63893747a1bf6f8049df607638c786252cb9243b86b6706 \
    --hash=sha256:baf7cee56bd552385c1ee39af360772fbfc2f43be005c78d1140204ad6148438 \
    --hash=sha256:bb19e30fdae77d357ce92192a3504579abe48a66877f476880238a962e5b96db \
    --hash=sha256:bece9527f5a98466d67fb5d34dc560c4da964240d8b09024bb21c1246545e04e \
    --hash=sha256:c0cae71e20e3c02c52f6b9e9722bca70e4a90a466d59477822739dc31ac18b4b \
    --hash=sha256:c268b5100cfeaa222c40f55e169d484efa1384b44bf9ca415eae6d556f02cb08 \
    --hash=sha256:c7b927155112ac858357ccf9d255dd8c044fd9ad2dc6ce4c4149527c901fa4c3 \
    --hash=sha256:c884de19528e0fcd9dc34ee94c810581dd6e74aef75437ff17e696c2bfefae3e \
    --hash=sha256:cd2f75598ae70bcfca9117d9e51a3b06fe29edd972fdd7fd57cc97b4dbf3b08a \
    --hash=sha256:cf0e99cdb600eabcd1d65cdba0d3c91418fee21c4aa1d28db47d095b1064a7d8 \
    --hash=sha256:d827099289c64589418ebbcaead0145cd19f4e3e8a93919a0100247af245fa00 \
    --hash=sha256:e8040680eaacdce4d635f12c55c714f3d4c7f57da2bc47a01229d115bd319191 \
    --hash=sha256:f0fda83e113bb0fb27dc003685f32a5dcb99c9c4f41f4fa0838ac35265c23b5c \
    --hash=sha256:f1ea21bef99c703f44444ad29c2c1b6bd55d202750b6de8e06a955380f4725d7 \
    --hash=sha256:f6bacab7514de6146a1976bc56e1545bee247242fab030b89e5f70336fc0003e \
    --hash=sha256:fe147fcd85aaed53ce90645c91ed5fca0cc88a797314c70dfd9d35925bd5d106
sqlalchemy[asyncio]==2.0.40 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:00a494ea6f42a44c326477b5bee4e0fc75f6a80c01570a32b57e89cf0fbef85a \
    --hash=sha256:0bb933a650323e476a2e4fbef8997a10d0003d4da996aad3fd7873e962fdde4d \
    --hash=sha256:110179728e442dae85dd39591beb74072ae4ad55a44eda2acc6ec98ead80d5f2 \
    --hash=sha256:15d08d5ef1b779af6a0909b97be6c1fd4298057504eb6461be88bd1696cb438e \
    --hash=sha256:16d325ea898f74b26ffcd1cf8c593b0beed8714f0317df2bed0d8d1de05a8f26 \
    --hash=sha256:1abb387710283fc5983d8a1209d9696a4eae9db8d7ac94b402981fe2fe2e39ad \
    --hash=sha256:1ffdf9c91428e59744f8e6f98190516f8e1d05eec90e936eb08b257332c5e870 \
    --hash=sha256:2be94d75ee06548d2fc591a3513422b873490efb124048f50556369a834853b0 \
    --hash=sha256:2cbafc8d39ff1abdfdda96435f38fab141892dc759a2165947d1a8fffa7ef596 \
    --hash=sha256:2ee5f9999a5b0e9689bed96e60ee53c3384f1a05c2dd8068cc2e8361b0df5b7a \
    --hash=sha256:32587e2e1e359276957e6fe5dad089758bc042a971a8a09ae8ecf7a8fe23d07a \
    --hash=sha256:35904d63412db21088739510216e9349e335f142ce4a04b69e2528020ee19ed4 \
    --hash=sha256:37a5c21ab099a83d669ebb251fddf8f5cee4d75ea40a5a1653d9c43d60e20867 \
    --hash=sha256:37f7a0f506cf78c80450ed1e816978643d3969f99c4ac6b01104a6fe95c5490a \
    --hash=sha256:46628ebcec4f23a1584fb52f2abe12ddb00f3bb3b7b337618b80fc1b51177aff \
    --hash=sha256:4a4c5a2905a9ccdc67a8963e24abd2f7afcd4348829412483695c59e0af9a705 \
    --hash=sha256:4aeb939bcac234b88e2d25d5381655e8353fe06b4e50b1c55ecffe56951d18c2 \
    --hash=sha256:50f5885bbed261fc97e2e66c5156244f9704083a674b8d17f24c72217d29baf5 \
    --hash=sha256:519624685a51525ddaa7d8ba8265a1540442a2ec71476f0e75241eb8263d6f51 \
    --hash=sha256:5434223b795be5c5ef8244e5ac98056e290d3a99bdcc539b916e282b160dda00 \
    --hash=sha256:55028d7a3ebdf7ace492fab9895cbc5270153f75442a0472d8516e03159ab364 \
    --hash=sha256:5654d1ac34e922b6c5711631f2da497d3a7bffd6f9f87ac23b35feea56098011 \
    --hash=sha256:574aea2c54d8f1dd1699449f332c7d9b71c339e04ae50163a3eb5ce4c4325ee4 \
    --hash=sha256:5cfa124eda500ba4b0d3afc3e91ea27ed4754e727c7f025f293a22f512bcd4c9 \
    --hash=sha256:5ea9181284754d37db15156eb7be09c86e16e50fbe77610e9e7bee09291771a1 \
    --hash=sha256:641ee2e0834812d657862f3a7de95e0048bdcb6c55496f39c6fa3d435f6ac6ad \
    --hash=sha256:650490653b110905c10adac69408380688cefc1f536a137d0d69aca1069dc1d1 \
    --hash=sha256:6959738971b4745eea16f818a2cd086fb35081383b078272c35ece2b07012716 \
    --hash=sha256:6cfedff6878b0e0d1d0a50666a817ecd85051d12d56b43d9d425455e608b5ba0 \
    --hash=sha256:7e0505719939e52a7b0c65d20e84a6044eb3712bb6f239c6b1db77ba8e173a37 \
    --hash=sha256:8b6b28d303b9d57c17a5164eb1fd2d5119bb6ff4413d5894e74873280483eeb5 \
    --hash=sha256:8bb131ffd2165fae48162c7bbd0d97c84ab961deea9b8bab16366543deeab625 \
    --hash=sha256:915866fd50dd868fdcc18d61d8258db1bf9ed7fbd6dfec960ba43365952f3b01 \
    --hash=sha256:9408fd453d5f8990405cc9def9af46bfbe3183e6110401b407c2d073c3388f47 \
    --hash=sha256:957f8d85d5e834397ef78a6109550aeb0d27a53b5032f7a57f2451e1adc37e98 \
    --hash=sha256:9c7a80ed86d6aaacb8160a1caef6680d4ddd03c944d985aecee940d168c411d1 \
    --hash=sha256:9d3b31d0a1c44b74d3ae27a3de422dfccd2b8f0b75e51ecb2faa2bf65ab1ba0d \
    --hash=sha256:a669cbe5be3c63f75bcbee0b266779706f1a54bcb1000f302685b87d1b8c1500 \
    --hash=sha256:a8aae085ea549a1eddbc9298b113cffb75e514eadbb542133dd2b99b5fb3b6af \
    --hash=sha256:ae9597cab738e7cc823f04a704fb754a9249f0b6695a6aeb63b74055cd417a96 \
    --hash=sha256:afe63b208153f3a7a2d1a5b9df452b0673082588933e54e7c8aac457cf35e758 \
    --hash=sha256:b5a5bbe29c10c5bfd63893747a1bf6f8049df607638c786252cb9243b86b6706 \
    --hash=sha256:baf7cee56bd552385c1ee39af360772fbfc2f43be005c78d1140204ad6148438 \
    --hash=sha256:bb19e30fdae77d357ce92192a3504579abe48a66877f476880238a962e5b96db \
    --hash=sha256:bece9527f5a98466d67fb5d34dc560c4da964240d8b09024bb21c1246545e04e \
    --hash=sha256:c0cae71e20e3c02c52f6b9e9722bca70e4a90a466d59477822739dc31ac18b4b \
    --hash=sha256:c268b5100cfeaa222c40f55e169d484efa1384b44bf9ca415eae6d556f02cb08 \
    --hash=sha256:c7b927155112ac858357ccf9d255dd8c044fd9ad2dc6ce4c4149527c901fa4c3 \
    --hash=sha256:c884de19528e0fcd9dc34ee94c810581dd6e74aef75437ff17e696c2bfefae3e \
    --hash=sha256:cd2f75598ae70bcfca9117d9e51a3b06fe29edd972fdd7fd57cc97b4dbf3b08a \
    --hash=sha256:cf0e99cdb600eabcd1d65cdba0d3c91418fee21c4aa1d28db47d095b1064a7d8 \
    --hash=sha256:d827099289c64589418ebbcaead0145cd19f4e3e8a93919a0100247af245fa00 \
    --hash=sha256:e8040680eaacdce4d635f12c55c714f3d4c7f57da2bc47a01229d115bd319191 \
    --hash=sha256:f0fda83e113bb0fb27dc003685f32a5dcb99c9c4f41f4fa0838ac35265c23b5c \
    --hash=sha256:f1ea21bef99c703f44444ad29c2c1b6bd55d202750b6de8e06a955380f4725d7 \
    --hash=sha256:f6bacab7514de6146a1976bc56e1545bee247242fab030b89e5f70336fc0003e \
    --hash=sha256:fe147fcd85aaed53ce90645c91ed5fca0cc88a797314c70dfd9d35925bd5d106
starlette==0.46.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:595633ce89f8ffa71a015caed34a5b2dc1c0cdb3f0f1fbd1e69339cf2abeec35 \
    --hash=sha256:7f7361f34eed179294600af672f565727419830b54b7b084efe44bb82d2fccd5
typing-extensions==4.13.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:a439e7c04b49fec3e5d3e2beaa21755cadbbdc391694e28ccdd36ca4a1408f8c \
    --hash=sha256:e6c81219bd689f51865d9e372991c540bda33a0379d5573cddb9a3a23f7caaef
typing-inspection==0.4.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:50e72559fcd2a6367a19f7a7e610e6afcb9fac940c650290eed893d61386832f \
    --hash=sha256:9765c87de36671694a67904bf2c96e395be9c6439bb6c87b5142569dcdd65122
tzdata==2025.2 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:1a403fada01ff9221ca8044d701868fa132215d84beb92242d9acd2147f667a8 \
    --hash=sha256:b60a638fcc0daffadf82fe0f57e53d06bdec2f36c4df66280ae79bce6bd6f2b9
urllib3==2.4.0 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:414bc6535b787febd7567804cc015fee39daab8ad86268f1310a9250697de466 \
    --hash=sha256:4e16665048960a0900c702d4a66415956a584919c03361cac9f1df5c5dd7e813
uvicorn[standard]==0.34.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:984c3a8c7ca18ebaad15995ee7401179212c59521e67bfc390c07fa2b8d2e065 \
    --hash=sha256:af981725fc4b7ffc5cb3b0e9eda6258a90c4b52cb2a83ce567ae0a7ae1757afc
uvloop==0.21.0 ; (sys_platform != "win32" and sys_platform != "cygwin") and platform_python_implementation != "PyPy" and python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0878c2640cf341b269b7e128b1a5fed890adc4455513ca710d77d5e93aa6d6a0 \
    --hash=sha256:10d66943def5fcb6e7b37310eb6b5639fd2ccbc38df1177262b0640c3ca68c1f \
    --hash=sha256:10da8046cc4a8f12c91a1c39d1dd1585c41162a15caaef165c2174db9ef18bdc \
    --hash=sha256:17df489689befc72c39a08359efac29bbee8eee5209650d4b9f34df73d22e414 \
    --hash=sha256:183aef7c8730e54c9a3ee3227464daed66e37ba13040bb3f350bc2ddc040f22f \
    --hash=sha256:196274f2adb9689a289ad7d65700d37df0c0930fd8e4e743fa4834e850d7719d \
    --hash=sha256:221f4f2a1f46032b403bf3be628011caf75428ee3cc204a22addf96f586b19fd \
    --hash=sha256:2d1f581393673ce119355d56da84fe1dd9d2bb8b3d13ce792524e1607139feff \
    --hash=sha256:359ec2c888397b9e592a889c4d72ba3d6befba8b2bb01743f72fffbde663b59c \
    --hash=sha256:3bf12b0fda68447806a7ad847bfa591613177275d35b6724b1ee573faa3704e3 \
    --hash=sha256:4509360fcc4c3bd2c70d87573ad472de40c13387f5fda8cb58350a1d7475e58d \
    --hash=sha256:460def4412e473896ef179a1671b40c039c7012184b627898eea5072ef6f017a \
    --hash=sha256:461d9ae6660fbbafedd07559c6a2e57cd553b34b0065b6550685f6653a98c1cb \
    --hash=sha256:46923b0b5ee7fc0020bef24afe7836cb068f5050ca04caf6b487c513dc1a20b2 \
    --hash=sha256:53e420a3afe22cdcf2a0f4846e377d16e718bc70103d7088a4f7623567ba5fb0 \
    --hash=sha256:5ee4d4ef48036ff6e5cfffb09dd192c7a5027153948d85b8da7ff705065bacc6 \
    --hash=sha256:67dd654b8ca23aed0a8e99010b4c34aca62f4b7fce88f39d452ed7622c94845c \
    --hash=sha256:787ae31ad8a2856fc4e7c095341cccc7209bd657d0e71ad0dc2ea83c4a6fa8af \
    --hash=sha256:86975dca1c773a2c9864f4c52c5a55631038e387b47eaf56210f873887b6c8dc \
    --hash=sha256:87c43e0f13022b998eb9b973b5e97200c8b90823454d4bc06ab33829e09fb9bb \
    --hash=sha256:88cb67cdbc0e483da00af0b2c3cdad4b7c61ceb1ee0f33fe00e09c81e3a6cb75 \
    --hash=sha256:8a375441696e2eda1c43c44ccb66e04d61ceeffcd76e4929e527b7fa401b90fb \
    --hash=sha256:a5c39f217ab3c663dc699c04cbd50c13813e31d917642d459fdcec07555cc553 \
    --hash=sha256:b9fb766bb57b7388745d8bcc53a359b116b8a04c83a2288069809d2b3466c37e \
    --hash=sha256:baa0e6291d91649c6ba4ed4b2f982f9fa165b5bbd50a9e203c416a2797bab3c6 \
    --hash=sha256:baa4dcdbd9ae0a372f2167a207cd98c9f9a1ea1188a8a526431eef2f8116cc8d \
    --hash=sha256:bc09f0ff191e61c2d592a752423c767b4ebb2986daa9ed62908e2b1b9a9ae206 \
    --hash=sha256:bd53ecc9a0f3d87ab847503c2e1552b690362e005ab54e8a48ba97da3924c0dc \
    --hash=sha256:bfd55dfcc2a512316e65f16e503e9e450cab148ef11df4e4e679b5e8253a5281 \
    --hash=sha256:c097078b8031190c934ed0ebfee8cc5f9ba9642e6eb88322b9958b649750f72b \
    --hash=sha256:c0f3fa6200b3108919f8bdabb9a7f87f20e7097ea3c543754cabc7d717d95cf8 \
    --hash=sha256:e678ad6fe52af2c58d2ae3c73dc85524ba8abe637f134bf3564ed07f555c5e79 \
    --hash=sha256:ec7e6b09a6fdded42403182ab6b832b71f4edaf7f37a9a0e371a01db5f0cb45f \
    --hash=sha256:f0ce1b49560b1d2d8a2977e3ba4afb2414fb46b86a1b64056bc4ab929efdafbe \
    --hash=sha256:f38b2e090258d051d68a5b14d1da7203a3c3677321cf32a95a6f4db4dd8b6f26 \
    --hash=sha256:f3df876acd7ec037a3d005b3ab85a7e4110422e4d9c1571d4fc89b0fc41b6816 \
    --hash=sha256:f7089d2dc73179ce5ac255bdf37c236a9f914b264825fdaacaded6990a7fb4c2
watchfiles==1.0.5 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0125f91f70e0732a9f8ee01e49515c35d38ba48db507a50c5bdcad9503af5827 \
    --hash=sha256:0a04059f4923ce4e856b4b4e5e783a70f49d9663d22a4c3b3298165996d1377f \
    --hash=sha256:0b289572c33a0deae62daa57e44a25b99b783e5f7aed81b314232b3d3c81a11d \
    --hash=sha256:10f6ae86d5cb647bf58f9f655fcf577f713915a5d69057a0371bc257e2553234 \
    --hash=sha256:13bb21f8ba3248386337c9fa51c528868e6c34a707f729ab041c846d52a0c69a \
    --hash=sha256:15ac96dd567ad6c71c71f7b2c658cb22b7734901546cd50a475128ab557593ca \
    --hash=sha256:18b3bd29954bc4abeeb4e9d9cf0b30227f0f206c86657674f544cb032296acd5 \
    --hash=sha256:1909e0a9cd95251b15bff4261de5dd7550885bd172e3536824bf1cf6b121e200 \
    --hash=sha256:1a2902ede862969077b97523987c38db28abbe09fb19866e711485d9fbf0d417 \
    --hash=sha256:1a7bac2bde1d661fb31f4d4e8e539e178774b76db3c2c17c4bb3e960a5de07a2 \
    --hash=sha256:237f9be419e977a0f8f6b2e7b0475ababe78ff1ab06822df95d914a945eac827 \
    --hash=sha256:266710eb6fddc1f5e51843c70e3bebfb0f5e77cf4f27129278c70554104d19ed \
    --hash=sha256:29c7fd632ccaf5517c16a5188e36f6612d6472ccf55382db6c7fe3fcccb7f59f \
    --hash=sha256:2b7a21715fb12274a71d335cff6c71fe7f676b293d322722fe708a9ec81d91f5 \
    --hash=sha256:2cfb371be97d4db374cba381b9f911dd35bb5f4c58faa7b8b7106c8853e5d225 \
    --hash=sha256:2cfcb3952350e95603f232a7a15f6c5f86c5375e46f0bd4ae70d43e3e063c13d \
    --hash=sha256:2f1fefb2e90e89959447bc0420fddd1e76f625784340d64a2f7d5983ef9ad246 \
    --hash=sha256:360a398c3a19672cf93527f7e8d8b60d8275119c5d900f2e184d32483117a705 \
    --hash=sha256:3e380c89983ce6e6fe2dd1e1921b9952fb4e6da882931abd1824c092ed495dec \
    --hash=sha256:4a8ec1e4e16e2d5bafc9ba82f7aaecfeec990ca7cd27e84fb6f191804ed2fcfc \
    --hash=sha256:4ab626da2fc1ac277bbf752446470b367f84b50295264d2d313e28dc4405d663 \
    --hash=sha256:4b6227351e11c57ae997d222e13f5b6f1f0700d84b8c52304e8675d33a808382 \
    --hash=sha256:554389562c29c2c182e3908b149095051f81d28c2fec79ad6c8997d7d63e0009 \
    --hash=sha256:5c40fe7dd9e5f81e0847b1ea64e1f5dd79dd61afbedb57759df06767ac719b40 \
    --hash=sha256:68b2dddba7a4e6151384e252a5632efcaa9bc5d1c4b567f3cb621306b2ca9f63 \
    --hash=sha256:7ee32c9a9bee4d0b7bd7cbeb53cb185cf0b622ac761efaa2eba84006c3b3a614 \
    --hash=sha256:830aa432ba5c491d52a15b51526c29e4a4b92bf4f92253787f9726fe01519487 \
    --hash=sha256:832ccc221927c860e7286c55c9b6ebcc0265d5e072f49c7f6456c7798d2b39aa \
    --hash=sha256:839ebd0df4a18c5b3c1b890145b5a3f5f64063c2a0d02b13c76d78fe5de34936 \
    --hash=sha256:852de68acd6212cd6d33edf21e6f9e56e5d98c6add46f48244bd479d97c967c6 \
    --hash=sha256:85fbb6102b3296926d0c62cfc9347f6237fb9400aecd0ba6bbda94cae15f2b3b \
    --hash=sha256:86c0df05b47a79d80351cd179893f2f9c1b1cae49d96e8b3290c7f4bd0ca0a92 \
    --hash=sha256:894342d61d355446d02cd3988a7326af344143eb33a2fd5d38482a92072d9563 \
    --hash=sha256:8c0db396e6003d99bb2d7232c957b5f0b5634bbd1b24e381a5afcc880f7373fb \
    --hash=sha256:8e637810586e6fe380c8bc1b3910accd7f1d3a9a7262c8a78d4c8fb3ba6a2b3d \
    --hash=sha256:9475b0093767e1475095f2aeb1d219fb9664081d403d1dff81342df8cd707034 \
    --hash=sha256:95cf944fcfc394c5f9de794ce581914900f82ff1f855326f25ebcf24d5397418 \
    --hash=sha256:974866e0db748ebf1eccab17862bc0f0303807ed9cda465d1324625b81293a18 \
    --hash=sha256:9848b21ae152fe79c10dd0197304ada8f7b586d3ebc3f27f43c506e5a52a863c \
    --hash=sha256:9f4571a783914feda92018ef3901dab8caf5b029325b5fe4558c074582815249 \
    --hash=sha256:a056c2f692d65bf1e99c41045e3bdcaea3cb9e6b5a53dcaf60a5f3bd95fc9763 \
    --hash=sha256:a0dbcb1c2d8f2ab6e0a81c6699b236932bd264d4cef1ac475858d16c403de74d \
    --hash=sha256:a16512051a822a416b0d477d5f8c0e67b67c1a20d9acecb0aafa3aa4d6e7d256 \
    --hash=sha256:a2014a2b18ad3ca53b1f6c23f8cd94a18ce930c1837bd891262c182640eb40a6 \
    --hash=sha256:a3904d88955fda461ea2531fcf6ef73584ca921415d5cfa44457a225f4a42bc1 \
    --hash=sha256:a74add8d7727e6404d5dc4dcd7fac65d4d82f95928bbee0cf5414c900e86773e \
    --hash=sha256:ab44e1580924d1ffd7b3938e02716d5ad190441965138b4aa1d1f31ea0877f04 \
    --hash=sha256:b551d4fb482fc57d852b4541f911ba28957d051c8776e79c3b4a51eb5e2a1b11 \
    --hash=sha256:b5eb568c2aa6018e26da9e6c86f3ec3fd958cee7f0311b35c2630fa4217d17f2 \
    --hash=sha256:b659576b950865fdad31fa491d31d37cf78b27113a7671d39f919828587b429b \
    --hash=sha256:b6e76ceb1dd18c8e29c73f47d41866972e891fc4cc7ba014f487def72c1cf096 \
    --hash=sha256:b7529b5dcc114679d43827d8c35a07c493ad6f083633d573d81c660abc5979e9 \
    --hash=sha256:b9dca99744991fc9850d18015c4f0438865414e50069670f5f7eee08340d8b40 \
    --hash=sha256:ba5552a1b07c8edbf197055bc9d518b8f0d98a1c6a73a293bc0726dce068ed01 \
    --hash=sha256:bfe0cbc787770e52a96c6fda6726ace75be7f840cb327e1b08d7d54eadc3bc85 \
    --hash=sha256:c0901429650652d3f0da90bad42bdafc1f9143ff3605633c455c999a2d786cac \
    --hash=sha256:cb1489f25b051a89fae574505cc26360c8e95e227a9500182a7fe0afcc500ce0 \
    --hash=sha256:cd47d063fbeabd4c6cae1d4bcaa38f0902f8dc5ed168072874ea11d0c7afc1ff \
    --hash=sha256:d363152c5e16b29d66cbde8fa614f9e313e6f94a8204eaab268db52231fe5358 \
    --hash=sha256:d5730f3aa35e646103b53389d5bc77edfbf578ab6dab2e005142b5b80a35ef25 \
    --hash=sha256:d6f9367b132078b2ceb8d066ff6c93a970a18c3029cea37bfd7b2d3dd2e5db8f \
    --hash=sha256:dfd6ae1c385ab481766b3c61c44aca2b3cd775f6f7c0fa93d979ddec853d29d5 \
    --hash=sha256:e0da39ff917af8b27a4bdc5a97ac577552a38aac0d260a859c1517ea3dc1a7c4 \
    --hash=sha256:ecf6cd9f83d7c023b1aba15d13f705ca7b7d38675c121f3cc4a6e25bd0857ee9 \
    --hash=sha256:ee0822ce1b8a14fe5a066f93edd20aada932acfe348bede8aa2149f1a4489512 \
    --hash=sha256:f2e55a9b162e06e3f862fb61e399fe9f05d908d019d87bf5b496a04ef18a970a \
    --hash=sha256:f436601594f15bf406518af922a89dcaab416568edb6f65c4e5bbbad1ea45c11 \
    --hash=sha256:f59b870db1f1ae5a9ac28245707d955c8721dd6565e7f411024fa374b5362d1d \
    --hash=sha256:fc533aa50664ebd6c628b2f30591956519462f5d27f951ed03d6c82b2dfd9965 \
    --hash=sha256:fe43139b2c0fdc4a14d4f8d5b5d967f7a2777fd3d38ecf5b1ec669b0d7e43c21 \
    --hash=sha256:fed1cd825158dcaae36acce7b2db33dcbfd12b30c34317a88b8ed80f0541cc57
websockets==15.0.1 ; python_version >= "3.12" and python_version < "4.0" \
    --hash=sha256:0701bc3cfcb9164d04a14b149fd74be7347a530ad3bbf15ab2c678a2cd3dd9a2 \
    --hash=sha256:0a34631031a8f05657e8e90903e656959234f3a04552259458aac0b0f9ae6fd9 \
    --hash=sha256:0af68c55afbd5f07986df82831c7bff04846928ea8d1fd7f30052638788bc9b5 \
    --hash=sha256:0c9e74d766f2818bb95f84c25be4dea09841ac0f734d1966f415e4edfc4ef1c3 \
    --hash=sha256:0f3c1e2ab208db911594ae5b4f79addeb3501604a165019dd221c0bdcabe4db8 \
    --hash=sha256:0fdfe3e2a29e4db3659dbd5bbf04560cea53dd9610273917799f1cde46aa725e \
    --hash=sha256:1009ee0c7739c08a0cd59de430d6de452a55e42d6b522de7aa15e6f67db0b8e1 \
    --hash=sha256:1234d4ef35db82f5446dca8e35a7da7964d02c127b095e172e54397fb6a6c256 \
    --hash=sha256:16b6c1b3e57799b9d38427dda63edcbe4926352c47cf88588c0be4ace18dac85 \
    --hash=sha256:2034693ad3097d5355bfdacfffcbd3ef5694f9718ab7f29c29689a9eae841880 \
    --hash=sha256:21c1fa28a6a7e3cbdc171c694398b6df4744613ce9b36b1a498e816787e28123 \
    --hash=sha256:229cf1d3ca6c1804400b0a9790dc66528e08a6a1feec0d5040e8b9eb14422375 \
    --hash=sha256:27ccee0071a0e75d22cb35849b1db43f2ecd3e161041ac1ee9d2352ddf72f065 \
    --hash=sha256:363c6f671b761efcb30608d24925a382497c12c506b51661883c3e22337265ed \
    --hash=sha256:39c1fec2c11dc8d89bba6b2bf1556af381611a173ac2b511cf7231622058af41 \
    --hash=sha256:3b1ac0d3e594bf121308112697cf4b32be538fb1444468fb0a6ae4feebc83411 \
    --hash=sha256:3be571a8b5afed347da347bfcf27ba12b069d9d7f42cb8c7028b5e98bbb12597 \
    --hash=sha256:3c714d2fc58b5ca3e285461a4cc0c9a66bd0e24c5da9911e30158286c9b5be7f \
    --hash=sha256:3d00075aa65772e7ce9e990cab3ff1de702aa09be3940d1dc88d5abf1ab8a09c \
    --hash=sha256:3e90baa811a5d73f3ca0bcbf32064d663ed81318ab225ee4f427ad4e26e5aff3 \
    --hash=sha256:47819cea040f31d670cc8d324bb6435c6f133b8c7a19ec3d61634e62f8d8f9eb \
    --hash=sha256:47b099e1f4fbc95b701b6e85768e1fcdaf1630f3cbe4765fa216596f12310e2e \
    --hash=sha256:4a9fac8e469d04ce6c25bb2610dc535235bd4aa14996b4e6dbebf5e007eba5ee \
    --hash=sha256:4b826973a4a2ae47ba357e4e82fa44a463b8f168e1ca775ac64521442b19e87f \
    --hash=sha256:4c2529b320eb9e35af0fa3016c187dffb84a3ecc572bcee7c3ce302bfeba52bf \
    --hash=sha256:54479983bd5fb469c38f2f5c7e3a24f9a4e70594cd68cd1fa6b9340dadaff7cf \
    --hash=sha256:558d023b3df0bffe50a04e710bc87742de35060580a293c2a984299ed83bc4e4 \
    --hash=sha256:5756779642579d902eed757b21b0164cd6fe338506a8083eb58af5c372e39d9a \
    --hash=sha256:592f1a9fe869c778694f0aa806ba0374e97648ab57936f092fd9d87f8bc03665 \
    --hash=sha256:595b6c3969023ecf9041b2936ac3827e4623bfa3ccf007575f04c5a6aa318c22 \
    --hash=sha256:5a939de6b7b4e18ca683218320fc67ea886038265fd1ed30173f5ce3f8e85675 \
    --hash=sha256:5d54b09eba2bada6011aea5375542a157637b91029687eb4fdb2dab11059c1b4 \
    --hash=sha256:5df592cd503496351d6dc14f7cdad49f268d8e618f80dce0cd5a36b93c3fc08d \
    --hash=sha256:5f4c04ead5aed67c8a1a20491d54cdfba5884507a48dd798ecaf13c74c4489f5 \
    --hash=sha256:64dee438fed052b52e4f98f76c5790513235efaa1ef7f3f2192c392cd7c91b65 \
    --hash=sha256:66dd88c918e3287efc22409d426c8f729688d89a0c587c88971a0faa2c2f3792 \
    --hash=sha256:678999709e68425ae2593acf2e3ebcbcf2e69885a5ee78f9eb80e6e371f1bf57 \
    --hash=sha256:67f2b6de947f8c757db2db9c71527933ad0019737ec374a8a6be9a956786aaf9 \
    --hash=sha256:693f0192126df6c2327cce3baa7c06f2a117575e32ab2308f7f8216c29d9e2e3 \
    --hash=sha256:746ee8dba912cd6fc889a8147168991d50ed70447bf18bcda7039f7d2e3d9151 \
    --hash=sha256:756c56e867a90fb00177d530dca4b097dd753cde348448a1012ed6c5131f8b7d \
    --hash=sha256:76d1f20b1c7a2fa82367e04982e708723ba0e7b8d43aa643d3dcd404d74f1475 \
    --hash=sha256:7f493881579c90fc262d9cdbaa05a6b54b3811c2f300766748db79f098db9940 \
    --hash=sha256:823c248b690b2fd9303ba00c4f66cd5e2d8c3ba4aa968b2779be9532a4dad431 \
    --hash=sha256:82544de02076bafba038ce055ee6412d68da13ab47f0c60cab827346de828dee \
    --hash=sha256:8dd8327c795b3e3f219760fa603dcae1dcc148172290a8ab15158cf85a953413 \
    --hash=sha256:8fdc51055e6ff4adeb88d58a11042ec9a5eae317a0a53d12c062c8a8865909e8 \
    --hash=sha256:a625e06551975f4b7ea7102bc43895b90742746797e2e14b70ed61c43a90f09b \
    --hash=sha256:abdc0c6c8c648b4805c5eacd131910d2a7f6455dfd3becab248ef108e89ab16a \
    --hash=sha256:ac017dd64572e5c3bd01939121e4d16cf30e5d7e110a119399cf3133b63ad054 \
    --hash=sha256:ac1e5c9054fe23226fb11e05a6e630837f074174c4c2f0fe442996112a6de4fb \
    --hash=sha256:ac60e3b188ec7574cb761b08d50fcedf9d77f1530352db4eef1707fe9dee7205 \
    --hash=sha256:b359ed09954d7c18bbc1680f380c7301f92c60bf924171629c5db97febb12f04 \
    --hash=sha256:b7643a03db5c95c799b89b31c036d5f27eeb4d259c798e878d6937d71832b1e4 \
    --hash=sha256:ba9e56e8ceeeedb2e080147ba85ffcd5cd0711b89576b83784d8605a7df455fa \
    --hash=sha256:c338ffa0520bdb12fbc527265235639fb76e7bc7faafbb93f6ba80d9c06578a9 \
    --hash=sha256:cad21560da69f4ce7658ca2cb83138fb4cf695a2ba3e475e0559e05991aa8122 \
    --hash=sha256:d08eb4c2b7d6c41da6ca0600c077e93f5adcfd979cd777d747e9ee624556da4b \
    --hash=sha256:d50fd1ee42388dcfb2b3676132c78116490976f1300da28eb629272d5d93e905 \
    --hash=sha256:d591f8de75824cbb7acad4e05d2d710484f15f29d4a915092675ad3456f11770 \
    --hash=sha256:d5f6b181bb38171a8ad1d6aa58a67a6aa9d4b38d0f8c5f496b9e42561dfc62fe \
    --hash=sha256:d63efaa0cd96cf0c5fe4d581521d9fa87744540d4bc999ae6e08595a1014b45b \
    --hash=sha256:d99e5546bf73dbad5bf3547174cd6cb8ba7273062a23808ffea025ecb1cf8562 \
    --hash=sha256:e09473f095a819042ecb2ab9465aee615bd9c2028e4ef7d933600a8401c79561 \
    --hash=sha256:e8b56bdcdb4505c8078cb6c7157d9811a85790f2f2b3632c7d1462ab5783d215 \
    --hash=sha256:ee443ef070bb3b6ed74514f5efaa37a252af57c90eb33b956d35c8e9c10a1931 \
    --hash=sha256:f29d80eb9a9263b8d109135351caf568cc3f80b9928bccde535c235de55c22d9 \
    --hash=sha256:f7a866fbc1e97b5c617ee4116daaa09b722101d4a3c170c787450ba409f9736f \
    --hash=sha256:fcd5cf9e305d7b8338754470cf69cf81f420459dbae8a3b40cee57417f4614a7


--- END OF FILE: requirements.txt ---

================================================================================

--- START OF FILE: test_db_connection.py ---

# test_db_connection.py
import asyncio
import os
from dotenv import load_dotenv
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.sql import text
import sys

async def test_connection():
    load_dotenv()
    db_url = os.getenv("DATABASE_URL")

    if not db_url:
        print("❌ ERROR: DATABASE_URL not found in .env file.")
        sys.exit(1)

    if not db_url.startswith("postgresql+asyncpg://"):
            print("⚠️ WARNING: DATABASE_URL does not use asyncpg driver. Ensure it starts with 'postgresql+asyncpg://'")
            # Attempt connection anyway, but it might fail depending on installed drivers
            # Or exit:
            # sys.exit(1)


    print(f"Attempting to connect to: {db_url.split('@')[1]}...") # Hide credentials

    engine = None
    try:
        # Adjust pool settings for a quick test
        engine = create_async_engine(db_url, pool_size=1, max_overflow=0, pool_timeout=5)
        async with engine.connect() as connection:
            print("✅ Database connection successful!")

            # Test pgvector extension
            try:
                result = await connection.execute(text("SELECT extname FROM pg_extension WHERE extname = 'vector';"))
                vector_extension = result.scalar_one_or_none()
                if vector_extension:
                    print("✅ pgvector extension is enabled.")
                else:
                    # Attempt to enable it (might fail if flag wasn't set correctly in Cloud SQL)
                    print("🟡 pgvector extension not found, attempting to enable...")
                    await connection.execute(text("CREATE EXTENSION IF NOT EXISTS vector;"))
                    # Re-check
                    result = await connection.execute(text("SELECT extname FROM pg_extension WHERE extname = 'vector';"))
                    if result.scalar_one_or_none():
                            print("✅ pgvector extension successfully enabled now.")
                    else:
                            print("❌ ERROR: Failed to find or enable pgvector extension. Check Cloud SQL flags and permissions.")

            except Exception as e:
                print(f"❌ ERROR checking/enabling pgvector extension: {e}")

    except Exception as e:
        print(f"❌ Database connection failed: {e}")
        print("   Check:")
        print("   - DATABASE_URL in your .env file is correct (including password, host, port 5432, db name 'postgres').")
        print("   - Your current IP address is added to the 'Authorized networks' in Cloud SQL.")
        print("   - The Cloud SQL instance is running.")
    finally:
        if engine:
            await engine.dispose() # Cleanly close the connection pool

if __name__ == "__main__":
    asyncio.run(test_connection())

--- END OF FILE: test_db_connection.py ---

================================================================================

--- START OF FILE: scripts/seed.py ---

import asyncio
# import logging # Removed logging import

from faker import Faker
from sqlalchemy.exc import IntegrityError
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.orm import selectinload # Added for potential eager loading if needed

# Make sure paths are correct for script execution
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.db.session import AsyncSessionLocal, engine # Assuming engine might be needed for direct ops
from app.models.user import User
from app.models.organization import Company, Startup # Import Company and Startup
from app.models.space import SpaceNode, Workstation # Added SpaceNode, Workstation
from app.schemas.space import WorkstationStatus # Added WorkstationStatus for workstation creation
from app.utils.security_utils import get_password_hash
# Add imports for profile and embedding generation
from app.crud import crud_user_profile # For updating profile and generating embeddings
from app.schemas.user_profile import UserProfileUpdate # For profile update schema
from app.models.profile import UserProfile # To create UserProfile object if needed

# logging.basicConfig(level=logging.INFO) # Removed logging config
# logger = logging.getLogger(__name__) # Removed logger instance

faker = Faker()

# Store credentials for easy output
test_user_credentials = {}

async def clear_specific_data(db: AsyncSession):
    print("Clearing specific existing test data (Users, Startups, Companies, SpaceNodes, Workstations)...")
    
    # Order of deletion matters to avoid foreign key constraint errors
    # Start with models that are referenced by others, or use cascade deletes if set up

    # If WorkstationAssignment exists and references users/workstations, clear it first.
    # from app.models.space import WorkstationAssignment # Assuming this model exists
    # await db.execute(WorkstationAssignment.__table__.delete()) 

    await db.execute(Workstation.__table__.delete())
    # Users who might be corporate_admin in SpaceNode or have space_id need careful handling
    # Easiest might be to temporarily nullify FKs or delete dependent SpaceNodes first.
    
    # Nullify corporate_admin_id in SpaceNodes before deleting users to avoid FK violation
    await db.execute(SpaceNode.__table__.update().values(corporate_admin_id=None))
    await db.commit() # Commit this change first

    # Nullify space_id and company_id and startup_id in Users
    await db.execute(User.__table__.update().values(space_id=None, company_id=None, startup_id=None))
    await db.commit() # Commit this change

    await db.execute(SpaceNode.__table__.delete())
    # Delete users, ensuring SYS_ADMIN is handled (e.g., by filtering or specific logic if it should persist)
    # For a full reset, delete all users except perhaps a superuser if needed.
    # Or, for specific test users, use their emails for targeted deletion.
    # For now, deleting all users for a clean slate, assuming SYS_ADMIN will be recreated.
    await db.execute(User.__table__.delete().where(User.email != "admin@shareyourspace.com")) # Keep SYS_ADMIN for now or recreate
    await db.execute(Startup.__table__.delete())
    await db.execute(Company.__table__.delete())
    
    await db.commit()
    print("Specific data cleared.")


async def seed_data():
    async with AsyncSessionLocal() as db:
        # It's often better to run this on a completely fresh DB (docker-compose down -v)
        # But adding a clear function for more targeted resets if needed.
        # await clear_specific_data(db) # Uncomment if you want the script to clear data

        print("Seeding initial data...")
        test_user_credentials.clear() # Clear any previous credentials

        # --- Seed SYS Admin (Essential) ---
        sys_admin_email = "admin@shareyourspace.com"
        sys_admin_password = "adminpassword"
        existing_sys_admin = (await db.execute(select(User).filter(User.email == sys_admin_email))).scalars().first()
        if not existing_sys_admin:
            sys_admin = User(
                email=sys_admin_email,
                hashed_password=get_password_hash(sys_admin_password),
                full_name="SYS Admin",
                role="SYS_ADMIN",
                status="ACTIVE",
                is_active=True
            )
            db.add(sys_admin)
            print(f"Created SYS Admin: {sys_admin_email}, Password: {sys_admin_password}")
            test_user_credentials[sys_admin_email] = sys_admin_password 
        else:
            print(f"SYS Admin {sys_admin_email} already exists.")
            # Ensure password is known if admin already exists and we didn't set it here
            if sys_admin_email not in test_user_credentials:
                 test_user_credentials[sys_admin_email] = sys_admin_password # Store for output

        # --- Seed Company: Pixida Group ---
        pixida_company_name = "Pixida Group"
        company_pixida = (await db.execute(select(Company).filter(Company.name == pixida_company_name))).scalars().first()
        if not company_pixida:
            company_pixida = Company(
                name=pixida_company_name,
                industry_focus="Automotive & Technology Consulting",
                description="Driving digital transformation.",
                website="https://www.pixida.com/"
            )
            db.add(company_pixida)
            print(f"Created Company: {pixida_company_name}")
            await db.flush()
        else:
            print(f"Company {pixida_company_name} already exists.")

        # --- Seed Startup: AI Innovations GmbH ---
        ai_startup_name = "AI Innovations GmbH"
        startup_ai = (await db.execute(select(Startup).filter(Startup.name == ai_startup_name))).scalars().first()
        if not startup_ai:
            startup_ai = Startup(
                name=ai_startup_name,
                industry_focus="Artificial Intelligence",
                description="Developing cutting-edge AI solutions.",
                mission="To democratize AI access.",
                website="https://fake-ai-innovations.com"
            )
            db.add(startup_ai)
            print(f"Created Startup: {ai_startup_name}")
            await db.flush()
        else:
            print(f"Startup {ai_startup_name} already exists.")

        # --- Seed Startup: GreenTech Solutions ---
        greentech_startup_name = "GreenTech Solutions"
        startup_greentech = (await db.execute(select(Startup).filter(Startup.name == greentech_startup_name))).scalars().first()
        if not startup_greentech:
            startup_greentech = Startup(
                name=greentech_startup_name,
                industry_focus="Sustainability Tech",
                description="Building a greener future with technology.",
                website="https://fake-greentech.com"
            )
            db.add(startup_greentech)
            print(f"Created Startup: {greentech_startup_name}")
            await db.flush()
        else:
            print(f"Startup {greentech_startup_name} already exists.")


        # --- Define Test Users ---
        users_to_create = [
            {
                "email": "corp.admin@pixida.com", "password": "Password123!", "full_name": "Corporate Admin Pat",
                "role": "CORP_ADMIN", "status": "ACTIVE", "company": company_pixida, "startup": None
            },
            {
                "email": "startup.admin@aiinnovations.com", "password": "Password123!", "full_name": "Startup Admin Sam",
                "role": "STARTUP_ADMIN", "status": "ACTIVE", "company": None, "startup": startup_ai
            },
            {
                "email": "startup.member@aiinnovations.com", "password": "Password123!", "full_name": "Startup Member Max",
                "role": "STARTUP_MEMBER", "status": "ACTIVE", "company": None, "startup": startup_ai
            },
            {
                "email": "freelancer.frank@example.com", "password": "Password123!", "full_name": "Freelancer Frank",
                "role": "FREELANCER", "status": "ACTIVE", "company": None, "startup": None # Freelancers might not be tied to a startup initially
            }
        ]

        created_users = {} # To store created user objects

        for user_data in users_to_create:
            existing_user = (await db.execute(select(User).filter(User.email == user_data["email"]))).scalars().first()
            if not existing_user:
                new_user = User(
                    email=user_data["email"],
                    hashed_password=get_password_hash(user_data["password"]),
                    full_name=user_data["full_name"],
                    role=user_data["role"],
                    status=user_data["status"],
                    is_active=True,
                    company_id=user_data["company"].id if user_data["company"] else None,
                    startup_id=user_data["startup"].id if user_data["startup"] else None
                )
                db.add(new_user)
                await db.flush() # Get ID for new_user
                created_users[user_data["email"]] = new_user
                print(f"Created {user_data['role']}: {user_data['email']}, Password: {user_data['password']}")
                test_user_credentials[user_data["email"]] = user_data["password"]
            else:
                created_users[user_data["email"]] = existing_user # Use existing if found
                print(f"User {user_data['email']} already exists.")
                if user_data["email"] not in test_user_credentials: # Store password if not already stored
                    test_user_credentials[user_data["email"]] = user_data["password"]

            # --- Populate Profile and Generate Embedding ---
            user_object_for_profile = created_users.get(user_data["email"])
            if user_object_for_profile:
                profile = await crud_user_profile.get_profile_by_user_id(db, user_id=user_object_for_profile.id)
                if not profile:
                    profile = await crud_user_profile.create_profile_for_user(db, user_id=user_object_for_profile.id)
                    print(f"Created empty profile for user {user_object_for_profile.email}")

                # Define profile data - make Corp Admin and Freelancer very similar to Startup Admin for testing
                startup_admin_profile_template = {
                    "bio": "A passionate professional working with a focus on driving innovation and collaboration in cutting-edge technology sectors.",
                    "skills_expertise": ["Collaboration", "Communication", "Python", "FastAPI", "Docker", "React", "Management", "Strategy", "Operations", "AI", "Cloud Computing"],
                    "industry_focus": ["Artificial Intelligence", "Technology", "Software Development"],
                    "project_interests_goals": "Interested in projects related to AI, cloud solutions, and scalable web applications.",
                    "collaboration_preferences": ["Remote Work", "Team Projects", "Agile Development"],
                    "tools_technologies": ["Python", "FastAPI", "Docker", "React", "Kubernetes", "AWS", "GCP"]
                }

                if user_data["email"] == "corp.admin@pixida.com":
                    profile_details = startup_admin_profile_template.copy()
                    profile_details["title"] = "Corporate Admin at Pixida" # Keep title distinct
                    profile_details["skills_expertise"].append("Corporate Governance") # Add one unique skill
                    print(f"Seeding VERY SIMILAR profile for {user_data['email']}")
                elif user_data["email"] == "freelancer.frank@example.com":
                    profile_details = startup_admin_profile_template.copy()
                    profile_details["title"] = "Independent Tech Consultant & Freelancer" # Keep title distinct
                    profile_details["skills_expertise"].append("Client Management") # Add one unique skill
                    print(f"Seeding VERY SIMILAR profile for {user_data['email']}")
                elif user_data["email"] == "startup.admin@aiinnovations.com":
                    profile_details = startup_admin_profile_template.copy()
                    profile_details["title"] = "Startup Admin at AI Innovations GmbH"
                    print(f"Seeding base profile for {user_data['email']}")
                else: # For startup.member@aiinnovations.com or any others
                    profile_details = {
                        "title": f"{user_data['role'].replace('_', ' ').title()} at {user_data['startup'].name if user_data['startup'] else 'ShareYourSpace'}",
                        "bio": f"A team member at {user_data['startup'].name if user_data['startup'] else 'the company'}.",
                        "skills_expertise": ["Teamwork", "Communication", faker.job()],
                        "industry_focus": [user_data['startup'].industry_focus if user_data['startup'] else "Technology"],
                        "project_interests_goals": f"Contributing to projects at {user_data['startup'].name if user_data['startup'] else 'the company'}.",
                        "collaboration_preferences": ["Team Projects"],
                        "tools_technologies": ["Python", "React"]
                    }
                    print(f"Seeding generic member profile for {user_data['email']}")
                
                profile_update_schema = UserProfileUpdate(**profile_details)
                print(f"PROFILE_UPDATE_SCHEMA for {user_data['email']}: {profile_update_schema.model_dump_json(indent=2)}") # Print the schema
                
                try:
                    print(f"SEED.PY: ---- BEFORE CALLING update_profile for {user_object_for_profile.email} ----")
                    updated_profile = await crud_user_profile.update_profile(
                        db=db, 
                        db_obj=profile, 
                        obj_in=profile_update_schema
                    )
                    print(f"SEED.PY: ---- AFTER CALLING update_profile for {user_object_for_profile.email} ----")

                    if updated_profile.profile_vector is not None: # Check if the attribute is not None
                        print(f"Successfully generated and saved profile vector for {user_object_for_profile.email}.")
                    else:
                        print(f"Profile vector NOT generated for {user_object_for_profile.email} (check logs in crud_user_profile).\nPossible error during embedding generation or data too sparse.")
                except Exception as e:
                    print(f"Error updating profile/generating embedding for {user_object_for_profile.email}: {e}")
                    # Add more detailed error logging if needed, e.g., import traceback; traceback.print_exc()
            # --- End Profile Population ---


        # --- Seed SpaceNode: Pixida Munich Office ---
        # Ensure the corp_admin_user is available
        corp_admin_user_object = created_users.get("corp.admin@pixida.com")
        if not corp_admin_user_object:
            # This should not happen if user creation was successful
            # Fetch from DB as a fallback if it existed previously and wasn't in created_users
            corp_admin_user_object = (await db.execute(select(User).filter(User.email == "corp.admin@pixida.com"))).scalars().first()
            if not corp_admin_user_object:
                 print("Critical error: Corporate Admin user not found, cannot create SpaceNode correctly.")
                 await db.rollback()
                 return # Stop seeding

        space_name = "Pixida Munich Central"
        space_node = (await db.execute(select(SpaceNode).filter(SpaceNode.name == space_name))).scalars().first()
        if not space_node:
            space_node = SpaceNode(
                name=space_name,
                address="123 Tech Street, Munich",
                company_id=company_pixida.id if company_pixida else None,
                corporate_admin_id=corp_admin_user_object.id # Link to the Corp Admin
            )
            db.add(space_node)
            await db.flush() # Get ID for space_node
            print(f"Created SpaceNode: {space_name} managed by {corp_admin_user_object.email}")
        else:
            # If space exists, ensure its corporate_admin_id is correctly set (e.g. if script is re-run)
            if space_node.corporate_admin_id != corp_admin_user_object.id:
                space_node.corporate_admin_id = corp_admin_user_object.id
                print(f"Updated SpaceNode {space_name} to be managed by {corp_admin_user_object.email}")
            print(f"SpaceNode {space_name} already exists.")

        # --- Assign Space to Users ---
        # All defined test users (except SYS_ADMIN) will belong to this space
        user_emails_for_space = [
            "corp.admin@pixida.com", 
            "startup.admin@aiinnovations.com",
            "startup.member@aiinnovations.com",
            "freelancer.frank@example.com"
        ]
        for email in user_emails_for_space:
            user_to_update = created_users.get(email)
            if user_to_update and space_node:
                if user_to_update.space_id != space_node.id:
                    user_to_update.space_id = space_node.id
                    print(f"Assigned Space '{space_node.name}' to user {email}")
            elif not user_to_update:
                print(f"Warning: User {email} not found in created_users for space assignment.")
            elif not space_node:
                 print(f"Warning: SpaceNode not available for assigning to user {email}")


        # --- Seed Workstations for the SpaceNode ---
        if space_node:
            num_workstations = 5
            for i in range(1, num_workstations + 1):
                workstation_name = f"Workstation {i:03}"
                existing_workstation = (await db.execute(
                    select(Workstation).filter(Workstation.name == workstation_name, Workstation.space_id == space_node.id)
                )).scalars().first()
                
                if not existing_workstation:
                    workstation = Workstation(
                        name=workstation_name,
                        space_id=space_node.id,
                        status=WorkstationStatus.AVAILABLE # Default status
                    )
                    db.add(workstation)
                    print(f"Created Workstation: {workstation_name} in {space_node.name}")
                else:
                    print(f"Workstation {workstation_name} in {space_node.name} already exists.")
        else:
            print("SpaceNode not available, skipping workstation creation.")
        
        # --- Remove old generic user seeding logic ---
        # (The section with `user_data` list and faker.unique.email() has been replaced)

        try:
            await db.commit()
            print("\n--- Seeding Complete ---")
            print("Created/Ensured the following test user credentials:")
            for email, password in test_user_credentials.items():
                print(f"  Email: {email}, Password: {password}")
            print("--- Please save these credentials securely. ---")

        except IntegrityError as e: # Catch specific IntegrityError
            await db.rollback()
            print(f"Error during seeding commit (IntegrityError): {e.orig}") # .orig can give more DB-specific error info
            print("This might be due to unique constraints or foreign key issues if data wasn't cleared properly or has unexpected existing IDs.")
        except Exception as e:
            await db.rollback()
            print(f"Error during seeding commit: {e}")

async def main():
    # logger.info("Initializing DB session for seeding.") # Removed logger call
    print("Initializing DB session for seeding.")
    # db: AsyncSession = AsyncSessionLocal() # Session is managed within seed_data
    try:
        await seed_data()
    finally:
        # await db.close() # Session is managed within seed_data
        if engine: # Ensure engine is not None before disposing
            await engine.dispose()
        # logger.info("DB session closed.") # Removed logger call
        print("DB session closed and engine disposed.")

if __name__ == "__main__":
    # Important: For a truly clean seed, it's best to reset the database volume:
    # 1. docker-compose down -v  (The -v removes the volume)
    # 2. docker-compose up -d db (Restart only the DB)
    # 3. Wait for DB to be ready
    # 4. poetry run alembic upgrade head (Apply migrations to the fresh DB)
    # 5. poetry run python scripts/seed.py (Run this script)
    #
    # The `clear_specific_data` function is an alternative if you cannot do a full volume reset,
    # but it might be less reliable for complex schemas or if new relations are added without updating it.

    # print("Optional: Running DB migrations before seeding if you haven't done so...")
    # os.system("poetry run alembic upgrade head") # Best to do this manually after db reset
    # print("Migrations complete (if run).")

    asyncio.run(main()) 

--- END OF FILE: scripts/seed.py ---

================================================================================

--- START OF FILE: scripts/generate_embeddings_for_users.py ---

import asyncio
import logging
import argparse
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.future import select
from sqlalchemy.orm import sessionmaker, joinedload
from typing import List

# Adjust imports based on your project structure
from app.core.config import settings
from app.models.user import User
from app.models.profile import UserProfile
from app.utils.embeddings import generate_embedding

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def update_and_embed_profile(db: AsyncSession, user_id: int, profile_data: dict):
    """Fetches user, updates profile text, generates embedding, and saves."""
    logger.info(f"Processing user_id: {user_id}")
    
    # Fetch user with profile eagerly loaded
    result = await db.execute(
        select(User).options(joinedload(User.profile)).filter(User.id == user_id)
    )
    user = result.scalars().first()

    if not user:
        logger.error(f"User with id {user_id} not found.")
        return
        
    if not user.profile:
        logger.warning(f"User {user_id} has no profile object. Creating one.")
        # Simplified profile creation for script context
        user.profile = UserProfile(user_id=user_id, contact_info_visibility='CONNECTIONS') 
        db.add(user.profile)
        # Need to flush to get the profile object associated before updating fields
        try:
            await db.flush() 
            logger.info(f"Created profile for user {user_id}")
        except Exception as e:
             logger.error(f"Error flushing new profile for user {user_id}: {e}", exc_info=True)
             await db.rollback()
             return # Stop processing this user if profile creation fails

    profile = user.profile

    # Update profile text fields
    logger.info(f"Updating profile fields for user_id: {user_id}")
    for field, value in profile_data.items():
        if hasattr(profile, field):
            setattr(profile, field, value)
        else:
            logger.warning(f"Profile object does not have field: {field}")

    # Combine text fields for embedding generation
    profile_text_parts = [
        profile.title or "",
        profile.bio or "",
        " ".join(profile.skills_expertise) if profile.skills_expertise else "",
        " ".join(profile.industry_focus) if profile.industry_focus else "",
        profile.project_interests_goals or "",
        " ".join(profile.collaboration_preferences) if profile.collaboration_preferences else "",
        " ".join(profile.tools_technologies) if profile.tools_technologies else ""
    ]
    profile_text = " ".join(filter(None, profile_text_parts)).strip()

    if profile_text:
        logger.info(f"Generating embedding for user_id: {user_id} with text: '{profile_text[:100]}...' ")
        embedding = generate_embedding(profile_text)
        if embedding:
            logger.info(f"Generated embedding length: {len(embedding)} for user_id: {user_id}")
            profile.profile_vector = embedding
        else:
            logger.warning(f"Embedding generation failed for user_id: {user_id}. Vector not updated.")
            profile.profile_vector = None # Explicitly set to None if failed
    else:
        logger.info(f"No text content for embedding for user_id: {user_id}. Vector not updated.")
        profile.profile_vector = None # Explicitly set to None if no text

    # Add the updated profile object to the session
    db.add(profile)
    logger.info(f"Profile for user {user_id} added to session. Attempting commit.")


async def main(user_ids: List[int]):
    DATABASE_URL = settings.DATABASE_URL
    engine = create_async_engine(DATABASE_URL, echo=False) # Set echo=True for SQL debugging
    AsyncSessionLocal = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

    # Define profile data for specific users
    # User 7 (Original - For Reference) - Assume already has 'AI', 'Python', 'Cloud' profile
    
    # User 6 (Different Profile)
    profile_data_user_6 = {
        "title": "Freelance Writer",
        "bio": "Experienced content writer specializing in tech and marketing.",
        "skills_expertise": ["Content Writing", "SEO", "Copywriting", "Marketing Strategy"],
        "industry_focus": ["Technology", "Marketing"],
        "project_interests_goals": "Looking for freelance writing projects for SaaS companies.",
        "collaboration_preferences": ["asynchronous", "clear briefs"],
        "tools_technologies": ["Google Docs", "WordPress", "Ahrefs"]
    }

    # User 8 (Similar Profile to User 7's potential profile)
    profile_data_user_8 = {
        "title": "AI Engineer",
        "bio": "Developing machine learning models and cloud solutions. Proficient in Python.",
        "skills_expertise": ["Machine Learning", "Python", "Cloud Computing", "Data Analysis", "AWS"],
        "industry_focus": ["Technology", "Artificial Intelligence"],
        "project_interests_goals": "Seeking collaboration on AI projects, particularly in NLP or computer vision.",
        "collaboration_preferences": ["brainstorming", "pair programming"],
        "tools_technologies": ["Python", "TensorFlow", "PyTorch", "Docker", "AWS"]
    }
    
    # User 9 (Different Space, Different Profile)
    profile_data_user_9 = {
        "title": "Graphic Designer",
        "bio": "Creative graphic designer focused on branding and UI design.",
        "skills_expertise": ["Graphic Design", "UI Design", "Branding", "Adobe Creative Suite"],
        "industry_focus": ["Design", "Marketing"],
        "project_interests_goals": "Interested in branding projects for startups.",
        "collaboration_preferences": ["visual feedback", "creative workshops"],
        "tools_technologies": ["Figma", "Adobe Illustrator", "Adobe Photoshop"]
    }
    
    user_profile_map = {
        6: profile_data_user_6,
        8: profile_data_user_8,
        9: profile_data_user_9,
        # Add user 11 here if you want to generate an embedding for them too
    }

    async with AsyncSessionLocal() as session:
        async with session.begin(): # Use a transaction
            for user_id in user_ids:
                if user_id in user_profile_map:
                    logger.info(f"Starting sequential processing for user_id: {user_id}")
                    await update_and_embed_profile(session, user_id, user_profile_map[user_id])
                    logger.info(f"Finished sequential processing for user_id: {user_id}")
                else:
                    logger.warning(f"No specific profile data defined for user_id: {user_id}. Skipping text update, attempting embedding if text exists.")
                    # Optionally, add logic here to still generate embedding based on whatever text might already be in the profile
            
            # Removed asyncio.gather
            logger.info("Committing changes for all processed users.")

    logger.info("Script finished.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate embeddings for specified user profiles.")
    parser.add_argument("user_ids", type=int, nargs='+', help="List of user IDs to process.")
    args = parser.parse_args()
    
    asyncio.run(main(args.user_ids))


--- END OF FILE: scripts/generate_embeddings_for_users.py ---

================================================================================

--- START OF FILE: scripts/backfill_embeddings.py ---

import asyncio
import logging

from sqlalchemy.future import select
from sqlalchemy.orm import selectinload

from app.db.session import AsyncSessionLocal
from app.models.user import User
from app.models.user_profile import UserProfile
from app.utils.embeddings import generate_embedding

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def backfill_embeddings():
    logger.info("Starting embedding backfill process...")
    db: AsyncSessionLocal = AsyncSessionLocal()
    try:
        # Fetch users who have a profile but no profile_vector
        result = await db.execute(
            select(User)
            .options(selectinload(User.profile))
            .join(User.profile)
            .filter(UserProfile.profile_vector == None) # noqa
        )
        users_to_update = result.scalars().all()

        if not users_to_update:
            logger.info("No users found needing embedding backfill.")
            return

        logger.info(f"Found {len(users_to_update)} users to update.")

        updated_count = 0
        failed_count = 0
        for user in users_to_update:
            profile = user.profile
            if not profile:
                logger.warning(f"User {user.id} has no profile, skipping.")
                continue

            logger.info(f"Processing user {user.id}...")

            # Combine text fields (ensure consistency with update_profile)
            profile_text_parts = [
                profile.title or "",
                profile.bio or "",
                " ".join(profile.skills_expertise or []),
                profile.industry_focus or "",
                profile.project_interests_goals or "",
                " ".join(profile.collaboration_preferences or []),
                " ".join(profile.tools_technologies or [])
            ]
            profile_text = " ".join(filter(None, profile_text_parts)).strip()

            if profile_text:
                embedding = generate_embedding(profile_text)
                if embedding:
                    profile.profile_vector = embedding
                    db.add(profile)
                    updated_count += 1
                    logger.info(f"Generated embedding for user {user.id}.")
                else:
                    failed_count += 1
                    logger.error(f"Failed to generate embedding for user {user.id}.")
            else:
                logger.info(f"User {user.id} has no text content in profile, skipping embedding.")
                # Optionally set profile_vector to None explicitly if desired
                # profile.profile_vector = None
                # db.add(profile)

            # Commit periodically to avoid large transactions (e.g., every 10 users)
            if (updated_count + failed_count) % 10 == 0:
                logger.info("Committing batch...")
                await db.commit()

        # Commit any remaining changes
        await db.commit()
        logger.info(f"Backfill complete. Updated: {updated_count}, Failed: {failed_count}")

    except Exception as e:
        logger.error(f"An error occurred during backfill: {e}", exc_info=True)
        await db.rollback() # Rollback on error
    finally:
        await db.close()

if __name__ == "__main__":
    asyncio.run(backfill_embeddings()) 

--- END OF FILE: scripts/backfill_embeddings.py ---

================================================================================

--- START OF FILE: app/main.py ---

import logging
import sys
import socketio

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

# Corrected and simplified router imports
from app.routers import (
    auth,
    users,
    organizations,
    spaces,
    connections,
    notifications,
    chat,
    admin,
    matching,
    agent,
    uploads,
    member_requests,
    invitations,
    startup_actions
)
# Any other routers you have should also be in this tuple, e.g., 'profiles' if it's ready.
# Make sure 'utils' is NOT here unless it's a valid, initialized router.

from app.core.config import settings
from app.socket_handlers import register_socketio_handlers
from app.socket_instance import sio
# from app.db.session import engine # Only if used for create_all
from app.db import base_class

# --- Basic Logging Configuration ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

origins = [
    "http://localhost:3000",
]

def create_app() -> FastAPI:
    app = FastAPI(
        title=settings.PROJECT_NAME,
        openapi_url=f"{settings.API_V1_STR}/openapi.json",
        description="API for ShareYourSpace platform.",
        version="0.1.0"
    )

    app.add_middleware(
        CORSMiddleware,
        allow_origins=origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    # Include routers using the names from the import tuple
    app.include_router(auth.router, prefix=settings.API_V1_STR + "/auth", tags=["auth"])
    app.include_router(users.router, prefix=settings.API_V1_STR + "/users", tags=["users"])
    app.include_router(organizations.router, prefix=settings.API_V1_STR + "/organizations", tags=["organizations"])
    app.include_router(admin.router, prefix=settings.API_V1_STR + "/admin", tags=["admin"])
    app.include_router(matching.router, prefix=settings.API_V1_STR + "/matching", tags=["matching"])
    app.include_router(connections.router, prefix=settings.API_V1_STR + "/connections", tags=["connections"])
    app.include_router(notifications.router, prefix=settings.API_V1_STR + "/notifications", tags=["notifications"])
    app.include_router(chat.router, prefix=settings.API_V1_STR + "/chat", tags=["chat"])
    app.include_router(agent.router, prefix=settings.API_V1_STR + "/agent", tags=["agent"])
    app.include_router(uploads.router, prefix=settings.API_V1_STR + "/uploads", tags=["uploads"])
    app.include_router(spaces.router, prefix=settings.API_V1_STR + "/spaces", tags=["spaces"])
    # If you have a profiles router ready and it's in app.routers.__init__.py and the import tuple above:
    # app.include_router(profiles.router, prefix=settings.API_V1_STR + "/profiles", tags=["profiles"])
    app.include_router(member_requests.router, prefix=settings.API_V1_STR + "/member-requests", tags=["member-requests"])
    app.include_router(invitations.router, prefix=settings.API_V1_STR + "/invitations", tags=["invitations"])
    app.include_router(startup_actions.router, prefix=settings.API_V1_STR + "/startup-actions", tags=["startup-actions"])

    @app.get("/health", tags=["health"])
    async def health_check():
        return {"status": "ok"}

    @app.get("/", tags=["root"])
    async def root():
        return {"message": f"Welcome to {settings.PROJECT_NAME}! Navigate to /docs for API documentation."}

    return app

fastapi_app = create_app()

register_socketio_handlers(sio)
app = socketio.ASGIApp(sio, other_asgi_app=fastapi_app)

# base_class.Base.metadata.create_all(bind=engine) # Usually for dev, ensure Alembic handles prod

--- END OF FILE: app/main.py ---

================================================================================

--- START OF FILE: app/dependencies.py ---

from fastapi import Depends, HTTPException, status

from app.models.user import User
from app.security import get_current_active_user

def require_sys_admin(
    current_user: User = Depends(get_current_active_user)
):
    """Dependency to check if the current user has the SYS_ADMIN role."""
    if current_user.role != 'SYS_ADMIN':
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="The user doesn't have enough privileges"
        )
    return current_user 

--- END OF FILE: app/dependencies.py ---

================================================================================

--- START OF FILE: app/__init__.py ---

# Leave this file empty 

--- END OF FILE: app/__init__.py ---

================================================================================

--- START OF FILE: app/security.py ---

from datetime import datetime, timedelta, timezone
from typing import Any

from jose import JWTError, jwt
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.core.config import settings
from app.db.session import get_db
from app.schemas.token import TokenPayload as TokenPayloadSchema
from app import crud, models # Removed schemas from here

# Define the OAuth2 scheme
# Use the URL of your token endpoint (login endpoint)
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/v1/auth/login") # Ensure correct path


def create_access_token(data: dict, expires_delta: timedelta | None = None) -> str:
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.now(timezone.utc) + expires_delta
    else:
        # Default token expiry: Consider making this configurable
        expire = datetime.now(timezone.utc) + timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES) # Use config if available
    to_encode.update({"exp": expire})
    # Use .get_secret_value() to get the actual string key
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY.get_secret_value(), algorithm=settings.ALGORITHM)
    return encoded_jwt

async def get_current_user(
    token: str = Depends(oauth2_scheme), db: AsyncSession = Depends(get_db)
) -> models.User:
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        # Use .get_secret_value() for decoding as well
        payload = jwt.decode(
            token, settings.SECRET_KEY.get_secret_value(), algorithms=[settings.ALGORITHM]
        )
        username: str = payload.get("sub")
        user_id: int | None = payload.get("user_id") # Assuming user_id is in token
        if username is None or user_id is None:
            raise credentials_exception
        token_data = TokenPayloadSchema(sub=username, user_id=user_id)
    except JWTError:
        raise credentials_exception

    # Use the user_id from the token for lookup and load profile eagerly
    user = await crud.crud_user.get_user_by_id(
        db,
        user_id=token_data.user_id, 
        options=[
            selectinload(models.User.profile),
            selectinload(models.User.startup)  # Eager load startup relationship
            ]
    )
    if user is None:
        raise credentials_exception
    return user

async def get_current_active_user(
    current_user: models.User = Depends(get_current_user),
) -> models.User:
    # Check if user is active (consider using the status field as well)
    if not current_user.is_active or current_user.status != 'ACTIVE':
        raise HTTPException(status_code=400, detail="Inactive user")
    return current_user 

# New dependency for role-based access control
def get_current_user_with_roles(required_roles: list[str]):
    async def role_checker(current_user: models.User = Depends(get_current_active_user)) -> models.User:
        if current_user.role not in required_roles:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail=f"User role '{current_user.role}' is not authorized for this endpoint. Required roles: {required_roles}"
            )
        return current_user
    return role_checker 

--- END OF FILE: app/security.py ---

================================================================================

--- START OF FILE: app/socket_handlers.py ---

import socketio
import logging
from jose import JWTError, jwt
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session # For DB operations

from app.core.config import settings
from app.db.session import AsyncSessionLocal # Import session factory
from app import crud, models # Ensure models is imported
from app.crud import crud_user # <<< ADDED IMPORT
from app.schemas.token import TokenPayload # Import schema
from app.schemas.chat import ChatMessageCreate, ChatMessageSchema # Import chat schemas
from app.crud.crud_chat import (
    create_message, 
    get_messages_for_conversation, 
    mark_conversation_messages_as_read,
    get_or_create_conversation
) # Corrected import names
from app.models.user import User as UserModel # Import UserModel

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# In-memory mapping for MVP: {sid: user_id}. NOTE: This will not scale beyond a single process.
# Consider Redis or another shared store for multi-process/distributed deployments.
sid_user_map = {}
online_user_ids = set() # Set to store IDs of currently online users

async def _get_user_from_token(token: str, db: AsyncSession) -> int | None:
    """Helper to validate token and get user ID."""
    if not token:
        return None
    try:
        payload = jwt.decode(
            token, settings.SECRET_KEY.get_secret_value(), algorithms=[settings.ALGORITHM]
        )
        token_data = TokenPayload(**payload) # Validate payload structure
        if token_data.user_id is None:
            logger.warning("Token payload missing user_id")
            return None
    except JWTError as e:
        logger.warning(f"JWT Error: {e}")
        return None
    except Exception as e: # Catch potential Pydantic validation errors too
        logger.error(f"Token validation error: {e}")
        return None

    user = await crud.crud_user.get_user_by_id(db, user_id=token_data.user_id)
    if user is None:
        logger.warning(f"User not found for ID: {token_data.user_id}")
        return None

    # Optional: Add checks like user.is_active or status == 'ACTIVE'
    if not user.is_active: # or user.status != 'ACTIVE':
         logger.warning(f"Attempted connection by inactive user: {user.id}")
         return None

    return user.id

def register_socketio_handlers(sio: socketio.AsyncServer):
    @sio.event
    async def connect(sid, environ, auth):
        """Handles new client connections with authentication."""
        logger.info(f"Socket.IO client connecting: {sid}")

        token = auth.get('token') if auth else None

        if not token:
             logger.warning(f"Connection attempt refused for {sid}: No token provided in auth")
             return False

        async with AsyncSessionLocal() as db:
            user_id = await _get_user_from_token(token, db)

        if not user_id:
            logger.warning(f"Socket.IO connection refused for {sid}: Invalid token or user")
            return False

        logger.info(f"Socket.IO client connected: {sid}, User ID: {user_id}")
        sid_user_map[sid] = user_id
        online_user_ids.add(user_id)
        logger.info(f"Authenticated user {user_id} mapped to sid {sid}. Online users: {len(online_user_ids)}")

        await sio.enter_room(sid, str(user_id))
        logger.info(f"Sid {sid} joined room '{user_id}'")

        await sio.emit('user_online', {'user_id': user_id}, skip_sid=sid)
        await sio.emit('online_users_list', list(online_user_ids), room=sid)

    @sio.event
    async def disconnect(sid):
        """Handles client disconnections."""
        logger.info(f"Socket.IO client disconnected: {sid}")
        user_id = sid_user_map.pop(sid, None)
        if user_id:
            online_user_ids.discard(user_id)
            logger.info(f"Removed mapping for sid {sid} (User: {user_id}). Online users: {len(online_user_ids)}")
            await sio.emit('user_offline', {'user_id': user_id}, skip_sid=sid)
        else:
            logger.warning(f"No user ID found for disconnected sid {sid}")

    # --- Chat Message Handler ---
    @sio.on('send_message')
    async def handle_send_message(sid, data):
        """Handles receiving and broadcasting chat messages, now with attachment support."""
        sender_id = sid_user_map.get(sid)
        if not sender_id:
            logger.warning(f"Received 'send_message' from unknown sid: {sid}")
            return

        try:
            # Expecting data = {"recipient_id": int, "content": str, 
            #                   "attachment_url": Optional[str], "attachment_filename": Optional[str], 
            #                   "attachment_mimetype": Optional[str]}
            recipient_id = int(data['recipient_id']) # Assuming direct messages for now
            content = str(data.get('content', '')) # Content can be empty for attachments
            
            attachment_url = data.get('attachment_url')
            attachment_filename = data.get('attachment_filename')
            attachment_mimetype = data.get('attachment_mimetype')

            # A message should have content or an attachment
            if not content and not attachment_url:
                 logger.warning(f"User {sender_id} sent an empty message (no content, no attachment) to {recipient_id}")
                 return

        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Invalid 'send_message' data from {sid} (User: {sender_id}): {data} - Error: {e}")
            return

        logger.info(f"User {sender_id} sending message to {recipient_id}. Content: '{content[:30]}...'. Attachment: {attachment_filename if attachment_url else 'None'}")

        async with AsyncSessionLocal() as db:
            # Create message object for saving
            message_in = ChatMessageCreate(
                recipient_id=recipient_id,
                content=content,
                attachment_url=attachment_url,
                attachment_filename=attachment_filename,
                attachment_mimetype=attachment_mimetype
            )

            # Save message to database
            try:
                db_message = await create_message( 
                    db=db, 
                    obj_in=message_in, 
                    sender_id=sender_id,
                    online_user_ids=online_user_ids # Pass the global set
                )
                logger.info(f"Message saved to DB (ID: {db_message.id}), Att: {db_message.attachment_filename}")
            except Exception as e:
                logger.error(f"Failed to save message from {sender_id} to {recipient_id}: {e}")
                return

            # Convert to Pydantic schema for broadcasting
            message_data = ChatMessageSchema.model_validate(db_message).model_dump(mode='json')

            # Fetch sender's details for notification
            sender_user = await crud_user.get_user_by_id(db, user_id=sender_id)
            sender_name = sender_user.full_name if sender_user else "Someone"

        recipient_room = str(recipient_id)
        logger.info(f"Emitting 'receive_message' to room: {recipient_room}")
        await sio.emit('receive_message', message_data, room=recipient_room)

        sender_room = str(sender_id)
        logger.info(f"Emitting 'receive_message' back to sender room: {sender_room}")
        await sio.emit('receive_message', message_data, room=sender_room)

        # Emit notification to recipient (if not themselves)
        if sender_id != recipient_id:
            message_preview = (db_message.content[:50] + '...') if db_message.content and len(db_message.content) > 50 else db_message.content
            if not message_preview and db_message.attachment_filename: # If no content, use filename as preview
                message_preview = f"Attachment: {db_message.attachment_filename}"
            
            notification_payload = {
                "message_id": db_message.id,
                "conversation_id": db_message.conversation_id,
                "sender_id": sender_id,
                "sender_name": sender_name,
                "message_preview": message_preview,
                "created_at": db_message.created_at.isoformat() # Include timestamp
            }
            logger.info(f"Emitting 'new_message_notification' to room {recipient_room} for message {db_message.id}")
            await sio.emit('new_message_notification', notification_payload, room=recipient_room)

    # --- Read Receipt Handler ---
    @sio.on('mark_as_read')
    async def handle_mark_as_read(sid, data):
        """Handles when a client marks messages in a conversation as read."""
        reader_user_id = sid_user_map.get(sid) # The user who is reading
        if not reader_user_id:
            logger.warning(f"Received 'mark_as_read' from unknown sid: {sid}")
            return

        try:
            conversation_partner_id = int(data['sender_id']) # The other user in the conversation
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Invalid 'mark_as_read' data from {sid} (User: {reader_user_id}): {data} - Error: {e}")
            return

        logger.info(f"User {reader_user_id} marking messages with user {conversation_partner_id} as read.")

        async with AsyncSessionLocal() as db:
            try:
                # First, get or create the conversation to ensure we have its ID
                conversation = await crud.crud_chat.get_or_create_conversation(
                    db=db, user1_id=reader_user_id, user2_id=conversation_partner_id
                )
                if not conversation:
                    logger.error(f"Could not get or create conversation between {reader_user_id} and {conversation_partner_id}")
                    return

                updated_count = await crud.crud_chat.mark_conversation_messages_as_read(
                    db=db, conversation_id=conversation.id, reader_id=reader_user_id
                )
                logger.info(f"Marked {updated_count} messages as read in conversation {conversation.id} for reader {reader_user_id}.")
                
                if updated_count > 0:
                    # Notify the conversation partner that their messages have been read
                    partner_room = str(conversation_partner_id)
                    await sio.emit('messages_read', 
                                   {'reader_id': reader_user_id, 
                                    'conversation_id': conversation.id, 
                                    'conversation_partner_id': conversation_partner_id, # Keep for client use if needed
                                    'count': updated_count},
                                   room=partner_room)
                    logger.info(f"Emitted 'messages_read' to room {partner_room} for conversation {conversation.id}")

            except Exception as e:
                logger.error(f"Failed to mark messages as read for user {reader_user_id} with {conversation_partner_id}: {e}")

    # --- Placeholder Handlers ---
    @sio.on('user_typing')
    async def handle_user_typing(sid, data):
        user_id = sid_user_map.get(sid)
        logger.info(f"User {user_id} typing status changed (Data: {data}) - Placeholder")

    # @sio.on('some_event') # Keep or remove the original placeholder as needed
    # async def handle_some_event(sid, data):
    #     ... 

--- END OF FILE: app/socket_handlers.py ---

================================================================================

--- START OF FILE: app/socket_instance.py ---

import socketio

# Configure allowed origins for Socket.IO (match FastAPI CORS or be more specific)
# For production, use a specific list, not "*"
sio = socketio.AsyncServer(async_mode='asgi', cors_allowed_origins='*') # TODO: Restrict origins for production 

--- END OF FILE: app/socket_instance.py ---

================================================================================

--- START OF FILE: app/routers/auth.py ---

from fastapi import APIRouter, Depends, HTTPException, status, Query, Body
from fastapi.security import OAuth2PasswordRequestForm
from sqlalchemy.ext.asyncio import AsyncSession
import secrets
from datetime import datetime, timedelta, timezone
import logging

# --- CRUD Imports ---
import app.crud.crud_user as crud_user
import app.crud.crud_verification_token as crud_verification_token
import app.crud.crud_password_reset_token as crud_password_reset_token

# --- Schema Imports ---
import app.schemas.user as user_schemas
import app.schemas.verification_token as verification_token_schemas
import app.schemas.password_reset_token as password_reset_schemas

# --- Model Imports ---
from app.models.user import User
from app.models.verification_token import VerificationToken
from app.models.password_reset_token import PasswordResetToken

# --- Other Imports ---
from app.db.session import get_db
from app.utils.email import send_email
from app.core.config import settings
from app.utils.security_utils import verify_password
from app import security

logger = logging.getLogger(__name__)

router = APIRouter()

@router.post("/register", response_model=user_schemas.User, status_code=status.HTTP_201_CREATED)
async def register_user(
    user_in: user_schemas.UserCreate,
    db: AsyncSession = Depends(get_db)
):
    """Register a new user and send verification email."""
    existing_user = await crud_user.get_user_by_email(db, email=user_in.email)
    if existing_user:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Email already registered"
        )

    try:
        # Create the user first
        db_user = await crud_user.create_user(db=db, obj_in=user_in)

        # Generate verification token
        token = secrets.token_urlsafe(32)
        expires_at = VerificationToken.get_default_expiry()
        token_create = verification_token_schemas.VerificationTokenCreate(
            user_id=db_user.id,
            token=token,
            expires_at=expires_at
        )
        await crud_verification_token.create_verification_token(db=db, obj_in=token_create)

        # Construct verification URL
        verification_url = f"{settings.FRONTEND_URL}/auth/verify?token={token}"

        # Send verification email
        subject = "Verify Your ShareYourSpace Account"
        html_content = f"""
        <p>Hi {db_user.full_name},</p>
        <p>Thanks for registering for ShareYourSpace!</p>
        <p>Please click the link below to verify your email address:</p>
        <p><a href="{verification_url}">{verification_url}</a></p>
        <p>This link will expire in 1 hour.</p>
        <p>If you did not register for an account, please ignore this email.</p>
        <p>Thanks,<br>The ShareYourSpace Team</p>
        """
        send_email(to=db_user.email, subject=subject, html_content=html_content)

        # Return the created user, but status is still PENDING_VERIFICATION
        return db_user

    except Exception as e:
        # Log the detailed error internally
        print(f"Error during user registration or email sending: {e}") # Improve logging
        # Consider rolling back user creation if email fails critically?
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred during registration or sending the verification email."
        )

@router.get("/verify-email", status_code=status.HTTP_200_OK)
async def verify_email(
    token: str = Query(...),
    db: AsyncSession = Depends(get_db)
):
    """Verify user's email using the provided token."""
    db_token = await crud_verification_token.get_verification_token(db=db, token=token)

    if not db_token or db_token.expires_at < datetime.now(timezone.utc):
        await crud_verification_token.delete_verification_token(db=db, token_obj=db_token) # Clean up expired/invalid token
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid or expired verification token."
        )

    user: User | None = await crud_user.get_user_by_id(db=db, user_id=db_token.user_id)
    if not user:
        # This case should ideally not happen if DB integrity is maintained
        await crud_verification_token.delete_verification_token(db=db, token_obj=db_token)
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found")

    # Determine the next status based on role (We might not need to set status here anymore)
    # next_status = ""
    # if user.role in ["STARTUP_ADMIN", "STARTUP_MEMBER", "FREELANCER"]:
    #     next_status = "WAITLISTED"
    # elif user.role in ["CORP_ADMIN", "CORP_EMPLOYEE"]:
    #     next_status = "PENDING_ONBOARDING"
    # else:
    #     next_status = "ACTIVE" # Default or for SYS_ADMIN if applicable

    # Activate user if they are not already active
    if not user.is_active: # Check if user is not active yet
        # Set is_active to True upon successful verification
        # We don't necessarily need to change the status here, 
        # as it should have been set correctly during creation.
        # If the status was somehow wrong, it should be fixed elsewhere.
        # updated_user_data = user_schemas.UserUpdateInternal(status=user.status, is_active=True)
        updated_user_data = user_schemas.UserUpdateInternal(is_active=True) # Just activate
        
        logger.info(f"Attempting to activate user {user.id} (current status: {user.status}). Setting is_active=True.")
        
        try:
            await crud_user.update_user_internal(db=db, db_obj=user, obj_in=updated_user_data)
            # Re-fetch the user to ensure we have the latest state
            user = await crud_user.get_user_by_id(db=db, user_id=db_token.user_id)
            
            if user:
                 logger.info(f"User {user.id} state after activation: status={user.status}, is_active={user.is_active}")
            else:
                 # This case is highly unlikely if the update worked
                 logger.error(f"User {db_token.user_id} not found after attempting activation update!")
                 # Even if user not found after update, proceed to delete token
        
        except Exception as e:
            logger.error(f"Error activating user {db_token.user_id}: {e}", exc_info=True)
            # Decide if we should raise an HTTP exception or just log and continue to delete token
            # For now, let's log and continue to prevent leaving tokens indefinitely
            pass # Continue to token deletion even if update fails? Or re-raise? Let's continue for now.


    # Delete the used token (always do this if token was valid)
    await crud_verification_token.delete_verification_token(db=db, token_obj=db_token)

    # Return success message along with the user's role (fetch role from user obj if re-fetched)
    final_role = user.role if user else "unknown" # Handle case where user might be None after failed update/refetch
    return {"success": True, "message": "Email verified successfully!", "role": final_role}

@router.post("/login")
async def login_for_access_token(
    db: AsyncSession = Depends(get_db),
    form_data: OAuth2PasswordRequestForm = Depends()
):
    """Authenticate user and return JWT access token."""
    user = await crud_user.get_user_by_email(db, email=form_data.username)
    
    # Check if user exists and password is correct
    if not user or not verify_password(form_data.password, user.hashed_password):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect email or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
        
    # Check if the user account is active (adjust based on your status logic)
    # Example: Allow login only if ACTIVE, WAITLISTED, or PENDING_ONBOARDING?
    # Or just check `is_active` boolean if using that.
    # if user.status not in ["ACTIVE", "WAITLISTED", "PENDING_ONBOARDING"]:
    if not user.is_active: # Assuming is_active is the primary check
         raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Inactive user. Please verify your email or contact support.",
        )
        
    # Create the access token
    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = security.create_access_token(
        data={"sub": user.email, "user_id": user.id, "role": user.role},
        expires_delta=access_token_expires
    )
    
    # Return the token in the response body (as expected by current frontend)
    return {"access_token": access_token, "token_type": "bearer"}

@router.post("/request-password-reset", status_code=status.HTTP_200_OK)
async def request_password_reset(
    request_data: password_reset_schemas.RequestPasswordResetRequest,
    db: AsyncSession = Depends(get_db)
):
    """Send a password reset email to the user if the email exists."""
    user = await crud_user.get_user_by_email(db, email=request_data.email)
    
    # IMPORTANT: Always return success to prevent email enumeration attacks
    if user:
        try:
            # Generate and store token
            token = PasswordResetToken.generate_token()
            expires_at = PasswordResetToken.get_default_expiry()
            token_create = password_reset_schemas.PasswordResetTokenCreate(
                user_id=user.id,
                token=token,
                expires_at=expires_at
            )
            await crud_password_reset_token.create_reset_token(db=db, obj_in=token_create)
            
            # Construct reset URL
            reset_url = f"{settings.FRONTEND_URL}/reset-password?token={token}"
            
            # Send email
            subject = "Reset Your ShareYourSpace Password"
            html_content = f"""
            <p>Hi {user.full_name},</p>
            <p>You requested a password reset for your ShareYourSpace account.</p>
            <p>Please click the link below to set a new password:</p>
            <p><a href="{reset_url}">{reset_url}</a></p>
            <p>This link will expire in 1 hour.</p>
            <p>If you did not request a password reset, please ignore this email.</p>
            <p>Thanks,<br>The ShareYourSpace Team</p>
            """
            # Consider running email sending in background task for responsiveness
            send_email(to=user.email, subject=subject, html_content=html_content)

        except Exception as e:
            # Log the error but still return a generic success message to the client
            print(f"Error processing password reset request for {request_data.email}: {e}")

    # Return generic message regardless of whether the user was found or email sent
    return {"message": "If an account exists for this email, a password reset link has been sent."}

@router.post("/reset-password", status_code=status.HTTP_200_OK)
async def reset_password(
    request_data: password_reset_schemas.ResetPasswordRequest,
    db: AsyncSession = Depends(get_db)
):
    """Reset the user's password using a valid token."""
    token = request_data.token
    new_password = request_data.new_password
    
    db_token = await crud_password_reset_token.get_reset_token_by_token(db=db, token=token)
    
    if not db_token or db_token.expires_at < datetime.now(timezone.utc):
        await crud_password_reset_token.delete_reset_token(db=db, token_obj=db_token) # Clean up
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid or expired password reset token."
        )
        
    user = await crud_user.get_user_by_id(db=db, user_id=db_token.user_id)
    if not user:
        await crud_password_reset_token.delete_reset_token(db=db, token_obj=db_token) # Clean up
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User associated with token not found.")
        
    try:
        # Update user password
        await crud_user.update_user_password(db=db, user=user, new_password=new_password)
        
        # Delete the used token
        await crud_password_reset_token.delete_reset_token(db=db, token_obj=db_token)
        
        return {"message": "Password has been reset successfully."}
        
    except Exception as e:
        print(f"Error during password reset for user {user.id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred while resetting the password."
        )

# --- Add CRUD for VerificationToken --- #
# (This assumes you create app/crud/crud_verification_token.py
# and app/schemas/verification_token.py)

# Add other auth routes here later (login, verify-email, etc.) 

--- END OF FILE: app/routers/auth.py ---

================================================================================

--- START OF FILE: app/routers/users.py ---

from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select # Add select
from sqlalchemy.orm import selectinload # Add selectinload
import uuid
import datetime
from fastapi.responses import StreamingResponse # Import StreamingResponse
import io # Import io for streaming
import logging # Import logging

from app import models, security, crud # Ensure crud is imported
from app.schemas.user import User as UserSchema, UserDetail as UserDetailSchema # Import UserDetailSchema
# Import profile schemas and crud functions
from app.schemas.user_profile import UserProfile as UserProfileSchema, UserProfileUpdate
from app.crud import crud_user_profile
from app.crud import crud_user # Add this line
from app.db.session import get_db
from app.utils import storage # Import storage utility
from app.utils.embeddings import generate_embedding # Import embedding utility
from app.models.space import WorkstationAssignment # Import WorkstationAssignment for type hint/logic

router = APIRouter()
logger = logging.getLogger(__name__) # Add logger


@router.get("/me", response_model=UserSchema)
async def read_users_me(
    current_user: models.User = Depends(security.get_current_user),
    db: AsyncSession = Depends(get_db) # Add db session
):
    """
    Fetch the details of the currently authenticated user.
    Includes corporate_admin_id if applicable.
    Also includes startup_id and space_id.
    Requires only a valid token, not necessarily ACTIVE status.
    """
    # The dependency already fetches and validates the user
    user_data = UserSchema.from_orm(current_user)
    
    # Explicitly set startup_id and space_id from the current_user model
    # These should be direct attributes on the User model
    user_data.startup_id = current_user.startup_id
    user_data.space_id = current_user.space_id
    
    user_data.corporate_admin_id = None # Default to None

    if current_user.space_id:
        # Efficiently load the space relationship if not already loaded
        # This depends on how current_user is loaded by get_current_user.
        # If relationships are not typically loaded, an explicit load might be needed.
        # However, for simplicity, we'll try direct access first.
        # If current_user.space is not loaded, we'd need an async query.
        
        # Assuming current_user.space might not be loaded or to be safe:
        stmt = select(models.SpaceNode).where(models.SpaceNode.id == current_user.space_id)
        result = await db.execute(stmt)
        space_node = result.scalar_one_or_none()

        if space_node:
            user_data.corporate_admin_id = space_node.corporate_admin_id
            
    return user_data

@router.get("/me/profile", response_model=UserProfileSchema)
async def read_my_profile(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(security.get_current_user),
):
    """Fetch the profile of the currently authenticated user.
    Returns profile data including a temporary signed URL for the profile picture.
    Requires only a valid token.
    """
    profile_db = await crud_user_profile.get_profile_by_user_id(db, user_id=current_user.id)
    if not profile_db:
        profile_db = await crud_user_profile.create_profile_for_user(db, user_id=current_user.id)

    # Convert DB model to Pydantic schema
    profile_data = UserProfileSchema.from_orm(profile_db)

    # Generate signed URL if profile picture exists
    signed_url = None
    if profile_db.profile_picture_url and storage.GCS_BUCKET:
        try:
            blob = storage.GCS_BUCKET.blob(profile_db.profile_picture_url)
            signed_url = blob.generate_signed_url(
                version="v4",
                # URL expires in 1 hour
                expiration=datetime.timedelta(hours=1),
                method="GET",
            )
        except Exception as e:
            # Log error but don't fail the request
            print(f"Error generating signed URL for {profile_db.profile_picture_url}: {e}") # Replace with logger

    # Add the signed URL to the response object (even if None)
    profile_data.profile_picture_signed_url = signed_url

    return profile_data

@router.put("/me/profile", response_model=UserProfileSchema)
async def update_my_profile(
    profile_in: UserProfileUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(security.get_current_user),
):
    """Update the profile of the currently authenticated user.
    If profile doesn't exist, it will be created.
    Generates and stores profile embedding vector on successful update.
    Returns updated profile data including the blob name.
    Requires only a valid token.
    """
    profile_db = await crud_user_profile.get_profile_by_user_id(db, user_id=current_user.id)
    if not profile_db:
        profile_db = await crud_user_profile.create_profile_for_user(db, user_id=current_user.id)

    # Update standard profile fields first
    updated_profile_db = await crud_user_profile.update_profile(
        db=db, db_obj=profile_db, obj_in=profile_in
    )
    
    # --- Generate and Save Embedding --- 
    try:
        # 1. Construct text input for embedding
        # Combine relevant text fields. Ensure None values are handled gracefully.
        text_parts = [
            updated_profile_db.title or "",
            updated_profile_db.bio or "",
            "Skills: " + ", ".join(updated_profile_db.skills_expertise or []),
            "Industry: " + ", ".join(updated_profile_db.industry_focus or []),
            "Goals: " + (updated_profile_db.project_interests_goals or ""),
            "Collaboration: " + ", ".join(updated_profile_db.collaboration_preferences or []),
            "Tools: " + ", ".join(updated_profile_db.tools_technologies or []),
        ]
        combined_text = "\n".join(filter(None, text_parts)) # Join non-empty parts
        logger.info(f"Generating embedding for user {current_user.id} based on text: {combined_text[:200]}...") # Log beginning of text

        # 2. Generate embedding
        embedding_vector = None
        if combined_text:
             embedding_vector = generate_embedding(combined_text)

        # 3. Save embedding (if generated successfully)
        if embedding_vector:
            logger.info(f"Embedding generated successfully for user {current_user.id}. Saving...")
            updated_profile_db.profile_vector = embedding_vector
            db.add(updated_profile_db) # Add to session again to include vector update
            await db.commit() # Commit the vector update
            await db.refresh(updated_profile_db) # Refresh to get the latest state including vector
            logger.info(f"Embedding vector saved for user {current_user.id}.")
        else:
            logger.warning(f"Embedding vector generation failed or text was empty for user {current_user.id}. Vector not saved.")

    except Exception as e:
        await db.rollback() # Rollback embedding commit on error
        logger.error(f"Error during embedding generation/saving for user {current_user.id}: {e}", exc_info=True)
        # Decide if this error should fail the whole request or just be logged
        # For now, let's log it but allow the profile update to succeed without the vector
        pass 
    # --- End Embedding Generation --- 

    # Convert final DB model (potentially with vector) to Pydantic schema for response
    updated_profile_data = UserProfileSchema.from_orm(updated_profile_db)

    # Generate signed URL for the potentially updated picture
    signed_url = None
    if updated_profile_db.profile_picture_url and storage.GCS_BUCKET:
        try:
            blob = storage.GCS_BUCKET.blob(updated_profile_db.profile_picture_url)
            signed_url = blob.generate_signed_url(
                version="v4",
                expiration=datetime.timedelta(hours=1),
                method="GET",
            )
        except Exception as e:
            logger.error(f"Error generating signed URL after update for {updated_profile_db.profile_picture_url}: {e}", exc_info=True) # Use logger

    updated_profile_data.profile_picture_signed_url = signed_url

    return updated_profile_data

@router.post("/me/profile/picture", response_model=UserProfileSchema)
async def upload_my_profile_picture(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(security.get_current_user),
):
    """Upload a profile picture for the currently authenticated user.
    Saves the blob name and returns the updated profile.
    Requires only a valid token.
    """
    profile_db = await crud_user_profile.get_profile_by_user_id(db, user_id=current_user.id)
    if not profile_db:
        profile_db = await crud_user_profile.create_profile_for_user(db, user_id=current_user.id)

    # Generate unique blob name
    file_extension = file.filename.split('.')[-1] if '.' in file.filename else 'jpg'
    unique_filename = f"user_{current_user.id}_profile_{uuid.uuid4()}.{file_extension}"
    destination_blob_name = f"profile_pictures/{unique_filename}"

    # Upload file to GCS - returns blob name on success
    blob_name = storage.upload_file(file=file, destination_blob_name=destination_blob_name)

    if not blob_name:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to upload profile picture.",
        )

    # Update profile with the new blob name
    profile_update_data = UserProfileUpdate(profile_picture_url=blob_name)
    updated_profile_db = await crud_user_profile.update_profile(
        db=db, db_obj=profile_db, obj_in=profile_update_data
    )

    # Convert DB model to Pydantic schema for response
    profile_data = UserProfileSchema.from_orm(updated_profile_db)

    # Generate signed URL for the *newly* uploaded picture
    signed_url = None
    if updated_profile_db.profile_picture_url and storage.GCS_BUCKET:
        try:
            blob = storage.GCS_BUCKET.blob(updated_profile_db.profile_picture_url)
            signed_url = blob.generate_signed_url(
                version="v4",
                expiration=datetime.timedelta(hours=1),
                method="GET",
            )
        except Exception as e:
            print(f"Error generating signed URL after upload for {updated_profile_db.profile_picture_url}: {e}") # Replace with logger

    profile_data.profile_picture_signed_url = signed_url

    return profile_data

# --- Endpoint to view OTHER users' profiles --- 
@router.get("/{user_id}/profile", response_model=UserProfileSchema)
async def read_user_profile(
    user_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(security.get_current_user), # Get current user to check relationship
):
    """Fetch the profile of a specific user by their ID.
    
    TODO: Implement privacy controls based on connection status and user settings.
    For now, returns most profile data but excludes sensitive details if not connected.
    """
    if user_id == current_user.id:
        # Redirect or call the "/me/profile" logic? For simplicity, let's call it.
        return await read_my_profile(db=db, current_user=current_user)

    # Fetch the target user's profile
    profile_db = await crud_user_profile.get_profile_by_user_id(db, user_id=user_id)
    if not profile_db:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User profile not found.")

    # Fetch the target user model as well (needed for relationship check, etc.)
    # target_user = await crud_user.get_user_by_id(db, user_id=user_id) # Assuming this exists
    # if not target_user:
    #     raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found.")

    # --- Privacy Check Logic (Basic MVP Implementation) --- 
    # Check connection status between current_user and target_user (user_id)
    # connection = await crud_connection.get_connection_between_users(db, user1_id=current_user.id, user2_id=user_id) # Assuming this exists
    # is_connected = connection and connection.status == 'accepted'
    
    # For now, let's assume we return the same profile data regardless of connection
    # We can add filtering later based on `is_connected` or `profile_db.contact_info_visibility`
    profile_data = UserProfileSchema.from_orm(profile_db)

    # --- Generate Signed URL --- 
    signed_url = None
    if profile_db.profile_picture_url and storage.GCS_BUCKET:
        try:
            blob = storage.GCS_BUCKET.blob(profile_db.profile_picture_url)
            signed_url = blob.generate_signed_url(
                version="v4",
                expiration=datetime.timedelta(hours=1),
                method="GET",
            )
        except Exception as e:
            logger.error(f"Error generating signed URL for user {user_id} profile pic {profile_db.profile_picture_url}: {e}", exc_info=True)

    profile_data.profile_picture_signed_url = signed_url

    return profile_data

@router.get(
    "/{user_id}/detailed-profile", 
    response_model=UserDetailSchema,
    dependencies=[Depends(security.get_current_active_user)] # Or specific role if needed
)
async def read_user_detailed_profile(
    user_id: int,
    db: AsyncSession = Depends(get_db),
    # current_user: models.User = Depends(security.get_current_active_user) # Can be used for permission checks
):
    """
    Fetch a comprehensive, detailed profile of a specific user by their ID.
    Includes profile, company, startup, space, managed space, and current workstation.
    """
    user_db = await crud_user.get_user_details_for_profile(db, user_id=user_id)
    if not user_db:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User not found")

    current_workstation_info_dict = None
    if user_db.assignments:
        active_assignment = next(
            (a for a in user_db.assignments if a.end_date is None and a.workstation), 
            None
        )
        if active_assignment and active_assignment.workstation:
            # Ensure start_date exists on WorkstationAssignment model, default if not for safety.
            start_date = getattr(active_assignment, 'start_date', datetime.datetime.utcnow()) 
            current_workstation_info_dict = {
                "workstation_id": active_assignment.workstation.id,
                "workstation_name": active_assignment.workstation.name,
                "assignment_start_date": start_date 
            }

    # Create the UserDetail object from the ORM model
    # The `current_workstation` field will be populated from current_workstation_info_dict if provided
    user_detail_data = UserDetailSchema.model_validate(
        user_db, 
        update={"current_workstation": current_workstation_info_dict} if current_workstation_info_dict else {}
    )
    
    # If UserProfileSchema within UserDetailSchema needs to generate signed URLs,
    # it should handle that upon its own instantiation from user_db.profile.
    # Or, we can manually trigger it here if necessary.
    if user_detail_data.profile and user_db.profile and user_db.profile.profile_picture_url and storage.GCS_BUCKET:
        try:
            blob = storage.GCS_BUCKET.blob(user_db.profile.profile_picture_url)
            signed_url = blob.generate_signed_url(
                version="v4",
                expiration=datetime.timedelta(hours=1),
                method="GET",
            )
            user_detail_data.profile.profile_picture_signed_url = signed_url
        except Exception as e:
            logger.error(f"Error generating signed URL for profile picture in detailed view for user {user_id}: {e}")
            # Do not fail the request, profile_picture_signed_url will remain None or its default

    return user_detail_data

# Add other user-related endpoints here later (e.g., update profile) 

--- END OF FILE: app/routers/users.py ---

================================================================================

--- START OF FILE: app/routers/organizations.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from typing import List

from app.db.session import get_db
from app import crud, schemas, models
from app.security import get_current_active_user, get_current_user_with_roles
from app.schemas.user import User as UserSchema

router = APIRouter()

@router.get(
    "/companies/{company_id}",
    response_model=schemas.organization.Company,
    dependencies=[Depends(get_current_active_user)] # Ensure user is authenticated
)
async def read_company(
    company_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Retrieve company details by ID."""
    db_company = await crud.crud_organization.get_company(db, company_id=company_id)
    if db_company is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Company not found")
    return db_company

@router.get(
    "/startups/{startup_id}",
    response_model=schemas.organization.Startup,
    dependencies=[Depends(get_current_active_user)] # Ensure user is authenticated
)
async def read_startup(
    startup_id: int,
    db: AsyncSession = Depends(get_db)
):
    """Retrieve startup details by ID."""
    db_startup = await crud.crud_organization.get_startup(db, startup_id=startup_id)
    if db_startup is None:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Startup not found")
    return db_startup

@router.get(
    "/startups/me/members",
    response_model=List[UserSchema],
    dependencies=[Depends(get_current_user_with_roles(required_roles=["STARTUP_ADMIN"]))],
)
async def read_my_startup_members(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """
    Retrieve members of the current Startup Admin's team.
    Requires the user to be a STARTUP_ADMIN.
    Members are users with the same startup_id and space_id.
    """
    if not current_user.startup_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Current user is not associated with a startup.",
        )
    if not current_user.space_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Current user is not associated with a space. Startup members must be in the same space.",
        )

    stmt = (
        select(models.User)
        .where(
            models.User.startup_id == current_user.startup_id,
            models.User.space_id == current_user.space_id,
            models.User.id != current_user.id
        )
    )
    result = await db.execute(stmt)
    team_members = result.scalars().all()

    return team_members

@router.post(
    "/startups/me/request-member",
    response_model=schemas.organization.MemberRequestResponse, # Use the new response schema
    dependencies=[Depends(get_current_user_with_roles(required_roles=["STARTUP_ADMIN"]))],
    status_code=status.HTTP_201_CREATED,
)
async def request_add_startup_member(
    request_data: schemas.organization.MemberRequestCreate, # Use the new request schema
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """
    Allows a Startup Admin to request adding a new member to their startup.
    This will send a notification to the Corporate Admin of the startup's space.
    """
    if not current_user.startup_id or not current_user.startup:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Current user is not associated with a startup.",
        )
    if not current_user.space_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Current user is not associated with a space.",
        )

    # Get the SpaceNode to find the Corporate Admin
    space_node = await db.get(models.SpaceNode, current_user.space_id)
    if not space_node or not space_node.corporate_admin_id:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT, # Or 500 if this state is unexpected
            detail="Cannot process request: Space admin not found for your startup's space.",
        )

    corporate_admin_id = space_node.corporate_admin_id

    # Create notification for the Corporate Admin
    try:
        startup_name = current_user.startup.name if current_user.startup else f"Startup ID {current_user.startup_id}"
        await crud.crud_notification.create_notification(
            db=db,
            user_id=corporate_admin_id,
            type="member_request",
            message=f"Startup '{startup_name}' (ID: {current_user.startup_id}) requests to add a new member: {request_data.email}.",
            reference=f"startup_id:{current_user.startup_id};requested_email:{request_data.email}",
            # link=f"/admin/member-requests?startup_id={current_user.startup_id}" # Optional: Link to a future admin UI
        )
    except Exception as e:
        # Log the error, but maybe don't fail the whole request if notification is secondary
        # For now, let's make it critical
        # logger.error(f"Failed to create notification for member request: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to create notification for corporate admin: {str(e)}",
        )

    return schemas.organization.MemberRequestResponse(
        message="Member addition request sent to Corporate Admin for approval.",
        notification_sent_to_admin_id=corporate_admin_id,
        requested_email=request_data.email,
    )

# Add more endpoints later for listing, creating, updating if needed.
# Consider adding more granular authorization based on user roles/relationships. 

--- END OF FILE: app/routers/organizations.py ---

================================================================================

--- START OF FILE: app/routers/member_requests.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
import logging
import re # For parsing
# from datetime import datetime # Not currently used directly

# Corrected import for the database session
from app.db.session import get_db

# Schemas used in this router
from app.schemas.member_request import MemberRequestActionResponse
# Note: List[schemas.notification.Notification] is used directly in an endpoint,
# so schemas.notification must be accessible.

# Main app components
from app import crud, schemas, models
from app.security import get_current_user_with_roles
from app.utils.email import send_startup_invitation_email # Added import

router = APIRouter()
logger = logging.getLogger(__name__) # Add logger instance

# Valid notification types for member requests that Corp Admins can action
VALID_MEMBER_REQUEST_NOTIFICATION_TYPES = ["member_request", "member_request_pending_approval"]

def parse_reference_string(reference: str) -> dict:
    """Parses a reference string, attempting comma-separated key=value first, then semicolon-separated key:value."""
    data = {}
    if not reference: 
        return data

    # Try parsing comma-separated key=value (new format)
    # Example: startup_id=3,email=user@example.com,full_name=Test User
    try:
        pairs_eq_comma = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*)=([^,]+)', reference)
        if pairs_eq_comma:
            for key, value in pairs_eq_comma:
                data[key.strip()] = value.strip()
            # If we found data with this primary method, check if essential keys are present
            if data.get("startup_id") and (data.get("email") or data.get("requested_email")):
                logger.debug(f"Parsed reference (comma-separated) '{reference}' into: {data}")
                return data
            else: # Potentially parsed something, but not the essential parts, try next method
                data = {} # Reset data if primary method didn't yield essential keys
    except Exception as e:
        logger.warning(f"Regex error parsing (comma-separated) '{reference}': {e}. Trying alternative.")
        data = {} # Reset data on error

    # Try parsing semicolon-separated key:value (potential old format)
    # Example: startup_id:3;requested_email:user@example.com
    try:
        pairs_colon_semicolon = re.findall(r'([a-zA-Z_][a-zA-Z0-9_]*):([^;]+)', reference)
        if pairs_colon_semicolon:
            for key, value in pairs_colon_semicolon:
                data[key.strip()] = value.strip()
            logger.debug(f"Parsed reference (semicolon-separated) '{reference}' into: {data}")
            return data # Return whatever was parsed by this method
    except Exception as e:
        logger.warning(f"Regex error parsing (semicolon-separated) '{reference}': {e}")
        data = {} # Reset data on error
    
    if not data:
        logger.warning(f"Could not parse reference string using known formats: {reference}")
    return data

@router.get(
    "/",
    response_model=List[schemas.notification.Notification],
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def list_pending_member_requests_for_admin(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"])),
):
    """
    Retrieve all pending member join requests (of valid types) for the authenticated Corporate Admin.
    """
    all_pending_requests: List[models.Notification] = [] # Explicitly type hint
    for notif_type in VALID_MEMBER_REQUEST_NOTIFICATION_TYPES:
        requests = await crud.crud_notification.get_notifications_by_type_for_user(
            db=db, user_id=current_user.id, notification_type=notif_type, is_read=False
        )
        if requests:
            all_pending_requests.extend(requests)
    
    # Sort by creation date, newest first
    all_pending_requests.sort(key=lambda x: x.created_at, reverse=True)
    return all_pending_requests

@router.put(
    "/{request_id}/approve",
    response_model=schemas.member_request.MemberRequestActionResponse,
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def approve_member_request_by_admin(
    request_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"])),
):
    notification = await crud.crud_notification.get_notification_by_id(db, notification_id=request_id)
    if not notification or notification.user_id != current_user.id or notification.type not in VALID_MEMBER_REQUEST_NOTIFICATION_TYPES:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Member request not found or not accessible.")

    if not notification.reference:
        logger.error(f"Notification {notification.id} is missing reference string.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Notification data incomplete.")

    ref_data = parse_reference_string(notification.reference)
    
    # Use "email" as the key from the new reference format
    # Fallback to "requested_email" for backward compatibility with old format if any.
    requested_email = ref_data.get("email") or ref_data.get("requested_email")
    startup_id_str = ref_data.get("startup_id")

    if not requested_email or not startup_id_str:
        logger.error(f"Failed to parse email or startup_id from reference: {notification.reference}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Invalid notification reference format.")
    
    try:
        target_startup_id = int(startup_id_str)
    except ValueError:
        logger.error(f"Invalid startup_id format in reference: {startup_id_str}")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Invalid startup ID in notification reference.")

    response_message = ""
    action_status = "pending_action"

    existing_user_in_target_startup = await crud.crud_user.get_user_by_email_and_startup(db, email=requested_email, startup_id=target_startup_id)
    if existing_user_in_target_startup:
        response_message = f"User {requested_email} is already a member of startup {target_startup_id}. No further action taken."
        action_status = "no_action_needed"
    else:
        invitation_create = schemas.invitation.InvitationCreate(
            email=requested_email,
            startup_id=target_startup_id,
            approved_by_admin_id=current_user.id
        )
        try:
            invitation = await crud.invitation.create_with_startup(db, obj_in=invitation_create)
            logger.info(f"Invitation created for {requested_email} to join startup {target_startup_id}. Token: {invitation.invitation_token}")
            
            target_startup = await crud.crud_organization.get_startup(db, startup_id=target_startup_id)
            if not target_startup:
                logger.error(f"Target startup {target_startup_id} not found when sending invitation for {requested_email}.")
                action_status = "invitation_created_email_failed"
                response_message = f"Invitation created for {requested_email}, but failed to retrieve startup details for email."
            else:
                try:
                    send_startup_invitation_email(
                        to_email=requested_email,
                        token=invitation.invitation_token,
                        startup_name=target_startup.name,
                        invited_by_name=current_user.full_name or current_user.email
                    )
                    response_message = f"Invitation sent to {requested_email} to join startup {target_startup.name}."
                    action_status = "invitation_sent"
                except Exception as email_exc:
                    logger.error(f"Created invitation for {requested_email} but failed to send email: {email_exc}")
                    response_message = f"Invitation created for {requested_email}, but email sending failed. Check logs."
                    action_status = "invitation_created_email_failed"

        except Exception as e:
            logger.error(f"Failed to create invitation for {requested_email} (startup {target_startup_id}): {e}")
            response_message = f"Failed to create invitation for {requested_email}. Please try again."
            action_status = "invitation_failed"

    await crud.crud_notification.mark_notification_as_read(db, notification=notification)
    
    return schemas.member_request.MemberRequestActionResponse(
        message=response_message, 
        request_id=request_id, 
        status=action_status
    )

@router.put(
    "/{request_id}/reject",
    response_model=schemas.member_request.MemberRequestActionResponse,
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def reject_member_request_by_admin(
    request_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"])),
):
    notification = await crud.crud_notification.get_notification_by_id(db, notification_id=request_id)
    if not notification or notification.user_id != current_user.id or notification.type not in VALID_MEMBER_REQUEST_NOTIFICATION_TYPES:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Member request not found or not accessible.")

    target_startup_id_for_notification = None
    if notification.reference:
        ref_data = parse_reference_string(notification.reference)
        requested_email = ref_data.get("email") or ref_data.get("requested_email", "[unknown email]")
        startup_id_str = ref_data.get("startup_id")
        startup_name = "[unknown startup]"
        if startup_id_str and startup_id_str.isdigit():
            target_startup_id_for_notification = int(startup_id_str)
            target_startup = await crud.crud_organization.get_startup(db, startup_id=target_startup_id_for_notification)
            if target_startup: 
                startup_name = target_startup.name
    else:
        requested_email = "[unknown email due to missing reference]"
        startup_name = "[unknown startup due to missing reference]"

    await crud.crud_notification.mark_notification_as_read(db, notification=notification)
    
    # Notify the Startup Admin(s) who originally requested (if applicable)
    if notification.type == "member_request_pending_approval" and target_startup_id_for_notification:
        startup_admins_to_notify = await crud.crud_user.get_users_by_role_and_startup(
            db, role="STARTUP_ADMIN", startup_id=target_startup_id_for_notification
        )
        for admin_to_notify in startup_admins_to_notify:
            await crud.crud_notification.create_notification_for_user(
                db,
                user_id=admin_to_notify.id,
                title=f"Member Request Rejected: {requested_email}",
                message=f"Your request to add member {requested_email} to startup '{startup_name}' was rejected by Corporate Admin {current_user.full_name or current_user.email}.",
                notification_type="startup_member_request_rejected",
                reference=f"rejected_email={requested_email},startup_id={target_startup_id_for_notification}" # Reference for the new notification
            )
            logger.info(f"Sent rejection notification to Startup Admin {admin_to_notify.id} for email {requested_email}, startup {startup_name}")

    logger.info(f"Corp Admin {current_user.id} (Notification ID: {request_id}) rejected request for {requested_email} to join {startup_name}.")

    return schemas.member_request.MemberRequestActionResponse(
        message=f"Request to add {requested_email} to startup {startup_name} has been rejected.", 
        request_id=request_id, 
        status="rejected"
    )


--- END OF FILE: app/routers/member_requests.py ---

================================================================================

--- START OF FILE: app/routers/matching.py ---

from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List, Optional, Tuple
import logging

from app import models, schemas, crud
from app.crud import crud_user_profile
from app.schemas.matching import MatchResult
from app.db.session import get_db
from app.security import get_current_active_user

logger = logging.getLogger(__name__)

router = APIRouter()

# --- Scoring Constants (Keep simple for MVP) ---
VECTOR_WEIGHT = 0.7
STRUCTURED_WEIGHT = 0.3
SHARED_SKILL_SCORE = 5
SHARED_INDUSTRY_SCORE = 3


def calculate_structured_score(
    requesting_profile: models.UserProfile,
    candidate_profile: models.UserProfile
) -> Tuple[int, List[str]]:
    """Calculates score based on structured data overlaps and returns reasons."""
    score = 0
    reasons = []
    
    req_skills = set(requesting_profile.skills_expertise or [])
    cand_skills = set(candidate_profile.skills_expertise or [])
    shared_skills = req_skills.intersection(cand_skills)
    if shared_skills:
        score += len(shared_skills) * SHARED_SKILL_SCORE
        reasons.extend([f"Shared Skill: {s}" for s in shared_skills])
        
    req_industries = set(requesting_profile.industry_focus or [])
    cand_industries = set(candidate_profile.industry_focus or [])
    shared_industries = req_industries.intersection(cand_industries)
    if shared_industries:
        score += len(shared_industries) * SHARED_INDUSTRY_SCORE
        reasons.extend([f"Shared Industry: {i}" for i in shared_industries])
        
    # Add more scoring logic here if needed (e.g., collaboration preferences)
    
    return score, reasons


@router.get("/discover", response_model=List[MatchResult])
async def discover_similar_users(
    *,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user)
) -> List[MatchResult]:
    """
    Discover users with similar profiles within the same space.
    Calculates a combined score based on vector similarity and structured data.
    Returns a ranked list with match reasons.
    """
    logger.info(f"Discover endpoint called by user_id={current_user.id}")

    if not current_user.profile:
        profile = await crud_user_profile.get_profile_by_user_id(db, user_id=current_user.id)
        if not profile:
             logger.error(f"User {current_user.id} has no profile object. Cannot perform discovery.")
             raise HTTPException(status_code=404, detail="User profile not found. Please complete your profile.")
        current_user.profile = profile
        
    if current_user.profile.profile_vector is None:
        logger.warning(f"User {current_user.id} profile has no embedding vector.")
        raise HTTPException(status_code=400, detail="Profile embedding not generated yet. Try updating your profile.")
        
    if current_user.space_id is None:
        logger.warning(f"User {current_user.id} is not assigned to a space.")
        raise HTTPException(status_code=400, detail="User not assigned to a space. Cannot discover connections.")

    logger.info(f"ROUTER_MATCHING: Calling find_similar_users for user {current_user.id} in space {current_user.space_id}")
    similar_users_with_distance = await crud_user_profile.find_similar_users(
        db=db, requesting_user=current_user, limit=20
    )
    logger.info(f"ROUTER_MATCHING: find_similar_users returned for user {current_user.id}. Count: {len(similar_users_with_distance)}")
    if similar_users_with_distance:
        # Log details of what was returned, e.g., user IDs and distances
        returned_data_log = [(p.user_id, d) for p, d in similar_users_with_distance]
        logger.info(f"ROUTER_MATCHING: Data from find_similar_users: {returned_data_log}")
    else:
        logger.info(f"ROUTER_MATCHING: find_similar_users returned an empty list.")
    
    if not similar_users_with_distance:
        logger.info(f"No initial similar users found for user_id={current_user.id}")
        return []

    results = []
    requesting_profile = current_user.profile

    for candidate_profile, distance in similar_users_with_distance:
        vector_similarity_score = max(0.0, 1.0 - float(distance)) 
        match_reasons = ["Similar Profile Vector"]
        
        structured_score_raw, structured_reasons = calculate_structured_score(
            requesting_profile, candidate_profile
        )
        match_reasons.extend(structured_reasons)
        
        final_score = (VECTOR_WEIGHT * vector_similarity_score * 10) + (STRUCTURED_WEIGHT * structured_score_raw)
        
        profile_schema = schemas.UserProfile.model_validate(candidate_profile)

        results.append(MatchResult(
            profile=profile_schema,
            score=final_score,
            reasons=match_reasons
        ))
        logger.debug(f"User {candidate_profile.user_id}: Dist={distance:.4f}, VecScore={vector_similarity_score:.4f}, StructScore={structured_score_raw}, Final={final_score:.4f}, Reasons={match_reasons}")

    results.sort(key=lambda x: x.score, reverse=True)
    
    final_results = results[:10]
    
    logger.info(f"Returning {len(final_results)} refined matches for user_id={current_user.id}")
    return final_results


--- END OF FILE: app/routers/matching.py ---

================================================================================

--- START OF FILE: app/routers/notifications.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List
import logging

from app import models, crud
from app.schemas.notification import Notification # Assuming schema exists
from app.db.session import get_db
from app.security import get_current_active_user

logger = logging.getLogger(__name__)

router = APIRouter()

@router.get("/", response_model=List[Notification])
async def get_user_notifications(
    skip: int = 0,
    limit: int = 20, # Default to fewer items for API response
    include_read: bool = False, 
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Retrieve notifications for the current user."""
    notifications = await crud.crud_notification.get_notifications_for_user(
        db=db, user_id=current_user.id, skip=skip, limit=limit, include_read=include_read
    )
    return notifications

@router.post("/{notification_id}/read", response_model=Notification)
async def mark_notification_read(
    notification_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Mark a specific notification as read."""
    notification = await crud.crud_notification.get_notification_by_id(db=db, notification_id=notification_id)

    if not notification:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Notification not found.")

    # Ensure the notification belongs to the current user
    if notification.user_id != current_user.id:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to mark this notification as read.")

    updated_notification = await crud.crud_notification.mark_notification_as_read(db=db, notification=notification)
    return updated_notification

@router.post("/read-all", status_code=status.HTTP_200_OK)
async def mark_all_notifications_read(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Mark all unread notifications for the current user as read."""
    count = await crud.crud_notification.mark_all_notifications_as_read(db=db, user_id=current_user.id)
    return {"message": f"Marked {count} notifications as read."} 

--- END OF FILE: app/routers/notifications.py ---

================================================================================

--- START OF FILE: app/routers/__init__.py ---

from . import auth
from . import users
from . import organizations
from . import admin
from . import matching
from . import connections
from . import notifications
from . import chat
from . import agent
from . import uploads
from . import spaces
# from . import profiles # Temporarily removed
from . import member_requests
from . import invitations # Ensure invitations is imported
from . import startup_actions # Add the new router
# If you have other router files like invites.py, add them here as well:
# from . import invites

# You can optionally define __all__ if you want to control `from app.routers import *` behavior
# __all__ = [
# "auth", "users", "organizations", "admin", "matching", 
# "connections", "notifications", "chat", "agent", "uploads", 
# "spaces", "member_requests" # Temporarily removed profiles
# ]

# Leave this file empty 

--- END OF FILE: app/routers/__init__.py ---

================================================================================

--- START OF FILE: app/routers/uploads.py ---

from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from fastapi.concurrency import run_in_threadpool # <-- ADDED IMPORT
from pydantic import BaseModel
import shutil # For saving file temporarily if needed, or getting filename/mimetype
import uuid # For generating unique filenames

from app.utils.storage import upload_file # Assuming this function exists and works
from app.schemas.user import User # To get current user for path generation
from app.dependencies import get_current_active_user # Assuming this dependency for auth

router = APIRouter()

class ChatAttachmentResponse(BaseModel):
    attachment_url: str
    original_filename: str
    content_type: str
    new_filename: str # The unique filename used for storage

@router.post("/chat-attachment", response_model=ChatAttachmentResponse)
async def upload_chat_attachment(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_active_user)
):
    if not file.filename:
        raise HTTPException(status_code=400, detail="No filename provided.")

    # Generate a unique filename to prevent overwrites and ensure privacy
    file_extension = file.filename.split('.')[-1] if '.' in file.filename else ''
    unique_filename = f"{uuid.uuid4()}.{file_extension}"
    
    # Define a destination path within GCS, e.g., chat_attachments/user_id/unique_filename
    # The upload_file utility should handle the bucket name itself.
    destination_blob_name = f"chat_attachments/{current_user.id}/{unique_filename}"

    try:
        # The upload_file function is synchronous, call it in a thread pool
        attachment_url = await run_in_threadpool(
            upload_file, # The synchronous function to call
            file=file,  # Arguments for upload_file
            destination_blob_name=destination_blob_name
        )
        
        if not attachment_url:
            raise HTTPException(status_code=500, detail="File upload failed, URL not returned.")

        return ChatAttachmentResponse(
            attachment_url=attachment_url,
            original_filename=file.filename,
            content_type=file.content_type or "application/octet-stream",
            new_filename=unique_filename # Useful if client wants to store this too
        )
    except Exception as e:
        # Log the exception e
        print(f"Error during chat attachment upload: {e}") # Basic logging
        raise HTTPException(status_code=500, detail=f"Could not upload file: {e}") 

--- END OF FILE: app/routers/uploads.py ---

================================================================================

--- START OF FILE: app/routers/connections.py ---

from fastapi import APIRouter, Depends, HTTPException, status, Query
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List, Dict
import logging

from app import models, crud # Removed schemas from here
from app.schemas import connection as connection_schemas # Import connection schemas specifically
from app.crud import crud_connection, crud_user, crud_notification # Import specific crud modules and notification
# Also import user schema if needed for validation or response
from app.schemas.user import User as UserSchema
from app.db.session import get_db
from app.security import get_current_active_user
# Import email utility
from app.utils.email import send_email
from app.schemas.connection import Connection, ConnectionCreate, ConnectionStatusCheck # Import new schema

logger = logging.getLogger(__name__)

router = APIRouter()

@router.post("/", response_model=connection_schemas.Connection, status_code=status.HTTP_201_CREATED)
async def create_connection_request(
    connection_in: connection_schemas.ConnectionCreate,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Send a connection request to another user."""
    if current_user.id == connection_in.recipient_id:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Cannot connect with yourself.")

    # Ensure recipient exists (optional, but good practice)
    recipient = await crud_user.get_user_by_id(db=db, user_id=connection_in.recipient_id)
    if not recipient:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Recipient user not found.")

    # TODO: Check if users are in the same space? Or allow cross-space requests?
    # if current_user.space_id != recipient.space_id:
    #     raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Users must be in the same space to connect.")

    # Call the CRUD function which handles new requests AND re-sending declined ones
    # It returns the connection object (new or updated)
    connection_obj = await crud_connection.create_connection(
        db=db, requester_id=current_user.id, obj_in=connection_in
    )

    # --- Notification Logic (Only if a NEW pending request was actually created/updated) --- 
    # Check the status returned by the CRUD function
    if connection_obj.status == 'pending' and connection_obj.requester_id == current_user.id:
        # Check if notification ALREADY exists for this (e.g., if we just re-activated a declined request)
        existing_notification = await crud_notification.get_notification_by_related_entity(
            db, 
            user_id=recipient.id, 
            type='connection_request', 
            related_entity_id=connection_obj.id
        )
        if not existing_notification:
            # Create in-app notification for recipient
            notification_message = f"{current_user.full_name or current_user.email} wants to connect with you."
            await crud_notification.create_notification(
                db, 
                user_id=recipient.id, 
                type='connection_request', 
                related_entity_id=connection_obj.id, 
                message=notification_message
            )
            # Send email notification via Resend
            email_subject = "New Connection Request on ShareYourSpace"
            email_html_content = f"<p>Hi {recipient.full_name or recipient.email},</p>" \
                               f"<p>{current_user.full_name or current_user.email} wants to connect with you on ShareYourSpace.</p>" \
                               f"<p>Please log in to your account to accept or decline the request.</p>" \
                               f"<p>Thanks,<br>The ShareYourSpace Team</p>"
            send_email(to=recipient.email, subject=email_subject, html_content=email_html_content)
        else:
            logger.info(f"Skipping notification creation for connection {connection_obj.id}; existing notification found.")
    # --- End Notification Logic --- 

    # Re-fetch the connection cleanly before returning to avoid serialization issues
    final_connection = await crud_connection.get_connection_by_id(db=db, connection_id=connection_obj.id)
    if not final_connection:
         # Should not happen, but handle defensively
         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Connection not found after creation/update.")

    return final_connection

@router.put("/{connection_id}/accept", response_model=connection_schemas.Connection)
async def accept_connection_request(
    connection_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Accept a pending connection request."""
    # Use the existing get_connection_by_id which already eager loads users
    connection = await crud_connection.get_connection_by_id(db=db, connection_id=connection_id)

    if not connection:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Connection request not found.")

    if connection.recipient_id != current_user.id:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to accept this request.")

    if connection.status != 'pending':
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Connection request status is '{connection.status}', not 'pending'.")

    # Update the status - the CRUD function should commit
    # We pass the existing connection object which already has users loaded
    await crud_connection.update_connection_status(
        db=db, connection=connection, status='accepted'
    )

    # --- Notification Logic --- 
    # We already have the requester from the initial fetch
    requester = connection.requester 
    if requester:
        # Create notification for the requester
        notification_message = f"{current_user.full_name or current_user.email} accepted your connection request."
        await crud_notification.create_notification(
            db, 
            user_id=connection.requester_id, 
            type='connection_accepted', 
            related_entity_id=connection.id, 
            message=notification_message
        )
        # Send email notification
        email_subject = "Connection Request Accepted"
        email_html_content = f"<p>Hi {requester.full_name or requester.email},</p>" \
                           f"<p>{current_user.full_name or current_user.email} has accepted your connection request on ShareYourSpace.</p>" \
                           f"<p>You are now connected!</p>" \
                           f"<p>Thanks,<br>The ShareYourSpace Team</p>"
        send_email(to=requester.email, subject=email_subject, html_content=email_html_content)
        
    # Mark the original connection_request notification for the current user (recipient) as read
    original_notification = await crud_notification.get_notification_by_related_entity(
        db, 
        user_id=current_user.id, 
        type='connection_request', 
        related_entity_id=connection_id
    )
    if original_notification:
        await crud_notification.mark_notification_as_read(db=db, notification=original_notification)
    # --- End Notification Logic --- 

    # No need to refresh here, as we re-fetch below
    # await db.refresh(connection)

    # Re-fetch the connection with users eagerly loaded AFTER the update to ensure latest data
    # Use the existing get_connection_by_id function
    final_connection = await crud_connection.get_connection_by_id(db=db, connection_id=connection_id)
    if not final_connection:
         # Should not happen if update succeeded, but handle defensively
         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Connection not found after update.")

    # Return the Pydantic schema object, not the raw ORM object
    # Pydantic will handle serialization based on the response_model
    return final_connection

@router.put("/{connection_id}/decline", response_model=connection_schemas.Connection)
async def decline_connection_request(
    connection_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Decline a pending connection request."""
    connection = await crud_connection.get_connection_by_id(db=db, connection_id=connection_id)

    if not connection:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Connection request not found.")

    if connection.recipient_id != current_user.id:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to decline this request.")

    if connection.status != 'pending':
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Connection request status is '{connection.status}', not 'pending'.")

    # We update status, but maybe delete declined requests later?
    await crud_connection.update_connection_status(
        db=db, connection=connection, status='declined'
    )
    
    # --- Mark original notification as read --- 
    original_notification = await crud_notification.get_notification_by_related_entity(
        db, 
        user_id=current_user.id, 
        type='connection_request', 
        related_entity_id=connection_id
    )
    if original_notification:
        await crud_notification.mark_notification_as_read(db=db, notification=original_notification)
    # --- End Notification Logic --- 

    # Explicitly re-fetch the connection AFTER the update to ensure clean state for serialization
    # This avoids potential issues with the ORM object state during response model validation
    final_connection = await crud_connection.get_connection_by_id(db=db, connection_id=connection_id)
    if not final_connection:
         # Should not happen if update succeeded, but handle defensively
         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Connection not found after update.")

    return final_connection

@router.get("/pending", response_model=List[connection_schemas.Connection])
async def get_pending_requests(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Get pending incoming connection requests for the current user."""
    pending_connections = await crud_connection.get_pending_connections_for_user(db=db, user_id=current_user.id)
    return pending_connections

@router.get("/accepted", response_model=List[connection_schemas.Connection])
async def get_accepted_connections(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Get accepted connections for the current user."""
    accepted_connections = await crud_connection.get_accepted_connections_for_user(db=db, user_id=current_user.id)
    return accepted_connections

@router.get("/pending/outgoing", response_model=List[connection_schemas.Connection])
async def get_pending_outgoing_requests(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Get pending outgoing connection requests made by the current user."""
    pending_outgoing = await crud_connection.get_pending_outgoing_connections_for_user(db=db, user_id=current_user.id)
    return pending_outgoing

@router.get("/declined", response_model=List[connection_schemas.Connection])
async def get_declined_connections(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Get connections involving the current user that were declined."""
    declined_connections = await crud_connection.get_declined_connections_for_user(db=db, user_id=current_user.id)
    return declined_connections

@router.get("/status/{other_user_id}", response_model=ConnectionStatusCheck)
async def get_connection_status_with_user(
    other_user_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Check the connection status between the current user and another user."""
    if other_user_id == current_user.id:
        # Or maybe return a specific status?
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Cannot check connection status with yourself.")

    connection = await crud_connection.get_connection_between_users(
        db=db, user1_id=current_user.id, user2_id=other_user_id
    )

    if not connection:
        return ConnectionStatusCheck(status='not_connected')

    status_detail = "unknown"
    if connection.status == 'accepted':
        status_detail = 'connected'
    elif connection.status == 'pending':
        if connection.requester_id == current_user.id:
            status_detail = 'pending_from_me'
        else:
            status_detail = 'pending_from_them'
    elif connection.status == 'declined':
        status_detail = 'declined' # Or maybe treat declined as not_connected?
    elif connection.status == 'blocked':
        status_detail = 'blocked' # Handle if blocking is implemented

    return ConnectionStatusCheck(status=status_detail, connection_id=connection.id)

# --- NEW BATCH ENDPOINT --- 
@router.get("/status-batch", response_model=Dict[int, ConnectionStatusCheck])
async def get_connection_status_batch(
    # Use Query for list parameters
    user_ids: List[int] = Query(..., alias="user_id"), # Read multiple user_id query params
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """Check the connection status between the current user and multiple other users."""
    if not user_ids:
        return {}
    
    # Prevent checking status with self if included in the list
    user_ids_to_check = [uid for uid in user_ids if uid != current_user.id]
    if not user_ids_to_check:
        return {}

    status_map = await crud_connection.get_connections_status_for_users(
        db=db, current_user_id=current_user.id, other_user_ids=user_ids_to_check
    )
    return status_map 

--- END OF FILE: app/routers/connections.py ---

================================================================================

--- START OF FILE: app/routers/invitations.py ---

from fastapi import APIRouter, Depends, HTTPException, status, Body
from sqlalchemy.ext.asyncio import AsyncSession
from datetime import datetime
import logging
from typing import Optional

from app import crud, models, schemas, security # Ensure security is imported
from app.db.session import get_db
from app.core.config import settings
from app.utils.email import send_email, send_startup_invitation_email # For potential notifications
from app.security import get_current_user_with_roles # For role checks and getting user details

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/accept/{invitation_token}", response_model=schemas.auth.TokenWithUser)
async def accept_startup_invitation(
    invitation_token: str,
    user_create_data: schemas.user.UserCreateAcceptInvitation, # Frontend will send this, but we ignore if user exists for now
    db: AsyncSession = Depends(get_db),
):
    invitation = await crud.invitation.get_by_invitation_token(db, token=invitation_token)

    if not invitation:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Invitation not found.")
    
    if invitation.status != models.invitation.InvitationStatus.PENDING:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invitation is no longer valid or has already been used.")

    if invitation.expires_at < datetime.utcnow():
        # await crud.invitation.mark_as_expired(db, invitation=invitation) # TODO: Consider batch job for expired tokens
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invitation has expired.")

    target_startup = await crud.crud_organization.get_startup(db, startup_id=invitation.startup_id)
    if not target_startup:
        logger.error(f"Startup {invitation.startup_id} linked to invitation {invitation.id} not found.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Error processing invitation: Associated startup not found.")

    existing_user = await crud.crud_user.get_user_by_email(db, email=invitation.email)
    
    final_user: models.User

    if existing_user:
        logger.info(f"Existing user {existing_user.email} (ID: {existing_user.id}) attempting to accept invitation {invitation.id}.")
        # User exists, check if they can be added to the startup
        if existing_user.startup_id is not None:
            if existing_user.startup_id == target_startup.id:
                 raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="User is already a member of this startup.")
            else:
                raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="User is already a member of another startup.")
        
        if existing_user.company_id is not None:
            # This logic might need refinement based on business rules (e.g., can a company employee also join a startup?)
            raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail="User is currently associated with a company.")

        # If suitable, update existing user
        update_data = schemas.user.UserUpdateInternal(
            startup_id=target_startup.id,
            space_id=target_startup.space_id,
            role="STARTUP_MEMBER", # Or keep existing role if more permissive/general and suitable
            is_active=True, 
            status="ACTIVE"
        )
        try:
            final_user = await crud.crud_user.update_user_internal(db, db_obj=existing_user, obj_in=update_data)
            logger.info(f"Existing user {final_user.id} successfully updated and linked to startup {target_startup.id}.")
        except Exception as e:
            logger.error(f"Error updating existing user {existing_user.id} for invitation {invitation.id}: {e}")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not update existing user account.")
    
    else:
        # User does not exist - Create a new user
        user_in_create = schemas.user.UserCreate(
            email=invitation.email, 
            full_name=user_create_data.full_name,
            password=user_create_data.password, 
            role="STARTUP_MEMBER",
            startup_id=target_startup.id,
            space_id=target_startup.space_id
        )
        try:
            new_user_created = await crud.crud_user.create_user(db=db, obj_in=user_in_create)
            activated_user = await crud.crud_user.activate_user_for_startup_invitation(db=db, user_to_activate=new_user_created)
            if not activated_user:
                 logger.error(f"Failed to activate new user {new_user_created.id} after accepting invitation {invitation.id}.")
                 raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="User account created but activation failed.")
            final_user = activated_user
            logger.info(f"New user {final_user.id} created and activated for startup {target_startup.id}.")
        except Exception as e:
            logger.error(f"Error creating new user from invitation {invitation.id} for email {invitation.email}: {e}")
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Could not create user account.")

    # Mark invitation as accepted
    await crud.invitation.mark_as_accepted(db, invitation=invitation, accepted_by_user_id=final_user.id)

    # Log the user in by creating an access token
    access_token = security.create_access_token(
        data={"sub": final_user.email, "user_id": final_user.id, "role": final_user.role}
    )

    # --- Send Notifications ---
    startup_admins = await crud.crud_user.get_users_by_role_and_startup(db, role="STARTUP_ADMIN", startup_id=target_startup.id)
    if startup_admins:
        for startup_admin in startup_admins:
            notification_content_to_startup_admin = f"{final_user.full_name} ({final_user.email}) has accepted their invitation and joined your startup, {target_startup.name}."
            if invitation.approved_by_admin_id:
                corp_admin_approver = await crud.crud_user.get_user_by_id(db, user_id=invitation.approved_by_admin_id)
                if corp_admin_approver:
                    notification_content_to_startup_admin += f" This invitation was originally approved by Corp Admin {corp_admin_approver.full_name}."
            
            await crud.crud_notification.create_notification(
                db=db, 
                user_id=startup_admin.id, 
                type="member_joined_startup",
                message=notification_content_to_startup_admin, 
                reference=f"user:{final_user.id},startup:{target_startup.id}"
            )

    if invitation.approved_by_admin_id:
        corp_admin_approver = await crud.crud_user.get_user_by_id(db, user_id=invitation.approved_by_admin_id)
        if corp_admin_approver:
            notification_content_to_corp_admin = (
                f"The invitation you approved for {final_user.full_name} ({final_user.email}) "
                f"to join startup {target_startup.name} has been accepted."
            )
            await crud.crud_notification.create_notification(
                db=db, 
                user_id=corp_admin_approver.id, 
                type="invitation_accepted",
                message=notification_content_to_corp_admin, 
                reference=f"user:{final_user.id},invitation:{invitation.id}"
            )

    return schemas.auth.TokenWithUser(access_token=access_token, token_type="bearer", user=final_user)


@router.get("/startup/pending", response_model=schemas.invitation.InvitationListResponse)
async def list_pending_invitations_for_startup(
    current_user: models.User = Depends(get_current_user_with_roles(["STARTUP_ADMIN"])),
    db: AsyncSession = Depends(get_db),
):
    """
    Lists all pending and non-expired invitations for the current startup admin's startup.
    """
    if not current_user.startup_id:
        logger.warning(f"Startup Admin {current_user.id} has no startup_id associated.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="User is not associated with a startup.")

    pending_invitations = await crud.invitation.get_pending_invitations_for_startup(
        db, startup_id=current_user.startup_id
    )
    return schemas.invitation.InvitationListResponse(invitations=pending_invitations)


@router.put("/{invitation_id}/revoke", response_model=schemas.invitation.Invitation)
async def revoke_startup_invitation(
    invitation_id: int,
    current_user: models.User = Depends(get_current_user_with_roles(["STARTUP_ADMIN"])),
    db: AsyncSession = Depends(get_db),
):
    """
    Revokes a pending invitation. Only accessible by Startup Admins for their own startup's invitations.
    """
    invitation_to_revoke = await crud.invitation.get(db, id=invitation_id)

    if not invitation_to_revoke:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Invitation not found.")

    if not current_user.startup_id or invitation_to_revoke.startup_id != current_user.startup_id:
        logger.warning(
            f"Startup Admin {current_user.id} (startup_id: {current_user.startup_id}) attempted to revoke invitation {invitation_id} "
            f"belonging to another startup (startup_id: {invitation_to_revoke.startup_id})."
        )
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Not authorized to revoke this invitation.")

    if invitation_to_revoke.status != models.invitation.InvitationStatus.PENDING:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Invitation cannot be revoked as its status is {invitation_to_revoke.status}.")
    
    if invitation_to_revoke.expires_at < datetime.utcnow():
        # This check is also in get_pending_invitations_for_startup, but good to have defense in depth
        # Optionally, could auto-mark as EXPIRED here if not already.
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Cannot revoke an already expired invitation. It will be automatically filtered.")

    revoked_invitation = await crud.invitation.revoke_invitation(
        db, invitation_to_revoke=invitation_to_revoke, revoking_admin_id=current_user.id
    )
    
    # TODO: Optionally, send a notification to the invited user that the invitation was revoked (if email was collected and user was PENDING)
    # TODO: Optionally, notify the Corp Admin (if one approved it) that it was revoked by the Startup Admin

    return revoked_invitation

@router.post("/decline/{invitation_token}", response_model=schemas.invitation.Invitation)
async def decline_startup_invitation(
    invitation_token: str,
    decline_data: Optional[schemas.invitation.InvitationDecline] = Body(None), # Reason is optional
    db: AsyncSession = Depends(get_db),
):
    """
    Allows a user to decline a pending startup invitation.
    """
    invitation = await crud.invitation.get_by_invitation_token(db, token=invitation_token)

    if not invitation:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Invitation not found.")
    
    if invitation.status != models.invitation.InvitationStatus.PENDING:
        # If already actioned (accepted, revoked, declined) or expired, inform appropriately.
        # We could return the current invitation status or a specific message.
        detail_message = f"Invitation is no longer pending. Current status: {invitation.status.value}."
        if invitation.status == models.invitation.InvitationStatus.EXPIRED:
            detail_message = "Invitation has expired and cannot be declined."
        elif invitation.status == models.invitation.InvitationStatus.ACCEPTED:
            detail_message = "Invitation has already been accepted."
        elif invitation.status == models.invitation.InvitationStatus.REVOKED:
            detail_message = "Invitation has been revoked by an administrator."
        elif invitation.status == models.invitation.InvitationStatus.DECLINED:
            detail_message = "Invitation has already been declined."
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=detail_message)

    if invitation.expires_at < datetime.utcnow():
        # This check is somewhat redundant if we only allow PENDING status, as an expired token should move to EXPIRED status.
        # However, having it ensures robustness if a token somehow remains PENDING past expiry without a batch job updating it.
        # The CRUD method `mark_as_declined` also checks for PENDING, so this is belt-and-suspenders.
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invitation has expired.")

    reason = decline_data.reason if decline_data else None
    declined_invitation = await crud.invitation.mark_as_declined(db, invitation=invitation, reason=reason)

    # --- Send Notifications --- 
    # Notify Corp Admin who approved (if any) and Startup Admins
    target_startup = await crud.crud_organization.get_startup(db, startup_id=invitation.startup_id)
    if not target_startup:
        logger.error(f"Startup {invitation.startup_id} for declined invitation {invitation.id} not found. Cannot send full notifications.")
        # Invitation is declined, but notifications might be incomplete.
    else:
        # Notify Startup Admins
        startup_admins = await crud.crud_user.get_users_by_role_and_startup(db, role="STARTUP_ADMIN", startup_id=target_startup.id)
        if startup_admins:
            for startup_admin in startup_admins:
                notification_msg = f"The invitation for {invitation.email} to join your startup, {target_startup.name}, has been declined."
                if reason:
                    notification_msg += f" Reason provided: \"{reason}\""
                if invitation.approved_by_admin_id:
                    corp_admin_approver = await crud.crud_user.get_user_by_id(db, user_id=invitation.approved_by_admin_id)
                    if corp_admin_approver:
                        notification_msg += f" (Original request approved by Corp Admin {corp_admin_approver.full_name or corp_admin_approver.email})"
                
                await crud.crud_notification.create_notification(
                    db=db, 
                    user_id=startup_admin.id, 
                    type="startup_invitation_declined", 
                    message=notification_msg, 
                    reference=f"invitation:{invitation.id},email:{invitation.email}"
                )
        
        # Notify the Corp Admin who approved this (if any)
        if invitation.approved_by_admin_id:
            corp_admin_approver = await crud.crud_user.get_user_by_id(db, user_id=invitation.approved_by_admin_id)
            if corp_admin_approver:
                notification_msg_corp_admin = f"The invitation for {invitation.email} to join startup {target_startup.name} (which you approved) has been declined."
                if reason:
                    notification_msg_corp_admin += f" Reason provided: \"{reason}\""

                await crud.crud_notification.create_notification(
                    db=db, 
                    user_id=corp_admin_approver.id, 
                    type="user_declined_approved_invitation",
                    message=notification_msg_corp_admin, 
                    reference=f"invitation:{invitation.id},email:{invitation.email}"
                )

    return declined_invitation 

@router.post("/corp-admin/direct-invite", response_model=schemas.invitation.Invitation, tags=["invitations", "corp_admin"])
async def corp_admin_direct_invite_user_to_startup(
    invite_data: schemas.invitation.CorpAdminDirectInviteCreate,
    current_user: models.User = Depends(get_current_user_with_roles(["CORP_ADMIN"])),
    db: AsyncSession = Depends(get_db),
):
    """
    Allows a Corp Admin to directly invite a user to a startup within their managed space.
    """
    if not current_user.space_id:
        logger.error(f"Corp Admin {current_user.id} attempting direct invite but is not associated with a space.")
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="You are not associated with a space to manage startups.")

    target_startup = await crud.crud_organization.get_startup(db, startup_id=invite_data.startup_id)
    if not target_startup:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Startup with ID {invite_data.startup_id} not found.")

    if target_startup.space_id != current_user.space_id:
        logger.warning(
            f"Corp Admin {current_user.id} (space_id: {current_user.space_id}) attempted to invite user {invite_data.email} "
            f"to startup {target_startup.id} (space_id: {target_startup.space_id}) which is not in their managed space."
        )
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="You can only invite users to startups within your managed space.")

    existing_user_in_startup = await crud.crud_user.get_user_by_email_and_startup(db, email=invite_data.email, startup_id=target_startup.id)
    if existing_user_in_startup:
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=f"User with email {invite_data.email} is already a member of startup '{target_startup.name}'.")

    existing_invitation = await crud.invitation.get_by_email_and_startup(db, email=invite_data.email, startup_id=target_startup.id)
    if existing_invitation and existing_invitation.status == models.invitation.InvitationStatus.PENDING and existing_invitation.expires_at > datetime.utcnow():
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=f"An active invitation for {invite_data.email} to join startup '{target_startup.name}' already exists.")

    invitation_create_schema = schemas.invitation.InvitationCreate(
        email=invite_data.email,
        startup_id=target_startup.id,
        approved_by_admin_id=current_user.id # The Corp Admin is the approver
    )

    try:
        invitation = await crud.invitation.create_with_startup(db, obj_in=invitation_create_schema)
        logger.info(f"Corp Admin {current_user.id} directly created invitation for {invite_data.email} to join startup {target_startup.id}. Token: {invitation.invitation_token}")
        
        send_startup_invitation_email(
            to_email=invite_data.email,
            token=invitation.invitation_token,
            startup_name=target_startup.name,
            invited_by_name=current_user.full_name or current_user.email # Corp Admin's name
        )
        
        # Notify Startup Admins of the target startup
        startup_admins_to_notify = await crud.crud_user.get_users_by_role_and_startup(db, role="STARTUP_ADMIN", startup_id=target_startup.id)
        if startup_admins_to_notify:
            for admin_to_notify in startup_admins_to_notify:
                await crud.crud_notification.create_notification(
                    db=db,
                    user_id=admin_to_notify.id,
                    type="corp_admin_direct_invite_to_startup", 
                    message=f"Corporate Admin {current_user.full_name or current_user.email} has directly invited {invite_data.email} to join your startup, {target_startup.name}.",
                    reference=f"invitation_id={invitation.id},email={invite_data.email},invited_by_corp_admin_id={current_user.id}"
                )
                logger.info(f"Sent direct invite notification to Startup Admin {admin_to_notify.id} for email {invite_data.email}, startup {target_startup.name}")
        return invitation
    except Exception as e:
        logger.error(f"Failed to create direct invitation for {invite_data.email} to startup {target_startup.id} by Corp Admin {current_user.id}: {e}")
        # Consider more specific error handling if email sending fails vs. DB creation
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Failed to create and send invitation. Please try again.") 

--- END OF FILE: app/routers/invitations.py ---

================================================================================

--- START OF FILE: app/routers/admin.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List, Optional

# Import schemas using submodule path
from app import schemas, models 
# Import specific CRUD functions needed
from app.crud import crud_user, crud_space 
from app.db.session import get_db
from app.dependencies import require_sys_admin

router = APIRouter()


@router.get("/pending-corporates", response_model=List[schemas.admin.UserAdminView], dependencies=[Depends(require_sys_admin)])
async def list_pending_corporate_users(
    db: AsyncSession = Depends(get_db)
):
    """List users with status PENDING_ONBOARDING."""
    # Use direct import path
    users = await crud_user.get_users_by_status(db, status='PENDING_ONBOARDING')
    return users

@router.post("/spaces", response_model=schemas.admin.Space, status_code=status.HTTP_201_CREATED, dependencies=[Depends(require_sys_admin)])
async def create_new_space(
    *, # Force keyword arguments
    db: AsyncSession = Depends(get_db),
    space_in: schemas.admin.SpaceCreate
):
    """Create a new SpaceNode. Typically done when approving a corporate user."""
    # Use direct import path and correct function name
    corp_admin = await crud_user.get_user_by_id(db, user_id=space_in.corporate_admin_id)
    if not corp_admin:
        raise HTTPException(
            status_code=400,
            detail=f"Corporate admin user with ID {space_in.corporate_admin_id} not found."
        )

    # Use direct import path
    space = await crud_space.create_space(db=db, obj_in=space_in)
    return space

@router.post("/simple-spaces", response_model=schemas.admin.Space, status_code=status.HTTP_201_CREATED, dependencies=[Depends(require_sys_admin)])
async def create_simple_space(
    *, # Force keyword arguments
    db: AsyncSession = Depends(get_db),
    space_in: schemas.admin.SimpleSpaceCreate
):
    """Create a simple SpaceNode without requiring a corporate admin ID."""
    # Adapt this to call a potentially simplified CRUD function or handle optional admin ID
    try:
        # Assuming crud_space.create_space can handle missing corporate_admin_id 
        # or we create a specific simple_create_space function.
        # For now, let's construct the full object with None admin_id
        # We need to use the SpaceCreate schema from admin for the input object
        full_space_data = schemas.admin.SpaceCreate(
            name=space_in.name,
            total_workstations=space_in.total_workstations,
            corporate_admin_id=None # Set admin ID to None
        )
        space = await crud_space.create_space(db=db, obj_in=full_space_data)
        # The response should match the response_model, which is schemas.admin.Space
        return space
    except Exception as e: # Catch potential errors if crud_space expects admin_id
        # Log the error properly
        print(f"Error creating simple space: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to create simple space: Check logs for details."
        )

@router.put("/users/{user_id}/activate-corporate", response_model=schemas.admin.UserAdminView, dependencies=[Depends(require_sys_admin)])
async def activate_corporate_admin_user(
    user_id: int,
    space_id: Optional[int] = None, # Optional query param to assign space upon activation
    db: AsyncSession = Depends(get_db)
):
    """Update user status from PENDING_ONBOARDING to ACTIVE and role to CORP_ADMIN."""
    if space_id:
        # Use direct import path
        space = await crud_space.get_space(db, space_id=space_id)
        if not space:
             raise HTTPException(
                status_code=404,
                detail=f"Space with ID {space_id} not found."
            )

    # Use direct import path
    updated_user = await crud_user.activate_corporate_user(db=db, user_id=user_id, space_id=space_id)
    if not updated_user:
        raise HTTPException(
            status_code=404,
            detail=f"User with ID {user_id} not found or not in PENDING_ONBOARDING status."
        )
    return updated_user

# Optional Basic Management Endpoints
@router.get("/users", response_model=List[schemas.admin.UserAdminView], dependencies=[Depends(require_sys_admin)])
async def list_all_users(
    skip: int = 0,
    limit: int = 100,
    db: AsyncSession = Depends(get_db)
):
    """List all users (paginated)."""
    # Use direct import path
    users = await crud_user.get_users(db, skip=skip, limit=limit)
    return users

@router.get("/spaces", response_model=List[schemas.admin.Space], dependencies=[Depends(require_sys_admin)])
async def list_all_spaces(
    skip: int = 0,
    limit: int = 100,
    db: AsyncSession = Depends(get_db)
):
    """List all spaces (paginated)."""
    # Use direct import path
    spaces = await crud_space.get_spaces(db, skip=skip, limit=limit)
    return spaces

@router.put("/users/{user_id}/assign-space", response_model=schemas.admin.UserAdminView, dependencies=[Depends(require_sys_admin)])
async def assign_user_space(
    user_id: int,
    assignment: schemas.admin.UserAssignSpace,
    db: AsyncSession = Depends(get_db)
):
    """Assigns or unassigns a user to a specific space node."""
    try:
        updated_user = await crud_user.assign_user_to_space(
            db=db, user_id=user_id, space_id=assignment.space_id
        )
        if not updated_user:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"User with ID {user_id} not found."
            )
        return updated_user
    except ValueError as e:
         # Handle case where space_id is provided but doesn't exist
         raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        # Catch unexpected errors from CRUD
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred while assigning the user to the space."
        )

@router.put("/users/{user_id}/status", response_model=schemas.admin.UserAdminView, dependencies=[Depends(require_sys_admin)])
async def update_user_status(
    user_id: int,
    status_update: schemas.admin.UserStatusUpdate,
    db: AsyncSession = Depends(get_db)
):
    """Update the status of a specific user."""
    user = await crud_user.get_user_by_id(db, user_id=user_id)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"User with ID {user_id} not found."
        )

    # Basic validation (can enhance later)
    allowed_statuses = ["PENDING_VERIFICATION", "WAITLISTED", "PENDING_ONBOARDING", "ACTIVE", "SUSPENDED", "BANNED"]
    if status_update.status not in allowed_statuses:
         raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Invalid status value: '{status_update.status}'. Allowed: {allowed_statuses}"
        )

    # Use the internal update function
    update_data = schemas.user.UserUpdateInternal(status=status_update.status)
    try:
        updated_user = await crud_user.update_user_internal(db=db, db_obj=user, obj_in=update_data)
        return updated_user
    except Exception as e:
        # Log error properly
        print(f"Error updating user status for {user_id}: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred while updating the user status."
        ) 

--- END OF FILE: app/routers/admin.py ---

================================================================================

--- START OF FILE: app/routers/spaces.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.orm import selectinload
from sqlalchemy import func
from typing import List
from datetime import datetime

from app.db.session import get_db
from app import models, schemas
from app.security import get_current_active_user, get_current_user_with_roles
from app.schemas.user import User as UserSchema, UserCreate, UserUpdateInternal # Import UserSchema and UserUpdateInternal
from app.schemas.space import (
    ManagedSpaceDetail,
    SpaceTenantResponse,
    SpaceWorkstationListResponse,
    WorkstationAssignmentRequest,
    WorkstationDetail,
    WorkstationUnassignRequest,
    WorkstationStatusUpdateRequest,
    SpaceUsersListResponse, # Added
    BasicUser, # Ensure BasicUser is imported if not already
    SpaceConnectionStatsResponse # Added SpaceConnectionStatsResponse
)
from app.models.organization import Company # Changed from app.models.company import CompanyNode
from app.crud import crud_organization # Import crud_organization
from app.schemas.organization import BasicStartup as BasicStartupSchema # Import BasicStartup schema

router = APIRouter()

async def get_managed_space(
    db: AsyncSession, current_user: models.User
) -> models.SpaceNode:
    """Helper function to get the space managed by the current Corp Admin."""
    # Corp admin might manage a space directly (via space.corporate_admin_id)
    # or they might be linked via their company if the company itself is primary contact for a space
    # For now, assume direct management via corporate_admin_id on SpaceNode
    stmt = select(models.SpaceNode).where(models.SpaceNode.corporate_admin_id == current_user.id)
    result = await db.execute(stmt)
    managed_space = result.scalar_one_or_none()

    if not managed_space:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="No space found managed by the current user. Ensure you are a Corporate Admin of a space.",
        )
    return managed_space

@router.get(
    "/me/employees",
    response_model=List[UserSchema],
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def list_my_space_employees(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """List users belonging to the Corp Admin's company within their managed space.
    Requires CORP_ADMIN role.
    """
    managed_space = await get_managed_space(db, current_user)

    if not current_user.company_id:
        # If the Corp Admin themselves are not tied to a company, they can't have company employees in the space.
        # Or, this could mean list *all* users in their space if company_id is not the filter.
        # For now, sticking to "Corp Admin's company employees".
        return [] 

    stmt = (
        select(models.User)
        .where(
            models.User.company_id == current_user.company_id,
            models.User.space_id == managed_space.id,
            models.User.id != current_user.id # Exclude the admin themselves
        )
        .options(selectinload(models.User.profile)) # Eager load profile for UserSchema
    )
    result = await db.execute(stmt)
    employees = result.scalars().all()
    return employees 

@router.get(
    "/me/startups-freelancers",
    response_model=schemas.space.SpaceTenantResponse, # Use the new schema
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def list_my_space_startups_freelancers(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """List Startups and Freelancers assigned to the Corp Admin's managed space."""
    managed_space = await get_managed_space(db, current_user)
    tenants: List[schemas.space.TenantInfo] = []

    # Fetch Freelancers
    freelancer_stmt = (
        select(models.User)
        .where(
            models.User.space_id == managed_space.id,
            models.User.role == "FREELANCER"
        )
        .options(selectinload(models.User.profile)) # Eager load profile
    )
    freelancer_result = await db.execute(freelancer_stmt)
    freelancers = freelancer_result.scalars().all()
    for f_user in freelancers:
        # Convert the ORM user model (f_user) to BasicUser schema
        basic_user_details = schemas.space.BasicUser.from_orm(f_user)
        tenants.append(schemas.space.FreelancerTenantInfo(details=basic_user_details))

    # Fetch Startups (distinct startup_ids from users in the space)
    startup_users_stmt = (
        select(models.User.startup_id, models.Startup, func.count(models.User.id).label("member_count"))
        .join(models.Startup, models.User.startup_id == models.Startup.id) # Join User with Startup
        .where(
            models.User.space_id == managed_space.id,
            models.User.startup_id.isnot(None),
            # Optionally filter by roles if needed, e.g., only STARTUP_ADMIN or STARTUP_MEMBER
            models.User.role.in_(["STARTUP_ADMIN", "STARTUP_MEMBER"])
        )
        .group_by(models.User.startup_id, models.Startup.id, models.Startup.name)
    )
    startup_result = await db.execute(startup_users_stmt)
    
    # Process results: (startup_id, Startup object, member_count)
    # The direct Startup object from the join might already be loaded if relationship is set up well.
    # If not, we might need another query or rely on from_orm from a fully loaded Startup model.

    for row in startup_result.all(): # Using .all() to get named tuples if columns are selected
        startup_model = row.Startup # Access the Startup model instance from the row
        member_count = row.member_count
        # Ensure BasicStartup or a similar schema is used for details
        tenants.append(schemas.space.StartupTenantInfo(
            details=schemas.organization.Startup.from_orm(startup_model), # Use your actual Startup schema
            member_count=member_count
        ))

    return schemas.space.SpaceTenantResponse(tenants=tenants)

@router.post(
    "/me/workstations/assign",
    response_model=schemas.space.WorkstationAssignmentResponse,
    status_code=status.HTTP_201_CREATED,
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def assign_workstation_to_user(
    assignment_data: schemas.space.WorkstationAssignmentRequest,
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """Assign a user to a workstation within the Corp Admin's managed space."""
    managed_space = await get_managed_space(db, current_user)

    # 1. Verify the user to be assigned exists and is part of this space or a startup in this space
    user_to_assign = await db.get(models.User, assignment_data.user_id)
    if not user_to_assign:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User to assign not found")

    # Check if user is in the same space or their startup is in the same space
    is_freelancer_in_space = user_to_assign.space_id == managed_space.id and user_to_assign.role == "FREELANCER"
    
    is_startup_member_in_space = False
    if user_to_assign.startup_id:
        startup_of_user = await db.get(models.Startup, user_to_assign.startup_id)
        if startup_of_user and startup_of_user.space_id == managed_space.id:
            is_startup_member_in_space = True

    if not (is_freelancer_in_space or is_startup_member_in_space):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="User is not a freelancer or part of a startup within the managed space."
        )

    # 2. Verify the workstation exists and is part of the managed space and is available
    workstation = await db.get(models.Workstation, assignment_data.workstation_id)
    if not workstation:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Workstation not found")
    if workstation.space_id != managed_space.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Workstation is not part of the managed space."
        )
    
    # Check if workstation is already assigned (assuming a direct link or an assignment table)
    # This example assumes a `user_id` field on `Workstation` model means it's occupied.
    # A more robust system would use a separate WorkstationAssignment table.
    existing_assignment_stmt = select(models.WorkstationAssignment).where(
        models.WorkstationAssignment.workstation_id == workstation.id,
        models.WorkstationAssignment.end_date.is_(None) # Active assignment
    )
    existing_assignment_result = await db.execute(existing_assignment_stmt)
    if existing_assignment_result.scalars().first():
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail="Workstation is already occupied by another user."
        )
    
    # 3. Create the WorkstationAssignment record
    # This assumes you have a `WorkstationAssignment` model. 
    # If not, you might be directly updating workstation.user_id or workstation.status

    new_assignment = models.WorkstationAssignment(
        user_id=user_to_assign.id,
        workstation_id=workstation.id,
        space_id=managed_space.id,
        # created_by_id=current_user.id # Optional: if you track who made the assignment
    )
    db.add(new_assignment)
    await db.commit()
    await db.refresh(new_assignment)

    # Update workstation status if you have such a field
    # workstation.status = schemas.space.WorkstationStatus.OCCUPIED 
    # db.add(workstation) # Add workstation to session if status changed
    # await db.commit() # Commit workstation status change
    # await db.refresh(workstation) # Refresh workstation if needed

    return new_assignment # Directly return the ORM model, Pydantic will convert it 

@router.get(
    "/me/workstations",
    response_model=schemas.space.SpaceWorkstationListResponse,
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def list_my_space_workstations(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """List all workstations within the Corp Admin's managed space, including status and occupant."""
    managed_space = await get_managed_space(db, current_user)

    # Fetch all workstations in the managed space
    stmt_workstations = (
        select(models.Workstation)
        .where(models.Workstation.space_id == managed_space.id)
        .options(
            selectinload(models.Workstation.active_assignment).options(
                selectinload(models.WorkstationAssignment.user).options(
                    selectinload(models.User.profile)
                )
            )
        ) # Eager load active assignment and the assigned user + profile
    )
    result_workstations = await db.execute(stmt_workstations)
    workstations_orm = result_workstations.scalars().unique().all()

    workstation_details_list: List[schemas.space.WorkstationDetail] = []

    for ws_orm in workstations_orm:
        occupant_info = None
        status = schemas.space.WorkstationStatus.AVAILABLE # Default to available

        active_assign = ws_orm.active_assignment # This is a WorkstationAssignment object or None
        
        if active_assign and active_assign.user:
            # User is present in the active assignment
            status = schemas.space.WorkstationStatus.OCCUPIED
            
            # Access full_name directly from the user model, fallback to email
            occupant_full_name = active_assign.user.full_name if active_assign.user.full_name else active_assign.user.email
            
            occupant_info = schemas.space.WorkstationTenantInfo(
                user_id=active_assign.user.id,
                full_name=occupant_full_name, # Corrected: use occupant_full_name
                email=active_assign.user.email # Always include email
            )
        elif ws_orm.status == schemas.space.WorkstationStatus.MAINTENANCE: # Check ws_orm.status directly
            status = schemas.space.WorkstationStatus.MAINTENANCE
        # No specific handling for 'RESERVED' here, defaults to AVAILABLE if not occupied or maintenance

        workstation_details_list.append(
            schemas.space.WorkstationDetail(
                id=ws_orm.id,
                name=ws_orm.name,
                status=status, # Use the determined status
                space_id=ws_orm.space_id,
                occupant=occupant_info,
                # features=ws_orm.features # Assuming features is a field on Workstation model
            )
        )

    return schemas.space.SpaceWorkstationListResponse(workstations=workstation_details_list)

@router.post(
    "/me/workstations/unassign",
    response_model=schemas.Message, # Corrected: Or a specific unassignment success response
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def unassign_user_from_workstation(
    unassign_data: schemas.space.WorkstationUnassignRequest,
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """Unassign a user from a workstation by ending their current assignment."""
    managed_space = await get_managed_space(db, current_user)

    # 1. Find the workstation and verify it's in the managed space
    workstation = await db.get(models.Workstation, unassign_data.workstation_id)
    if not workstation:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Workstation not found")
    if workstation.space_id != managed_space.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Workstation is not part of the managed space."
        )

    # 2. Find the active assignment for this workstation
    # This assumes active_assignment relationship on Workstation model or querying WorkstationAssignment table
    active_assignment_stmt = (
        select(models.WorkstationAssignment)
        .where(
            models.WorkstationAssignment.workstation_id == workstation.id,
            models.WorkstationAssignment.end_date.is_(None) # Active assignment
        )
    )
    active_assignment_result = await db.execute(active_assignment_stmt)
    assignment_to_end = active_assignment_result.scalars().first()

    if not assignment_to_end:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="No active assignment found for this workstation."
        )
    
    # 3. End the assignment
    assignment_to_end.end_date = datetime.utcnow()
    db.add(assignment_to_end)
    await db.commit()
    await db.refresh(assignment_to_end)

    # Optional: Update workstation status if it has a status field that changes upon unassignment
    # if workstation.status == schemas.space.WorkstationStatus.OCCUPIED:
    #     workstation.status = schemas.space.WorkstationStatus.AVAILABLE
    #     db.add(workstation)
    #     await db.commit()

    return schemas.Message(message="User successfully unassigned from workstation.")

@router.get(
    "/me",
    response_model=schemas.space.ManagedSpaceDetail,
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def get_my_managed_space_details(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """Get detailed information about the space managed by the current Corp Admin."""
    managed_space = await get_managed_space(db, current_user) # Re-use the helper

    # Count workstations by status
    stmt_total = select(func.count(models.Workstation.id)).where(models.Workstation.space_id == managed_space.id)
    total_workstations = (await db.execute(stmt_total)).scalar_one_or_none() or 0

    stmt_maintenance = select(func.count(models.Workstation.id)).where(
        models.Workstation.space_id == managed_space.id,
        models.Workstation.status == "MAINTENANCE" # Assuming 'MAINTENANCE' is a string status
    )
    maintenance_workstations = (await db.execute(stmt_maintenance)).scalar_one_or_none() or 0

    # Count occupied workstations (active assignments)
    stmt_occupied = (
        select(func.count(models.WorkstationAssignment.id))
        .join(models.Workstation, models.WorkstationAssignment.workstation_id == models.Workstation.id)
        .where(
            models.Workstation.space_id == managed_space.id,
            models.WorkstationAssignment.end_date.is_(None)
        )
    )
    occupied_workstations = (await db.execute(stmt_occupied)).scalar_one_or_none() or 0
    
    available_workstations = total_workstations - occupied_workstations - maintenance_workstations

    return schemas.space.ManagedSpaceDetail(
        id=managed_space.id,
        name=managed_space.name,
        address=managed_space.address, # Assuming Space model has an address field
        total_workstations=total_workstations,
        occupied_workstations=occupied_workstations,
        available_workstations=max(0, available_workstations), # Ensure non-negative
        maintenance_workstations=maintenance_workstations,
        company_id=managed_space.company_id # Assuming Space model has company_id
    ) 

@router.put(
    "/me/workstations/{workstation_id}/status",
    response_model=schemas.space.WorkstationDetail, # Return updated workstation details
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
)
async def update_workstation_status(
    workstation_id: int,
    status_update: schemas.space.WorkstationStatusUpdateRequest,
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """Update the status of a specific workstation within the Corp Admin's managed space."""
    managed_space = await get_managed_space(db, current_user)

    # 1. Fetch the workstation
    workstation = await db.get(models.Workstation, workstation_id)
    if not workstation:
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Workstation not found")
    
    # 2. Verify workstation is in the managed space
    if workstation.space_id != managed_space.id:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Workstation is not part of the managed space."
        )

    new_status = status_update.status

    # 3. Logic for status update
    # Check for active assignment if attempting to set to AVAILABLE or MAINTENANCE when OCCUPIED
    active_assignment_stmt = select(models.WorkstationAssignment).where(
        models.WorkstationAssignment.workstation_id == workstation.id,
        models.WorkstationAssignment.end_date.is_(None)
    )
    active_assignment = (await db.execute(active_assignment_stmt)).scalars().first()

    if new_status == schemas.space.WorkstationStatus.AVAILABLE:
        if active_assignment:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail="Cannot set to AVAILABLE. Workstation is currently occupied. Unassign first."
            )
        workstation.status = schemas.space.WorkstationStatus.AVAILABLE.value
    elif new_status == schemas.space.WorkstationStatus.MAINTENANCE:
        # Optionally, if setting to MAINTENANCE while occupied, you might want to end the assignment.
        # For now, let's assume you can mark it for maintenance even if assigned, 
        # but it won't be assignable to others.
        workstation.status = schemas.space.WorkstationStatus.MAINTENANCE.value
    elif new_status == schemas.space.WorkstationStatus.OCCUPIED:
        # This status should typically be set implicitly by assigning a user.
        # Explicitly setting to OCCUPIED without an assignment might be disallowed.
        if not active_assignment:
            raise HTTPException(
                status_code=status.HTTP_409_CONFLICT,
                detail="Cannot set to OCCUPIED. No active assignment found. Assign a user instead."
            )
        # If it's already occupied and this is called, it's a bit redundant, but we can just affirm.
        workstation.status = schemas.space.WorkstationStatus.OCCUPIED.value 
        # Note: The `Workstation.status` field might be a direct string representation of the enum.
        # Or it could be derived. The current logic assumes it's a direct field to store these states.

    db.add(workstation)
    await db.commit()
    await db.refresh(workstation)
    
    # Re-fetch occupant details for the response
    occupant_info_resp = None
    if active_assignment and active_assignment.user:
        user_profile = active_assignment.user.profile # Assumes profile is loaded or accessible
        # It might be better to reload the user and profile if not already loaded via workstation relations
        if not user_profile: # Attempt to load if not present (e.g., if active_assignment was just from a simple query)
            await db.refresh(active_assignment.user, relationship_names=["profile"])
            user_profile = active_assignment.user.profile

        occupant_info_resp = schemas.space.WorkstationTenantInfo(
            user_id=active_assignment.user.id,
            full_name=user_profile.full_name if user_profile else active_assignment.user.email,
            email=active_assignment.user.email
        )

    return schemas.space.WorkstationDetail(
        id=workstation.id,
        name=workstation.name,
        status=schemas.space.WorkstationStatus(workstation.status), # Convert string back to Enum for response
        space_id=workstation.space_id,
        occupant=occupant_info_resp if workstation.status == schemas.space.WorkstationStatus.OCCUPIED.value else None
    ) 

@router.get("/me/users", response_model=SpaceUsersListResponse, dependencies=[Depends(get_current_user_with_roles(required_roles=['CORP_ADMIN']))])
async def list_all_users_in_managed_space(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """List all users belonging to the Corp Admin's managed space."""
    managed_space = await get_managed_space(db, current_user)

    stmt = (
        select(models.User)
        .where(models.User.space_id == managed_space.id)
        .options(selectinload(models.User.profile)) # Eager load profile
    )
    result = await db.execute(stmt)
    users_orm = result.scalars().all()
    
    # Convert ORM users to BasicUser schema
    users = [BasicUser.from_orm(user_obj) for user_obj in users_orm]
    
    return SpaceUsersListResponse(users=users) 

@router.get(
    "/me/member-requests",
    response_model=List[schemas.notification.Notification], # Use the existing Notification schema
    dependencies=[Depends(get_current_user_with_roles(required_roles=['CORP_ADMIN']))]
)
async def list_pending_member_requests(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """List pending member requests for the Corporate Admin's managed space.
    These are identified by unread notifications of type 'member_request'.
    """
    # The notification is targeted to the Corp Admin (current_user.id)
    # The type is 'member_request'
    # We only want unread notifications
    pending_requests_stmt = (
        select(models.Notification)
        .where(
            models.Notification.user_id == current_user.id,
            models.Notification.type == "member_request",
            models.Notification.is_read == False
        )
        .order_by(models.Notification.created_at.desc())
    )
    result = await db.execute(pending_requests_stmt)
    member_requests = result.scalars().all()
    return member_requests

@router.post(
    "/me/member-requests/{notification_id}/approve",
    response_model=schemas.Message, # Or a more specific response
    dependencies=[Depends(get_current_user_with_roles(required_roles=['CORP_ADMIN']))]
)
async def approve_member_request(
    notification_id: int,
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
): 
    managed_space = await get_managed_space(db, current_user)

    notification = await crud.crud_notification.get_notification_by_id(db=db, notification_id=notification_id)

    if not notification or \
       notification.user_id != current_user.id or \
       notification.type != "member_request" or \
       notification.is_read:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, 
            detail="Pending member request notification not found or already actioned."
        )

    email_to_add = notification.reference
    startup_id_from_notification = notification.related_entity_id

    if not email_to_add or not startup_id_from_notification:
        # Mark as read to prevent re-processing a bad notification
        await crud.crud_notification.mark_notification_as_read(db=db, notification=notification)
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Notification is missing email reference or startup ID."
        )

    # 2. Fetch Startup
    startup_to_join = await crud.crud_organization.get_startup(db, startup_id=startup_id_from_notification)
    if not startup_to_join:
        await crud.crud_notification.mark_notification_as_read(db=db, notification=notification)
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Startup with ID {startup_id_from_notification} not found.")

    # 3. Verify Startup is in the Corp Admin's managed space
    # THIS ASSUMES Startup model has a space_id linking it to a SpaceNode
    if startup_to_join.space_id != managed_space.id: 
        await crud.crud_notification.mark_notification_as_read(db=db, notification=notification)
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN, 
            detail=f"Startup {startup_to_join.name} is not part of your managed space."
        )

    # 4. Find or Create User
    user_to_add = await crud.user.get_user_by_email(db, email=email_to_add)
    new_user_created = False

    if user_to_add:
        # User exists, update them
        if user_to_add.startup_id and user_to_add.startup_id != startup_to_join.id:
             await crud.crud_notification.mark_notification_as_read(db=db, notification=notification) # Mark original as read
             # Notify original requester (Startup Admin) - find them first
             stmt_startup_admin = select(models.User).where(models.User.startup_id == startup_to_join.id, models.User.role == "STARTUP_ADMIN")
             startup_admin_user_result = await db.execute(stmt_startup_admin)
             startup_admin_user = startup_admin_user_result.scalars().first()
             if startup_admin_user:
                await crud.crud_notification.create_notification(
                    db, user_id=startup_admin_user.id, type="member_request_failed", 
                    message=f"Request to add {email_to_add} failed: User already belongs to another startup."
                )
             raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=f"User {email_to_add} already belongs to another startup.")
        
        user_to_add.startup_id = startup_to_join.id
        user_to_add.space_id = managed_space.id # Ensure they are in this space
        user_to_add.role = "STARTUP_MEMBER" # Default role for member request
        user_to_add.status = "ACTIVE"
        user_to_add.is_active = True
        db.add(user_to_add)
    else:
        # User does not exist, create them
        # TODO: Secure password generation/handling. For now, placeholder.
        # Consider what full_name should be - perhaps from original request if provided
        placeholder_password = "DefaultPassword123!" # THIS IS INSECURE
        new_user_data = UserCreate(
            email=email_to_add, 
            full_name=email_to_add.split('@')[0], # Basic default full_name
            password=placeholder_password, 
            role="STARTUP_MEMBER"
        )
        try:
            user_to_add = await crud.user.create_user(db, obj_in=new_user_data)
            new_user_created = True
            # Update status, space_id, startup_id for the new user
            # create_user sets initial status and is_active=False
            user_to_add.startup_id = startup_to_join.id
            user_to_add.space_id = managed_space.id
            # user_to_add.status = "ACTIVE" # create_user sets PENDING_VERIFICATION, let's make them active directly
            # user_to_add.is_active = True
            # Use UserUpdateInternal to make them active
            update_payload = UserUpdateInternal(status="ACTIVE", is_active=True)
            user_to_add = await crud.user.update_user_internal(db=db, db_obj=user_to_add, obj_in=update_payload)
            db.add(user_to_add) # Ensure it's added to session if update_user_internal doesn't handle it fully
        except Exception as e:
            # Log error, notify original requester if possible
            await crud.crud_notification.mark_notification_as_read(db=db, notification=notification) # Mark original as read
            # Notify Startup Admin of failure
            stmt_startup_admin_fail = select(models.User).where(models.User.startup_id == startup_to_join.id, models.User.role == "STARTUP_ADMIN")
            startup_admin_user_fail_result = await db.execute(stmt_startup_admin_fail)
            startup_admin_user_fail = startup_admin_user_fail_result.scalars().first()
            if startup_admin_user_fail:
                await crud.crud_notification.create_notification(
                    db, user_id=startup_admin_user_fail.id, type="member_request_failed", 
                    message=f"Request to add {email_to_add} failed: Could not create user account. Error: {str(e)}"
                )
            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Failed to create user: {str(e)}")

    try:
        await db.commit()
        await db.refresh(user_to_add)
    except Exception as e:
        await db.rollback()
        # Mark original as read to prevent loop if commit fails
        # but be careful with db session state here.
        # Best to try marking read outside a failed transaction context or handle idempotency
        # For now, we assume notification read can proceed or is handled by caller on error.
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f"Database error during user update/creation: {str(e)}")

    # 5. Mark original notification as read
    await crud.crud_notification.mark_notification_as_read(db=db, notification=notification)

    # 6. Notify Startup Admin of success
    stmt_startup_admin_success = select(models.User).where(models.User.startup_id == startup_to_join.id, models.User.role == "STARTUP_ADMIN")
    startup_admin_user_success_result = await db.execute(stmt_startup_admin_success)
    startup_admin_user_success = startup_admin_user_success_result.scalars().first()

    if startup_admin_user_success:
        success_message = f"Your request to add {email_to_add} to startup '{startup_to_join.name}' has been approved."
        if new_user_created:
            success_message += " A new account has been created."
        await crud.crud_notification.create_notification(
            db, user_id=startup_admin_user_success.id, type="member_request_approved", 
            message=success_message
        )
    
    return schemas.Message(message=f"User {email_to_add} successfully added to startup {startup_to_join.name}.")

@router.post(
    "/me/member-requests/{notification_id}/deny",
    response_model=schemas.Message,
    dependencies=[Depends(get_current_user_with_roles(required_roles=['CORP_ADMIN']))]
)
async def deny_member_request(
    notification_id: int,
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    notification = await crud.crud_notification.get_notification_by_id(db=db, notification_id=notification_id)

    if not notification or \
       notification.user_id != current_user.id or \
       notification.type != "member_request" or \
       notification.is_read:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND, 
            detail="Pending member request notification not found or already actioned."
        )

    email_denied = notification.reference
    startup_id_from_notification = notification.related_entity_id

    # Mark original notification as read first
    await crud.crud_notification.mark_notification_as_read(db=db, notification=notification)

    # Notify Startup Admin of denial
    if startup_id_from_notification:
        startup_involved = await crud.crud_organization.get_startup(db, startup_id=startup_id_from_notification)
        startup_name = startup_involved.name if startup_involved else "the startup"
        
        stmt_startup_admin = select(models.User).where(models.User.startup_id == startup_id_from_notification, models.User.role == "STARTUP_ADMIN")
        startup_admin_user_result = await db.execute(stmt_startup_admin)
        startup_admin_user = startup_admin_user_result.scalars().first()

        if startup_admin_user:
            await crud.crud_notification.create_notification(
                db, 
                user_id=startup_admin_user.id, 
                type="member_request_denied", 
                message=f"Your request to add {email_denied if email_denied else 'a member'} to {startup_name} has been denied."
            )
            # We commit here as mark_notification_as_read also commits.
            # If create_notification also commits, it's fine. If not, this commit covers both.
            await db.commit() 
        else:
            # Log if startup admin not found, but proceed with denial confirmation
            print(f"Warning: Could not find Startup Admin for startup ID {startup_id_from_notification} to notify of denial.")
            await db.commit() # Commit the read status of original notification
    else:
        # If no startup_id, still commit the read status
        await db.commit()

    return schemas.Message(message=f"Member request for {email_denied if email_denied else 'a member'} has been denied.")

@router.get("/me/stats/connections", response_model=SpaceConnectionStatsResponse, dependencies=[Depends(get_current_user_with_roles(required_roles=['CORP_ADMIN']))])
async def get_space_connection_stats(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """Calculates the total number of internal connections among startup tenants in the managed space."""
    managed_space = await get_managed_space(db=db, current_user=current_user)

    # This Cypher query will fail if db is an SQLAlchemy session.
    # This endpoint needs to be re-evaluated based on whether it's meant for Neo4j or SQLAlchemy.
    # For now, to prevent startup error, I will comment out the Neo4j logic and return a default.
    # TODO: Implement connection stats logic using SQLAlchemy or ensure Neo4j setup is correct.
    # cypher_query = """
    # MATCH (space:SpaceNode {id: $space_id})
    # // Find startups in this space
    # OPTIONAL MATCH (startup:StartupNode)-[:IN_SPACE]->(space)
    # // Count members for each startup
    # WITH startup, COUNT{(user:UserNode)-[:WORKS_FOR]->(startup)} AS member_count
    # // Calculate connections for this startup: n * (n - 1) / 2
    # // Ensure member_count > 1 to avoid division by zero or negative results if a startup has 0 or 1 member
    # WITH CASE WHEN member_count > 1 THEN member_count * (member_count - 1) / 2 ELSE 0 END AS startup_connections
    # // Sum connections across all startups in the space
    # RETURN sum(startup_connections) AS total_connections
    # """

    # result = await db.run(cypher_query, space_id=managed_space.id) # This would fail
    # data = await result.single()

    # total_connections = data["total_connections"] if data and data["total_connections"] is not None else 0
    total_connections = 0 # Placeholder

    return SpaceConnectionStatsResponse(total_connections=int(total_connections)) 

@router.get(
    "/my-space/startups",
    response_model=List[BasicStartupSchema],
    dependencies=[Depends(get_current_user_with_roles(required_roles=["CORP_ADMIN"]))],
    tags=["spaces", "corp_admin"]
)
async def list_startups_in_my_managed_space(
    current_user: models.User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_db),
):
    """
    Lists all startups within the current Corporate Admin's managed space.
    Requires CORP_ADMIN role and the admin to be associated with a space.
    """
    if not current_user.space_id:
        # This check might be redundant if get_managed_space is used and handles it,
        # but it's a good direct check specific to this endpoint's logic.
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Corporate Admin is not directly associated with a space."
        )
    
    # Alternative: Use the get_managed_space helper if it aligns with how CORP_ADMIN's space is determined
    # managed_space = await get_managed_space(db, current_user)
    # if not managed_space:
    #     # get_managed_space would raise 404 if no space, this is an additional safeguard or alternative logic.
    #     raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="No managed space found for admin.")

    startups_orm = await crud_organization.get_startups_by_space_id(db, space_id=current_user.space_id)
    
    # Convert ORM objects to Pydantic schemas if not automatically handled by FastAPI response_model
    # Pydantic v2 with from_attributes=True should handle this, but explicit conversion is also an option:
    # return [BasicStartupSchema.from_orm(startup) for startup in startups_orm]
    return startups_orm 

--- END OF FILE: app/routers/spaces.py ---

================================================================================

--- START OF FILE: app/routers/agent.py ---

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel

from app.dependencies import get_current_active_user # Assuming for auth
from app.schemas.user import User as UserSchema # Assuming for current_user type
# from app.agents.recruiting_agent import run_recruiting_agent # Will be needed later

router = APIRouter()

class AgentQuery(BaseModel):
    description: str

class AgentCandidate(BaseModel):
    # Define structure for agent results later based on [AG-03]
    name: str
    source: str # 'waitlist' or 'web'
    details: str
    relevance_score: float | None = None
    profile_url: str | None = None

# Placeholder for [AG-04] contact initiation
class AgentContactInitiation(BaseModel):
    target_user_id: int | None = None
    target_profile_url: str | None = None
    contact_type: str # 'internal' or 'external'

@router.post("/recruiting/find-talent", response_model=list[AgentCandidate])
async def find_talent_via_agent(
    query: AgentQuery,
    current_user: UserSchema = Depends(get_current_active_user) # Ensure user is Corp Admin via dependency
):
    """Endpoint for Corporate Admins to find talent using the recruiting agent."""
    # Check if current_user.role is appropriate (e.g., CORP_ADMIN)
    # This should ideally be part of get_current_active_user or a separate dependency
    # if current_user.role != "CORP_ADMIN":
    #     raise HTTPException(status_code=403, detail="Not authorized")

    # Placeholder logic - replace with actual call to run_recruiting_agent
    # agent_results = await run_recruiting_agent(query=query.description, space_context={"location": "Munich"} # Get space context from user
    # )
    # return agent_results
    
    # Dummy response for now
    print(f"Agent find talent called by {current_user.email} with query: {query.description}")
    return [
        AgentCandidate(name="Placeholder Freelancer", source="waitlist", details="Skilled in Python, FastAPI", relevance_score=0.9, profile_url="/users/123"),
        AgentCandidate(name="Placeholder Startup Inc.", source="web", details="AI solutions for logistics", profile_url="http://example.com")
    ]

@router.post("/recruiting/initiate-contact") # Add response model later
async def initiate_agent_contact(
    contact_data: AgentContactInitiation,
    current_user: UserSchema = Depends(get_current_active_user)
):
    """Endpoint for Corporate Admin to initiate contact with a lead found by the agent."""
    # Add role check for CORP_ADMIN
    print(f"Agent initiate contact called by {current_user.email} for target: {contact_data}")
    # Actual logic for [AG-04] will be implemented here
    return {"status": "Contact initiation placeholder successful", "details": contact_data.model_dump()}

# Add other agent-related endpoints if necessary 

--- END OF FILE: app/routers/agent.py ---

================================================================================

--- START OF FILE: app/routers/startup_actions.py ---

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
import logging
from datetime import datetime

from app import crud, models, schemas
from app.db.session import get_db
from app.security import get_current_user_with_roles

router = APIRouter()
logger = logging.getLogger(__name__)

@router.post("/request-member", response_model=schemas.message.Message, status_code=status.HTTP_202_ACCEPTED)
async def request_new_member_for_startup(
    member_request_data: schemas.member_request.StartupMemberRequestCreate,
    current_user: models.User = Depends(get_current_user_with_roles(["STARTUP_ADMIN"])),
    db: AsyncSession = Depends(get_db),
):
    """
    Allows a Startup Admin to request the addition of a new member to their startup.
    This will create a notification for Corp Admins of the space to approve.
    """
    if not current_user.startup_id:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="User is not associated with a startup.")

    startup = await crud.crud_organization.get_startup(db, startup_id=current_user.startup_id)
    if not startup:
        logger.error(f"Startup {current_user.startup_id} not found for Startup Admin {current_user.id}")
        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Associated startup not found.")

    if not startup.space_id:
        logger.error(f"Startup {startup.id} (name: {startup.name}) is not associated with any space.")
        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail="Startup is not part of a space, cannot process member request.")

    # Check if user with this email already exists and is part of *this* startup
    existing_user_in_startup = await crud.crud_user.get_user_by_email_and_startup(db, email=member_request_data.email, startup_id=startup.id)
    if existing_user_in_startup:
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=f"User with email {member_request_data.email} is already a member of your startup.")

    # Check if an active invitation already exists for this email and startup
    # (created by a corp admin previously, or via another startup admin request)
    existing_invitation = await crud.invitation.get_by_email_and_startup(
        db, email=member_request_data.email, startup_id=startup.id
    )
    if existing_invitation and existing_invitation.status == models.invitation.InvitationStatus.PENDING and existing_invitation.expires_at > datetime.utcnow():
        raise HTTPException(status_code=status.HTTP_409_CONFLICT, detail=f"An active invitation for {member_request_data.email} to join your startup already exists.")


    corp_admins_in_space = await crud.crud_user.get_users_by_role_and_space_id(
        db, role="CORP_ADMIN", space_id=startup.space_id
    )

    if not corp_admins_in_space:
        logger.warning(f"No Corp Admins found for space {startup.space_id} to handle member request for startup {startup.id}. Request cannot be processed.")
        # Depending on policy, this could be an error or the request could be queued differently.
        # For now, returning an error as no one can approve it.
        raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail="No corporate administrators available in the space to approve this request.")

    notification_title = f"Member Request: {startup.name}"
    message_detail = f"Startup '{startup.name}' requests to add member: {member_request_data.email}"
    if member_request_data.full_name:
        message_detail += f" (Name: {member_request_data.full_name})"
    message_detail += ". Please review and approve or reject this request."
    
    # Using a structured reference for easier parsing later by Corp Admin when approving
    reference_payload = f"startup_id={startup.id},email={member_request_data.email}"
    if member_request_data.full_name:
        reference_payload += f",full_name={member_request_data.full_name}"

    for corp_admin in corp_admins_in_space:
        await crud.crud_notification.create_notification_for_user(
            db,
            user_id=corp_admin.id,
            title=notification_title,
            message=message_detail,
            notification_type="member_request_pending_approval",
            reference=reference_payload 
        )
        logger.info(f"Sent member request notification to Corp Admin {corp_admin.id} for startup {startup.id}, email {member_request_data.email}")

    return schemas.message.Message(message="Member addition request submitted successfully. It will be reviewed by a Corporate Administrator.") 

--- END OF FILE: app/routers/startup_actions.py ---

================================================================================

--- START OF FILE: app/routers/chat.py ---

from fastapi import APIRouter, Depends, HTTPException, Query, WebSocket, WebSocketDisconnect, status # Add WebSocket, WebSocketDisconnect
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List, Optional
import logging # Add logging

from app import crud, models, schemas # schemas.chat will be used
from app.db.session import get_db
from app.security import get_current_active_user # Assuming this dependency exists
from app.schemas.chat import MessageReactionCreate, MessageReactionResponse, MessageReactionsListResponse, ChatMessageUpdate, ChatMessageSchema
from app.socket_instance import sio # <--- IMPORT SIO FROM NEW LOCATION
from app.schemas.notification import NotificationUpdate # Assuming this schema exists or we will create it
from app.crud.crud_notification import mark_notifications_as_read_by_ref # Assuming this exists or we will create it

router = APIRouter()
logger = logging.getLogger(__name__) # Add logger instance


@router.get(
    "/conversations",
    response_model=List[schemas.chat.ConversationInfo], # Changed to ConversationInfo
    summary="Get User's Conversations",
    description="Retrieves a list of conversations the current user is part of, ordered by the most recent message."
)
async def get_user_conversations_endpoint(
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """
    Retrieve conversations for the current user.
    Each conversation includes the other participant's user info and the last message exchanged.
    """
    conversations_data = await crud.crud_chat.get_user_conversations_with_details(db=db, user_id=current_user.id)
    # The CRUD function now returns a list of dicts that should match ConversationInfo structure
    # Pydantic will validate this structure upon return. No explicit model_validate loop needed if CRUD matches schema.
    return conversations_data


@router.get(
    "/conversations/{other_user_id}/messages",
    response_model=List[schemas.chat.ChatMessageSchema], # Changed to ChatMessageSchema
    summary="Get Messages Between Two Users for their Conversation",
    description="Retrieves the message history for the conversation between the current user and another specified user."
)
async def get_messages_for_conversation_with_user(
    other_user_id: int,
    skip: int = Query(0, ge=0, description="Number of messages to skip"),
    limit: int = Query(100, ge=1, le=200, description="Maximum number of messages to return"),
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """
    Retrieve message history between the current user and `other_user_id`.
    Messages are returned ordered from oldest to newest.
    """
    # Optional: Check if other_user_id exists or if users are connected
    other_user = await crud.crud_user.get_user_by_id(db, user_id=other_user_id)
    if not other_user:
        raise HTTPException(status_code=404, detail="Other user not found")

    # Get or create the 1-on-1 conversation between current_user and other_user
    conversation = await crud.crud_chat.get_or_create_conversation(
        db=db, user1_id=current_user.id, user2_id=other_user_id
    )
    if not conversation:
        # This case should ideally not be reached if get_or_create always returns or creates
        raise HTTPException(status_code=404, detail="Conversation could not be found or created.")

    messages = await crud.crud_chat.get_messages_for_conversation(
        db=db, conversation_id=conversation.id, skip=skip, limit=limit
    )
    return messages

@router.post("/messages/{message_id}/reactions", response_model=MessageReactionResponse | None)
async def add_or_toggle_reaction(
    message_id: int,
    reaction_in: MessageReactionCreate,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user)
):
    reaction_orm = await crud.crud_chat.add_or_toggle_reaction(
        db,
        message_id=message_id,
        user_id=current_user.id,
        emoji=reaction_in.emoji
    )

    chat_message = await crud.crud_chat.get_chat_message_by_id(db, message_id=message_id)
    if chat_message and chat_message.conversation:
        conversation = chat_message.conversation
        action = "added" if reaction_orm else "removed"
        reaction_payload = None
        if reaction_orm:
            await db.refresh(reaction_orm) 
            reaction_payload = MessageReactionResponse.model_validate(reaction_orm).model_dump(mode='json')

        for participant in conversation.participants:
            logger.info(f"Attempting to emit 'reaction_updated' to room: {str(participant.id)} for conversation {conversation.id}")
            logger.info(f"Reaction payload for emit: {reaction_payload}")
            await sio.emit(
                "reaction_updated",
                data={
                    "message_id": message_id,
                    "conversation_id": conversation.id,
                    "reaction": reaction_payload,
                    "user_id_who_reacted": current_user.id,
                    "emoji": reaction_in.emoji, # The emoji that was acted upon
                    "action": action,
                },
                room=str(participant.id)
            )
    
    return reaction_orm

@router.delete("/messages/{message_id}/reactions", response_model=dict)
async def remove_reaction(
    message_id: int,
    emoji: str, # emoji is a query parameter for DELETE
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user)
):
    success = await crud.crud_chat.remove_reaction(
        db,
        message_id=message_id,
        user_id=current_user.id,
        emoji=emoji
    )
    if not success:
        raise HTTPException(status_code=404, detail="Reaction not found or already removed")

    chat_message = await crud.crud_chat.get_chat_message_by_id(db, message_id=message_id)
    if chat_message and chat_message.conversation:
        conversation = chat_message.conversation
        logger.info(f"Attempting to emit 'reaction_updated' (action: removed) to rooms for conversation {conversation.id}")
        for participant in conversation.participants:
            logger.info(f"Emitting reaction removal to user {str(participant.id)} for message {message_id}, emoji {emoji}")
            await sio.emit(
                "reaction_updated",
                data={
                    "message_id": message_id,
                    "conversation_id": conversation.id,
                    "reaction": None, 
                    "user_id_who_reacted": current_user.id,
                    "emoji": emoji, 
                    "action": "removed",
                },
                room=str(participant.id)
            )

    return {"ok": True}

@router.get("/messages/{message_id}/reactions", response_model=MessageReactionsListResponse)
async def get_reactions_for_message(
    message_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user)
):
    reactions = await crud.crud_chat.get_reactions_for_message(db, message_id=message_id)
    return {"reactions": reactions}

@router.post(
    "/conversations/{conversation_id}/read", 
    status_code=status.HTTP_204_NO_CONTENT, # Use 204 No Content for successful updates with no body
    summary="Mark Conversation as Read",
    description="Updates the timestamp indicating the current user has read the specified conversation."
)
async def mark_conversation_as_read_endpoint(
    conversation_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    """
    Marks a conversation as read for the current user by updating their 
    `last_read_at` timestamp in the ConversationParticipant record.
    Also marks related 'new_chat_message' notifications as read.
    """
    updated = await crud.crud_chat.mark_conversation_as_read(
        db=db, 
        conversation_id=conversation_id, 
        user_id=current_user.id
    )
    
    if not updated:
        # This could mean the conversation doesn't exist or the user isn't a participant.
        # Raising 404 is appropriate as the target resource (user's participation) wasn't found/updated.
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="Conversation not found or user is not a participant."
        )

    # Now, mark related notifications as read
    # We need a way to link notifications to conversations. Assuming a reference like `conversation:{id}`
    notification_ref = f"conversation:{conversation_id}"
    try:
        # Assuming mark_notifications_as_read_by_ref exists and handles not finding notifications gracefully
        # We'll implement/verify this function in crud_notification next.
        await crud.crud_notification.mark_notifications_as_read_by_ref(
            db=db,
            user_id=current_user.id,
            reference=notification_ref
        )
        logger.info(f"Marked notifications as read for user {current_user.id} with reference {notification_ref}")
    except Exception as e:
        # Log error but don't fail the request just because notification update failed
        logger.error(f"Failed to mark notifications as read for user {current_user.id} with reference {notification_ref}: {e}")

    # If successful, return No Content (HTTP 204)
    return None 

@router.put(
    "/messages/{message_id}",
    response_model=schemas.chat.ChatMessageSchema,
    summary="Edit a Chat Message",
    description="Allows the sender of a message to edit its content within a configured time window."
)
async def edit_chat_message(
    message_id: int,
    message_update: schemas.chat.ChatMessageUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    updated_message_orm = await crud.crud_chat.update_message(
        db=db, 
        message_id=message_id, 
        current_user_id=current_user.id, 
        new_content=message_update.content
    )

    if not updated_message_orm:
        original_message = await crud.crud_chat.get_chat_message_by_id(db=db, message_id=message_id)
        if not original_message:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Message not found")
        if original_message.sender_id != current_user.id:
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="User cannot edit this message")
        # Check if it was due to time window or other condition like already deleted
        # This part can be more granular if needed, for now, a generic 403 if update fails for valid reasons
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Message cannot be edited (e.g., time window expired or already deleted)")

    # Emit event to conversation participants
    if updated_message_orm.conversation:
        # The ORM object from crud.update_message should have conversation loaded or be None
        # For safety, re-fetch if necessary, or ensure CRUD loads it if conversation_id exists
        conversation_participants = updated_message_orm.conversation.participants
        if not conversation_participants:
            # If somehow participants are not loaded, fetch them
            conv_with_participants = await db.get(models.Conversation, updated_message_orm.conversation_id, options=[selectinload(models.Conversation.participants)])
            if conv_with_participants:
                conversation_participants = conv_with_participants.participants

        if conversation_participants:
            updated_message_data = schemas.chat.ChatMessageSchema.model_validate(updated_message_orm).model_dump(mode='json')
            for participant in conversation_participants:
                logger.info(f"Emitting 'message_updated' to room: {str(participant.id)} for message {updated_message_orm.id}")
                await sio.emit(
                    "message_updated",
                    data=updated_message_data,
                    room=str(participant.id)
                )

    return updated_message_orm

@router.delete(
    "/messages/{message_id}",
    response_model=schemas.chat.ChatMessageSchema, # Or a specific schema for deleted messages
    summary="Delete a Chat Message",
    description="Allows the sender of a message to soft-delete it within a configured time window."
)
async def delete_chat_message(
    message_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: models.User = Depends(get_current_active_user),
):
    deleted_message_orm = await crud.crud_chat.delete_message(
        db=db, 
        message_id=message_id, 
        current_user_id=current_user.id
    )

    if not deleted_message_orm:
        # Similar error handling as edit
        original_message = await crud.crud_chat.get_chat_message_by_id(db=db, message_id=message_id)
        if not original_message:
            raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Message not found")
        if original_message.sender_id != current_user.id:
            raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="User cannot delete this message")
        # If it was already deleted, the CRUD returns the message, so this path is for other denials like time window.
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Message cannot be deleted (e.g., time window expired)")
    
    # Emit event to conversation participants
    if deleted_message_orm.conversation:
        conversation_participants = deleted_message_orm.conversation.participants
        if not conversation_participants:
            conv_with_participants = await db.get(models.Conversation, deleted_message_orm.conversation_id, options=[selectinload(models.Conversation.participants)])
            if conv_with_participants:
                conversation_participants = conv_with_participants.participants
        
        if conversation_participants:
            # For delete, we only need to send the ID and conversation_id usually
            # But sending the full object with is_deleted=True is also fine and matches response_model
            deleted_message_data = schemas.chat.ChatMessageSchema.model_validate(deleted_message_orm).model_dump(mode='json')
            for participant in conversation_participants:
                logger.info(f"Emitting 'message_deleted' to room: {str(participant.id)} for message {deleted_message_orm.id}")
                await sio.emit(
                    "message_deleted",
                    data=deleted_message_data, # Or simpler: {"id": message_id, "conversation_id": deleted_message_orm.conversation_id}
                    room=str(participant.id)
                )

    return deleted_message_orm 

--- END OF FILE: app/routers/chat.py ---

================================================================================

--- START OF FILE: app/utils/email.py ---

import resend
import logging
from app.core.config import settings
from typing import Optional # Added for Optional type hint

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def send_email(to: str, subject: str, html_content: str) -> None:
    """Sends an email using the Resend service."""
    if not settings.RESEND_API_KEY:
        logger.error("RESEND_API_KEY is not configured. Cannot send email.")
        # In a real application, you might want to raise an exception
        # or handle this more gracefully depending on requirements.
        return

    try:
        # Correctly extract the secret value from SecretStr
        resend.api_key = settings.RESEND_API_KEY.get_secret_value()
        params = {
            "from": "ShareYourSpace Onboarding <onboarding@shareyourspace.app>",
            "to": [to],
            "subject": subject,
            "html": html_content,
        }
        email = resend.Emails.send(params)
        logger.info(f"Email sent successfully to {to}. Message ID: {email['id']}")
    except Exception as e:
        logger.error(f"Failed to send email to {to}. Error: {e}")
        # Handle exceptions appropriately (e.g., retry logic, alerts)
        # For now, we just log, but the caller might need to know if it failed.
        raise # Re-raise the exception so the caller can handle it

def send_startup_invitation_email(
    to_email: str, 
    token: str, 
    startup_name: str,
    invited_by_name: str, # Name of the Corp Admin who approved
    full_name: Optional[str] = None 
) -> None:
    """Sends an invitation email to a user to join a startup."""
    invitation_url = f"{settings.FRONTEND_URL}/accept-invitation/{token}"
    
    user_greeting = f"Hi {full_name}," if full_name else "Hello,"

    subject = f"Invitation to Join {startup_name} on ShareYourSpace"
    html_content = f"""
    <p>{user_greeting}</p>
    <p>{invited_by_name} has invited you to join the startup "<strong>{startup_name}</strong>" on ShareYourSpace.</p>
    <p>ShareYourSpace is a platform for startups, freelancers, and corporate teams to connect and collaborate within shared workspaces.</p>
    <p>To accept this invitation and create your account, please click the link below:</p>
    <p><a href="{invitation_url}">{invitation_url}</a></p>
    <p>This link will expire in 7 days.</p>
    <p>If you were not expecting this invitation, please ignore this email.</p>
    <p>Welcome aboard!<br>The ShareYourSpace Team</p>
    """
    try:
        send_email(to=to_email, subject=subject, html_content=html_content)
        logger.info(f"Startup invitation email successfully sent to {to_email} for startup {startup_name}.")
    except Exception as e:
        logger.error(f"Failed to send startup invitation email to {to_email} for startup {startup_name}. Error: {e}")
        # The initial send_email function already logs and re-raises.
        # We can re-raise here as well if the caller (router) needs to act on this failure.
        raise 

--- END OF FILE: app/utils/email.py ---

================================================================================

--- START OF FILE: app/utils/security_utils.py ---

from passlib.context import CryptContext

# Setup password hashing context
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password: str, hashed_password: str) -> bool:
    return pwd_context.verify(plain_password, hashed_password)

def get_password_hash(password: str) -> str:
    return pwd_context.hash(password) 

--- END OF FILE: app/utils/security_utils.py ---

================================================================================

--- START OF FILE: app/utils/storage.py ---

import logging
import os
import datetime
from google.cloud import storage
from google.api_core.exceptions import GoogleAPICallError
from fastapi import UploadFile, Response
from google.cloud.storage.blob import Blob
import google.auth
from google.auth.transport.requests import Request
from google.oauth2 import service_account
from google.auth import impersonated_credentials
from datetime import timedelta

from app.core.config import settings

# Configure logging
logger = logging.getLogger(__name__)

# Initialize GCS client
# If GOOGLE_APPLICATION_CREDENTIALS is set in the environment or config,
# the client will use that keyfile. Otherwise, it attempts to use ADC.
try:
    # Get default credentials (expected to be user ADC via mounted file)
    source_credentials, project_id = google.auth.default()

    if settings.TARGET_SERVICE_ACCOUNT_EMAIL:
        print(f"Attempting to impersonate Service Account: {settings.TARGET_SERVICE_ACCOUNT_EMAIL}") # Temporary print
        # Create impersonated credentials
        scoped_credentials = impersonated_credentials.Credentials(
            source_credentials=source_credentials,
            target_principal=settings.TARGET_SERVICE_ACCOUNT_EMAIL,
            target_scopes=['https://www.googleapis.com/auth/devstorage.full_control'], # Scope needed for GCS
            # lifetime=3600, # Optional: default is 1 hour
        )
        # Initialize client with impersonated credentials
        storage_client = storage.Client(credentials=scoped_credentials, project=project_id)
        print("GCS Client initialized with IMPERSONATED credentials.") # Temporary print
    else:
        # Fallback to using default (user) credentials directly if no impersonation target
        # Note: This won't be able to sign URLs
        print("Impersonation target email not set. Using default credentials directly.") # Temporary print
        storage_client = storage.Client(credentials=source_credentials, project=project_id)

    GCS_BUCKET = storage_client.bucket(settings.GCS_BUCKET_NAME)
except Exception as e:
    logger.error(f"Failed to initialize Google Cloud Storage client: {e}", exc_info=True)
    storage_client = None
    GCS_BUCKET = None

def upload_file(
    file: UploadFile,
    destination_blob_name: str
) -> str | None:
    """Uploads a file to the GCS bucket and returns a signed URL valid for 1 hour."""
    if not GCS_BUCKET or not storage_client:
        logger.error("GCS bucket or client not initialized. Cannot upload file.")
        return None

    blob = GCS_BUCKET.blob(destination_blob_name)

    try:
        # Upload the file content directly from the UploadFile object
        file.file.seek(0)
        blob.upload_from_file(file.file, content_type=file.content_type)

        logger.info(f"File {file.filename} uploaded to {destination_blob_name}.")
        # Generate a signed URL valid for 1 hour
        url = blob.generate_signed_url(expiration=timedelta(hours=1))
        return url

    except GoogleAPICallError as e:
        logger.error(f"GCS API error during upload to {destination_blob_name}: {e}", exc_info=True)
        return None
    except Exception as e:
        logger.error(f"Unexpected error during upload to {destination_blob_name}: {e}", exc_info=True)
        return None

def download_blob(blob_name: str) -> Blob | None:
    """Downloads a blob object from GCS. Returns the Blob object itself."""
    if not GCS_BUCKET or not storage_client:
        logger.error("GCS bucket or client not initialized. Cannot download blob.")
        return None
    if not blob_name:
        return None
    try:
        blob = GCS_BUCKET.blob(blob_name)
        # Check if blob exists before trying to download (optional but good practice)
        if not blob.exists():
             logger.warning(f"Attempted to download non-existent blob: {blob_name}")
             return None
        return blob
    except GoogleAPICallError as e:
        logger.error(f"GCS API error downloading blob {blob_name}: {e}", exc_info=True)
        return None
    except Exception as e:
        logger.error(f"Unexpected error downloading blob {blob_name}: {e}", exc_info=True)
        return None 

--- END OF FILE: app/utils/storage.py ---

================================================================================

--- START OF FILE: app/utils/embeddings.py ---

import google.generativeai as genai
import logging
from typing import List

from app.core.config import settings

logger = logging.getLogger(__name__)

# Configure the client
if settings.GOOGLE_AI_API_KEY:
    # Extract the actual string value from SecretStr
    genai.configure(api_key=settings.GOOGLE_AI_API_KEY.get_secret_value())
else:
    logger.warning("GOOGLE_AI_API_KEY not found in settings. Embedding generation will fail.")

# Define the model name
EMBEDDING_MODEL = "models/text-embedding-004"

def generate_embedding(text: str) -> List[float] | None:
    """Generates an embedding for the given text using the Google AI API."""
    # Check if key exists *before* trying to use the client
    if not settings.GOOGLE_AI_API_KEY:
        logger.error("Cannot generate embedding: GOOGLE_AI_API_KEY is not configured.")
        return None

    try:
        # Clean the text - embedding model prefers non-empty strings
        cleaned_text = text.strip()
        if not cleaned_text:
            logger.warning("Input text for embedding is empty after stripping.")
            # Return a zero vector or None, depending on desired handling
            # Returning None might be safer to indicate failure/empty input
            return None 
            # Alternative: return [0.0] * 768 # text-embedding-004 dimension is 768

        result = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=cleaned_text,
            task_type="RETRIEVAL_DOCUMENT" # Use RETRIEVAL_DOCUMENT for searchable embeddings
        )
        return result['embedding']
    except Exception as e:
        logger.error(f"Error generating embedding: {e}", exc_info=True)
        return None 

--- END OF FILE: app/utils/embeddings.py ---

================================================================================

--- START OF FILE: app/utils/__pycache__/security_utils.cpython-312.pyc ---



    e
hi                     J    d dl mZ  edgd      ZdededefdZd	edefd
Zy)    )CryptContextbcryptauto)schemes
deprecatedplain_passwordhashed_passwordreturnc                 .    t         j                  | |      S N)pwd_contextverify)r   r	   s     N/home/marcel/ShareYourSpace/shareyourspace-backend/app/utils/security_utils.pyverify_passwordr      s    no>>    passwordc                 ,    t         j                  |       S r   )r
   hash)r   s    r   get_password_hashr   	   s    H%%r   N)passlib.contextr   r
   strboolr   r    r   r   <module>r      sE    ( H:&A?C ?# ?$ ?& & &r   

--- END OF FILE: app/utils/__pycache__/security_utils.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/core/__init__.py ---

# Leave this file empty 

--- END OF FILE: app/core/__init__.py ---

================================================================================

--- START OF FILE: app/core/config.py ---

import os
from pydantic_settings import BaseSettings, SettingsConfigDict
from pydantic import Field, EmailStr, HttpUrl, PostgresDsn, SecretStr
from typing import List, Optional


class Settings(BaseSettings):
    PROJECT_NAME: str = "ShareYourSpace 2.0" # Added default project name
    DATABASE_URL: PostgresDsn
    SECRET_KEY: SecretStr
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 60 * 24 * 7 # 1 week
    API_V1_STR: str = "/api/v1"

    # Add other secrets/config variables here later as needed
    RESEND_API_KEY: SecretStr | None = None
    STRIPE_SECRET_KEY: SecretStr | None = None
    STRIPE_PUBLISHABLE_KEY: str | None = None # No SecretStr needed
    STRIPE_WEBHOOK_SECRET: SecretStr | None = None
    GOOGLE_CLIENT_ID: str | None = None
    GOOGLE_CLIENT_SECRET: SecretStr | None = None
    LINKEDIN_CLIENT_ID: str | None = None
    LINKEDIN_CLIENT_SECRET: SecretStr | None = None
    APPLE_CLIENT_ID: str | None = None
    APPLE_TEAM_ID: str | None = None
    APPLE_KEY_ID: str | None = None
    APPLE_PRIVATE_KEY: SecretStr | None = None
    GOOGLE_AI_API_KEY: SecretStr | None = None
    FRONTEND_URL: str = Field(default="http://localhost:3000", description="Base URL for the frontend application")
    GCS_BUCKET_NAME: str
    TARGET_SERVICE_ACCOUNT_EMAIL: str | None = Field(None, validation_alias='TARGET_SERVICE_ACCOUNT_EMAIL')
    GOOGLE_APPLICATION_CREDENTIALS: Optional[str] = None # Path to service account key file (if not using ADC/impersonation)
    MESSAGE_EDIT_DELETE_WINDOW_SECONDS: int = 300 # Default 5 minutes, time in seconds
    INVITATION_EXPIRE_DAYS: int = 7 # Default 7 days for invitation expiry

    model_config = SettingsConfigDict(env_file='.env', extra='ignore')

settings = Settings() 

--- END OF FILE: app/core/config.py ---

================================================================================

--- START OF FILE: app/core/__pycache__/config.cpython-312.pyc ---



    p1h                     l    d dl Z d dlmZmZ d dlmZmZmZmZm	Z	 d dl
mZmZ  G d de      Z
 e
       Zy)    N)BaseSettingsSettingsConfigDict)FieldEmailStrHttpUrlPostgresDsn	SecretStr)ListOptionalc                      e Zd ZU dZeed<   eed<   eed<   dZeed<   dZ	e
ed<   d	Zeed
<   dZedz  ed<   dZ
edz  ed
<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<   dZedz  ed<    edd      Zeed<   eed<    edd      Zedz  ed<   dZee   ed <   d!Ze
ed"<   d#Ze
ed$<    e d%d&'      Z!y)(SettingszShareYourSpace 2.0PROJECT_NAMEDATABASE_URL
SECRET_KEYHS256	ALGORITHMi`'  ACCESS_TOKEN_EXPIRE_MINUTESz/api/v1
API_V1_STRNRESEND_API_KEYSTRIPE_SECRET_KEYSTRIPE_PUBLISHABLE_KEYSTRIPE_WEBHOOK_SECRETGOOGLE_CLIENT_IDGOOGLE_CLIENT_SECRETLINKEDIN_CLIENT_IDLINKEDIN_CLIENT_SECRETAPPLE_CLIENT_ID
APPLE_TEAM_IDAPPLE_KEY_IDAPPLE_PRIVATE_KEYGOOGLE_AI_API_KEYzhttp://localhost:3000z%Base URL for the frontend application)defaultdescriptionFRONTEND_URLGCS_BUCKET_NAMETARGET_SERVICE_ACCOUNT_EMAIL)validation_aliasGOOGLE_APPLICATION_CREDENTIALSi,  "MESSAGE_EDIT_DELETE_WINDOW_SECONDS   INVITATION_EXPIRE_DAYSz.envignore)env_fileextra)"__name__
__module____qualname__r   str__annotations__r   r	   r   r   intr   r   r   r   r   r   r   r   r   r   r   r   r    r!   r   r$   r&   r(   r   r)   r+   r   model_config     E/home/marcel/ShareYourSpace/shareyourspace-backend/app/core/config.pyr
   r
      s`   ,L#,Is'22J (,NI$+*.y4'.)-C$J-.29t+2#'cDj'-1)d*1%)d
)/3I,3"&OS4Z& $M3:$#L#*#*.y4'.*.y4'.&=KrsL#s/4TLj/k #*k48"HSM8.1&1"#C#%vXFLr7   r
   )ospydantic_settingsr   r   pydanticr   r   r   r   r	   typingr
   r   r
   settingsr6   r7   r8   <module>r>      s+    	 > E E !G| G> :r7   

--- END OF FILE: app/core/__pycache__/config.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/core/__pycache__/__init__.cpython-312.pyc ---



    8&h                           y )N r       G/home/marcel/ShareYourSpace/shareyourspace-backend/app/core/__init__.py<module>r      s   r   

--- END OF FILE: app/core/__pycache__/__init__.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/message.py ---

from pydantic import BaseModel

 
class Message(BaseModel):
    message: str 

--- END OF FILE: app/schemas/message.py ---

================================================================================

--- START OF FILE: app/schemas/auth.py ---

from pydantic import BaseModel
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from app.schemas.user import User # Assuming your user schema is named User

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenPayload(BaseModel):
    sub: str | None = None # Subject (usually email)
    user_id: int | None = None
    role: str | None = None 

class TokenWithUser(Token):
    user: "User" 

# Resolve forward references
# TokenWithUser.model_rebuild() 

--- END OF FILE: app/schemas/auth.py ---

================================================================================

--- START OF FILE: app/schemas/user.py ---

from pydantic import BaseModel, EmailStr, ConfigDict
from typing import Optional
from datetime import datetime
# from app.models.user import UserStatus # Assuming UserStatus enum exists in models

# Forward references for nested schemas
from app.schemas.user_profile import UserProfile as UserProfileSchema
from app.schemas.organization import BasicCompany as BasicCompanySchema, BasicStartup as BasicStartupSchema
from app.schemas.space import BasicSpace as BasicSpaceSchema, UserWorkstationInfo as UserWorkstationInfoSchema

# Base properties shared by user models
class UserBase(BaseModel):
    email: EmailStr
    full_name: Optional[str] = None # full_name can be optional in base if some flows set it later

# Properties required for user creation via API (e.g. direct registration)
class UserCreate(UserBase):
    email: EmailStr # Make email explicit here if not optional in UserBase
    full_name: str  # Make full_name required for direct creation
    password: str
    role: str 
    company_name: Optional[str] = None
    title: Optional[str] = None

# Properties for user self-update 
class UserUpdate(BaseModel):
    full_name: Optional[str] = None
    password: Optional[str] = None # For changing password
    # Add other fields a user can update themselves

# Schema for user creation via invitation acceptance
class UserCreateAcceptInvitation(BaseModel):
    full_name: str
    password: str

# Schema for internal updates (e.g., system changing status, role, linking to entities)
class UserUpdateInternal(BaseModel):
    email: Optional[EmailStr] = None
    full_name: Optional[str] = None
    role: Optional[str] = None
    status: Optional[str] = None # Replace str with UserStatus if enum is available
    is_active: Optional[bool] = None
    hashed_password: Optional[str] = None # If system needs to update hashed_password directly
    corporate_admin_id: Optional[int] = None
    startup_id: Optional[int] = None
    space_id: Optional[int] = None
    company_id: Optional[int] = None

    model_config = ConfigDict(
        from_attributes=True
    )

# Properties to return to client (excluding sensitive info like password)
class User(UserBase):
    id: int
    email: EmailStr # Ensure email is non-optional in output
    full_name: str  # Ensure full_name is non-optional in output
    role: str
    status: str # Replace str with UserStatus if enum is available
    is_active: bool
    created_at: datetime
    updated_at: datetime
    corporate_admin_id: Optional[int] = None
    startup_id: Optional[int] = None
    space_id: Optional[int] = None
    company_id: Optional[int] = None # Added company_id for completeness

    model_config = ConfigDict(
        from_attributes=True # Allows reading data from ORM models
    )

# Detailed User Schema for Profile Page
class UserDetail(User): # Inherits fields from User schema
    profile: Optional[UserProfileSchema] = None
    company: Optional[BasicCompanySchema] = None
    startup: Optional[BasicStartupSchema] = None
    space: Optional[BasicSpaceSchema] = None # The space they BELONG to
    managed_space: Optional[BasicSpaceSchema] = None # The space they MANAGE (if CORP_ADMIN)
    current_workstation: Optional[UserWorkstationInfoSchema] = None
    
    model_config = ConfigDict(from_attributes=True)

# You can add more schemas here as needed, e.g., UserUpdate 

--- END OF FILE: app/schemas/user.py ---

================================================================================

--- START OF FILE: app/schemas/space.py ---

from pydantic import BaseModel, EmailStr
from typing import List, Optional, Union
from enum import Enum
from pydantic import ConfigDict
from datetime import datetime

# Schemas for app.schemas.user.User, assuming it exists and has relevant fields like id, full_name, email, role
# This is a simplified placeholder. You'd import your actual User schema.
class BasicUser(BaseModel):
    id: int
    full_name: Optional[str] = None
    email: EmailStr
    role: str

    model_config = ConfigDict(
        from_attributes=True # Allows reading data from ORM models
    )

# Schemas for app.schemas.organization.Startup, assuming it exists and has relevant fields like id, name
# This is a simplified placeholder. You'd import your actual Startup schema.
class BasicStartup(BaseModel):
    id: int
    name: str
    # Add other relevant startup details to show to Corp Admin
    # e.g., mission: Optional[str] = None

    model_config = ConfigDict(
        from_attributes=True # Allows reading data from ORM models
    )

# Basic Space Information
class BasicSpace(BaseModel):
    id: int
    name: str
    model_config = ConfigDict(from_attributes=True)

class StartupTenantInfo(BaseModel):
    type: str = "startup"
    details: BasicStartup
    member_count: int # Number of members from this startup in the admin's space
    # You might want to add a list of members here too, or a link to view them

class FreelancerTenantInfo(BaseModel):
    type: str = "freelancer"
    details: BasicUser # The Freelancer user object

# Union type for the response list
TenantInfo = Union[StartupTenantInfo, FreelancerTenantInfo]

class SpaceTenantResponse(BaseModel):
    tenants: List[TenantInfo]

# Schemas for Workstation info
class WorkstationStatus(str, Enum):
    AVAILABLE = "AVAILABLE"
    OCCUPIED = "OCCUPIED"
    MAINTENANCE = "MAINTENANCE"

class WorkstationAssignmentRequest(BaseModel):
    user_id: int
    workstation_id: int
    # Optional: Add start_date and end_date if assignments are time-bound
    # start_date: Optional[date] = None
    # end_date: Optional[date] = None

    class Config:
        orm_mode = True

# Potentially a response schema for assignment, or just a success message
class WorkstationAssignmentResponse(BaseModel):
    assignment_id: int # Assuming an ID for the assignment itself
    user_id: int
    workstation_id: int
    space_id: int
    # start_date: Optional[date]
    # end_date: Optional[date]

    class Config:
        orm_mode = True

# Schema for detailed workstation info, including occupant
class WorkstationTenantInfo(BaseModel):
    user_id: int
    full_name: Optional[str]
    email: Optional[EmailStr]
    # Add any other relevant user details you want to show

    model_config = ConfigDict(
        from_attributes=True # Allows reading data from ORM models
    )

class WorkstationDetail(BaseModel):
    id: int
    name: str
    status: WorkstationStatus # Reuse the Enum
    space_id: int
    occupant: Optional[WorkstationTenantInfo] = None # Details of the user occupying it

    class Config:
        orm_mode = True

class SpaceWorkstationListResponse(BaseModel):
    workstations: List[WorkstationDetail]

class WorkstationUnassignRequest(BaseModel):
    workstation_id: int
    # Alternatively, could use assignment_id if that's preferred for unassignment
    # assignment_id: int

    class Config:
        orm_mode = True

# Schema for detailed information about the managed space
class ManagedSpaceDetail(BaseModel):
    id: int
    name: str
    address: Optional[str] = None
    total_workstations: int = 0
    occupied_workstations: int = 0
    available_workstations: int = 0
    maintenance_workstations: int = 0
    # Add other relevant space details like amenities, opening hours, etc.
    # amenities: List[str] = []
    company_id: Optional[int] = None # Company that owns/manages this space node

    class Config:
        orm_mode = True

class WorkstationStatusUpdateRequest(BaseModel):
    status: WorkstationStatus # Use the existing Enum

    class Config:
        orm_mode = True

# Schema for listing all users within a specific space
class SpaceUsersListResponse(BaseModel):
    users: List[BasicUser]

    model_config = ConfigDict(
        from_attributes=True # Allows reading data from ORM models
    )

# New schema for connection statistics
class SpaceConnectionStatsResponse(BaseModel):
    total_connections: int
    model_config = ConfigDict(from_attributes=True)

# Information about a user's current workstation assignment
class UserWorkstationInfo(BaseModel):
    workstation_id: int
    workstation_name: str
    assignment_start_date: datetime # from WorkstationAssignment model
    # assignment_id: Optional[int] = None # If needed from WorkstationAssignment model
    model_config = ConfigDict(from_attributes=True) 

--- END OF FILE: app/schemas/space.py ---

================================================================================

--- START OF FILE: app/schemas/connection.py ---

from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional

# Import User schema for nesting
from .user import User

# Shared properties
class ConnectionBase(BaseModel):
    recipient_id: int

# Properties to receive via API on creation
class ConnectionCreate(ConnectionBase):
    pass # Only recipient_id is needed from the user

# Properties to receive via API on update (e.g., changing status)
class ConnectionUpdate(BaseModel):
    status: str # Expecting 'accepted', 'declined', 'blocked'?

# Properties stored in DB
class ConnectionInDBBase(ConnectionBase):
    id: int
    requester_id: int
    status: str
    created_at: datetime
    updated_at: datetime

    model_config = {
        "from_attributes": True
    }

# Properties to return to client
class Connection(ConnectionInDBBase):
    requester: User # Add nested User object for the requester
    recipient: User # Add nested User object for the recipient

# Additional schema for representing a connection with user details (optional)
# from .user import User as UserSchema # Import User schema
# class ConnectionWithUsers(Connection):
#     requester: UserSchema
#     recipient: UserSchema

# Shared properties
class NotificationBase(BaseModel):
    type: str
    message: str
    related_entity_id: Optional[int] = None

# Properties stored in DB
class NotificationInDBBase(NotificationBase):
    id: int
    user_id: int # Recipient ID
    is_read: bool
    created_at: datetime

    model_config = {
        "from_attributes": True
    }

# Properties to return to client
class Notification(NotificationInDBBase):
    pass # Return all DB fields for now

# Schema for checking connection status between two users
class ConnectionStatusCheck(BaseModel):
    status: Optional[str] = None # e.g., 'pending_from_me', 'pending_from_them', 'connected', 'not_connected'
    connection_id: Optional[int] = None # ID if pending or connected 

--- END OF FILE: app/schemas/connection.py ---

================================================================================

--- START OF FILE: app/schemas/organization.py ---

from pydantic import BaseModel, HttpUrl, ConfigDict
from typing import Optional
from datetime import datetime

# Shared properties
class OrganizationBase(BaseModel):
    name: str
    logo_url: Optional[HttpUrl] = None
    industry_focus: Optional[str] = None
    description: Optional[str] = None
    website: Optional[HttpUrl] = None

# Properties to receive on creation (if needed later)
class CompanyCreate(OrganizationBase):
    pass

class StartupCreate(OrganizationBase):
    mission: Optional[str] = None

# Properties to receive on update (if needed later)
class CompanyUpdate(OrganizationBase):
    pass

class StartupUpdate(OrganizationBase):
    mission: Optional[str] = None

# Properties shared by models stored in DB
class OrganizationInDBBase(OrganizationBase):
    id: int
    created_at: datetime
    updated_at: Optional[datetime] = None

    model_config = ConfigDict(
        from_attributes=True
    )

# Properties to return to client
class Company(OrganizationInDBBase):
    pass

class Startup(OrganizationInDBBase):
    mission: Optional[str] = None

# Properties stored in DB
class CompanyInDB(OrganizationInDBBase):
    pass

class StartupInDB(OrganizationInDBBase):
    mission: Optional[str] = None

# Basic Company Information
class BasicCompany(BaseModel):
    id: int
    name: str
    model_config = ConfigDict(from_attributes=True)

# Basic Startup Information (e.g., for dropdowns or lists)
class BasicStartup(BaseModel):
    id: int
    name: str
    model_config = ConfigDict(from_attributes=True)

# Schema for requesting to add a new member
class MemberRequestCreate(BaseModel):
    email: str # For now, just email. Could expand to full_name, etc.
    # Add any other details you want the Startup Admin to provide
    # e.g., proposed_role: Optional[str] = None

# Schema for the response after requesting a member
class MemberRequestResponse(BaseModel):
    message: str
    notification_sent_to_admin_id: Optional[int] = None
    requested_email: str 

--- END OF FILE: app/schemas/organization.py ---

================================================================================

--- START OF FILE: app/schemas/matching.py ---

from pydantic import BaseModel
from typing import List, Optional

from .user_profile import UserProfile # Import the existing UserProfile schema
 
class MatchResult(BaseModel):
    profile: UserProfile
    score: float # Combined ranking score (higher is better)
    reasons: List[str] # List of reasons for the match 

--- END OF FILE: app/schemas/matching.py ---

================================================================================

--- START OF FILE: app/schemas/__init__.py ---

# Leave this file empty 
from .user import User, UserCreate, UserUpdateInternal # noqa
from .verification_token import VerificationToken, VerificationTokenCreate # noqa
# Import specific password reset schemas needed
from .password_reset_token import PasswordResetTokenCreate, RequestPasswordResetRequest, ResetPasswordRequest # noqa
from .token import Token, TokenPayload # noqa
from .user_profile import UserProfile, UserProfileUpdate # noqa
from . import organization # noqa: Import the organization schemas
from . import chat # noqa: Import the chat schemas 
from .message import Message # noqa 
from . import auth # noqa: Import the auth schemas

# After all schemas are imported, rebuild models with forward references
from .auth import TokenWithUser
from .user import User, UserDetail

TokenWithUser.model_rebuild()
User.model_rebuild() # Rebuild User schema as well, as it's referenced
UserDetail.model_rebuild() # And UserDetail, as it references other schemas

# Add other model_rebuild calls here if new forward refs are introduced

--- END OF FILE: app/schemas/__init__.py ---

================================================================================

--- START OF FILE: app/schemas/token.py ---

from pydantic import BaseModel
from typing import Optional

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenPayload(BaseModel):
    sub: Optional[str] = None # 'sub' is the standard JWT field for subject (usually user identifier)
    user_id: Optional[int] = None # Add user_id field 

--- END OF FILE: app/schemas/token.py ---

================================================================================

--- START OF FILE: app/schemas/verification_token.py ---

from pydantic import BaseModel
from datetime import datetime

# Schema for creating a VerificationToken
class VerificationTokenCreate(BaseModel):
    user_id: int
    token: str
    expires_at: datetime

# Schema for reading a VerificationToken (if needed)
class VerificationToken(VerificationTokenCreate):
    id: int
    created_at: datetime

    class Config:
        from_attributes = True # Pydantic v2 uses this instead of orm_mode 

--- END OF FILE: app/schemas/verification_token.py ---

================================================================================

--- START OF FILE: app/schemas/password_reset_token.py ---

from pydantic import BaseModel
from datetime import datetime

class PasswordResetTokenBase(BaseModel):
    token: str
    user_id: int
    expires_at: datetime

class PasswordResetTokenCreate(PasswordResetTokenBase):
    pass

class PasswordResetTokenRead(PasswordResetTokenBase):
    id: int

    class Config:
        from_attributes = True

# Schema for the request body of /request-password-reset
class RequestPasswordResetRequest(BaseModel):
    email: str

# Schema for the request body of /reset-password
class ResetPasswordRequest(BaseModel):
    token: str
    new_password: str 

--- END OF FILE: app/schemas/password_reset_token.py ---

================================================================================

--- START OF FILE: app/schemas/admin.py ---

from pydantic import BaseModel, Field
from typing import List, Optional
from datetime import datetime

# Re-using User schema, potentially create a specific Admin view later
from .user import User as UserSchema


# Schema for assigning a user to a space
class UserAssignSpace(BaseModel):
    space_id: Optional[int] = None # Allow unassigning by passing null/None

# Schema for changing user status
class UserStatusUpdate(BaseModel):
    # Add validation? Should only allow valid status strings?
    status: str = Field(..., description="The new status for the user.") 

# Schema for creating a SpaceNode via API
class SpaceCreate(BaseModel):
    name: str
    location_description: Optional[str] = None
    corporate_admin_id: Optional[int] = None
    total_workstations: int

# Schema for creating a simple SpaceNode (without requiring corp admin)
class SimpleSpaceCreate(BaseModel):
    name: str = Field(..., description="Name of the pilot/test space")
    total_workstations: int = Field(..., gt=0, description="Number of workstations available")

# Schema for returning a SpaceNode from API
class Space(BaseModel):
    id: int
    name: str
    location_description: Optional[str] = None
    corporate_admin_id: Optional[int] = None
    total_workstations: int
    created_at: datetime
    updated_at: datetime

    class Config:
        from_attributes = True # Replaces orm_mode = True

# Schema for the response when listing users (simplified view)
class UserAdminView(BaseModel):
    id: int
    email: str
    full_name: Optional[str] = None
    role: str
    status: str
    is_active: bool
    created_at: datetime
    space_id: Optional[int] = None # Include space_id

    class Config:
        from_attributes = True 

--- END OF FILE: app/schemas/admin.py ---

================================================================================

--- START OF FILE: app/schemas/user_profile.py ---

from pydantic import BaseModel, HttpUrl, ConfigDict
from typing import Optional, List
from app.models.enums import ContactVisibility

# Base properties shared by profile models
class UserProfileBase(BaseModel):
    title: Optional[str] = None
    bio: Optional[str] = None
    contact_info_visibility: Optional[ContactVisibility] = ContactVisibility.CONNECTIONS
    skills_expertise: Optional[List[str]] = None
    industry_focus: Optional[List[str]] = None
    project_interests_goals: Optional[str] = None
    collaboration_preferences: Optional[List[str]] = None
    tools_technologies: Optional[List[str]] = None
    linkedin_profile_url: Optional[HttpUrl] = None
    profile_picture_url: Optional[str] = None # Stores blob name

# Properties to receive via API on update
class UserProfileUpdate(UserProfileBase):
    pass # Inherits all fields from Base, all are optional

# Properties to return to client
class UserProfile(UserProfileBase):
    id: int
    user_id: int
    full_name: Optional[str] = None # Add full_name field
    profile_picture_signed_url: Optional[str] = None # Added for temporary signed URL

    # Pydantic V2 uses model_config instead of Config
    model_config = ConfigDict(
        from_attributes=True # Allows reading data from ORM models
    ) 

--- END OF FILE: app/schemas/user_profile.py ---

================================================================================

--- START OF FILE: app/schemas/notification.py ---

from pydantic import BaseModel
from datetime import datetime
from typing import Optional

# Shared properties
class NotificationBase(BaseModel):
    type: str
    message: str
    related_entity_id: Optional[int] = None
    reference: Optional[str] = None
    link: Optional[str] = None

# Properties stored in DB
class NotificationInDBBase(NotificationBase):
    id: int
    user_id: int # Recipient ID
    is_read: bool
    created_at: datetime

    model_config = {
        "from_attributes": True
    }

# Properties to return to client
class Notification(NotificationInDBBase):
    pass # Return all DB fields for now 

class NotificationUpdate(BaseModel):
    is_read: Optional[bool] = None 

--- END OF FILE: app/schemas/notification.py ---

================================================================================

--- START OF FILE: app/schemas/member_request.py ---

from pydantic import BaseModel, EmailStr
from typing import List, Optional, Literal
from datetime import datetime
from enum import Enum

# Simplified info about the startup making the request
class RequestingStartupInfo(BaseModel):
    id: int
    name: str

    class Config:
        orm_mode = True

# Simplified info about the user being requested (if they exist)
# or details provided in the request for a new user.
class RequestedUserInfo(BaseModel):
    id: Optional[int] = None # Present if the user already exists in the system
    full_name: Optional[str] = None # Can be pre-filled if user exists, or from request
    email: EmailStr # Always present, from the original request

    class Config:
        orm_mode = True

class MemberRequestStatus(str, Enum):
    PENDING = "PENDING"
    APPROVED = "APPROVED"
    REJECTED = "REJECTED"

class MemberRequestDetail(BaseModel):
    id: int # This will likely be the ID of the NotificationNode
    requested_at: datetime
    status: MemberRequestStatus
    requesting_startup: RequestingStartupInfo
    # If the request is for an existing user, their details can be included.
    # If it's for a new user, only the email might be available initially.
    requested_user_details: Optional[RequestedUserInfo] = None # Populated if the email matches an existing user
    requested_email: EmailStr # The email as entered in the request

    class Config:
        orm_mode = True

class MemberRequestListResponse(BaseModel):
    requests: List[MemberRequestDetail]

    class Config:
        orm_mode = True

class MemberRequestActionResponse(BaseModel):
    message: str
    request_id: int
    status: str
    # Optionally, include details of the created/activated user if approved
    # activated_user: Optional[BasicUser] = None # BasicUser from app.schemas.space 

# Schema for Startup Admin to request a new member
class StartupMemberRequestCreate(BaseModel):
    email: EmailStr
    # Optional: Startup Admin can provide a full name if known
    full_name: Optional[str] = None 
    # startup_id will be derived from the authenticated Startup Admin 

--- END OF FILE: app/schemas/member_request.py ---

================================================================================

--- START OF FILE: app/schemas/chat.py ---

from datetime import datetime
from typing import Optional, List
from pydantic import BaseModel

# Assuming a User schema exists for embedding sender/recipient info
from .user import User as UserSchema

# --- Conversation Schemas --- #
class ConversationParticipantBase(BaseModel):
    user_id: int

class ConversationParticipantCreate(ConversationParticipantBase):
    pass

class ConversationParticipantSchema(ConversationParticipantBase):
    user: UserSchema
    model_config = {
        'from_attributes': True
    }

class ConversationBase(BaseModel):
    pass

class ConversationCreate(ConversationBase):
    # Typically created with a list of participant user IDs
    participant_ids: List[int]

class ConversationSchema(ConversationBase):
    id: int
    created_at: datetime
    participants: List[UserSchema]

    model_config = {
        'from_attributes': True
    }

# --- Message Reaction Schemas (MOVED UP) --- #
class MessageReactionBase(BaseModel):
    emoji: str

class MessageReactionCreate(MessageReactionBase):
    pass

class MessageReactionResponse(MessageReactionBase):
    id: int
    message_id: int
    user_id: int
    created_at: datetime
    # Optionally include user info
    # user: UserSchema | None = None

    model_config = {
        'from_attributes': True
    }

class MessageReactionsListResponse(BaseModel):
    reactions: list[MessageReactionResponse]

# --- Chat Message Schemas --- #

# Schema for receiving message content from client
class ChatMessageCreate(BaseModel):
    recipient_id: Optional[int] = None
    conversation_id: Optional[int] = None
    content: str
    attachment_url: Optional[str] = None
    attachment_filename: Optional[str] = None
    attachment_mimetype: Optional[str] = None

# Base schema for message properties included in responses
class ChatMessageBase(BaseModel):
    id: int
    sender_id: int
    recipient_id: Optional[int] = None
    conversation_id: Optional[int] = None
    content: str
    created_at: datetime
    read_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None
    is_deleted: bool = False
    attachment_url: Optional[str] = None
    attachment_filename: Optional[str] = None
    attachment_mimetype: Optional[str] = None

# Full message schema including loaded relationships
class ChatMessageSchema(ChatMessageBase):
    sender: UserSchema
    reactions: List[MessageReactionResponse] = []

    model_config = {
        'from_attributes': True
    }

# Schema for updating a message
class ChatMessageUpdate(BaseModel):
    content: str

# Schema for representing a conversation in the list view for the frontend
class ConversationInfo(BaseModel):
    id: int
    other_user: UserSchema
    last_message: Optional[ChatMessageSchema] = None
    has_unread_messages: bool

    model_config = {
        'from_attributes': True
    }

# To resolve forward reference for ConversationSchema.messages if you uncomment it
# ConversationSchema.model_rebuild() 

# ConversationSchema.model_rebuild() # May not be needed if Pydantic handles it 

--- END OF FILE: app/schemas/chat.py ---

================================================================================

--- START OF FILE: app/schemas/invitation.py ---

from pydantic import BaseModel, EmailStr, ConfigDict
from typing import Optional
from datetime import datetime
from app.models.invitation import InvitationStatus # Use the enum from the model

# Forward references for relationships if User and Startup schemas are in other files
# This is a common pattern. Adjust if your User/Startup schemas are imported directly.
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from app.schemas.user import User as UserSchema # Assuming User schema is named User
    from app.schemas.organization import Startup as StartupSchema # Assuming Startup schema is named Startup

# Properties to receive via API on creation
class InvitationBase(BaseModel):
    email: EmailStr
    startup_id: int
    # status will default to PENDING in model, not needed in base usually
    # expires_at will be set by the server
    # invitation_token will be generated by the server

class InvitationCreate(InvitationBase):
    approved_by_admin_id: int # Corp Admin who approved

# Properties to receive via API on update (e.g., admin resending or changing expiry)
# For now, we might only update status internally via token acceptance.
class InvitationUpdate(BaseModel):
    # Potentially status could be updated here by an admin (e.g., revoke)
    status: Optional[InvitationStatus] = None
    # Other fields if updatable, e.g., expires_at by an admin
    expires_at: Optional[datetime] = None

# Properties to receive via API on update - specific for marking accepted
class InvitationAccept(BaseModel):
    pass # For now, token in path is enough, user details will be separate step or pre-filled

# New schema for declining an invitation
class InvitationDecline(BaseModel):
    reason: Optional[str] = None
    model_config = ConfigDict(extra='forbid') # Ensure no extra fields are passed

# Schema for Corp Admin to directly invite a user to a startup
class CorpAdminDirectInviteCreate(BaseModel):
    email: EmailStr
    startup_id: int
    # approved_by_admin_id will be the current_user.id (Corp Admin)

# Base properties shared by models stored in DB
class InvitationInDBBase(InvitationBase):
    id: int
    invitation_token: str
    expires_at: datetime
    status: InvitationStatus
    approved_by_admin_id: Optional[int] = None # Was required in Create, but make optional in DB read
    accepted_at: Optional[datetime] = None
    accepted_by_user_id: Optional[int] = None
    revoked_at: Optional[datetime] = None
    revoked_by_admin_id: Optional[int] = None
    declined_at: Optional[datetime] = None # New field
    decline_reason: Optional[str] = None    # New field
    created_at: datetime # Added from model
    updated_at: datetime # Added from model

    model_config = ConfigDict(from_attributes=True)

# Additional properties to return to API
class Invitation(InvitationInDBBase):
    startup: Optional["StartupSchema"] = None # Populate with startup details
    approved_by_admin: Optional["UserSchema"] = None
    accepted_by_user: Optional["UserSchema"] = None
    revoked_by_admin: Optional["UserSchema"] = None

# Additional properties stored in DB
class InvitationInDB(InvitationInDBBase):
    pass

class InvitationListResponse(BaseModel):
    invitations: list[Invitation] 

--- END OF FILE: app/schemas/invitation.py ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/password_reset_token.cpython-312.pyc ---



    fhL                         d dl mZ d dlmZ  G d de      Z G d de      Z G d de      Z G d	 d
e      Z G d de      Zy
)    )	BaseModel)datetimec                   ,    e Zd ZU eed<   eed<   eed<   y)PasswordResetTokenBasetokenuser_id
expires_atN)__name__
__module____qualname__str__annotations__intr        V/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/password_reset_token.pyr   r      s    J
Lr   r   c                       e Zd Zy)PasswordResetTokenCreateN)r
   r   r   r   r   r   r   r   	   s    r   r   c                   ,    e Zd ZU eed<    G d d      Zy)PasswordResetTokenReadidc                       e Zd ZdZy)PasswordResetTokenRead.ConfigTN)r
   r   r   from_attributesr   r   r   Configr      s    r   r   N)r
   r   r   r   r   r   r   r   r   r   r      s    G r   r   c                       e Zd ZU eed<   y)RequestPasswordResetRequestemailNr
   r   r   r
   r   r   r   r   r   r      s    Jr   r   c                   "    e Zd ZU eed<   eed<   y)ResetPasswordRequestr   new_passwordNr   r   r   r   r!   r!      s
    Jr   r!   N)pydanticr   r   r   r   r   r   r!   r   r   r   <module>r$      sI     Y 
	5 	3 ) 9 r   

--- END OF FILE: app/schemas/__pycache__/password_reset_token.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/verification_token.cpython-312.pyc ---



    h                     H    d dl mZ d dlmZ  G d de      Z G d de      Zy)    )	BaseModel)datetimec                   ,    e Zd ZU eed<   eed<   eed<   y)VerificationTokenCreateuser_idtoken
expires_atN)__name__
__module____qualname__int__annotations__strr        T/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/verification_token.pyr   r      s    
LJr   r   c                   6    e Zd ZU eed<   eed<    G d d      Zy)VerificationTokenid
created_atc                       e Zd ZdZy)VerificationToken.ConfigTN)r
   r   r   from_attributesr   r   r   Configr      s    r   r   N)r
   r   r   r
   r   r   r   r   r   r   r   r      s    G r   r   N)pydanticr   r   r   r   r   r   r   <module>r      s$     i / r   

--- END OF FILE: app/schemas/__pycache__/verification_token.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/organization.cpython-312.pyc ---



    =1h                     d   d dl mZmZmZ d dlmZ d dlmZ  G d de      Z G d de      Z G d d	e      Z	 G d
 de      Z
 G d d
e      Z G d de      Z G d de      Z
 G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Zy )!    )	BaseModelHttpUrl
ConfigDict)Optional)datetimec                   h    e Zd ZU eed<   dZee   ed<   dZee   ed<   dZ	ee   ed<   dZ
ee   ed<   y)OrganizationBasenameNlogo_urlindustry_focusdescriptionwebsite)__name__
__module____qualname__str__annotations__r   r   r   r   r
   r        N/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/organization.pyr	   r	      sA    

I"&Hhw&$(NHSM(!%K#%!%GXg
%r   r	   c                       e Zd Zy)
CompanyCreateNr   r   r   r   r   r   r   r          r   r   c                   "    e Zd ZU dZee   ed<   y)
StartupCreateNmissionr   r   r   r   r   r   r   r   r   r   r   r          !GXc]!r   r   c                       e Zd Zy)
CompanyUpdateNr   r   r   r   r!   r!      r   r   r!   c                   "    e Zd ZU dZee   ed<   y)
StartupUpdateNr   r   r   r   r   r#   r#      r   r   r#   c                   H    e Zd ZU eed<   eed<   dZee   ed<    ed      Z	y)OrganizationInDBBaseid
created_atN
updated_atTfrom_attributes)
r   r   r   intr   r   r(   r   r   model_configr   r   r   r%   r%      s)    G%)J")Lr   r%   c                       e Zd Zy)CompanyNr   r   r   r   r.   r.   &   r   r   r.   c                   "    e Zd ZU dZee   ed<   y)StartupNr   r   r   r   r   r0   r0   )   r   r   r0   c                       e Zd Zy)CompanyInDBNr   r   r   r   r2   r2   -   r   r   r2   c                   "    e Zd ZU dZee   ed<   y)StartupInDBNr   r   r   r   r   r4   r4   0   r   r   r4   c                   4    e Zd ZU eed<   eed<    ed      Zy)BasicCompanyr&   r
   Tr)   Nr   r   r   r+   r   r   r   r,   r   r   r   r6   r6   4       G

Id3Lr   r6   c                   4    e Zd ZU eed<   eed<    ed      Zy)BasicStartupr&   r
   Tr)   Nr7   r   r   r   r:   r:   :   r8   r   r:   c                       e Zd ZU eed<   y)MemberRequestCreateemailN)r   r   r   r   r   r   r   r   r<   r<   @   s    Jr   r<   c                   6    e Zd ZU eed<   dZee   ed<   eed<   y)MemberRequestResponsemessageNnotification_sent_to_admin_idrequested_email)r   r   r   r   r   rA   r   r+   r   r   r   r?   r?   F   s    
L37!8C=7r   r?   N)pydanticr   r   r   typingr   r   r	   r   r   r!   r#   r%   r.   r0   r2   r4   r6   r:   r<   r?   r   r   r   <module>rE      s    3 3  &y &	$ 	"$ "	$ 	"$ "+ 	" 	"" "	& 	"& "49 449 4) I r   

--- END OF FILE: app/schemas/__pycache__/organization.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/user.cpython-312.pyc ---



    h1h
                         d dl mZmZmZ d dlmZ d dlmZ d dlmZ	 d dl
mZm
Z d dlmZmZ  G d de      Z G d	 d
e      Z G d de      Z G d
 de      Z G d de      Z G d de      Z G d de      Zy)    )	BaseModelEmailStr
ConfigDict)Optional)datetime)UserProfile)BasicCompanyBasicStartup)
BasicSpaceUserWorkstationInfoc                   ,    e Zd ZU eed<   dZee   ed<   y)UserBaseemailN	full_name)__name__
__module____qualname__r   __annotations__r   r   str     F/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/user.pyr   r      s    O#Ix}#r   r   c                   ^    e Zd ZU eed<   eed<   eed<   eed<   dZee   ed<   dZee   ed<   y)
UserCreater   r   passwordroleNcompany_nametitle)	r   r   r   r   r   r   r   r   r   r   r   r   r   r      s2    ONM

I"&L(3-&E8C=r   r   c                   6    e Zd ZU dZee   ed<   dZee   ed<   y)
UserUpdateNr   r   )r   r   r   r   r   r   r   r   r   r   r   r    r       s    #Ix}#"Hhsm"r   r    c                   "    e Zd ZU eed<   eed<   y)UserCreateAcceptInvitationr   r   N)r   r   r   r   r   r   r   r   r"   r"       s    NMr   r"   c                       e Zd ZU dZee   ed<   dZee   ed<   dZ	ee   ed<   dZ
ee   ed<   dZee   ed<   dZ
ee   ed<   dZee   ed<   dZee   ed	<   dZee   ed
<   dZee   ed<    ed
      Zy)UserUpdateInternalNr   r   r   status	is_activehashed_passwordcorporate_admin_id
startup_idspace_id
company_idTfrom_attributes)r   r   r   r   r   r   r   r   r   r   r%   r&   boolr'   r(   intr)   r*   r+   r   model_configr   r   r   r$   r$   %   s     $E8H$#Ix}#D(3- FHSM  $Ix~$%)OXc])(,
, $J
$"Hhsm" $J
$Lr   r$   c                       e Zd ZU eed<   eed<   eed<   eed<   eed<   eed<   eed<   eed<   d	Z	e
e   ed
<   d	Ze
e   ed<   d	Ze
e   ed<   d	Z
e
e   ed
<    ed      Zy	)Useridr   r   r   r%   r&   
created_at
updated_atNr(   r)   r*   r+   Tr,   )r   r   r   r/   r   r   r   r.   r   r(   r   r)   r*   r+   r   r0   r   r   r   r2   r2   6   sr    GON

IKO(,
, $J
$"Hhsm" $J
$Lr   r2   c                       e Zd ZU dZee   ed<   dZee   ed<   dZ	ee
   ed<   dZee   ed<   dZ
ee   ed<   dZee   ed<    ed	      Zy)

UserDetailNprofilecompanystartupspace
managed_spacecurrent_workstationTr,   )r   r   r   r8   r   UserProfileSchemar   r9   BasicCompanySchemar:   BasicStartupSchemar;   BasicSpaceSchemar<   r=   UserWorkstationInfoSchemar   r0   r   r   r   r7   r7   I   sm    +/GX'
(/,0GX(
)0,0GX(
)0(,E8$%,04M8,-4?C";<Cd3Lr   r7   N)pydanticr   r   r   typingr   r   app.schemas.user_profiler   r>   app.schemas.organizationr	   r?   r
   r@   app.schemas.spacer   rA   r   rB   r   r   r    r"   r$   r2   r7   r   r   r   <module>rH      sq    4 4   F k n$y $
   # # 
 "8 &4 4r   

--- END OF FILE: app/schemas/__pycache__/user.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/token.cpython-312.pyc ---



    Ph:                     H    d dl mZ d dlmZ  G d de      Z G d de      Zy)    )	BaseModel)Optionalc                   "    e Zd ZU eed<   eed<   y)Tokenaccess_token
token_typeN)__name__
__module____qualname__str__annotations__     G/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/token.pyr   r      s
    Or   r   c                   6    e Zd ZU dZee   ed<   dZee   ed<   y)TokenPayloadNsubuser_id)	r	   r
   r   r   r   r   r
   r   intr   r   r   r   r      s    C#!GXc]!r   r   N)pydanticr   typingr   r   r   r   r   r   <module>r      s#     I "9 "r   

--- END OF FILE: app/schemas/__pycache__/token.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/auth.cpython-312.pyc ---



    1h                     n    d dl mZ d dlmZ erd dlmZ  G d de      Z G d de      Z G d d	e      Zy
)    )	BaseModel)
TYPE_CHECKING)Userc                   "    e Zd ZU eed<   eed<   y)Tokenaccess_token
token_typeN)__name__
__module____qualname__str__annotations__     F/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/auth.pyr   r      s
    Or   r   c                   J    e Zd ZU dZedz  ed<   dZedz  ed<   dZedz  ed<   y)TokenPayloadNsubuser_idrole)	r
   r   r   r   r
   r   r   intr   r   r   r   r   r      s,    CtGS4ZD#*r   r   c                       e Zd ZU ded<   y)
TokenWithUserr   userN)r
   r   r   r   r   r   r   r   r      s    
Lr   r   N)	pydanticr   typingr   app.schemas.userr   r   r   r   r   r   r   <module>r      s5      %I 9 
E r   

--- END OF FILE: app/schemas/__pycache__/auth.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/__init__.cpython-312.pyc ---



    ͜1h                        d dl mZmZmZ d dlmZmZ d dlmZm	Z	m
Z
 d dlmZm
Z
 d dlmZmZ d dlmZ d dlmZ d dlmZ d d	lmZ d d
lmZ d dl mZmZ  ej2                           ej2                           ej2                          y)
   )User
UserCreateUserUpdateInternal)VerificationTokenVerificationTokenCreate)PasswordResetTokenCreateRequestPasswordResetRequestResetPasswordRequest)TokenTokenPayload)UserProfileUserProfileUpdate)organization)chat)Message)auth)
TokenWithUser)r   
UserDetailN)userr   r   r   verification_tokenr   r   password_reset_tokenr   r	   r
   tokenr   r   user_profiler
   r    r   r   messager   r   r   r   
model_rebuild     J/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/__init__.py<module>r       sX    6 6 J m m & 8       " 
        
   r   

--- END OF FILE: app/schemas/__pycache__/__init__.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/space.cpython-312.pyc ---



    U1h                        d dl mZmZ d dlmZmZmZ d dlmZ d dl m	Z	 d dl
m
Z
  G d de      Z G d d	e      Z G d
 de      Z
 G d d
e      Z G d de      Zeeef   Z G d de      Z G d dee      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d  d!e      Z G d" d#e      Z G d$ d%e      Z G d& d'e      Z G d( d)e      Zy*)+    )	BaseModelEmailStr)ListOptionalUnion)Enum)
ConfigDict)datetimec                   R    e Zd ZU eed<   dZee   ed<   eed<   eed<    e	d      Z
y)	BasicUseridN	full_nameemailroleTfrom_attributes)__name__
__module____qualname__int__annotations__r   r   strr   r	   model_config     G/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/space.pyr   r   	   s,    G#Ix}#O

ILr   r   c                   4    e Zd ZU eed<   eed<    ed      Zy)BasicStartupr
   nameTr   Nr   r   r   r   r   r   r	   r   r   r   r   r   r      s    G

I Lr   r   c                   4    e Zd ZU eed<   eed<    ed      Zy)
BasicSpacer
   r   Tr   Nr    r   r   r   r"   r"       s    G

Id3Lr   r"   c                   0    e Zd ZU dZeed<   eed<   eed<   y)StartupTenantInfostartuptypedetailsmember_countN)r   r   r   r&   r   r   r   r   r   r   r   r$   r$   %   s    D#
r   r$   c                   &    e Zd ZU dZeed<   eed<   y)FreelancerTenantInfo
freelancerr&   r'   N)r   r   r   r&   r   r   r   r   r   r   r*   r*   +   s    D#
r   r*   c                       e Zd ZU ee   ed<   y)SpaceTenantResponsetenantsN)r   r   r   r   
TenantInfor   r   r   r   r-   r-   2   s
    
*
r   r-   c                       e Zd ZdZdZdZy)WorkstationStatus	AVAILABLEOCCUPIEDMAINTENANCEN)r   r   r   r2   r3   r4   r   r   r   r1   r1   6   s    IHKr   r1   c                   6    e Zd ZU eed<   eed<    G d d      Zy)WorkstationAssignmentRequestuser_idworkstation_idc                       e Zd ZdZy)#WorkstationAssignmentRequest.ConfigTNr   r   r   orm_moder   r   r   Configr:   B       r   r=   Nr   r   r   r   r   r=   r   r   r   r6   r6   ;   s    
L
 r   r6   c                   J    e Zd ZU eed<   eed<   eed<   eed<    G d d      Zy)WorkstationAssignmentResponse
assignment_idr7   r8   space_idc                       e Zd ZdZy)$WorkstationAssignmentResponse.ConfigTNr;   r   r   r   r=   rE   N   r>   r   r=   Nr?   r   r   r   rA   rA   F   s"    
LM r   rA   c                   J    e Zd ZU eed<   ee   ed<   ee   ed<    ed      Z	y)WorkstationTenantInfor7   r   r   Tr   N)
r   r   r   r   r   r   r   r   r	   r   r   r   r   rG   rG   R   s+    
L}H Lr   rG   c                   ^    e Zd ZU eed<   eed<   eed<   eed<   dZee	   ed<    G d d      Z
y)	WorkstationDetailr
   r   statusrC   Noccupantc                       e Zd ZdZy)WorkstationDetail.ConfigTNr;   r   r   r   r=   rM   c   r>   r   r=   )r   r   r   r   r   r   r1   rK   r   rG   r=   r   r   r   rI   rI   \   s1    G

IM04Hh,-4 r   rI   c                       e Zd ZU ee   ed<   y)SpaceWorkstationListResponseworkstationsN)r   r   r   r   rI   r   r   r   r   rO   rO   f   s    ())r   rO   c                   ,    e Zd ZU eed<    G d d      Zy)WorkstationUnassignRequestr8   c                       e Zd ZdZy)!WorkstationUnassignRequest.ConfigTNr;   r   r   r   r=   rT   n   r>   r   r=   Nr?   r   r   r   rR   rR   i   s     r   rR   c                       e Zd ZU eed<   eed<   dZee   ed<   dZeed<   dZ	eed<   dZ
eed<   dZeed	<   dZee   ed
<    G d d      Z
y)
ManagedSpaceDetailr
   r   Naddressr   total_workstationsoccupied_workstationsavailable_workstationsmaintenance_workstations
company_idc                       e Zd ZdZy)ManagedSpaceDetail.ConfigTNr;   r   r   r   r=   r^   ~   r>   r   r=   )r   r   r   r   r   r   rW   r   rX   rY   rZ   r[   r\   r=   r   r   r   rV   rV   r   s`    G

I!GXc]!!"3""#C#$%c% !%J
$ r   rV   c                   ,    e Zd ZU eed<    G d d      Zy)WorkstationStatusUpdateRequestrJ   c                       e Zd ZdZy)%WorkstationStatusUpdateRequest.ConfigTNr;   r   r   r   r=   rb      r>   r   r=   N)r   r   r   r1   r   r=   r   r   r   r`   r`      s     r   r`   c                   0    e Zd ZU ee   ed<    ed      Zy)SpaceUsersListResponseusersTr   N)r   r   r   r   r   r   r	   r   r   r   r   rd   rd      s    	?Lr   rd   c                   *    e Zd ZU eed<    ed      Zy)SpaceConnectionStatsResponsetotal_connectionsTr   N)r   r   r   r   r   r	   r   r   r   r   rg   rg      s    d3Lr   rg   c                   >    e Zd ZU eed<   eed<   eed<    ed      Zy)UserWorkstationInfor8   workstation_nameassignment_start_dateTr   N)	r   r   r   r   r   r   r
   r	   r   r   r   r   rj   rj      s    ##d3Lr   rj   N)pydanticr   r   typingr   r   r   enumr   r	   r
   r   r   r"   r$   r*   r/   r-   r   r1   r6   rA   rG   rI   rO   rR   rV   r`   rd   rg   rj   r   r   r   <module>rp      s   ( ( (   	 9 4 4
	 9 
 $&::
;
)  T  
9 	I 	I 	 *9 * 
 
Y Y 49 4
4) 4r   

--- END OF FILE: app/schemas/__pycache__/space.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/message.cpython-312.pyc ---



    -hM                      &    d dl mZ  G d de      Zy)    )	BaseModelc                       e Zd ZU eed<   y)MessagemessageN)__name__
__module____qualname__str__annotations__     I/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/message.pyr   r      s    
Lr
   r   N)pydanticr   r   r   r
   r   <module>r      s    i r
   

--- END OF FILE: app/schemas/__pycache__/message.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/chat.cpython-312.pyc ---



    "h                        d dl m Z  d dlmZmZ d dlmZ ddlmZ  G d de      Z	 G d d	e	      Z
 G d
 de	      Z G d d
e      Z G d de      Z
 G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d de      Z G d  d!e      Z G d" d#e      Zy$)%    )datetime)OptionalList)	BaseModel   )Userc                       e Zd ZU eed<   y)ConversationParticipantBaseuser_idN)__name__
__module____qualname__int__annotations__     F/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/chat.pyr
   r
   	       
Lr   r
   c                       e Zd Zy)ConversationParticipantCreateNr   r
   r   r   r   r   r   r          r   r   c                        e Zd ZU eed<   ddiZy)ConversationParticipantSchemauserfrom_attributesTN)r   r
   r   
UserSchemar   model_configr   r   r   r   r      s    
4Lr   r   c                       e Zd Zy)ConversationBaseNr   r   r   r   r    r       r   r   r    c                       e Zd ZU ee   ed<   y)ConversationCreateparticipant_idsN)r   r
   r   r   r   r   r   r   r   r"   r"      s    #Yr   r"   c                   :    e Zd ZU eed<   eed<   ee   ed<   ddiZy)ConversationSchemaid
created_atparticipantsr   TN)	r   r
   r   r   r   r   r   r   r   r   r   r   r%   r%      s&    Gz"" 	4Lr   r%   c                       e Zd ZU eed<   y)MessageReactionBaseemojiNr   r
   r   strr   r   r   r   r*   r*   &   s    Jr   r*   c                       e Zd Zy)MessageReactionCreateNr   r   r   r   r/   r/   )   r   r   r/   c                   >    e Zd ZU eed<   eed<   eed<   eed<   ddiZy)MessageReactionResponser&   
message_idr   r'   r   TN)r   r
   r   r   r   r   r   r   r   r   r1   r1   ,   s%    GO
L
 	4Lr   r1   c                       e Zd ZU ee   ed<   y)MessageReactionsListResponse	reactionsN)r   r
   r   listr1   r   r   r   r   r4   r4   8   s    +,,r   r4   c                   |    e Zd ZU dZee   ed<   dZee   ed<   eed<   dZ	ee   ed<   dZ
ee   ed<   dZee   ed<   y)ChatMessageCreateNrecipient_idconversation_idcontentattachment_urlattachment_filenameattachment_mimetype)r   r
   r   r9   r   r   r   r:   r-   r<   r=   r>   r   r   r   r8   r8   >   sO    "&L(3-&%)OXc])
L$(NHSM()-#-)-#-r   r8   c                       e Zd ZU eed<   eed<   dZee   ed<   dZee   ed<   eed<   e	ed<   dZ
ee	   ed<   dZee	   ed	<   d
Ze
ed<   dZee   ed<   dZee   ed
<   dZee   ed<   y)ChatMessageBaser&   	sender_idNr9   r:   r;   r'   read_at
updated_atF
is_deletedr<   r=   r>   )r   r
   r   r   r   r9   r   r:   r-   r   rB   rC   rD   boolr<   r=   r>   r   r   r   r@   r@   G   s    GN"&L(3-&%)OXc])
L"&GXh
&%)J")J$(NHSM()-#-)-#-r   r@   c                   4    e Zd ZU eed<   g Zee   ed<   ddiZy)ChatMessageSchemasenderr5   r   TN)	r   r
   r   r   r   r5   r   r1   r   r   r   r   rG   rG   V   s&    /1It+,1 	4Lr   rG   c                       e Zd ZU eed<   y)ChatMessageUpdater;   Nr,   r   r   r   rJ   rJ   _   r   r   rJ   c                   H    e Zd ZU eed<   eed<   dZee   ed<   e	ed<   ddiZ
y)ConversationInfor&   
other_userNlast_messagehas_unread_messagesr   T)r   r
   r   r   r   r   rN   r   rG   rE   r   r   r   r   rL   rL   c   s1    G04L(,-4 	4Lr   rL   N)r   typingr   r   pydanticr   r   r   r   r
   r   r   r    r"   r%   r*   r/   r1   r4   r8   r@   rG   rJ   rL   r   r   r   <module>rR      s     !  %) 	$? 	$? 	y 	) ) ) 	/ 	
1 
-9 -.	 ..i . 	 y r   

--- END OF FILE: app/schemas/__pycache__/chat.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/schemas/__pycache__/user_profile.cpython-312.pyc ---



    w\h                     v    d dl mZmZmZ d dlmZmZ d dlmZ  G d de      Z	 G d de	      Z
 G d d	e	      Zy
)    )	BaseModelHttpUrl
ConfigDict)OptionalList)ContactVisibilityc                      e Zd ZU dZee   ed<   dZee   ed<   ej                  Z
ee   ed<   dZeee      ed<   dZ
eee      ed<   dZee   ed<   dZeee      ed<   dZeee      ed	<   dZee   ed
<   dZee   ed<   y)UserProfileBaseNtitlebiocontact_info_visibilityskills_expertiseindustry_focusproject_interests_goalscollaboration_preferencestools_technologieslinkedin_profile_urlprofile_picture_url)__name__
__module____qualname__r   r   str__annotations__r   r   CONNECTIONSr
   r   r   r   r   r   r   r   r   r        N/home/marcel/ShareYourSpace/shareyourspace-backend/app/schemas/user_profile.pyr
   r
      s    E8C=C#;L;X;XX&78X,0htCy)0*.NHT#Y'.-1Xc]159xS	29.2c+2.2(7+2)-#-r   r
   c                       e Zd Zy)UserProfileUpdateN)r   r   r   r   r   r   r   r      s    r   r   c                   \    e Zd ZU eed<   eed<   dZee   ed<   dZee   ed<    e	d      Z
y)UserProfileiduser_idN	full_nameprofile_picture_signed_urlT)from_attributes)r   r   r   intr   r$   r   r   r%   r   model_configr   r   r   r!   r!      s8    G
L#Ix}#04
4 Lr   r!   N)pydanticr   r   r   typingr   r   app.models.enumsr   r
   r   r!   r   r   r   <module>r,      s5    3 3 ! .
.i 
.	 		/ 	r   

--- END OF FILE: app/schemas/__pycache__/user_profile.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/user.py ---

from sqlalchemy import Boolean, Column, Integer, String, DateTime, func, ForeignKey
from sqlalchemy.orm import relationship
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from .space import SpaceNode, Workstation # noqa: F401
    from .organization import Company, Startup # noqa: F401
    from .chat import Conversation # noqa: F401
    from .space import WorkstationAssignment # Add this import for type hinting

from app.db.base_class import Base
from .profile import UserProfile


class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String, unique=True, index=True, nullable=False)
    hashed_password = Column(String, nullable=False)
    full_name = Column(String, index=True, nullable=True)
    # e.g., 'SYS_ADMIN', 'CORP_ADMIN', 'CORP_EMPLOYEE', 'STARTUP_ADMIN', 'STARTUP_MEMBER', 'FREELANCER'
    role = Column(String, nullable=False)
    # e.g., 'PENDING_VERIFICATION', 'WAITLISTED', 'PENDING_ONBOARDING', 'ACTIVE', 'SUSPENDED', 'BANNED'
    status = Column(String, nullable=False, index=True)
    is_active = Column(Boolean, default=False)
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())

    # Added ForeignKeys and Relationships
    company_id = Column(Integer, ForeignKey("companies.id"), nullable=True)
    startup_id = Column(Integer, ForeignKey("startups.id"), nullable=True)

    company = relationship("Company", back_populates="members")
    startup = relationship("Startup", back_populates="members")

    # One-to-one relationship to UserProfile
    profile = relationship(
        "app.models.profile.UserProfile", 
        back_populates="user", 
        uselist=False, 
        cascade="all, delete-orphan",
        remote_side=[UserProfile.user_id]
    )

    # Relationships for tokens (if they exist)
    verification_tokens = relationship("VerificationToken", back_populates="user")
    password_reset_tokens = relationship("PasswordResetToken", back_populates="user")

    space_id = Column(Integer, ForeignKey('spacenodes.id'), nullable=True, index=True)
    # Temporarily removed until PromoCode model exists
    # applied_promo_code_id = Column(Integer, ForeignKey('promocodes.id'), nullable=True)

    # Relationships
    # Relationship to the SpaceNode this user manages (if they are a Corp Admin)
    # Corresponds to `admin = relationship("User", back_populates="managed_space")` in SpaceNode
    # Explicitly state the foreign key to resolve ambiguity
    managed_space = relationship(
        "SpaceNode", 
        foreign_keys="[SpaceNode.corporate_admin_id]", 
        back_populates="admin", 
        uselist=False
    )

    # Relationship to the SpaceNode this user BELONGS TO
    # Uses the space_id foreign key on this User model
    space = relationship(
        "SpaceNode", 
        foreign_keys=[space_id],
        back_populates="users"
    )

    # Relationship to WorkstationAssignments
    assignments = relationship("WorkstationAssignment", back_populates="user", cascade="all, delete-orphan")

    # Define relationships for Company/Startup Admins/Members if needed
    # company = relationship("Company", back_populates="admin")
    # startup = relationship("Startup", back_populates="admin")
    # member_of_company = relationship("Company", secondary="user_company_association", back_populates="members")
    # member_of_startup = relationship("Startup", secondary="user_startup_association", back_populates="members")

    # Placeholder for Verification/Reset Tokens relationships if needed for cascade delete etc.
    # verification_tokens = relationship("VerificationToken", back_populates="user", cascade="all, delete-orphan")
    # password_reset_tokens = relationship("PasswordResetToken", back_populates="user", cascade="all, delete-orphan")

    # Relationships for Referrals
    # referrals_made = relationship("Referral", foreign_keys="[Referral.referrer_id]", back_populates="referrer", cascade="all, delete-orphan")
    # referral_received = relationship("Referral", foreign_keys="[Referral.referred_user_id]", back_populates="referred_user", uselist=False)

    # Relationships for Blocks/Reports
    # blocks_made = relationship("Block", foreign_keys="[Block.blocker_id]", back_populates="blocker", cascade="all, delete-orphan")
    # blocks_received = relationship("Block", foreign_keys="[Block.blocked_user_id]", back_populates="blocked_user", cascade="all, delete-orphan")
    # reports_made = relationship("Report", foreign_keys="[Report.reporter_id]", back_populates="reporter", cascade="all, delete-orphan")
    # reports_received = relationship("Report", foreign_keys="[Report.reported_user_id]", back_populates="reported_user")

    # Define relationships for connections
    sent_connections = relationship("Connection", foreign_keys="Connection.requester_id", back_populates="requester")
    received_connections = relationship("Connection", foreign_keys="Connection.recipient_id", back_populates="recipient")

    # Relationship for Conversations (many-to-many via ConversationParticipant)
    conversations = relationship(
        "Conversation", # String name of the related model
        secondary="conversation_participants", # Name of the association table
        back_populates="participants" # Name of the relationship on the Conversation model
    ) 

--- END OF FILE: app/models/user.py ---

================================================================================

--- START OF FILE: app/models/space.py ---

from sqlalchemy import Column, Integer, String, ForeignKey, DateTime, func, Enum as SQLAlchemyEnum, and_
from sqlalchemy.orm import relationship, foreign, remote
from sqlalchemy.ext.hybrid import hybrid_property

from app.db.base_class import Base
# Ensure User model is available for ForeignKey reference
from .user import User # Adjust import if User model is elsewhere
from .organization import Company # Assuming Company model is here

# Enum for Workstation Status
from app.schemas.space import WorkstationStatus # For status values

class SpaceNode(Base):
    __tablename__ = 'spacenodes' # Using plural table name convention

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, index=True, nullable=False)
    address = Column(String, nullable=True) # Renamed from location_description, or added
    # Allow corporate_admin_id to be NULL initially or for generic spaces
    corporate_admin_id = Column(Integer, ForeignKey('users.id'), nullable=True) 
    company_id = Column(Integer, ForeignKey('companies.id'), nullable=True) # Added company link
    # total_workstations can be a derived property or removed if workstations are counted dynamically
    # For now, let's keep it as a potential field if it's set manually, or remove if it causes sync issues.
    # total_workstations = Column(Integer, nullable=False, default=0) 
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())

    # Relationship to the Corporate Admin (User) - One SpaceNode belongs to one Admin User
    # Explicitly state the foreign key to resolve ambiguity
    admin = relationship(
        "User", 
        foreign_keys=[corporate_admin_id], # Specify the FK column from this model
        back_populates="managed_space"
    )
    company = relationship("Company", back_populates="spaces") # Add relationship to Company

    # Relationship to Workstations - One SpaceNode has many Workstations
    workstations = relationship("Workstation", back_populates="space_node", cascade="all, delete-orphan")

    # Relationship to Users belonging to this SpaceNode
    # Corresponds to `space = relationship(...)` in User model
    users = relationship("User", back_populates="space", foreign_keys="[User.space_id]")
    assignments = relationship("WorkstationAssignment", back_populates="space_node", cascade="all, delete-orphan")

    # Relationship to Startups in this SpaceNode
    startups = relationship("Startup", back_populates="space", cascade="all, delete-orphan")

class Workstation(Base):
    __tablename__ = 'workstations'

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, nullable=False, index=True, default="Workstation") # Added name
    space_id = Column(Integer, ForeignKey('spacenodes.id'), nullable=False)
    # Status field now uses the Enum from schemas for consistency in values
    status = Column(SQLAlchemyEnum(WorkstationStatus, name="workstation_status_enum"), 
                    default=WorkstationStatus.AVAILABLE, 
                    nullable=False, 
                    index=True)
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())

    # Relationship to SpaceNode - Many Workstations belong to one SpaceNode
    space_node = relationship("SpaceNode", back_populates="workstations")

    # All assignments for this workstation (history)
    assignments = relationship("WorkstationAssignment", back_populates="workstation", cascade="all, delete-orphan", lazy="selectin")

    # Relationship for the current, active assignment (if any)
    # This is what `selectinload(models.Workstation.active_assignment)` will use.
    active_assignment = relationship(
        "WorkstationAssignment",
        primaryjoin=lambda: and_(
            Workstation.id == remote(WorkstationAssignment.workstation_id),
            remote(WorkstationAssignment.end_date).is_(None)
        ),
        uselist=False, # one-to-one nature for an *active* assignment
        viewonly=True, # This relationship is for reading the current state
        lazy='selectin' # Efficient loading
    )

class WorkstationAssignment(Base):
    __tablename__ = 'workstation_assignments'

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey('users.id'), nullable=False)
    workstation_id = Column(Integer, ForeignKey('workstations.id'), nullable=False)
    space_id = Column(Integer, ForeignKey('spacenodes.id'), nullable=False) # Denormalized for easier queries
    
    start_date = Column(DateTime, default=func.now(), nullable=False)
    end_date = Column(DateTime, nullable=True) # Null if currently active

    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())

    # Who created the assignment (optional, e.g. a Corp Admin user)
    # created_by_id = Column(Integer, ForeignKey('users.id'), nullable=True)

    user = relationship("User", back_populates="assignments") # Changed from assigned_workstations
    workstation = relationship("Workstation", back_populates="assignments", foreign_keys=[workstation_id])
    space_node = relationship("SpaceNode", back_populates="assignments")
    # created_by = relationship("User", foreign_keys=[created_by_id])


# Need to update User model to have:
# managed_space = relationship("SpaceNode", back_populates="admin", foreign_keys="[SpaceNode.corporate_admin_id]", uselist=False)
# space = relationship("SpaceNode", back_populates="users", foreign_keys="[User.space_id]")
# assignments = relationship("WorkstationAssignment", back_populates="user")
# (and remove assigned_workstation if it was there) 

--- END OF FILE: app/models/space.py ---

================================================================================

--- START OF FILE: app/models/connection.py ---

import enum # Add enum import
from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, UniqueConstraint, func, Enum as SqlEnum # Add SqlEnum import
from sqlalchemy.orm import relationship

from app.db.base_class import Base
from app.models.user import User # Import User for relationships

# Define the ConnectionStatus Enum
class ConnectionStatus(str, enum.Enum):
    PENDING = "pending"
    ACCEPTED = "accepted"
    DECLINED = "declined"
    BLOCKED = "blocked"

class Connection(Base):
    __tablename__ = "connections"

    id = Column(Integer, primary_key=True, index=True)
    requester_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    recipient_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    # Use the Enum for the status column
    status = Column(SqlEnum(ConnectionStatus), nullable=False, default=ConnectionStatus.PENDING, index=True)
    created_at = Column(DateTime, default=func.now())
    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())

    # Relationships to User
    requester = relationship("User", foreign_keys=[requester_id]) # Add backref in User model if needed
    recipient = relationship("User", foreign_keys=[recipient_id]) # Add backref in User model if needed

    # Ensure a user can only send one request to another user
    __table_args__ = (UniqueConstraint('requester_id', 'recipient_id', name='_requester_recipient_uc'),) 

--- END OF FILE: app/models/connection.py ---

================================================================================

--- START OF FILE: app/models/organization.py ---

from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey
from sqlalchemy.orm import relationship, Mapped
from sqlalchemy.sql import func
from typing import TYPE_CHECKING, List

from app.db.base_class import Base

if TYPE_CHECKING:
    from .user import User # noqa F401
    from .space import SpaceNode # Add this import for type hinting
    from .invitation import Invitation # Import Invitation for relationship

class Company(Base):
    __tablename__ = 'companies'

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, index=True, nullable=False)
    logo_url = Column(String, nullable=True)
    industry_focus = Column(String, nullable=True) # Consider ARRAY(String) later if multiple needed
    description = Column(Text, nullable=True)
    website = Column(String, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())

    # Relationship to Users (Employees + Admin)
    members = relationship("User", back_populates="company")

    # Relationship to SpaceNodes managed/owned by this company
    spaces = relationship("SpaceNode", back_populates="company")

class Startup(Base):
    __tablename__ = 'startups'

    id = Column(Integer, primary_key=True, index=True)
    name = Column(String, index=True, nullable=False)
    logo_url = Column(String, nullable=True)
    industry_focus = Column(String, nullable=True) # Consider ARRAY(String) later if multiple needed
    description = Column(Text, nullable=True)
    mission = Column(Text, nullable=True)
    website = Column(String, nullable=True)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())

    # Foreign Key to SpaceNode
    space_id = Column(Integer, ForeignKey("spacenodes.id"), nullable=False, index=True)

    # Relationship to SpaceNode
    space = relationship("SpaceNode", back_populates="startups")

    # Relationship to Users (Members + Admin)
    members = relationship("User", back_populates="startup")

    # Relationship to Invitations sent by this startup
    invitations: Mapped[List["Invitation"]] = relationship("Invitation", back_populates="startup", cascade="all, delete-orphan") 

--- END OF FILE: app/models/organization.py ---

================================================================================

--- START OF FILE: app/models/profile.py ---

from sqlalchemy import Column, Integer, String, Text, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import relationship
from sqlalchemy.dialects.postgresql import ARRAY
from pgvector.sqlalchemy import Vector

from app.db.base_class import Base
# Import the enum from the new location
from .enums import ContactVisibility

# REMOVED Enum definition from here
# import enum
# class ContactVisibility(str, enum.Enum):
#     PRIVATE = "private"
#     CONNECTIONS = "connections"
#     PUBLIC = "public"

class UserProfile(Base):
    __tablename__ = "user_profiles"
    # Add extend_existing=True to handle potential double registration
    __table_args__ = {'extend_existing': True}

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), unique=True, index=True, nullable=False)

    title = Column(String, nullable=True)
    bio = Column(Text, nullable=True)
    # Use the imported enum
    contact_info_visibility = Column(SQLEnum(ContactVisibility, name="contact_visibility_enum", create_type=False), nullable=False, default=ContactVisibility.CONNECTIONS)
    # Add other fields back based on schema and embedding logic (ensure ARRAY is imported)
    skills_expertise = Column(ARRAY(String), nullable=True)
    industry_focus = Column(ARRAY(String), nullable=True)
    project_interests_goals = Column(Text, nullable=True)
    collaboration_preferences = Column(ARRAY(String), nullable=True)
    tools_technologies = Column(ARRAY(String), nullable=True)
    linkedin_profile_url = Column(String, nullable=True)
    profile_picture_url = Column(String, nullable=True)
    profile_vector = Column(Vector(768), nullable=True)

    # Relationship back to User (one-to-one)
    # Add explicit foreign_keys based on the FK defined in this model
    user = relationship(
        "app.models.user.User", 
        foreign_keys=[user_id], # Specify FK column from this model
        back_populates="profile"
    )

    # Add other profile fields here as defined in Step 2.3

--- END OF FILE: app/models/profile.py ---

================================================================================

--- START OF FILE: app/models/__init__.py ---

# Import the Base class to make it accessible for models
# and for Alembic discovery via Base.metadata
from app.db.base_class import Base  # noqa: F401

# Models will be discovered by Alembic via Base.metadata
# and should be imported explicitly where needed in the application code,
# not necessarily via this __init__.py.

# However, sometimes explicit imports here ARE needed for relationship setup
# across files before the full app loads. Let's restore necessary ones carefully.

from .user import User # Needed by other models/routers
from .organization import Company, Startup # Needed by User
from .space import SpaceNode, Workstation, WorkstationAssignment # Needed by User?
from .profile import UserProfile # Import the CORRECT profile model
from .connection import Connection # Needed by User
from .notification import Notification # Needed by routers?
from .password_reset_token import PasswordResetToken # Needed by auth?
from .verification_token import VerificationToken # Needed by auth?
from .enums import ContactVisibility # Needed by profile model/schema
from .chat import ChatMessage # Add ChatMessage model import
from .invitation import Invitation, InvitationStatus # Add this line

# You can also import all your models here later so Alembic can find them
# e.g., from .item import Item 

# Optional: if you want to define a __all__ for explicit exports
__all__ = [
    "User",
    "Role",
    "UserRoleLink", 
    "Organization", 
    "OrganizationMember",
    "Startup",
    "Company",
    "Space",
    "Workstation",
    "WorkstationAssignment",
    "Notification",
    "Profile",
    "UserInterest",
    "Skill",
    "UserProfileSkillLink",
    "PasswordResetToken",
    "VerificationToken",
    "Message",
    "MessageReaction",
    "ChatRoom",
    "ChatRoomMember",
    "Connection",
    "ConnectionRequest",
    "Invitation", # Add this line
    "InvitationStatus", # Add this line
    # Enums if they are defined in separate files and imported here, or directly if here.
    "OrganizationRole",
    "UserStatus",
    "SpaceStatus",
    "WorkstationStatus",
    "NotificationType", 
    "NotificationStatus",
    "UserChatRoomRole"
] 

--- END OF FILE: app/models/__init__.py ---

================================================================================

--- START OF FILE: app/models/verification_token.py ---

import sqlalchemy as sa
from sqlalchemy.orm import relationship
from datetime import datetime, timedelta, timezone

from app.db.base_class import Base

class VerificationToken(Base):
    __tablename__ = 'verification_tokens'

    id: int = sa.Column(sa.Integer, primary_key=True, index=True)
    user_id: int = sa.Column(sa.Integer, sa.ForeignKey('users.id'), nullable=False)
    token: str = sa.Column(sa.String, unique=True, index=True, nullable=False)
    expires_at: datetime = sa.Column(sa.DateTime(timezone=True), nullable=False)
    created_at: datetime = sa.Column(sa.DateTime(timezone=True), default=lambda: datetime.now(timezone.utc))

    user = relationship("User")

    @staticmethod
    def get_default_expiry() -> datetime:
        return datetime.now(timezone.utc) + timedelta(hours=1) # Token valid for 1 hour 

--- END OF FILE: app/models/verification_token.py ---

================================================================================

--- START OF FILE: app/models/password_reset_token.py ---

import secrets
from datetime import datetime, timedelta, timezone
from sqlalchemy import Column, Integer, String, DateTime, ForeignKey
from sqlalchemy.orm import relationship

from app.db.base_class import Base

class PasswordResetToken(Base):
    __tablename__ = "password_reset_tokens"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), nullable=False)
    token = Column(String, unique=True, index=True, nullable=False)
    expires_at = Column(DateTime(timezone=True), nullable=False)

    user = relationship("User") # Optional relationship back to User

    @staticmethod
    def get_default_expiry() -> datetime:
        """Returns the default expiration time for a token (e.g., 1 hour from now)."""
        return datetime.now(timezone.utc) + timedelta(hours=1)

    @staticmethod
    def generate_token() -> str:
         """Generates a secure random token."""
         return secrets.token_urlsafe(32) 

--- END OF FILE: app/models/password_reset_token.py ---

================================================================================

--- START OF FILE: app/models/enums.py ---

import enum

class ContactVisibility(str, enum.Enum):
    PRIVATE = "private"
    CONNECTIONS = "connections"
    PUBLIC = "public"

# Add other enums here as needed, e.g.:
# class UserRole(str, enum.Enum):
#     ADMIN = "admin"
#     USER = "user" 

--- END OF FILE: app/models/enums.py ---

================================================================================

--- START OF FILE: app/models/notification.py ---

from sqlalchemy import Column, Integer, String, Boolean, DateTime, ForeignKey
from sqlalchemy.sql import func
from sqlalchemy.orm import relationship

from app.db.base_class import Base

class Notification(Base):
    __tablename__ = 'notifications'

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), nullable=False, index=True) # Recipient
    type = Column(String, index=True, nullable=False) # e.g., 'connection_request', 'connection_accepted', 'new_chat_message'
    message = Column(String, nullable=False)
    is_read = Column(Boolean, default=False, nullable=False)
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    # Optional fields for linking and grouping
    related_entity_id = Column(Integer, index=True, nullable=True) # e.g., connection.id, message.id (kept for potential legacy use)
    reference = Column(String, index=True, nullable=True) # e.g., 'connection:<id>', 'conversation:<id>'
    link = Column(String, nullable=True) # e.g., '/profile/123', '/chat?conversationId=456'

    # Relationship back to the user (optional, but can be useful)
    user = relationship("User") 

--- END OF FILE: app/models/notification.py ---

================================================================================

--- START OF FILE: app/models/chat.py ---

from sqlalchemy import Column, Integer, Text, ForeignKey, DateTime, func, String, UniqueConstraint, Boolean
from sqlalchemy.orm import relationship

from app.db.base_class import Base
# Assuming User model is in app.models.user
# Adjust import if needed
from app.models.user import User


class Conversation(Base):
    __tablename__ = "conversations"
    id = Column(Integer, primary_key=True, index=True)
    created_at = Column(DateTime, default=func.now())
    # participants relationship (many-to-many via ConversationParticipant)
    participants = relationship("User", secondary="conversation_participants", back_populates="conversations")
    messages = relationship("ChatMessage", back_populates="conversation", order_by="ChatMessage.created_at")

class ConversationParticipant(Base):
    __tablename__ = "conversation_participants"
    conversation_id = Column(Integer, ForeignKey("conversations.id", ondelete="CASCADE"), primary_key=True)
    user_id = Column(Integer, ForeignKey("users.id", ondelete="CASCADE"), primary_key=True)
    joined_at = Column(DateTime(timezone=True), server_default=func.now())
    # New field to track when the user last read messages in this conversation
    last_read_at = Column(DateTime(timezone=True), nullable=True)

    user = relationship("User", overlaps="conversations,participants")
    conversation = relationship("Conversation", overlaps="conversations,participants")


class ChatMessage(Base):
    __tablename__ = "chat_messages"

    id = Column(Integer, primary_key=True, index=True)
    
    # Option 1: Direct message fields (simpler for 1-on-1, might be removed if Conversation model is primary)
    sender_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    recipient_id = Column(Integer, ForeignKey("users.id"), nullable=True) # Nullable if using conversation_id primarily
    
    # Option 2: Link to a conversation (better for group chats and cleaner for 1-on-1 too)
    conversation_id = Column(Integer, ForeignKey("conversations.id"), nullable=True) # Made nullable for now, can be false if we enforce conversations for all messages

    content = Column(Text, nullable=False)
    created_at = Column(DateTime, default=func.now())
    read_at = Column(DateTime, nullable=True)

    # New fields for edit/delete
    updated_at = Column(DateTime(timezone=True), nullable=True) # Stores timestamp of last edit
    is_deleted = Column(Boolean, default=False, nullable=False) # Flag for soft deletion

    # Attachment fields
    attachment_url = Column(String, nullable=True)
    attachment_filename = Column(String, nullable=True)
    attachment_mimetype = Column(String, nullable=True) # e.g., 'image/jpeg', 'application/pdf'

    sender = relationship("User", foreign_keys=[sender_id], backref="sent_messages")
    recipient = relationship("User", foreign_keys=[recipient_id], backref="received_messages") # This backref might need adjustment if using conversations primarily
    
    conversation = relationship("Conversation", back_populates="messages", foreign_keys=[conversation_id])
    reactions = relationship(
        "MessageReaction",
        back_populates="message",
        cascade="all, delete-orphan"
    )

class MessageReaction(Base):
    __tablename__ = "message_reactions"
    id = Column(Integer, primary_key=True, index=True)
    message_id = Column(Integer, ForeignKey("chat_messages.id"), nullable=False)
    user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    emoji = Column(String, nullable=False)
    created_at = Column(DateTime, default=func.now())

    # Ensure a user can only react with a given emoji once per message
    __table_args__ = (UniqueConstraint('message_id', 'user_id', 'emoji', name='_message_user_emoji_uc'),)

    message = relationship("ChatMessage", back_populates="reactions")
    user = relationship("User") 

--- END OF FILE: app/models/chat.py ---

================================================================================

--- START OF FILE: app/models/invitation.py ---

import enum
from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, Enum as SQLEnum, Text
from sqlalchemy.orm import relationship, Mapped, mapped_column
from app.db.base_class import Base
from datetime import datetime, timedelta
import uuid
from typing import TYPE_CHECKING, Optional
from app.models.user import User # Ensure User is imported for relationships

if TYPE_CHECKING: # Add this for type hinting if not already present
    from .organization import Startup # For relationship type hint

class InvitationStatus(str, enum.Enum):
    PENDING = "pending"
    ACCEPTED = "accepted"
    EXPIRED = "expired"
    REVOKED = "revoked"
    DECLINED = "declined" # New status
    # Consider DECLINED if users can explicitly decline

class Invitation(Base):
    __tablename__ = "invitations"

    id: Mapped[int] = mapped_column(Integer, primary_key=True, index=True)
    email: Mapped[str] = mapped_column(String, index=True, nullable=False)
    
    # Foreign key to the startup (Startup table) that is inviting the user
    startup_id: Mapped[int] = mapped_column(ForeignKey("startups.id"), nullable=False)
    startup: Mapped["Startup"] = relationship(back_populates="invitations")

    invitation_token: Mapped[str] = mapped_column(String, unique=True, index=True, nullable=False, default=lambda: str(uuid.uuid4()))
    status: Mapped[InvitationStatus] = mapped_column(SQLEnum(InvitationStatus, name='invitationstatus', create_type=False), default=InvitationStatus.PENDING, nullable=False)
    
    expires_at: Mapped[datetime] = mapped_column(DateTime, nullable=False, default=lambda: datetime.utcnow() + timedelta(days=7)) # Default 7 days expiry
    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)
    updated_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # New fields for tracking approval and acceptance
    approved_by_admin_id: Mapped[Optional[int]] = mapped_column(ForeignKey("users.id"), nullable=True)
    approved_by_admin: Mapped[Optional["User"]] = relationship(foreign_keys=[approved_by_admin_id])

    accepted_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
    accepted_by_user_id: Mapped[Optional[int]] = mapped_column(ForeignKey("users.id"), nullable=True)
    accepted_by_user: Mapped[Optional["User"]] = relationship(foreign_keys=[accepted_by_user_id])

    # Admin who revoked this invitation
    revoked_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
    revoked_by_admin_id: Mapped[Optional[int]] = mapped_column(ForeignKey("users.id"), nullable=True)
    revoked_by_admin: Mapped[Optional["User"]] = relationship(foreign_keys=[revoked_by_admin_id])

    # New fields for declining
    declined_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
    decline_reason: Mapped[Optional[str]] = mapped_column(Text, nullable=True) # Using Text for potentially longer reasons

    def __repr__(self):
        return f"<Invitation(id={self.id}, email='{self.email}', status='{self.status}')>" 

--- END OF FILE: app/models/invitation.py ---

================================================================================

--- START OF FILE: app/models/__pycache__/password_reset_token.cpython-312.pyc ---



    eh                     j    d dl Z d dlmZmZmZ d dlmZmZmZmZm	Z	 d dl
mZ d dlm
Z
  G d de
      Zy)    N)datetime	timedeltatimezone)ColumnIntegerStringDateTime
ForeignKey)relationship)Basec                       e Zd ZdZ eedd      Z ee edd      d      Z ee	ddd	      Z
 e ed
      d      Z e
d      Zedefd
       Zedefd       Zy)PasswordResetTokenpassword_reset_tokensT)primary_keyindexzusers.idCASCADE)ondeleteF)nullable)uniquer   r   )r   Userreturnc                  b    t        j                  t        j                        t	        d      z   S )zHReturns the default expiration time for a token (e.g., 1 hour from now).   )hours)r   nowr   utcr        U/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/password_reset_token.pyget_default_expiryz%PasswordResetToken.get_default_expiry   s!     ||HLL)IA,>>>r   c                  ,    t        j                  d      S )z Generates a secure random token.    )secrets
token_urlsafer   r   r   generate_tokenz!PasswordResetToken.generate_token   s     %%b)	)r   N)__name__
__module____qualname__
__tablename__r   r   idr
   user_idr   tokenr	   
expires_atr   userstaticmethodr   r    strr%   r   r   r   r   r      s    +M	T	6BWjiHSXYG6$dUCE$/%@JD? ? ? *C * *r   r   )r#   r   r   r   
sqlalchemyr   r   r   r	   r
   sqlalchemy.ormr   app.db.base_classr   r   r   r   r   <module>r4      s&     2 2 D D ' "* *r   

--- END OF FILE: app/models/__pycache__/password_reset_token.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/connection.cpython-312.pyc ---



    h                         d dl Z d dlmZmZmZmZmZmZmZm	Z
 d dlmZ d dl
mZ d dlmZ  G d dee j                        Z G d d	e      Zy)
    N)ColumnIntegerStringDateTime
ForeignKeyUniqueConstraintfuncEnum)relationship)Base)Userc                       e Zd ZdZdZdZdZy)ConnectionStatuspendingaccepteddeclinedblockedN)__name__
__module____qualname__PENDINGACCEPTEDDECLINEDBLOCKED     K/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/connection.pyr   r   	   s    GHHGr   r   c                   j   e Zd ZdZ eedd      Z ee ed      d      Z ee ed      d      Z	 e e
e      dej                  d      Z
 ee ej                                Z ee ej                           ej                          	      Z ed
eg      Z ed
e	g      Z edd
d      fZy)
ConnectionconnectionsT)primary_keyindexzusers.idF)nullable)r#   defaultr"   )r$   )r$   onupdater
   )foreign_keysrequester_idrecipient_id_requester_recipient_uc)nameN)r   r   r   
__tablename__r   r   idr   r'   r(   SqlEnumr   r   statusr   r	   now
created_at
updated_atr   	requester	recipientr   __table_args__r   r   r   r   r      s    !M	T	6B':j#9EJL':j#9EJL
G,-GWG_G_gk
lF($((*5J($((*xtxxzJJ V<.AIV<.AI '~~LefhNr   r   )enum
sqlalchemyr   r   r   r   r   r   r	   r
   r-   sqlalchemy.ormr   app.db.base_classr   app.models.userr
   strr   r   r   r   r   <module>r;      s:     m m m ' "  sDII i ir   

--- END OF FILE: app/models/__pycache__/connection.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/notification.cpython-312.pyc ---



    '"h                     ^    d dl mZmZmZmZmZmZ d dlmZ d dl	m
Z
 d dlmZ  G d de      Z
y)    )ColumnIntegerStringBooleanDateTime
ForeignKey)func)relationship)Basec                      e Zd ZdZ eedd      Z ee ed      dd      Z ee	dd      Z
 ee	d      Z eedd	      Z
 e ed
       ej                                Z eedd      Z ee	dd      Z ee	d      Z ed      Zy
)Notification
notificationsT)primary_keyindexzusers.idF)nullabler   )r   r   )r   )defaultr   )timezone)server_defaultUserN)__name__
__module____qualname__
__tablename__r   r   idr   user_idr   typemessager   is_readr   r	   now
created_atrelated_entity_id	referencelinkr
   user     M/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/notification.pyr
   r
      s    #M	T	6BWj4uDQG&u5DVe,GWee<G$/
KJ wdTBvTD9I&4(D Dr&   r
   N)
sqlalchemyr   r   r   r   r   r   sqlalchemy.sqlr	   sqlalchemy.ormr
   app.db.base_classr   r
   r%   r&   r'   <module>r,      s     M M  ' " 4  r&   

--- END OF FILE: app/models/__pycache__/notification.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/invitation.cpython-312.pyc ---



    z1h                         d dl Z d dlmZmZmZmZmZmZm	Z	 d dl
mZmZm
Z
 d dlmZ d dlmZmZ d dlZd dlmZmZ d dlmZ erdd	lmZ  G d
 dee j                        Z G d d
e      Zy)    N)ColumnIntegerStringDateTime
ForeignKeyEnumText)relationshipMapped
mapped_column)Base)datetime	timedelta)
TYPE_CHECKINGOptional)User   )Startupc                        e Zd ZdZdZdZdZdZy)InvitationStatuspendingacceptedexpiredrevokeddeclinedN)__name__
__module____qualname__PENDINGACCEPTEDEXPIREDREVOKEDDECLINED     K/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/invitation.pyr   r   
   s    GHGGHr%   r   c                      e Zd ZU dZ eedd      Zee   e	d<    ee
dd      Zee   e	d<    e e
d      d	      Zee   e	d
<    ed      Zed   e	d
<    ee
dddd       Zee   e	d<    e ee      ej(                  d      Zee   e	d<    eedd       Zee   e	d<    eeej2                        Zee   e	d<    eeej2                  ej2                        Zee   e	d<    e e
d      d	      Zeee      e	d<    eeg      Zeed      e	d<    eed	      Zeee      e	d<    e e
d      d	      Z eee      e	d <    ee g      Z!eed      e	d!<    eed	      Z"eee      e	d"<    e e
d      d	      Z#eee      e	d#<    ee#g      Z$eed      e	d$<    eed	      Z%eee      e	d%<    ee&d	      Z'eee      e	d&<   d' Z(y())
InvitationinvitationsT)primary_keyindexidF)r+   nullableemailzstartups.id)r-   
startup_id)back_populatesr   startupc                  <    t        t        j                               S )N)struuiduuid4r$   r%   r&   <lambda>zInvitation.<lambda>   s&    svw{  xB  xB  xD  tE r%   )uniquer+   r-   defaultinvitation_token)r8   r-   statusc                  D    t        j                         t        d      z   S )N   )days)r   utcnowr   r$   r%   r&   r6   zInvitation.<lambda>"   s$    [c[j[j[lox~  pA  \A r%   )r-   r8   
expires_at)r8   
created_at)r8   onupdate
updated_atzusers.idapproved_by_admin_id)foreign_keysr   approved_by_adminaccepted_ataccepted_by_user_idaccepted_by_user
revoked_atrevoked_by_admin_idrevoked_by_admindeclined_atdecline_reasonc                 V    d| j                    d| j                   d| j                   dS )Nz<Invitation(id=z	, email='z', status='z')>)r,   r.   r:   )selfs    r&   __repr__zInvitation.__repr__7   s*     	4::,k$++VYZZr%   N))r   r   r   
__tablename__r   r   r,   r   int__annotations__r   r.   r3   r   r/   r
   r1   r9   SQLEnumr   r   r:   r   r?   r   r>   r@   rB   rC   r   rE   rF   rG   rH   rI   rJ   rK   rL   r	   rM   rP   r$   r%   r&   r(   r(      sT   !M#GTJBsJ&vTEJE6#;J ,J},EPUVJsV!-]!KGVI
K$1&T\a  lE  %FfSk  F'4W=M5NXhXpXp  |A  (BFF#$  B#0E  TA  $BJx   B#08??#SJx S#08??]e]l]l#mJx m 3@
:@Vae2f&#/f2>MaLb2cvhv./c.;Ht.TK*+T1>z*?U`d1e
.e1=L_K`1afXf-.a .;8d-SJx)*S1>z*?U`d1e
.e1=L_K`1afXf-.a /<Ht.TK*+T,9$,NNF8C=)N[r%   r(   )enum
sqlalchemyr   r   r   r   r   r   rT   r	   sqlalchemy.ormr
   r   r   app.db.base_classr
   r   r   r4   typingr   r   app.models.userr   organizationr   r3   r   r(   r$   r%   r&   <module>r\      sL     [ [ [ > > " (  *  %sDII #[ #[r%   

--- END OF FILE: app/models/__pycache__/invitation.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/enums.cpython-312.pyc ---



    ]\h                      8    d dl Z  G d dee j                        Zy)    Nc                       e Zd ZdZdZdZy)ContactVisibilityprivateconnectionspublicN)__name__
__module____qualname__PRIVATECONNECTIONSPUBLIC     F/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/enums.pyr   r      s    GK
Fr   r   )enumstrEnumr   r   r   r   <module>r      s    TYY r   

--- END OF FILE: app/models/__pycache__/enums.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/verification_token.cpython-312.pyc ---



    vh;                     N    d dl Zd dlmZ d dlmZmZmZ d dlmZ  G d de      Z	y)    N)relationship)datetime	timedeltatimezone)Basec                      e Zd ZU dZ ej
                  ej                  dd      Zee	d<    ej
                  ej                   ej                  d      d      Zee	d<    ej
                  ej                  ddd	      Z
ee	d
<    ej
                   ej                  d      d      Zee	d<    ej
                   ej                  d      d
       Zee	d<    ed      Zedefd       Zy)VerificationTokenverification_tokensT)primary_keyindexidzusers.idF)nullableuser_id)uniquer   r   token)r   
expires_atc                  H    t        j                  t        j                        S )N)r   nowr   utc     S/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/verification_token.py<lambda>zVerificationToken.<lambda>   s    QYQ]Q]^f^j^jQk r   )default
created_atUserreturnc                  b    t        j                  t        j                        t	        d      z   S )N   )hours)r   r   r   r   r   r   r   r   get_default_expiryz$VerificationToken.get_default_expiry   s    ||HLL)IA,>>>r   N)__name__
__module____qualname__
__tablename__saColumnIntegerr
   int__annotations__
ForeignKeyr   Stringr   strDateTimer   r   r   r   userstaticmethodr!   r   r   r   r	   r	      s    )Mbii

DABA299RZZz)BUSGSS299TNE3N$299[R[[$%?%PJP$299[R[[$%?IklJlD? ? ?r   r	   )

sqlalchemyr&   sqlalchemy.ormr   r   r   r   app.db.base_classr   r	   r   r   r   <module>r4      s      ' 2 2 "
? 
?r   

--- END OF FILE: app/models/__pycache__/verification_token.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/organization.cpython-312.pyc ---



    1h	                         d dl mZmZmZmZmZmZ d dlmZm	Z	 d dl
mZ d dlm
Z
mZ d dlmZ e
rddlmZ ddlmZ dd	lmZ  G d
 de      Z G d d
e      Zy)    )ColumnIntegerStringTextDateTime
ForeignKey)relationshipMapped)func)
TYPE_CHECKINGList)Base   )User)	SpaceNode)
Invitationc                   4   e Zd ZdZ eedd      Z eedd      Z eed      Z	 eed      Z
 eed      Z eed      Z
 e ed       ej                                Z e ed       ej                          	      Z ed
d      Z ed
d      Zy)Company	companiesTprimary_keyindexFr   nullabler   timezoneserver_defaultonupdater   companyback_populatesr   N)__name__
__module____qualname__
__tablename__r   r   idr   namelogo_urlindustry_focusr   descriptionwebsiter   r   now
created_at
updated_atr	   membersspaces     M/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/organization.pyr   r   
   s    M	T	6B&u5Dft,HFT2N-KVd+G$/
KJ$/($((*EJ 6)<G +i
@Fr5   r   c                      e Zd ZU dZ eedd      Z eedd      Z eed      Z	 eed      Z
 eed      Z eed      Z
 eed      Z e ed       ej"                               Z e ed       ej"                         	      Z ee ed
      dd      Z edd
      Z edd
      Z eddd      Zeed      ed<   y)StartupstartupsTr   Fr   r   r   r   r    z
spacenodes.id)r   r   r   r#   r   startupr   zall, delete-orphan)r$   cascadeinvitationsN)r%   r&   r'   r(   r   r   r)   r   r*   r+   r,   r   r-   missionr.   r   r   r/   r0   r1   r   space_idr	   spacer2   r<   r
   r
   __annotations__r4   r5   r6   r8   r8      s    M	T	6B&u5Dft,HFT2N-KTD)GVd+G$/
KJ$/($((*EJ gz/:URVWH 
Z@E 6)<G /;<Xak  /AK\*+  Ar5   r8   N)
sqlalchemyr   r   r   r   r   r   sqlalchemy.ormr	   r
   sqlalchemy.sqlr   typingr   r
   app.db.base_classr   userr   r?   r   
invitationr   r   r8   r4   r5   r6   <module>rH      s?    J J /  & " &Ad A$Ad Ar5   

--- END OF FILE: app/models/__pycache__/organization.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/user.cpython-312.pyc ---



    u0,h                         d dl mZmZmZmZmZmZmZ d dlm	Z	 d dl
mZ erddlm
Z
mZ ddlmZmZ ddlmZ ddlmZ d d	lmZ dd
lmZ  G d de      Zy
)    )BooleanColumnIntegerStringDateTimefunc
ForeignKey)relationship)
TYPE_CHECKING   )	SpaceNodeWorkstation)CompanyStartup)Conversation)WorkstationAssignment)Base)UserProfilec                      e Zd ZdZ eedd      Z eeddd      Z eed      Z	 eedd      Z
 eed      Z eedd      Z ee
d	      Z ee ej"                         	      Z ee ej"                          ej"                         
      Z ee ed      d      Z ee ed      d      Z ed
d      Z edd      Z eddddej6                  g      Z edd      Z edd      Z ee ed      dd      Z edddd      Z  edegd      Z! eddd      Z" edd d!      Z# edd"d#      Z$ ed$d%d&'      Z%y())UserusersT)primary_keyindexF)uniquer   nullable)r   )r   r   )r   r   )default)r   onupdatezcompanies.idzstartups.idr   members)back_populatesr   zapp.models.profile.UserProfileuserzall, delete-orphan)r   uselistcascaderemote_sideVerificationTokenPasswordResetTokenz
spacenodes.idr
   z[SpaceNode.corporate_admin_id]admin)foreign_keysr   r!   )r'   r   r   )r   r"   
ConnectionzConnection.requester_id	requesterzConnection.recipient_id	recipientr   conversation_participantsparticipants)	secondaryr   N)&__name__
__module____qualname__
__tablename__r   r   idr   emailhashed_password	full_namerolestatusr   	is_activer   r   now
created_at
updated_atr	   
company_id
startup_idr
   companystartupr   user_idprofileverification_tokenspassword_reset_tokensspace_id
managed_spacespaceassignmentssent_connectionsreceived_connections
conversations     E/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/user.pyr   r      s   M	T	6B6$dUCEVe4OvTD9I&5)D
FU$
7Fw.I($((*5J($((*xtxxzJJ N!;dKJM!:TJJ9Y?G9Y?G ($ (()G '':6R()=fUgz/:TQUVH !5	M 
Z
E 6vWklK. $L?Xitu'C\mxy !-%MrL   r   N)
sqlalchemyr   r   r   r   r   r   r	   sqlalchemy.ormr
   typingr   rF   r
   r   organizationr   r   chatr   r   app.db.base_classr   rA   r   r   rK   rL   rM   <module>rT      s7    S S S '  -.", "  Z4 ZrL   

--- END OF FILE: app/models/__pycache__/user.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/__init__.cpython-312.pyc ---



    _1hs                         d dl mZ ddlmZ ddlmZmZ ddlmZm	Z	m
Z
 ddlmZ ddl
mZ ddlmZ dd	lmZ dd
lmZ ddlmZ ddlmZ dd
lmZmZ g dZy)    )Base   )User)CompanyStartup)	SpaceNodeWorkstationWorkstationAssignment)UserProfile)
Connection)Notification)PasswordResetToken)VerificationToken)ContactVisibility)ChatMessage)
InvitationInvitationStatus) r   RoleUserRoleLinkOrganizationOrganizationMemberr   r   Spacer	   r
   r
   ProfileUserInterestSkillUserProfileSkillLinkr   r   MessageMessageReactionChatRoomChatRoomMemberr   ConnectionRequestr   r   OrganizationRole
UserStatusSpaceStatusWorkstationStatusNotificationTypeNotificationStatusUserChatRoomRoleN)app.db.base_classr   userr   organizationr   r   spacer   r	   r
   profiler   
connectionr   notificationr
   password_reset_tokenr   verification_tokenr   enumsr   chatr   
invitationr   r   __all__     I/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/__init__.py<module>r9      s7    #  * @ @   " & 4 1 $  4"r7   

--- END OF FILE: app/models/__pycache__/__init__.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/space.cpython-312.pyc ---



    ?0h                         d dl mZmZmZmZmZmZmZm	Z	 d dl
mZmZm
Z
 d dlmZ d dlmZ ddlmZ ddlmZ d dlmZ  G d	 d
e      Z G d de      Z G d
 de      Zy)    )ColumnIntegerString
ForeignKeyDateTimefuncEnumand_)relationshipforeignremote)hybrid_property)Base   )User)Company)WorkstationStatusc                      e Zd ZdZ eedd      Z eedd      Z eed      Z	 ee e
d      d      Z ee e
d      d      Z ee
 ej                         	      Z ee
 ej                          ej                         
      Z edegd
      Z edd      Z eddd      Z eddd      Z eddd      Z eddd      Zy)	SpaceNode
spacenodesTprimary_keyindexF)r   nullabler   users.idzcompanies.iddefaultr   onupdater   
managed_space)foreign_keysback_populatesr   spacesr#   Workstation
space_nodeall, delete-orphan)r#   cascadespacez[User.space_id]r#   r"   WorkstationAssignmentStartupN)__name__
__module____qualname__
__tablename__r   r   idr   nameaddressr   corporate_admin_id
company_idr   r   now
created_at
updated_atr   admincompanyworkstationsusersassignmentsstartups     F/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/space.pyr   r   
   s     M	T	6B&u5DVd+GJ)?$ON!;dKJ ($((*5J($((*xtxxzJJ 
()&
E
 9X>G  
lThiL 
FWXE6|]qrK IgG[\HrA   r   c                   h   e Zd ZdZ eedd      Z eeddd       Z ee e	d      d      Z
 e eed	      ej                  dd
      Z ee ej"                               Z ee ej"                          ej"                               Z ed
d      Z edddd      Z edd ddd      Zy)r&   r<   Tr   F)r   r   r   
spacenodes.idr   workstation_status_enum)r3   )r   r   r   r   r   r   r%   r,   workstationr(   selectin)r#   r)   lazyc                      t        t        j                  t        t        j
                        k(  t        t        j                        j                  d             S )N)r
   r&   r2   r
   r,   workstation_idend_dateis_r@   rA   rB   <lambda>zWorkstation.<lambda>H   s=    DNNf%:%I%IJJ(11266t<
 rA   )primaryjoinuselistviewonlyrH   N)r.   r/   r0   r1   r   r   r2   r   r3   r   space_idSQLAlchemyEnumr   	AVAILABLEstatusr   r   r7   r8   r9   r   r'   r>   active_assignmentr@   rA   rB   r&   r&   0   s    "M	T	6B&5mLDgz/:UKH
N#4;TU-77" F ($((*5J($((*xtxxzJJ k.IJ 6}^r  zD  EK %
 
	rA   r&   c                      e Zd ZdZ eedd      Z ee ed      d      Z ee ed      d      Z	 ee ed      d      Z
 ee ej                         d	      Z eed      Z ee ej                         
      Z ee ej                          ej                               Z edd
      Z edd
e	g      Z edd
      Zy)r,   workstation_assignmentsTr   r   Fr   zworkstations.idrD   )r   r   r   r   r   r>   r%   r&   r+   r   N)r.   r/   r0   r1   r   r   r2   r   user_idrJ   rQ   r   r   r7   
start_daterK   r8   r9   r   userrF   r'   r@   rA   rB   r,   r,   Q   s    -M	T	6BWj4uEGGZ0A%BUSNgz/:UKH($((*uEJh.H($((*5J($((*xtxxzJJ
 }=D}]ZhYijKk-HJrA   r,   N)
sqlalchemyr   r   r   r   r   r   r	   rR   r
   sqlalchemy.ormr   r   r
   sqlalchemy.ext.hybridr   app.db.base_classr   rZ   r   organizationr   app.schemas.spacer   r   r&   r,   r@   rA   rB   <module>ra      sO    h h h 8 8 1 "  ! 0!] !]F$ BID IrA   

--- END OF FILE: app/models/__pycache__/space.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/chat.cpython-312.pyc ---



    d.h                         d dl mZmZmZmZmZmZmZmZm	Z	 d dl
mZ d dlm
Z
 d dlmZ  G d de
      Z G d de
      Z G d	 d
e
      Z G d de
      Zy
)    )	ColumnIntegerText
ForeignKeyDateTimefuncStringUniqueConstraintBoolean)relationship)Base)Userc                       e Zd ZdZ eedd      Z ee ej                               Z
 eddd      Z edd	d
      Z
y)
Conversation
conversationsTprimary_keyindexdefaultr   conversation_participants)	secondaryback_populatesChatMessageconversationzChatMessage.created_at)r   order_byN)__name__
__module____qualname__
__tablename__r   r   idr   r   now
created_atr   participantsmessages     E/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/chat.pyr   r   
   sH    #M	T	6B($((*5J2M^mnLM.SklHr'   r   c                       e Zd ZdZ ee edd      d      Z ee edd      d      Z e e	d       e
j                         	      Z e e	d      d
      Z
 edd
      Z edd
      Zy)ConversationParticipantr   conversations.idCASCADE)ondeleteT)r   users.idtimezone)server_defaultnullabler   zconversations,participants)overlapsr   N)r   r   r   r    r   r   r   conversation_iduser_idr   r   r"   	joined_atlast_read_atr   userr   r&   r'   r(   r*   r*      sx    /MWj1Ci&XfjkOWjiHVZ[Gx.xtxxzJI(D1DAL)EFD9UVLr'   r*   c                      e Zd ZdZ eedd      Z ee ed      d      Z ee ed      d      Z	 ee ed      d      Z
 eed      Z ee
 ej                               Z ee
d      Z e e
d	      d      Z eedd
      Z eed      Z eed      Z eed      Z edegd
      Z ede	gd
      Z edde
g      Z eddd      Zy)r   
chat_messagesTr   r.   Fr2   r+   r   r/   )r   r3   r   
sent_messages)foreign_keysbackrefreceived_messagesr   r%   )r   r=   MessageReactionmessagezall, delete-orphan)r   cascadeN)r   r   r   r    r   r   r!   r   	sender_idrecipient_idr5   r   contentr   r   r"   r#   read_at
updated_atr   
is_deletedr	   attachment_urlattachment_filenameattachment_mimetyper   sender	recipientr   	reactionsr&   r'   r(   r   r      s   #M	T	6B w
: 6GI':j#9DIL Wj1C&DtTOTE*G($((*5JX-G $/$?J?J FT2N $7 $7
&	{O
TFV<.J]^IzYhXijL $Ir'   r   c                       e Zd ZdZ eedd      Z ee ed      d      Z ee ed      d      Z	 ee
d      Z ee e
j                               Z ed	d
dd
      fZ edd      Z ed      Zy)r@   message_reactionsTr   zchat_messages.idFr2   r.   r   
message_idr6   emoji_message_user_emoji_uc)namer   rN   )r   r   N)r   r   r   r    r   r   r!   r   rQ   r6   r	   rR   r   r   r"   r#   r
   __table_args__r   rA   r9   r&   r'   r(   r@   r@   A   s    'M	T	6B,>!?%PJWj4uEG6E*E($((*5J '|YNfgiN=EGDr'   r@   N)
sqlalchemyr   r   r   r   r   r   r	   r
   r   sqlalchemy.ormr   app.db.base_classr
   app.models.userr   r   r*   r   r@   r&   r'   r(   <module>rZ      sN    k k k ' " !m4 m	Wd 	W!$ !F d  r'   

--- END OF FILE: app/models/__pycache__/chat.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/user_profile.cpython-312.pyc ---



    "h                         d dl mZmZmZmZmZmZmZ d dl	m
Z
 d dlmZ d dl
mZ d dlZ G d deej                        Z G d d	e      Zy)
    )ColumnIntegerStringText
ForeignKeyEnumBoolean)relationship)ARRAY)BaseNc                       e Zd ZdZdZdZy)ContactVisibilityprivateconnectionspublicN)__name__
__module____qualname__PRIVATECONNECTIONSPUBLIC     M/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/user_profile.pyr   r   	   s    GK
Fr   r   c                   ~   e Zd ZdZ eedd      Z ee ed      ddd      Z ee	d      Z
 eed      Z e e
ed	      dej                  
      Z e ee	      d      Z e ee	      d      Z eed      Z e ee	      d      Z e ee	      d      Z ee	d      Z ee	d      Z edd
      Zy)UserProfileuser_profileT)primary_keyindexzusers.idF)uniquer   nullable)r!   contact_visibility_enum)name)r!   defaultUserprofile)back_populatesN)r   r   r   
__tablename__r   r   idr   user_idr   titler   bioSQLEnumr   r   contact_info_visibilityr   skills_expertiseindustry_focusproject_interests_goalscollaboration_preferencestools_technologieslinkedin_profile_urlprofile_picture_urlr
   userr   r   r   r   r      s    "M	T	6BWj4TX]^G6D)E

%C$W->E^%_jo  zK  zW  zW  XeFmd;E&MD9N$TD9 &uV}t Df
=!&48 $7 y9Dr   r   )
sqlalchemyr   r   r   r   r   r   r-   r	   sqlalchemy.ormr
   sqlalchemy.dialects.postgresqlr   app.db.base_classr   enumstrr   r   r   r   r   <module>r=      s:    Z Z Z ' 0 " TYY 
:$ :r   

--- END OF FILE: app/models/__pycache__/user_profile.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/models/__pycache__/profile.cpython-312.pyc ---



    sh                     v    d dl mZmZmZmZmZmZ d dlm	Z	 d dl
mZ d dlm
Z
 d dlmZ ddlmZ  G d d	e      Zy
)    )ColumnIntegerStringText
ForeignKeyEnum)relationship)ARRAY)Vector)Base   )ContactVisibilityc                      e Zd ZdZddiZ eedd      Z ee ed      ddd      Z	 ee
d      Z eed      Z
 e eed	d
      dej                         Z e ee
      d      Z e ee
      d      Z eed      Z e ee
      d      Z e ee
      d      Z ee
d      Z ee
d      Z e ed      d      Z ed
e	gd      Zy)UserProfile
user_profilesextend_existingT)primary_keyindexzusers.idF)uniquer   nullable)r   contact_visibility_enum)namecreate_type)r   defaulti   zapp.models.user.Userprofile)foreign_keysback_populatesN)__name__
__module____qualname__
__tablename____table_args__r   r   idr   user_idr   titler   bioSQLEnumr   CONNECTIONScontact_info_visibilityr
   skills_expertiseindustry_focusproject_interests_goalscollaboration_preferencestools_technologieslinkedin_profile_urlprofile_picture_urlr   profile_vectorr	   user     H/home/marcel/ShareYourSpace/shareyourspace-backend/app/models/profile.pyr   r      s   #M'.N	T	6BWj4TX]^G6D)E

%C$W->E^lq%r  ~C  M^  Mj  Mj  keFmd;E&MD9N$TD9 &uV}t Df
=!&48 $7F3K$7N Y Dr4   r   N)
sqlalchemyr   r   r   r   r   r   r'   sqlalchemy.ormr	   sqlalchemy.dialects.postgresqlr
   pgvector.sqlalchemyr   app.db.base_classr   enumsr   r   r3   r4   r5   <module>r<      s&    Q Q ' 0 & " $$ r4   

--- END OF FILE: app/models/__pycache__/profile.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/crud/crud_organization.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select

from app.models.organization import Company, Startup
from app.schemas.organization import CompanyCreate, CompanyUpdate, StartupCreate, StartupUpdate

# CRUD operations for Company
async def get_company(db: AsyncSession, company_id: int) -> Company | None:
    result = await db.execute(select(Company).filter(Company.id == company_id))
    return result.scalars().first()

# Add create_company, update_company later if needed
# async def create_company(db: AsyncSession, *, obj_in: CompanyCreate) -> Company:
#     db_obj = Company(**obj_in.dict())
#     db.add(db_obj)
#     await db.commit()
#     await db.refresh(db_obj)
#     return db_obj

# CRUD operations for Startup
async def get_startup(db: AsyncSession, startup_id: int) -> Startup | None:
    result = await db.execute(select(Startup).filter(Startup.id == startup_id))
    return result.scalars().first()

async def get_startups_by_space_id(db: AsyncSession, space_id: int) -> list[Startup]:
    """Fetches all startups associated with a given space_id."""
    result = await db.execute(
        select(Startup)
        .filter(Startup.space_id == space_id)
        .order_by(Startup.name) # Optional: order by name
    )
    return result.scalars().all()

# Add create_startup, update_startup later if needed

# Potentially add get_company_by_admin_user, get_startup_by_admin_user later 

--- END OF FILE: app/crud/crud_organization.py ---

================================================================================

--- START OF FILE: app/crud/crud_verification_token.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, delete
from sqlalchemy.orm import selectinload # For potential future use if relationships needed

from app.models.verification_token import VerificationToken
from app.schemas.verification_token import VerificationTokenCreate

async def create_verification_token(db: AsyncSession, *, obj_in: VerificationTokenCreate) -> VerificationToken:
    """Create a new verification token."""
    db_obj = VerificationToken(**obj_in.model_dump())
    db.add(db_obj)
    await db.commit()
    await db.refresh(db_obj)
    return db_obj

async def get_verification_token(db: AsyncSession, *, token: str) -> VerificationToken | None:
    """Get a verification token by its token string."""
    statement = select(VerificationToken).where(VerificationToken.token == token)
    result = await db.execute(statement)
    return result.scalar_one_or_none()

async def delete_verification_token(db: AsyncSession, *, token_obj: VerificationToken | None) -> None:
    """Delete a verification token object."""
    if token_obj:
        await db.delete(token_obj)
        await db.commit()

async def delete_verification_token_by_token(db: AsyncSession, *, token: str) -> None:
    """Delete a verification token by its token string."""
    statement = delete(VerificationToken).where(VerificationToken.token == token)
    await db.execute(statement)
    await db.commit() 

--- END OF FILE: app/crud/crud_verification_token.py ---

================================================================================

--- START OF FILE: app/crud/crud_invitation.py ---

from sqlalchemy.orm import Session
from sqlalchemy.future import select
from typing import Optional
import uuid
from datetime import datetime, timedelta
import logging

from app.crud.base import CRUDBase
from app.models.invitation import Invitation, InvitationStatus
from app.schemas.invitation import InvitationCreate, InvitationUpdate
from app.core.config import settings

logger = logging.getLogger(__name__)

class CRUDInvitation(CRUDBase[Invitation, InvitationCreate, InvitationUpdate]):
    async def get_by_email_and_startup(
        self, db: Session, *, email: str, startup_id: int
    ) -> Optional[Invitation]:
        statement = select(self.model).where(self.model.email == email, self.model.startup_id == startup_id)
        result = await db.execute(statement)
        return result.scalar_one_or_none()

    async def get_by_invitation_token(self, db: Session, *, token: str) -> Optional[Invitation]:
        statement = select(self.model).where(self.model.invitation_token == token)
        result = await db.execute(statement)
        return result.scalar_one_or_none()

    async def create_with_startup(
        self, db: Session, *, obj_in: InvitationCreate
    ) -> Invitation:
        # Check if an active (PENDING and not EXPIRED) invitation already exists for this email and startup
        existing_invitation_stmt = select(self.model).where(
            self.model.email == obj_in.email,
            self.model.startup_id == obj_in.startup_id,
            self.model.status == InvitationStatus.PENDING,
            self.model.expires_at > datetime.utcnow()
        )
        existing_invitation_result = await db.execute(existing_invitation_stmt)
        existing_invitation = existing_invitation_result.scalar_one_or_none()

        if existing_invitation:
            # Optionally, update the expiry of the existing invitation or just return it
            # For now, let's return the existing one if it's still valid
            # Consider if approved_by_admin_id should be updated if it's a re-invite by a different admin
            return existing_invitation

        db_obj = self.model(
            email=obj_in.email,
            startup_id=obj_in.startup_id,
            approved_by_admin_id=obj_in.approved_by_admin_id, # Store who approved
            invitation_token=str(uuid.uuid4()), # Ensure a new token is generated
            expires_at=datetime.utcnow() + timedelta(days=settings.INVITATION_EXPIRE_DAYS) # Use config for expiry
        )
        db.add(db_obj)
        await db.commit()
        await db.refresh(db_obj)
        return db_obj

    async def mark_as_accepted(self, db: Session, *, invitation: Invitation, accepted_by_user_id: int) -> Invitation:
        invitation.status = InvitationStatus.ACCEPTED
        invitation.accepted_at = datetime.utcnow()
        invitation.accepted_by_user_id = accepted_by_user_id
        invitation.updated_at = datetime.utcnow() # Ensure updated_at is set
        db.add(invitation)
        await db.commit()
        await db.refresh(invitation)
        return invitation

    async def mark_as_expired(self, db: Session, *, invitation: Invitation) -> Invitation:
        invitation.status = InvitationStatus.EXPIRED
        invitation.updated_at = datetime.utcnow()
        db.add(invitation)
        await db.commit()
        await db.refresh(invitation)
        return invitation

    async def get_pending_invitations_for_startup(self, db: Session, *, startup_id: int) -> list[Invitation]:
        """Fetches all PENDING invitations for a specific startup."""
        stmt = select(self.model).where(
            self.model.startup_id == startup_id,
            self.model.status == InvitationStatus.PENDING,
            self.model.expires_at > datetime.utcnow() # Only show non-expired pending ones
        ).order_by(self.model.created_at.desc()) # Show newest first
        
        result = await db.execute(stmt)
        return result.scalars().all()

    async def revoke_invitation(self, db: Session, *, invitation_to_revoke: Invitation, revoking_admin_id: int) -> Invitation:
        """Marks an invitation as REVOKED."""
        if invitation_to_revoke.status != InvitationStatus.PENDING:
            # Or raise an error, depending on how you want to handle it.
            # For now, just log and return the invitation as is if not PENDING.
            # This prevents revoking an already accepted/expired/revoked invitation.
            logger.warning(f"Attempt to revoke invitation {invitation_to_revoke.id} which is not PENDING. Status: {invitation_to_revoke.status}")
            return invitation_to_revoke 
            
        invitation_to_revoke.status = InvitationStatus.REVOKED
        invitation_to_revoke.revoked_at = datetime.utcnow()
        invitation_to_revoke.revoked_by_admin_id = revoking_admin_id
        invitation_to_revoke.updated_at = datetime.utcnow() # Ensure updated_at is set
        db.add(invitation_to_revoke)
        await db.commit()
        await db.refresh(invitation_to_revoke)
        logger.info(f"Invitation {invitation_to_revoke.id} for {invitation_to_revoke.email} to startup {invitation_to_revoke.startup_id} revoked by admin {revoking_admin_id}.")
        return invitation_to_revoke

    async def mark_as_declined(self, db: Session, *, invitation: Invitation, reason: Optional[str] = None) -> Invitation:
        """Marks an invitation as DECLINED."""
        if invitation.status != InvitationStatus.PENDING:
            logger.warning(f"Attempt to decline invitation {invitation.id} which is not PENDING. Status: {invitation.status}")
            # Depending on business logic, you might raise an error or just return as is.
            # For now, if it's not pending (e.g., already accepted, revoked, expired), declining it might not make sense.
            # However, if it was EXPIRED and user clicks decline, maybe we still mark it declined.
            # Let's stick to only allowing decline for PENDING invitations for now for simplicity.
            return invitation 

        invitation.status = InvitationStatus.DECLINED
        invitation.declined_at = datetime.utcnow()
        invitation.decline_reason = reason
        invitation.updated_at = datetime.utcnow()
        db.add(invitation)
        await db.commit()
        await db.refresh(invitation)
        logger.info(f"Invitation {invitation.id} for {invitation.email} to startup {invitation.startup_id} marked as DECLINED.")
        return invitation

invitation = CRUDInvitation(Invitation) 

--- END OF FILE: app/crud/crud_invitation.py ---

================================================================================

--- START OF FILE: app/crud/crud_space.py ---

from sqlalchemy.future import select
from sqlalchemy.ext.asyncio import AsyncSession
from typing import List, Optional

from app.models.space import SpaceNode
from app.schemas.admin import SpaceCreate


async def create_space(db: AsyncSession, *, obj_in: SpaceCreate) -> SpaceNode:
    """Creates a new SpaceNode in the database."""
    db_obj = SpaceNode(
        name=obj_in.name,
        location_description=obj_in.location_description,
        corporate_admin_id=obj_in.corporate_admin_id,
        total_workstations=obj_in.total_workstations
    )
    db.add(db_obj)
    await db.commit()
    await db.refresh(db_obj)
    return db_obj

async def get_space(db: AsyncSession, space_id: int) -> Optional[SpaceNode]:
    """Gets a specific SpaceNode by its ID."""
    result = await db.execute(select(SpaceNode).filter(SpaceNode.id == space_id))
    return result.scalars().first()

async def get_spaces(db: AsyncSession, skip: int = 0, limit: int = 100) -> List[SpaceNode]:
    """Gets a list of SpaceNodes."""
    result = await db.execute(select(SpaceNode).offset(skip).limit(limit))
    return result.scalars().all() 

--- END OF FILE: app/crud/crud_space.py ---

================================================================================

--- START OF FILE: app/crud/crud_user.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import Select # Import Select for type hint
from sqlalchemy.orm import Load, selectinload # Import Load, selectinload for type hint
import logging # Add logging import

from app.models.user import User
from app.models.space import WorkstationAssignment # Ensure WorkstationAssignment is imported
from app.schemas.user import UserCreate, UserUpdateInternal
from app.utils.security_utils import get_password_hash, verify_password
from typing import List, Optional, Sequence # Import Sequence

logger = logging.getLogger(__name__) # Add logger instance

async def get_user_by_id(
    db: AsyncSession, 
    *, 
    user_id: int, 
    options: Optional[Sequence[Load]] = None # Add options parameter
) -> User | None:
    """Fetch a single user by ID, optionally applying loading options."""
    try:
        stmt = select(User).filter(User.id == user_id)
        if options:
            stmt = stmt.options(*options) # Apply options if provided
            
        result = await db.execute(stmt)
        return result.scalars().first()
    except SQLAlchemyError as e:
        print(f"Database error fetching user by ID {user_id}: {e}")
        return None

async def get_user_by_email(db: AsyncSession, *, email: str) -> User | None:
    """Fetch a single user by email."""
    try:
        result = await db.execute(select(User).filter(User.email == email))
        return result.scalars().first()
    except SQLAlchemyError as e:
        # Handle potential database errors (log them, etc.)
        print(f"Database error fetching user by email: {e}")
        return None

async def create_user(db: AsyncSession, *, obj_in: UserCreate) -> User:
    """Create a new user."""
    hashed_password = get_password_hash(obj_in.password)
    
    # Determine initial status based on role
    initial_status = 'PENDING_VERIFICATION' # Default
    if obj_in.role == 'FREELANCER':
        initial_status = 'WAITLISTED' # As per ON-05 flow
    elif obj_in.role == 'STARTUP_ADMIN':
        initial_status = 'WAITLISTED' # As per ON-05 flow
    elif obj_in.role == 'CORP_ADMIN': # Should be CORP_REPRESENTATIVE during signup
        initial_status = 'PENDING_ONBOARDING' # As per ON-06 flow

    # Create the User model instance
    db_user = User(
        email=obj_in.email,
        full_name=obj_in.full_name,
        hashed_password=hashed_password,
        role=obj_in.role,
        status=initial_status, # Use determined status
        is_active=False # Usually set to True after verification/activation
    )
    
    try:
        db.add(db_user)
        await db.commit()
        await db.refresh(db_user)
        return db_user
    except SQLAlchemyError as e:
        await db.rollback() 
        # Handle potential database errors (log them, raise specific exceptions, etc.)
        print(f"Database error creating user: {e}")
        raise # Re-raise the exception for the router to handle 

async def update_user_internal(db: AsyncSession, *, db_obj: User, obj_in: UserUpdateInternal) -> User:
    """Update user fields internally (e.g., status)."""
    update_data = obj_in.model_dump(exclude_unset=True)
    logger.info(f"Updating user {db_obj.id}. Current state: status={db_obj.status}, is_active={db_obj.is_active}. Update data: {update_data}")
    for field, value in update_data.items():
        setattr(db_obj, field, value)
    logger.info(f"User {db_obj.id} state after setattr: status={db_obj.status}, is_active={db_obj.is_active}") # Log after setattr
    db.add(db_obj)
    try:
        await db.commit()
        logger.info(f"User {db_obj.id} update commit successful.")
        await db.refresh(db_obj)
        logger.info(f"User {db_obj.id} state after refresh: status={db_obj.status}, is_active={db_obj.is_active}")
        return db_obj
    except SQLAlchemyError as e:
        await db.rollback()
        logger.error(f"Database error during internal update for user {db_obj.id}: {e}", exc_info=True) # Log exception info
        raise 

async def update_user_password(db: AsyncSession, *, user: User, new_password: str) -> User:
    """Update a user's password."""
    hashed_password = get_password_hash(new_password)
    user.hashed_password = hashed_password
    db.add(user)
    try:
        await db.commit()
        await db.refresh(user)
        return user
    except SQLAlchemyError as e:
        await db.rollback()
        print(f"Database error updating user password: {e}")
        raise 

async def get_users_by_status(db: AsyncSession, status: str) -> List[User]:
    """Get a list of users filtered by their status."""
    result = await db.execute(select(User).filter(User.status == status))
    return result.scalars().all()

async def get_users_by_role_and_startup(db: AsyncSession, *, role: str, startup_id: int) -> List[User]:
    """Get a list of users filtered by their role and startup ID."""
    stmt = select(User).where(User.role == role, User.startup_id == startup_id)
    result = await db.execute(stmt)
    return result.scalars().all()

async def get_users_by_role_and_space_id(db: AsyncSession, *, role: str, space_id: int) -> List[User]:
    """Get a list of users filtered by their role and space ID."""
    stmt = select(User).where(User.role == role, User.space_id == space_id)
    result = await db.execute(stmt)
    return result.scalars().all()

async def get_user_by_email_and_startup(db: AsyncSession, *, email: str, startup_id: int) -> Optional[User]:
    """Fetch a single user by email if they belong to a specific startup."""
    try:
        stmt = select(User).where(User.email == email, User.startup_id == startup_id)
        result = await db.execute(stmt)
        return result.scalars().first()
    except SQLAlchemyError as e:
        logger.error(f"Database error fetching user by email {email} for startup {startup_id}: {e}")
        return None

async def activate_corporate_user(db: AsyncSession, *, user_id: int, space_id: Optional[int] = None) -> Optional[User]:
    """Activates a user with PENDING_ONBOARDING status to CORP_ADMIN and ACTIVE."""
    user = await get_user_by_id(db, user_id=user_id)
    if not user or user.status != 'PENDING_ONBOARDING':
        return None # Or raise an exception

    update_data = {
        "status": "ACTIVE",
        "role": "CORP_ADMIN",
        "is_active": True,
        "space_id": space_id # Assign space if provided
    }
    return await update_user_internal(db, db_obj=user, obj_in=UserUpdateInternal(**update_data))

async def assign_user_to_space(db: AsyncSession, *, user_id: int, space_id: Optional[int]) -> Optional[User]:
    """Assigns or unassigns a user to a specific space."""
    user = await get_user_by_id(db, user_id=user_id)
    if not user:
        return None # Or raise error
    
    # Check if space exists if assigning (space_id is not None)
    if space_id is not None:
        from .crud_space import get_space # Local import to avoid circular dependency issues
        space = await get_space(db, space_id=space_id)
        if not space:
            # Raise a specific error or return None/False to indicate space not found
            raise ValueError(f"Space with ID {space_id} not found.") 

    user.space_id = space_id
    db.add(user)
    try:
        await db.commit()
        await db.refresh(user)
        return user
    except SQLAlchemyError as e:
        await db.rollback()
        print(f"Database error assigning user to space: {e}")
        raise

async def activate_user_for_startup_invitation(db: AsyncSession, *, user_to_activate: User) -> Optional[User]:
    """Activates a user created via startup invitation and sets their status."""
    if user_to_activate:
        user_to_activate.is_active = True
        user_to_activate.status = "ACTIVE" # Or UserStatus.ACTIVE if using enum
        db.add(user_to_activate)
        await db.commit()
        await db.refresh(user_to_activate)
        logger.info(f"User {user_to_activate.id} activated via startup invitation. Status: {user_to_activate.status}")
        return user_to_activate
    return None

async def get_user_details_for_profile(db: AsyncSession, user_id: int) -> Optional[User]:
    """
    Fetches a user by ID with related details for their profile page.
    Eager loads profile, company, startup, space (they belong to), 
    managed_space (if Corp Admin), and active workstation assignment.
    """
    stmt = (
        select(User)
        .where(User.id == user_id)
        .options(
            selectinload(User.profile),
            selectinload(User.company),
            selectinload(User.startup),
            selectinload(User.space), # Space the user belongs to
            selectinload(User.managed_space), # Space the user manages (if Corp Admin)
            selectinload(User.assignments).options( # Load assignments
                selectinload(WorkstationAssignment.workstation) # And the related workstation for each assignment
            )
        )
    )
    result = await db.execute(stmt)
    user = result.scalars().first()
    return user

# Note: Consider consolidating activation logic if rules become complex.
# For example, a generic activate_user(user, new_status) might be useful.

# user = CRUDUser(User) # This line seems to be for a CRUDBase pattern not fully used here yet

--- END OF FILE: app/crud/crud_user.py ---

================================================================================

--- START OF FILE: app/crud/crud_password_reset_token.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.exc import SQLAlchemyError
from datetime import datetime, timezone

from app.models.password_reset_token import PasswordResetToken
from app.schemas.password_reset_token import PasswordResetTokenCreate

async def create_reset_token(db: AsyncSession, *, obj_in: PasswordResetTokenCreate) -> PasswordResetToken:
    """Create a new password reset token."""
    db_token = PasswordResetToken(
        user_id=obj_in.user_id,
        token=obj_in.token,
        expires_at=obj_in.expires_at
    )
    try:
        db.add(db_token)
        await db.commit()
        await db.refresh(db_token)
        return db_token
    except SQLAlchemyError as e:
        await db.rollback()
        print(f"Database error creating password reset token: {e}")
        raise

async def get_reset_token_by_token(db: AsyncSession, *, token: str) -> PasswordResetToken | None:
    """Fetch a password reset token by the token string."""
    try:
        result = await db.execute(select(PasswordResetToken).filter(PasswordResetToken.token == token))
        return result.scalars().first()
    except SQLAlchemyError as e:
        print(f"Database error fetching password reset token: {e}")
        return None

async def delete_reset_token(db: AsyncSession, *, token_obj: PasswordResetToken | None):
    """Delete a password reset token object."""
    if token_obj:
        try:
            await db.delete(token_obj)
            await db.commit()
        except SQLAlchemyError as e:
            await db.rollback()
            print(f"Database error deleting password reset token: {e}")
            # Decide if deletion failure should raise an error or just be logged 

--- END OF FILE: app/crud/crud_password_reset_token.py ---

================================================================================

--- START OF FILE: app/crud/__init__.py ---

# Import individual CRUD modules so they can be accessed via the package
from . import crud_user # noqa
from . import crud_verification_token # noqa
from . import crud_password_reset_token # noqa
from . import crud_organization # noqa
from . import crud_space # noqa
from . import crud_connection # noqa: Import connection CRUD
from . import crud_notification # noqa: Import notification CRUD
from . import crud_chat # noqa: Import chat CRUD
from .crud_invitation import invitation # Make invitation instance directly available on crud package

# Add other CRUD modules here as they are created 

from .crud_space import create_space, get_space, get_spaces

# Remove the block re-importing user functions
# from .crud_user import (
#     get_user,
#     get_user_by_email,
#     get_users,
#     create_user,
#     update_user,
#     get_users_by_status,
#     activate_corporate_user
# ) 

__all__ = [
    "user", 
    "role", 
    "organization", 
    "startup", 
    "company", 
    "space", 
    "workstation", 
    "notification",
    "user_profile",
    "user_interest",
    "skill",
    "user_profile_skill_link",
    "password_reset_token",
    "verification_token",
    "message",
    "chat_room",
    "chat_room_member",
    "message_reaction",
    "connection",
    "connection_request",
    "invitation",
] 

--- END OF FILE: app/crud/__init__.py ---

================================================================================

--- START OF FILE: app/crud/crud_connection.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update, and_, or_
from sqlalchemy.orm import selectinload

from app import models # Import models at the top level
from app.models.connection import ConnectionStatus # Import the enum
from app.models.user import User
from app.schemas.connection import ConnectionCreate, ConnectionStatusCheck # Import the necessary schema
from typing import List, Optional, Dict
import logging
from fastapi import HTTPException, status

logger = logging.getLogger(__name__)

async def create_connection(db: AsyncSession, *, requester_id: int, obj_in: ConnectionCreate) -> models.Connection:
    """Create a new connection request or resend if previously declined."""
    # Check if any connection (pending, accepted, declined, blocked) exists between the two users
    existing_connection = await db.execute(
        select(models.Connection).options(selectinload(models.Connection.requester), selectinload(models.Connection.recipient))
        .filter(
            or_(
                and_(models.Connection.requester_id == requester_id, models.Connection.recipient_id == obj_in.recipient_id),
                and_(models.Connection.requester_id == obj_in.recipient_id, models.Connection.recipient_id == requester_id)
            )
        )
    )
    existing = existing_connection.scalars().first()

    if existing:
        # If already pending or accepted, just return the existing record
        if existing.status in [ConnectionStatus.PENDING, ConnectionStatus.ACCEPTED]:
            logger.warning(f"Attempt to create duplicate connection between {requester_id} and {obj_in.recipient_id}. Status: {existing.status}. Returning existing.")
            return existing
        # If previously declined, allow resending by updating status to pending
        elif existing.status == ConnectionStatus.DECLINED:
            logger.info(f"Re-sending connection request between {requester_id} and {obj_in.recipient_id} (previously declined).")
            # Ensure the requester is the one initiating this new request
            if existing.requester_id != requester_id:
                # If the other person declined the current user before, update the direction
                existing.requester_id = requester_id
                existing.recipient_id = obj_in.recipient_id
            existing.status = ConnectionStatus.PENDING 
            # Update timestamp? Let's rely on updated_at for now.
            # existing.created_at = func.now() # Or keep original?
            db.add(existing)
            await db.commit()
            await db.refresh(existing, attribute_names=['requester', 'recipient'])
            return existing
        # If blocked, prevent any action (optional: raise specific error?)
        elif existing.status == ConnectionStatus.BLOCKED:
            logger.warning(f"Attempt to create connection between {requester_id} and {obj_in.recipient_id}, but connection is BLOCKED.")
            # Raise HTTPException or just return the blocked connection?
            # Raising error is probably better feedback
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Cannot send connection request; connection is blocked."
            )
        else: # Should not happen
            logger.error(f"Existing connection found with unexpected status: {existing.status}")
            return existing # Fallback

    # If no existing connection, create a new one
    logger.info(f"Creating new connection request from {requester_id} to {obj_in.recipient_id}")
    db_connection = models.Connection(
        requester_id=requester_id,
        recipient_id=obj_in.recipient_id,
        status=ConnectionStatus.PENDING # Initial status
    )
    db.add(db_connection)
    await db.commit()
    await db.refresh(db_connection, attribute_names=['requester', 'recipient'])
    return db_connection

async def get_connection_by_id(db: AsyncSession, *, connection_id: int) -> Optional[models.Connection]:
    """Get a connection by its ID."""
    result = await db.execute(
        select(models.Connection)
        .options(selectinload(models.Connection.requester), selectinload(models.Connection.recipient))
        .filter(models.Connection.id == connection_id)
    )
    return result.scalars().first()

async def update_connection_status(db: AsyncSession, *, connection: models.Connection, status: str) -> models.Connection:
    """Update the status of a connection."""
    allowed_statuses = ['accepted', 'declined', 'blocked'] # Define valid statuses
    if status not in allowed_statuses:
        raise ValueError(f"Invalid status: {status}. Must be one of {allowed_statuses}")
    
    connection.status = status
    db.add(connection)
    await db.commit()
    await db.refresh(connection, attribute_names=['requester', 'recipient'])
    logger.info(f"Updated connection id {connection.id} status to {status}")
    return connection

async def get_pending_connections_for_user(db: AsyncSession, *, user_id: int) -> List[models.Connection]:
    """Get pending incoming connection requests for a user."""
    result = await db.execute(
        select(models.Connection)
        .options(selectinload(models.Connection.requester), selectinload(models.Connection.recipient))
        .filter(models.Connection.recipient_id == user_id, models.Connection.status == 'pending')
        .order_by(models.Connection.created_at.desc()) # Show newest first
    )
    return result.scalars().all()

async def get_accepted_connections_for_user(db: AsyncSession, *, user_id: int) -> List[models.Connection]:
    """Get accepted connections for a user (where they are requester or recipient)."""
    result = await db.execute(
        select(models.Connection)
        .options(selectinload(models.Connection.requester), selectinload(models.Connection.recipient))
        .filter(
            or_(models.Connection.requester_id == user_id, models.Connection.recipient_id == user_id),
            models.Connection.status == 'accepted'
        )
        .order_by(models.Connection.updated_at.desc())
    )
    return result.scalars().all()

async def get_connection_between_users(db: AsyncSession, *, user1_id: int, user2_id: int) -> models.Connection | None:
    """Check if a connection exists between two specific users, regardless of direction."""
    query = select(models.Connection).options(
        selectinload(models.Connection.requester),
        selectinload(models.Connection.recipient)
    ).where(
        or_(
            and_(models.Connection.requester_id == user1_id, models.Connection.recipient_id == user2_id),
            and_(models.Connection.requester_id == user2_id, models.Connection.recipient_id == user1_id)
        )
    )
    result = await db.execute(query)
    return result.scalars().first()

async def get_connections_status_for_users(db: AsyncSession, *, current_user_id: int, other_user_ids: List[int]) -> Dict[int, ConnectionStatusCheck]:
    """Get the connection status between the current user and a list of other users."""
    if not other_user_ids:
        return {}

    # Fetch all relevant connections in one query
    # Use models.Connection
    query = select(models.Connection).where(
        or_(
            # Current user is requester, other user is recipient
            and_(models.Connection.requester_id == current_user_id, models.Connection.recipient_id.in_(other_user_ids)),
            # Other user is requester, current user is recipient
            and_(models.Connection.requester_id.in_(other_user_ids), models.Connection.recipient_id == current_user_id)
        )
    )
    result = await db.execute(query)
    connections = result.scalars().all()

    # Process connections into a dictionary keyed by other_user_id
    # Use the correct type hint
    status_map: Dict[int, ConnectionStatusCheck] = {}
    for conn in connections:
        other_id = conn.recipient_id if conn.requester_id == current_user_id else conn.requester_id
        
        status_detail = "unknown"
        # Use the enum for comparison
        if conn.status == ConnectionStatus.ACCEPTED:
            status_detail = 'connected'
        elif conn.status == ConnectionStatus.PENDING:
            if conn.requester_id == current_user_id:
                status_detail = 'pending_from_me'
            else:
                status_detail = 'pending_from_them'
        elif conn.status == ConnectionStatus.DECLINED:
            status_detail = 'declined' # Or maybe treat declined as not_connected?
        elif conn.status == ConnectionStatus.BLOCKED:
            status_detail = 'blocked' # Handle if blocking is implemented

        # Assign the correct schema object
        status_map[other_id] = ConnectionStatusCheck(status=status_detail, connection_id=conn.id)

    # Fill in 'not_connected' for users without an existing connection record
    for user_id in other_user_ids:
        if user_id not in status_map:
            # Assign the correct schema object
            status_map[user_id] = ConnectionStatusCheck(status='not_connected')

    return status_map 

async def get_pending_outgoing_connections_for_user(db: AsyncSession, *, user_id: int) -> List[models.Connection]:
    """Get pending outgoing connection requests made by a user."""
    query = select(models.Connection).options(
        selectinload(models.Connection.requester).selectinload(models.User.profile),
        selectinload(models.Connection.recipient).selectinload(models.User.profile)
    ).where(
        models.Connection.requester_id == user_id,
        models.Connection.status == ConnectionStatus.PENDING
    ).order_by(models.Connection.created_at.desc())
    result = await db.execute(query)
    return result.scalars().all()

async def get_declined_connections_for_user(db: AsyncSession, *, user_id: int) -> List[models.Connection]:
    """Get connections involving the user that have been declined (either by them or by the other party)."""
    query = select(models.Connection).options(
        selectinload(models.Connection.requester).selectinload(models.User.profile),
        selectinload(models.Connection.recipient).selectinload(models.User.profile)
    ).where(
        or_(models.Connection.requester_id == user_id, models.Connection.recipient_id == user_id),
        models.Connection.status == ConnectionStatus.DECLINED
    ).order_by(models.Connection.updated_at.desc())
    result = await db.execute(query)
    return result.scalars().all() 

--- END OF FILE: app/crud/crud_connection.py ---

================================================================================

--- START OF FILE: app/crud/crud_user_profile.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.sql import func, or_, not_, exists # Add or_, not_, exists
from typing import Optional, List, Tuple # Add Tuple
from pydantic import HttpUrl # Import HttpUrl
import logging # Import logging
from sqlalchemy.orm import joinedload # Add joinedload for eager loading user data

from app import models, schemas
from app.models.profile import UserProfile # Corrected import path
from app.models.user import User # Import User model
from app.models.connection import Connection, ConnectionStatus # Add Connection imports
from app.schemas.user_profile import UserProfileUpdate # Import the schema directly
from app.utils.embeddings import generate_embedding # Import the embedding function

logger = logging.getLogger(__name__) # Add logger

async def get_profile_by_user_id(db: AsyncSession, *, user_id: int) -> Optional[UserProfile]:
    """Get user profile by user ID."""
    result = await db.execute(select(UserProfile).filter(UserProfile.user_id == user_id))
    return result.scalars().first()

async def create_profile_for_user(db: AsyncSession, *, user_id: int) -> UserProfile:
    """Create a new default profile for a user."""
    db_profile = UserProfile(user_id=user_id)
    db.add(db_profile)
    await db.commit()
    await db.refresh(db_profile)
    return db_profile

async def update_profile(
    db: AsyncSession, *, db_obj: UserProfile, obj_in: UserProfileUpdate
) -> UserProfile:
    """Update user profile and generate embedding."""
    logger.info(f"Updating profile for user_id: {db_obj.user_id}")
    update_data = obj_in.model_dump(exclude_unset=True)

    # Update standard fields
    for field, value in update_data.items():
        # Convert HttpUrl to string before setting attribute for DB
        if field == 'linkedin_profile_url' and isinstance(value, HttpUrl):
            setattr(db_obj, field, str(value))
        else:
            setattr(db_obj, field, value)

    # Combine text fields for embedding generation
    # Join list fields into single strings first
    profile_text_parts = [
        db_obj.title or "",
        db_obj.bio or "",
        " ".join(db_obj.skills_expertise) if db_obj.skills_expertise is not None and len(db_obj.skills_expertise) > 0 else "",
        " ".join(db_obj.industry_focus) if db_obj.industry_focus is not None and len(db_obj.industry_focus) > 0 else "", # Assuming industry_focus is also ARRAY(String)
        db_obj.project_interests_goals or "",
        " ".join(db_obj.collaboration_preferences) if db_obj.collaboration_preferences is not None and len(db_obj.collaboration_preferences) > 0 else "",
        " ".join(db_obj.tools_technologies) if db_obj.tools_technologies is not None and len(db_obj.tools_technologies) > 0 else ""
    ]
    # Filter out empty strings before joining
    profile_text = " ".join(filter(None, profile_text_parts)).strip()

    if profile_text:
        logger.info(f"Generating embedding for user_id: {db_obj.user_id}")
        embedding = generate_embedding(profile_text)
        logger.info(f"Type of embedding from generate_embedding: {type(embedding)} for user_id: {db_obj.user_id}")

        if embedding is not None:
            logger.info(f"Generated embedding (is not None) for user_id: {db_obj.user_id}. Type: {type(embedding)}, Length: {len(embedding)}")
            try:
                db_obj.profile_vector = embedding
                logger.info(f"Assigned embedding to db_obj.profile_vector. Type now: {type(db_obj.profile_vector)} for user_id: {db_obj.user_id}")
            except Exception as e_assign:
                logger.error(f"ERROR DURING ASSIGNMENT to db_obj.profile_vector for user_id {db_obj.user_id}: {e_assign}", exc_info=True)
                raise e_assign # Re-raise to see it in seed script
            logger.info(f"Embedding assigned successfully for user_id: {db_obj.user_id}")
        else:
            logger.warning(f"Embedding generation failed for user_id: {db_obj.user_id}. Setting profile_vector to None.")
            db_obj.profile_vector = None
    else:
        logger.info(f"No text content for embedding for user_id: {db_obj.user_id}. Setting profile_vector to None.")
        db_obj.profile_vector = None

    try:
        db.add(db_obj)
        logger.info(f"Preparing to commit for user_id: {db_obj.user_id}. Current profile_vector type: {type(db_obj.profile_vector)}")
        # logger.info(f"Value of db_obj.profile_vector before commit: {db_obj.profile_vector is not None} (Type: {type(db_obj.profile_vector)}) for user_id: {db_obj.user_id}")
        logger.info(f"Type of db_obj.profile_vector before commit: {type(db_obj.profile_vector)} for user_id: {db_obj.user_id}") # Simplified logging
        logger.info(f"Attempting to commit profile changes for user_id: {db_obj.user_id}")
        await db.commit()
        logger.info(f"Commit successful for user_id: {db_obj.user_id}")
        await db.refresh(db_obj)
        logger.info(f"Refresh successful for user_id: {db_obj.user_id}")
    except Exception as e:
        logger.error(f"DATABASE COMMIT/REFRESH FAILED for user_id {db_obj.user_id}: {e}", exc_info=True)
        await db.rollback()
        logger.info(f"Rolled back transaction for user_id: {db_obj.user_id}")
        # Re-raise the exception so the endpoint handler knows about it
        raise e 
    
    return db_obj 

async def find_similar_users(
    db: AsyncSession,
    *,
    requesting_user: models.User,
    limit: int = 10
) -> List[Tuple[UserProfile, float]]: # Return tuples of (profile, distance)
    """Find users with similar profile vectors within the same space, excluding self, colleagues, and existing connections."""
    if not requesting_user.profile or requesting_user.profile.profile_vector is None:
        logger.warning(f"User {requesting_user.id} has no profile vector. Cannot find similar users.")
        return []
    if requesting_user.space_id is None:
        logger.warning(f"User {requesting_user.id} is not associated with a space. Cannot find similar users.")
        return []

    embedding = requesting_user.profile.profile_vector
    space_id = requesting_user.space_id
    user_id = requesting_user.id
    company_id = requesting_user.company_id
    startup_id = requesting_user.startup_id

    logger.info(f"Finding similar users for user_id={user_id} in space_id={space_id}")

    # Subquery to find user IDs with existing pending or accepted connections
    existing_connection_subquery = (
        select(Connection.id)
        .where(
            or_(
                (Connection.requester_id == user_id) & (Connection.recipient_id == User.id),
                (Connection.recipient_id == user_id) & (Connection.requester_id == User.id)
            ),
            Connection.status.in_([ConnectionStatus.PENDING, ConnectionStatus.ACCEPTED])
        )
        .limit(1)
    )

    stmt = (
        select(
            UserProfile,
            UserProfile.profile_vector.cosine_distance(embedding).label('distance')
        )
        .join(User, UserProfile.user_id == User.id) # Join UserProfile with User
        .options(joinedload(UserProfile.user)) # Eager load the User relationship
        .filter(User.space_id == space_id) # Filter by the same space_id from the User table
        .filter(User.id != user_id) # Filter out the user themselves
        .filter(User.status == 'ACTIVE') # Only match with active users
        .filter(UserProfile.profile_vector.is_not(None)) # Ensure target users have vectors
        .filter(not_(exists(existing_connection_subquery))) # <-- Restore this filter
    )

    # Add filters to exclude users from the same company or startup, if applicable
    if company_id:
        stmt = stmt.filter(User.company_id != company_id)
        logger.info(f"Excluding users from company_id={company_id} for user_id={user_id}")
    if startup_id: # If the requesting user belongs to a startup
        # Exclude other users from the SAME startup.
        # Users with no startup (startup_id IS NULL) should NOT be excluded by this.
        stmt = stmt.filter(or_(User.startup_id.is_(None), User.startup_id != startup_id))
        logger.info(f"Excluding users from startup_id={startup_id} (but allowing NULL startup_id) for user_id={user_id}")
    # else: # Optional: if you want to log when the requesting user doesn't have a startup_id
        # logger.info(f"Requesting user {user_id} does not have a startup_id, so no startup-based exclusion applied.")

    stmt = stmt.order_by(UserProfile.profile_vector.cosine_distance(embedding)).limit(limit)

    results = await db.execute(stmt)
    
    # Fetch all results as (UserProfile, distance) tuples
    similar_users_with_distance = results.fetchall()
    for profile_obj, dist in similar_users_with_distance:
        logger.info(f"CRUD_USER_PROFILE: Candidate User ID: {profile_obj.user_id}, Distance: {dist}")

    logger.info(f"Found {len(similar_users_with_distance)} similar users for user_id={user_id}")
    return similar_users_with_distance # Return the list of tuples

--- END OF FILE: app/crud/crud_user_profile.py ---

================================================================================

--- START OF FILE: app/crud/crud_chat.py ---

from sqlalchemy import select, or_, and_, update, func, delete
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import joinedload, selectinload, contains_eager
from datetime import datetime, timedelta, timezone # Ensure datetime and timedelta are imported

from app.models.chat import ChatMessage, Conversation, ConversationParticipant, MessageReaction
from app.models.user import User
from app.schemas.chat import ChatMessageCreate, ConversationCreate, ChatMessageUpdate
from typing import List, Optional, Set
from app.core.config import settings # Import settings

# Need crud_notification for creating notifications
from app.crud import crud_notification
import logging # Add logger

logger = logging.getLogger(__name__) # Add logger instance

async def get_or_create_conversation(
    db: AsyncSession, *, user1_id: int, user2_id: int
) -> Conversation:
    """Gets an existing 1-on-1 conversation or creates a new one."""
    # Ensure order for consistent lookup
    participant_ids_sorted = sorted([user1_id, user2_id])

    # Try to find an existing conversation with these exact two participants
    # This query is a bit more complex because we need to match participants exactly.
    stmt = (
        select(Conversation)
        .join(Conversation.participants)
        .group_by(Conversation.id)
        .having(func.count(User.id) == 2) # Ensure exactly two participants
        .having(func.bool_and(User.id.in_(participant_ids_sorted))) # Both users are in this conversation
    )
    result = await db.execute(stmt)
    conversation = result.scalars().first()

    if not conversation:
        # Create new conversation
        conversation = Conversation()
        db.add(conversation)
        await db.flush() # Ensure conversation.id is populated before use
        # Add participants
        user1_participant = ConversationParticipant(conversation_id=conversation.id, user_id=user1_id)
        user2_participant = ConversationParticipant(conversation_id=conversation.id, user_id=user2_id)
        db.add_all([user1_participant, user2_participant])
        await db.commit()
        await db.refresh(conversation, attribute_names=['participants'])
    return conversation

async def create_message(
    db: AsyncSession, 
    *, 
    obj_in: ChatMessageCreate, 
    sender_id: int, 
    online_user_ids: Set[int] # Added parameter for online users
) -> ChatMessage:
    """Creates a new chat message, links it to a conversation,
       and creates notifications for offline participants."""
    
    conversation_id = obj_in.conversation_id
    conversation = None
    if not conversation_id and obj_in.recipient_id:
        conversation = await get_or_create_conversation(db, user1_id=sender_id, user2_id=obj_in.recipient_id)
        conversation_id = conversation.id
    elif conversation_id:
        # Fetch the conversation if only ID was provided initially
        res = await db.execute(select(Conversation).where(Conversation.id == conversation_id).options(selectinload(Conversation.participants)))
        conversation = res.scalars().first()
    
    if not conversation or not conversation_id:
        raise ValueError("Message creation requires a valid conversation.")

    db_obj_data = obj_in.model_dump()
    db_obj_data.pop('recipient_id', None)
    db_obj_data.pop('conversation_id', None)
    
    db_obj = ChatMessage(
        **db_obj_data,
        sender_id=sender_id,
        conversation_id=conversation_id
    )
    db.add(db_obj)
    await db.commit()
    
    # Eager load necessary fields for the response and for notification creation
    # First, refresh the message itself to get IDs and basic relationships populated
    await db.refresh(db_obj, attribute_names=['sender', 'conversation', 'reactions'])
    
    # Ensure the sender object is fully loaded (especially for full_name)
    sender_for_notification = None
    if db_obj.sender:
        await db.refresh(db_obj.sender) # Refresh the User object linked as sender
        sender_for_notification = db_obj.sender
    
    # Ensure the conversation object and its participants are loaded
    conversation_for_notification = None
    if db_obj.conversation:
        await db.refresh(db_obj.conversation, attribute_names=['participants'])
        conversation_for_notification = db_obj.conversation

    # --- Create Notifications for Offline Recipients --- 
    if conversation_for_notification and sender_for_notification: 
        sender_name = sender_for_notification.full_name or f"User {sender_for_notification.id}" # Fallback name
        notification_ref = f"conversation:{conversation_for_notification.id}"
        notification_link = f"/chat?conversationId={conversation_for_notification.id}"

        for participant_user_obj in conversation_for_notification.participants:
            if participant_user_obj.id != sender_id and participant_user_obj.id not in online_user_ids:
                try:
                    await crud_notification.create_notification(
                        db=db,
                        user_id=participant_user_obj.id,
                        type="new_chat_message",
                        message=f"New message from {sender_name}",
                        reference=notification_ref,
                        link=notification_link,
                        related_entity_id=db_obj.id # ID of the chat message itself
                    )
                    logger.info(f"Created new_chat_message notification for offline user {participant_user_obj.id} regarding conversation {conversation_for_notification.id}")
                except Exception as e:
                    logger.error(f"Failed to create notification for user {participant_user_obj.id}: {e}", exc_info=True)
        
    return db_obj

async def get_messages_for_conversation(
    db: AsyncSession, *, conversation_id: int, skip: int = 0, limit: int = 100
) -> List[ChatMessage]:
    """Retrieves messages for a specific conversation, ordered by creation time."""
    statement = (
        select(ChatMessage)
        .where(ChatMessage.conversation_id == conversation_id)
        .options(
            selectinload(ChatMessage.sender), 
            selectinload(ChatMessage.reactions) # Eager load reactions
        )
        .order_by(ChatMessage.created_at.asc()) 
        .offset(skip)
        .limit(limit)
    )
    result = await db.execute(statement)
    return result.scalars().all()

async def get_user_conversations_with_details(db: AsyncSession, user_id: int) -> List[dict]:
    """Fetches conversations for a user, eager loading participants, the last message,
       and determining if there are unread messages for the user."""
    
    # Subquery to find the latest message timestamp for each conversation the user is part of
    latest_message_subquery = (
        select(
            ChatMessage.conversation_id,
            func.max(ChatMessage.created_at).label("max_created_at")
        )
        # Ensure we only consider conversations the current user is in for the latest message context
        .join(ConversationParticipant, 
              (ChatMessage.conversation_id == ConversationParticipant.conversation_id) & 
              (ConversationParticipant.user_id == user_id)
             )
        .group_by(ChatMessage.conversation_id)
        .subquery('latest_message_sq')
    )

    # Main statement to select Conversation, the actual last ChatMessage, 
    # and the current user's ConversationParticipant record for last_read_at
    stmt = (
        select(
            Conversation,
            ChatMessage,  # The last message object
            ConversationParticipant  # The specific participant record for the current user
        )
        .join(
            ConversationParticipant,
            (Conversation.id == ConversationParticipant.conversation_id) &
            (ConversationParticipant.user_id == user_id) # Join to get *this* user's participation details
        )
        .outerjoin( # Join to the subquery to find the timestamp of the latest message
            latest_message_subquery, 
            Conversation.id == latest_message_subquery.c.conversation_id
        )
        .outerjoin( # Join to ChatMessage again to get the actual latest message content
            ChatMessage,
            (Conversation.id == ChatMessage.conversation_id) &
            (ChatMessage.created_at == latest_message_subquery.c.max_created_at)
        )
        .options(
            selectinload(Conversation.participants), # Eager load all participants for "other_user" logic
            # No need to selectinload current_user_participant_orm as it's directly selected
        )
        .order_by(latest_message_subquery.c.max_created_at.desc().nulls_last(), Conversation.id)
    )

    result = await db.execute(stmt)
    # result_tuples will contain (Conversation, ChatMessage (or None), ConversationParticipant)
    result_tuples = result.unique().all()

    conversations_data = []
    for conv_orm, last_msg_orm_from_query, current_user_participant_orm in result_tuples:
        other_participant_user = next((p for p in conv_orm.participants if p.id != user_id), None)
        if not other_participant_user:
            # This should ideally not happen if data is consistent
            # (i.e., user is a participant and there's another participant)
            continue

        processed_last_message = None
        if last_msg_orm_from_query:
            # Refresh required attributes for the Pydantic model serialization
            await db.refresh(last_msg_orm_from_query, attribute_names=['sender', 'reactions'])
            processed_last_message = last_msg_orm_from_query

        # Calculate has_unread_messages
        has_unread = False
        if processed_last_message and current_user_participant_orm:
            # Check if the last message is not from the current user
            if processed_last_message.sender_id != user_id:
                # Ensure datetimes are comparable (both UTC aware)
                participant_last_read_dt = current_user_participant_orm.last_read_at
                last_message_created_dt = processed_last_message.created_at

                # Convert participant_last_read_dt if it's not None
                if participant_last_read_dt:
                    if participant_last_read_dt.tzinfo is None:
                        participant_last_read_dt = participant_last_read_dt.replace(tzinfo=timezone.utc)
                    elif participant_last_read_dt.tzinfo != timezone.utc:
                        participant_last_read_dt = participant_last_read_dt.astimezone(timezone.utc)
                
                # Convert last_message_created_dt (should always exist if processed_last_message exists)
                if last_message_created_dt.tzinfo is None:
                    last_message_created_dt = last_message_created_dt.replace(tzinfo=timezone.utc)
                elif last_message_created_dt.tzinfo != timezone.utc:
                    last_message_created_dt = last_message_created_dt.astimezone(timezone.utc)

                if participant_last_read_dt is None or \
                   participant_last_read_dt < last_message_created_dt:
                    has_unread = True
        
        conversations_data.append({
            "id": conv_orm.id,
            "other_user": other_participant_user,
            "last_message": processed_last_message,
            "has_unread_messages": has_unread # Add the new field
        })

    return conversations_data

async def mark_conversation_as_read(db: AsyncSession, *, conversation_id: int, user_id: int) -> bool:
    """Updates the last_read_at timestamp for a user in a specific conversation."""
    stmt = (
        update(ConversationParticipant)
        .where(
            (ConversationParticipant.conversation_id == conversation_id) &
            (ConversationParticipant.user_id == user_id)
        )
        .values(last_read_at=func.now())
        # Ensure that the update actually happens if the row exists, 
        # and we can check if it did.
        .execution_options(synchronize_session=False) 
    )
    result = await db.execute(stmt)
    await db.commit()
    # result.rowcount will be 1 if the update occurred, 0 otherwise.
    return result.rowcount > 0

async def mark_conversation_messages_as_read(
    db: AsyncSession, *, conversation_id: int, reader_id: int
) -> int:
    """Marks all unread messages in a conversation as read by the reader_id.
       This assumes messages in the conversation are directed towards the reader implicitly
       or that recipient_id is not strictly used for read status in a conversation context.
       For more precise 'recipient' based read status, recipient_id on ChatMessage is key.
    """
    statement = (
        update(ChatMessage)
        .where(
            ChatMessage.conversation_id == conversation_id,
            ChatMessage.sender_id != reader_id,  # Don't mark own messages as read by self
            ChatMessage.read_at.is_(None)
        )
        .values(read_at=func.now())
        .execution_options(synchronize_session=False)
    )
    result = await db.execute(statement)
    await db.commit()
    return result.rowcount

async def add_or_toggle_reaction(db, *, message_id: int, user_id: int, emoji: str):
    # Check if reaction exists
    stmt = select(MessageReaction).where(
        MessageReaction.message_id == message_id,
        MessageReaction.user_id == user_id,
        MessageReaction.emoji == emoji
    )
    result = await db.execute(stmt)
    reaction = result.scalars().first()
    if reaction:
        # If exists, remove (toggle off)
        await db.delete(reaction)
        await db.commit()
        return None
    else:
        # Add new reaction
        new_reaction = MessageReaction(message_id=message_id, user_id=user_id, emoji=emoji)
        db.add(new_reaction)
        await db.commit()
        await db.refresh(new_reaction)
        return new_reaction

async def remove_reaction(db, *, message_id: int, user_id: int, emoji: str):
    stmt = select(MessageReaction).where(
        MessageReaction.message_id == message_id,
        MessageReaction.user_id == user_id,
        MessageReaction.emoji == emoji
    )
    result = await db.execute(stmt)
    reaction = result.scalars().first()
    if reaction:
        await db.delete(reaction)
        await db.commit()
        return True
    return False

async def get_reactions_for_message(db, *, message_id: int):
    stmt = select(MessageReaction).where(MessageReaction.message_id == message_id)
    result = await db.execute(stmt)
    return result.scalars().all()

async def get_chat_message_by_id(db: AsyncSession, *, message_id: int) -> ChatMessage | None:
    """Fetches a specific chat message by its ID, eager loading sender, reactions, and conversation with its participants."""
    statement = (
        select(ChatMessage)
        .where(ChatMessage.id == message_id)
        .options(
            selectinload(ChatMessage.sender),
            selectinload(ChatMessage.reactions),
            selectinload(ChatMessage.conversation).selectinload(Conversation.participants)
        )
    )
    result = await db.execute(statement)
    return result.scalars().first()

async def update_message(
    db: AsyncSession, *, message_id: int, current_user_id: int, new_content: str
) -> ChatMessage | None:
    """Updates a chat message if the user is the sender and it's within the edit window."""
    message = await get_chat_message_by_id(db=db, message_id=message_id)

    if not message:
        return None # Message not found
    
    if message.sender_id != current_user_id:
        return None # User is not the sender

    if message.is_deleted:
        return None # Message is already deleted

    # Ensure created_at is offset-aware (UTC)
    created_at_utc = message.created_at
    if created_at_utc.tzinfo is None:
        created_at_utc = created_at_utc.replace(tzinfo=timezone.utc)
    else:
        created_at_utc = created_at_utc.astimezone(timezone.utc)

    # Current time in UTC
    now_utc = datetime.now(timezone.utc)
    
    # Check if within the editable window
    if now_utc > created_at_utc + timedelta(seconds=settings.MESSAGE_EDIT_DELETE_WINDOW_SECONDS):
        return None # Past editable window

    message.content = new_content
    message.updated_at = now_utc
    
    db.add(message)
    await db.commit()
    await db.refresh(message, attribute_names=['sender', 'reactions'])
    return message

async def delete_message(
    db: AsyncSession, *, message_id: int, current_user_id: int
) -> ChatMessage | None:
    """Soft deletes a chat message if the user is the sender and it's within the delete window."""
    message = await get_chat_message_by_id(db=db, message_id=message_id)

    if not message:
        return None # Message not found

    if message.sender_id != current_user_id:
        return None # User is not the sender

    if message.is_deleted:
        return message # Already deleted, return current state

    # Ensure created_at is offset-aware (UTC)
    created_at_utc = message.created_at
    if created_at_utc.tzinfo is None:
        created_at_utc = created_at_utc.replace(tzinfo=timezone.utc)
    else:
        created_at_utc = created_at_utc.astimezone(timezone.utc)
    
    # Current time in UTC
    now_utc = datetime.now(timezone.utc)

    # Check if within the deletable window
    if now_utc > created_at_utc + timedelta(seconds=settings.MESSAGE_EDIT_DELETE_WINDOW_SECONDS):
        return None # Past deletable window

    message.is_deleted = True
    message.updated_at = now_utc # Mark when the deletion occurred
    # Optionally, clear content for privacy, though frontend will handle display
    # message.content = "This message was deleted."

    db.add(message)
    await db.commit()
    await db.refresh(message, attribute_names=['sender', 'reactions'])
    return message

# Old get_conversation_messages - to be replaced or removed
# async def get_conversation_messages(
#     db: AsyncSession, *, user1_id: int, user2_id: int, skip: int = 0, limit: int = 100
# ) -> list[ChatMessage]:
#     """Retrieves messages exchanged between two users, ordered by creation time."""
#     statement = (
#         select(ChatMessage)
#         .where(
#             or_(
#                 and_(ChatMessage.sender_id == user1_id, ChatMessage.recipient_id == user2_id),
#                 and_(ChatMessage.sender_id == user2_id, ChatMessage.recipient_id == user1_id),
#             )
#         )
#         .options(joinedload(ChatMessage.sender), joinedload(ChatMessage.recipient)) # Eager load users
#         .order_by(ChatMessage.created_at.desc()) # Get latest first
#         .offset(skip)
#         .limit(limit)
#     )
#     result = await db.execute(statement)
#     messages = result.scalars().all()
#     return list(reversed(messages)) # Reverse to show oldest first in typical chat UI

# Old mark_messages_as_read - to be replaced or removed
# async def mark_messages_as_read(
#     db: AsyncSession, *, recipient_id: int, sender_id: int
# ) -> int:
#     """Marks all unread messages from sender_id to recipient_id as read."""
#     statement = (
#         update(ChatMessage)
#         .where(
#             ChatMessage.recipient_id == recipient_id,
#             ChatMessage.sender_id == sender_id,
#             ChatMessage.read_at.is_(None) # Only update unread messages
#         )
#         .values(read_at=func.now())
#         .execution_options(synchronize_session=False) # Important for async updates
#     )
#     result = await db.execute(statement)
#     await db.commit()
#     return result.rowcount 

--- END OF FILE: app/crud/crud_chat.py ---

================================================================================

--- START OF FILE: app/crud/crud_notification.py ---

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update
from typing import List, Optional
import logging

from app.models.notification import Notification

logger = logging.getLogger(__name__)

async def create_notification(
    db: AsyncSession, 
    *, 
    user_id: int, 
    type: str, 
    message: str, 
    related_entity_id: Optional[int] = None,
    reference: Optional[str] = None,
    link: Optional[str] = None
) -> Notification:
    """Create a new notification."""
    db_notification = Notification(
        user_id=user_id,
        type=type,
        message=message,
        related_entity_id=related_entity_id,
        reference=reference,
        link=link,
        is_read=False
    )
    db.add(db_notification)
    await db.commit()
    await db.refresh(db_notification)
    logger.info(f"Created notification id {db_notification.id} for user {user_id}")
    return db_notification

async def get_notifications_for_user(
    db: AsyncSession, 
    *, 
    user_id: int, 
    skip: int = 0, 
    limit: int = 100, 
    include_read: bool = False
) -> List[Notification]:
    """Get notifications for a user, optionally filtering out read ones."""
    query = select(Notification).filter(Notification.user_id == user_id)
    if not include_read:
        query = query.filter(Notification.is_read == False)
    
    query = query.order_by(Notification.created_at.desc()).offset(skip).limit(limit)
    
    result = await db.execute(query)
    return result.scalars().all()

async def get_notification_by_id(db: AsyncSession, *, notification_id: int) -> Optional[Notification]:
    """Get a notification by its ID."""
    result = await db.execute(select(Notification).filter(Notification.id == notification_id))
    return result.scalars().first()

async def get_notification_by_related_entity(
    db: AsyncSession, 
    *, 
    user_id: int, 
    type: str, 
    related_entity_id: int
) -> Optional[Notification]:
    """Get a specific notification based on user, type, and related entity ID."""
    query = select(Notification).filter(
        Notification.user_id == user_id,
        Notification.type == type,
        Notification.related_entity_id == related_entity_id,
        Notification.is_read == False # Usually want the unread one
    ).order_by(Notification.created_at.desc()) # Get the latest if multiple somehow exist
    
    result = await db.execute(query)
    return result.scalars().first()

async def mark_notification_as_read(db: AsyncSession, *, notification: Notification) -> Notification:
    """Mark a specific notification as read."""
    if not notification.is_read:
        notification.is_read = True
        db.add(notification)
        await db.commit()
        await db.refresh(notification)
        logger.info(f"Marked notification id {notification.id} as read for user {notification.user_id}")
    return notification

async def mark_all_notifications_as_read(db: AsyncSession, *, user_id: int) -> int:
    """Mark all unread notifications for a user as read. Returns count of marked items."""
    stmt = (
        update(Notification)
        .where(Notification.user_id == user_id, Notification.is_read == False)
        .values(is_read=True)
    )
    result = await db.execute(stmt)
    await db.commit() # Commit the change
    count = result.rowcount
    logger.info(f"Marked {count} notifications as read for user {user_id}")
    return count

async def mark_notifications_as_read_by_ref(
    db: AsyncSession, 
    *, 
    user_id: int, 
    reference: str,
    notification_type: str = "new_chat_message"
) -> int:
    """Mark all unread notifications for a user with a specific reference and type as read.
       Returns the count of notifications marked as read.
    """
    stmt = (
        update(Notification)
        .where(
            Notification.user_id == user_id,
            Notification.reference == reference,
            Notification.type == notification_type,
            Notification.is_read == False
        )
        .values(is_read=True)
        .execution_options(synchronize_session=False)
    )
    result = await db.execute(stmt)
    await db.commit()
    count = result.rowcount
    if count > 0:
        logger.info(f"Marked {count} notifications of type '{notification_type}' as read for user {user_id} with reference '{reference}'")
    return count

async def get_notifications_by_type_for_user(
    db: AsyncSession,
    user_id: int,
    notification_type: str,
    is_read: bool | None = None, # Optional filter by read status
    skip: int = 0,
    limit: int = 100
) -> List[Notification]:
    stmt = (
        select(Notification)
        .where(Notification.user_id == user_id)
        .where(Notification.type == notification_type)
    )
    if is_read is not None:
        stmt = stmt.where(Notification.is_read == is_read)
    
    stmt = stmt.order_by(Notification.created_at.desc()).offset(skip).limit(limit)
    result = await db.execute(stmt)
    return result.scalars().all()

async def mark_notification_as_read_by_id(db: AsyncSession, notification_id: int) -> Notification | None:
    stmt = (
        update(Notification)
        .where(Notification.id == notification_id)
        .values(is_read=True)
        .returning(Notification)
    )
    result = await db.execute(stmt)
    await db.commit()
    return result.scalar_one_or_none() 

--- END OF FILE: app/crud/crud_notification.py ---

================================================================================

--- START OF FILE: app/crud/base.py ---

from typing import Any, Dict, Generic, List, Optional, Type, TypeVar, Union
from fastapi.encoders import jsonable_encoder
from pydantic import BaseModel
from sqlalchemy.orm import Session
from sqlalchemy.future import select # For SQLAlchemy 2.0 style selects

from app.db.base_class import Base # Your SQLAlchemy declarative base

ModelType = TypeVar("ModelType", bound=Base)
CreateSchemaType = TypeVar("CreateSchemaType", bound=BaseModel)
UpdateSchemaType = TypeVar("UpdateSchemaType", bound=BaseModel)

class CRUDBase(Generic[ModelType, CreateSchemaType, UpdateSchemaType]):
    def __init__(self, model: Type[ModelType]):
        """
        CRUD object with default methods to Create, Read, Update, Delete (CRUD).

        **Parameters**

        * `model`: A SQLAlchemy model class
        """
        self.model = model

    async def get(self, db: Session, id: Any) -> Optional[ModelType]:
        statement = select(self.model).filter(self.model.id == id)
        result = await db.execute(statement)
        return result.scalar_one_or_none()

    async def get_multi(
        self, db: Session, *, skip: int = 0, limit: int = 100
    ) -> List[ModelType]:
        statement = select(self.model).offset(skip).limit(limit)
        result = await db.execute(statement)
        return result.scalars().all()

    async def create(self, db: Session, *, obj_in: CreateSchemaType) -> ModelType:
        obj_in_data = jsonable_encoder(obj_in)
        db_obj = self.model(**obj_in_data)  # type: ignore
        db.add(db_obj)
        await db.commit()
        await db.refresh(db_obj)
        return db_obj

    async def update(
        self,
        db: Session,
        *,
        db_obj: ModelType,
        obj_in: Union[UpdateSchemaType, Dict[str, Any]]
    ) -> ModelType:
        obj_data = jsonable_encoder(db_obj)
        if isinstance(obj_in, dict):
            update_data = obj_in
        else:
            update_data = obj_in.model_dump(exclude_unset=True) # Use model_dump for Pydantic v2
        for field in obj_data:
            if field in update_data:
                setattr(db_obj, field, update_data[field])
        db.add(db_obj)
        await db.commit()
        await db.refresh(db_obj)
        return db_obj

    async def remove(self, db: Session, *, id: Any) -> Optional[ModelType]: # Changed to return Optional[ModelType]
        obj = await self.get(db, id=id) # Use await for async get
        if obj:
            await db.delete(obj)
            await db.commit()
        return obj 

--- END OF FILE: app/crud/base.py ---

================================================================================

--- START OF FILE: app/db/session.py ---

from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from app.core.config import settings

# Convert Pydantic DSN object to string for SQLAlchemy engine
engine = create_async_engine(str(settings.DATABASE_URL), pool_pre_ping=True)

# Create a session factory bound to the engine
AsyncSessionLocal = sessionmaker(
    engine,
    class_=AsyncSession,
    expire_on_commit=False,
    autocommit=False,
    autoflush=False,
)

# Dependency function for FastAPI to get a DB session
async def get_db() -> AsyncSession:
    """Dependency function to get DB session."""
    async with AsyncSessionLocal() as session:
        try:
            yield session
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close() 

--- END OF FILE: app/db/session.py ---

================================================================================

--- START OF FILE: app/db/base_class.py ---

from sqlalchemy.orm import declarative_base

# Define the declarative base
Base = declarative_base() 

--- END OF FILE: app/db/base_class.py ---

================================================================================

--- START OF FILE: app/db/__pycache__/session.cpython-312.pyc ---



    MhD                         d dl mZmZ d dlmZ d dlmZ  e eej                        d      Z	 ee	eddd      Z
defd	Zy
)    )create_async_engineAsyncSession)sessionmaker)settingsT)
pool_pre_pingF)class_expire_on_commit
autocommit	autoflushreturnc                 P  K   t               4 d{   } 	 |  	 | j                          d{    ddd      d{    y7 4# t        $ r | j                          d{  7    w xY w7 ># | j                          d{  7   w xY w7 N# 1 d{  7  sw Y   yxY ww)z&Dependency function to get DB session.N)AsyncSessionLocal	Exceptionrollbackclose)sessions    D/home/marcel/ShareYourSpace/shareyourspace-backend/app/db/session.pyget_dbr      s      " " "g	"M
 --/!!" " "  	""$$$	 
"'--/!!" " " "s   B&AB&BABA/BB& BB&A,$A'%A,,A1/B1BB
BBB&B#BB#B&N)sqlalchemy.ext.asyncior   r   sqlalchemy.ormr   app.core.configr   strDATABASE_URLenginer   r        r   <module>r      sO    D ' $ 
S!6!67t	L !
 	"l 	"r   

--- END OF FILE: app/db/__pycache__/session.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/db/__pycache__/base_class.cpython-312.pyc ---



    dZhe                          d dl mZ  e       Zy)    )declarative_baseN)sqlalchemy.ormr   Base     G/home/marcel/ShareYourSpace/shareyourspace-backend/app/db/base_class.py<module>r	      s    + r   

--- END OF FILE: app/db/__pycache__/base_class.cpython-312.pyc ---

================================================================================

--- START OF FILE: app/__pycache__/__init__.cpython-312.pyc ---



    %h                           y )N r       B/home/marcel/ShareYourSpace/shareyourspace-backend/app/__init__.py<module>r      s   r   

--- END OF FILE: app/__pycache__/__init__.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/env.py ---

import asyncio # Import asyncio
import os
import sys
from logging.config import fileConfig

# Explicitly load .env file before importing application modules
from dotenv import load_dotenv
load_dotenv()

from sqlalchemy import pool
# Use create_async_engine for async connection
from sqlalchemy.ext.asyncio import create_async_engine

from alembic import context

# Ensure the app directory is in the Python path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# Import application settings and Base model
# Now settings should correctly load variables from the .env file
from app.core.config import settings
from app.db.base_class import Base

# --- Import all necessary models for Alembic autogenerate ---
# Ensure all models are imported here so Base.metadata is complete
from app.models.user import User
from app.models.organization import Company, Startup
from app.models.profile import UserProfile
from app.models.space import SpaceNode, Workstation, WorkstationAssignment
from app.models.connection import Connection
from app.models.notification import Notification
from app.models.verification_token import VerificationToken
from app.models.password_reset_token import PasswordResetToken
from app.models.invitation import Invitation # Ensure Invitation model is imported
# --- End Model Imports ---

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Check for an environment variable to use IP for Alembic
ALEMBIC_USE_DB_IP = os.getenv("ALEMBIC_USE_DB_IP", "false").lower() == "true"
# This IP was found using: docker network inspect shareyourspace-backend_default
# It's the IP of the 'db' service on that network.
DB_IP_ADDRESS = "172.18.0.2"

db_url_str = str(settings.DATABASE_URL) # Get DATABASE_URL from Pydantic settings

if ALEMBIC_USE_DB_IP:
    print(f"ALEMBIC_INFO: ALEMBIC_USE_DB_IP is true. Original DB_URL: {db_url_str}")
    if "@db:" in db_url_str: # Basic check for hostname 'db'
        db_url_str = db_url_str.replace("@db:", f"@{DB_IP_ADDRESS}:")
        print(f"ALEMBIC_INFO: Modified DB_URL for Alembic: {db_url_str}")
    else:
        print(f"ALEMBIC_WARNING: Could not find '@db:' in DB_URL to replace with IP. Using original: {db_url_str}")
else:
    print(f"ALEMBIC_INFO: ALEMBIC_USE_DB_IP is false or not set. Using original DB_URL: {db_url_str}")

# Set the database URL directly in the config object from settings
# This ensures commands like 'revision' use the correct, environment-aware URL
# Convert Pydantic SecretStr to plain string if necessary
config.set_main_option("sqlalchemy.url", db_url_str)

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# Set the Base metadata object for 'autogenerate' support
target_metadata = Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def run_migrations_offline() -> None:
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    # Use the DATABASE_URL from application settings
    context.configure(
        url=config.get_main_option("sqlalchemy.url"), # Use the potentially modified URL
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()


# --- Start of modified run_migrations_online ---
def do_run_migrations(connection):
    context.configure(connection=connection, target_metadata=target_metadata)

    with context.begin_transaction():
        context.run_migrations()

async def run_migrations_online() -> None:
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    # --- Print the DB URL being used for debugging ---
    # print(f"Attempting to connect to database: {db_url}") # Removed debug print
    # -----------------------------------------------

    # Create an async engine using the DATABASE_URL from settings
    connectable = create_async_engine(
        config.get_main_option("sqlalchemy.url"), # Use the potentially modified URL
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    # Dispose the engine
    await connectable.dispose()
# --- End of modified run_migrations_online ---


if context.is_offline_mode():
    run_migrations_offline()
else:
    # Run the async online migration function using asyncio
    asyncio.run(run_migrations_online())


--- END OF FILE: alembic/env.py ---

================================================================================

--- START OF FILE: alembic/script.py.mako ---

"""${message}

Revision ID: ${up_revision}
Revises: ${down_revision | comma,n}
Create Date: ${create_date}

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
${imports if imports else ""}

# revision identifiers, used by Alembic.
revision: str = ${repr(up_revision)}
down_revision: Union[str, None] = ${repr(down_revision)}
branch_labels: Union[str, Sequence[str], None] = ${repr(branch_labels)}
depends_on: Union[str, Sequence[str], None] = ${repr(depends_on)}


def upgrade() -> None:
    """Upgrade schema."""
    ${upgrades if upgrades else "pass"}


def downgrade() -> None:
    """Downgrade schema."""
    ${downgrades if downgrades else "pass"}


--- END OF FILE: alembic/script.py.mako ---

================================================================================

--- START OF FILE: alembic/README ---

Generic single-database configuration.

--- END OF FILE: alembic/README ---

================================================================================

--- START OF FILE: alembic/versions/25802b79acda_add_message_reaction_table.py ---

"""Add message_reaction table

Revision ID: 25802b79acda
Revises: a3cc12c29cbe
Create Date: 2025-05-09 08:20:58.573890

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '25802b79acda'
down_revision: Union[str, None] = 'a3cc12c29cbe'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('message_reactions',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('message_id', sa.Integer(), nullable=False),
    sa.Column('emoji_char', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['message_id'], ['chat_messages.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('user_id', 'message_id', 'emoji_char', name='_user_message_emoji_uc')
    )
    op.create_index(op.f('ix_message_reactions_id'), 'message_reactions', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_message_reactions_id'), table_name='message_reactions')
    op.drop_table('message_reactions')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/25802b79acda_add_message_reaction_table.py ---

================================================================================

--- START OF FILE: alembic/versions/08eced71251f_add_last_read_at_to_.py ---

"""Add last_read_at to ConversationParticipant

Revision ID: 08eced71251f
Revises: f6faaa54ca44
Create Date: 2025-05-13 05:49:17.342621

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '08eced71251f'
down_revision: Union[str, None] = 'f6faaa54ca44'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('conversation_participants', sa.Column('joined_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True))
    op.add_column('conversation_participants', sa.Column('last_read_at', sa.DateTime(timezone=True), nullable=True))
    op.drop_constraint('conversation_participants_user_id_fkey', 'conversation_participants', type_='foreignkey')
    op.drop_constraint('conversation_participants_conversation_id_fkey', 'conversation_participants', type_='foreignkey')
    op.create_foreign_key(None, 'conversation_participants', 'conversations', ['conversation_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(None, 'conversation_participants', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'conversation_participants', type_='foreignkey')
    op.drop_constraint(None, 'conversation_participants', type_='foreignkey')
    op.create_foreign_key('conversation_participants_conversation_id_fkey', 'conversation_participants', 'conversations', ['conversation_id'], ['id'])
    op.create_foreign_key('conversation_participants_user_id_fkey', 'conversation_participants', 'users', ['user_id'], ['id'])
    op.drop_column('conversation_participants', 'last_read_at')
    op.drop_column('conversation_participants', 'joined_at')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/08eced71251f_add_last_read_at_to_.py ---

================================================================================

--- START OF FILE: alembic/versions/9a0c9d66f8f4_create_connection_table.py ---

"""Create connection table

Revision ID: 9a0c9d66f8f4
Revises: 5294db0e7af9
Create Date: 2025-04-28 05:09:39.143766

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '9a0c9d66f8f4'
down_revision: Union[str, None] = '5294db0e7af9'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('connections',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('requester_id', sa.Integer(), nullable=False),
    sa.Column('recipient_id', sa.Integer(), nullable=False),
    sa.Column('status', sa.String(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['recipient_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['requester_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('requester_id', 'recipient_id', name='_requester_recipient_uc')
    )
    op.create_index(op.f('ix_connections_id'), 'connections', ['id'], unique=False)
    op.create_index(op.f('ix_connections_status'), 'connections', ['status'], unique=False)
    # op.drop_index('ix_user_profiles_profile_vector_hnsw', table_name='user_profiles', postgresql_using='hnsw') # Removed incorrect autogen line
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # op.create_index('ix_user_profiles_profile_vector_hnsw', 'user_profiles', ['profile_vector'], unique=False, postgresql_using='hnsw') # Removed incorrect autogen line
    op.drop_index(op.f('ix_connections_status'), table_name='connections')
    op.drop_index(op.f('ix_connections_id'), table_name='connections')
    op.drop_table('connections')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/9a0c9d66f8f4_create_connection_table.py ---

================================================================================

--- START OF FILE: alembic/versions/a9db281d289d_add_attachment_fields_to_chat_messages_.py ---

"""Add attachment fields to chat_messages and conversation models

Revision ID: a9db281d289d
Revises: 25802b79acda
Create Date: 2025-05-09 11:17:48.347454

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'a9db281d289d'
down_revision: Union[str, None] = '25802b79acda'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('conversations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_conversations_id'), 'conversations', ['id'], unique=False)
    op.create_table('conversation_participants',
    sa.Column('conversation_id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.ForeignKeyConstraint(['conversation_id'], ['conversations.id'], ),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('conversation_id', 'user_id')
    )
    op.add_column('chat_messages', sa.Column('conversation_id', sa.Integer(), nullable=True))
    op.add_column('chat_messages', sa.Column('attachment_url', sa.String(), nullable=True))
    op.add_column('chat_messages', sa.Column('attachment_filename', sa.String(), nullable=True))
    op.add_column('chat_messages', sa.Column('attachment_mimetype', sa.String(), nullable=True))
    op.alter_column('chat_messages', 'recipient_id',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('chat_messages', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('chat_messages', 'read_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.drop_index('ix_chat_messages_recipient_id', table_name='chat_messages', if_exists=True)
    op.drop_index('ix_chat_messages_sender_id', table_name='chat_messages', if_exists=True)
    op.create_foreign_key('fk_chat_messages_conversation_id_conversations', 'chat_messages', 'conversations', ['conversation_id'], ['id'])
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('fk_chat_messages_conversation_id_conversations', 'chat_messages', type_='foreignkey')
    op.create_index('ix_chat_messages_sender_id', 'chat_messages', ['sender_id'], unique=False)
    op.create_index('ix_chat_messages_recipient_id', 'chat_messages', ['recipient_id'], unique=False)
    op.alter_column('chat_messages', 'read_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('chat_messages', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.alter_column('chat_messages', 'recipient_id',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.drop_column('chat_messages', 'attachment_mimetype')
    op.drop_column('chat_messages', 'attachment_filename')
    op.drop_column('chat_messages', 'attachment_url')
    op.drop_column('chat_messages', 'conversation_id')
    op.drop_table('conversation_participants')
    op.drop_index(op.f('ix_conversations_id'), table_name='conversations')
    op.drop_table('conversations')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/a9db281d289d_add_attachment_fields_to_chat_messages_.py ---

================================================================================

--- START OF FILE: alembic/versions/6e42b588d2b7_add_user_profile_table_and_relationship.py ---

"""Add user profile table and relationship

Revision ID: 6e42b588d2b7
Revises: bd906d8dba40
Create Date: 2025-04-20 16:44:58.310022

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6e42b588d2b7'
down_revision: Union[str, None] = 'bd906d8dba40'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('user_profile',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(), nullable=True),
    sa.Column('bio', sa.Text(), nullable=True),
    sa.Column('contact_info_visibility', sa.Enum('PRIVATE', 'CONNECTIONS', 'PUBLIC', name='contact_visibility_enum'), nullable=False),
    sa.Column('skills_expertise', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('industry_focus', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('project_interests_goals', sa.Text(), nullable=True),
    sa.Column('collaboration_preferences', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('tools_technologies', postgresql.ARRAY(sa.String()), nullable=True),
    sa.Column('linkedin_profile_url', sa.String(), nullable=True),
    sa.Column('profile_picture_url', sa.String(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_user_profile_id'), 'user_profile', ['id'], unique=False)
    op.create_index(op.f('ix_user_profile_user_id'), 'user_profile', ['user_id'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_user_profile_user_id'), table_name='user_profile')
    op.drop_index(op.f('ix_user_profile_id'), table_name='user_profile')
    op.drop_table('user_profile')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/6e42b588d2b7_add_user_profile_table_and_relationship.py ---

================================================================================

--- START OF FILE: alembic/versions/f6faaa54ca44_add_message_reactions_table.py ---

"""add message reactions table

Revision ID: f6faaa54ca44
Revises: a9db281d289d
Create Date: 2025-05-11 07:04:29.275231

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'f6faaa54ca44'
down_revision: Union[str, None] = 'a9db281d289d'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('chat_messages', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=True,
               existing_server_default=sa.text('now()'))
    op.add_column('message_reactions', sa.Column('emoji', sa.String(), nullable=False))
    op.drop_constraint('_user_message_emoji_uc', 'message_reactions', type_='unique')
    op.create_unique_constraint('_message_user_emoji_uc', 'message_reactions', ['message_id', 'user_id', 'emoji'])
    op.drop_column('message_reactions', 'emoji_char')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('message_reactions', sa.Column('emoji_char', sa.VARCHAR(), autoincrement=False, nullable=False))
    op.drop_constraint('_message_user_emoji_uc', 'message_reactions', type_='unique')
    op.create_unique_constraint('_user_message_emoji_uc', 'message_reactions', ['user_id', 'message_id', 'emoji_char'])
    op.drop_column('message_reactions', 'emoji')
    op.alter_column('chat_messages', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               nullable=False,
               existing_server_default=sa.text('now()'))
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/f6faaa54ca44_add_message_reactions_table.py ---

================================================================================

--- START OF FILE: alembic/versions/835b07ae6f4e_add_approval_acceptance_to_invitations.py ---

"""add_approval_acceptance_to_invitations

Revision ID: 835b07ae6f4e
Revises: a0f683693a70
Create Date: 2024-05-26 12:00:00.000000 # Placeholder, will be updated by Alembic

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '835b07ae6f4e'
down_revision: Union[str, None] = 'a0f683693a70'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('invitations', sa.Column('approved_by_admin_id', sa.Integer(), nullable=True))
    op.create_foreign_key(
        'fk_invitations_approved_by_admin_id_users',
        'invitations', 'users',
        ['approved_by_admin_id'], ['id']
    )

    op.add_column('invitations', sa.Column('accepted_at', sa.DateTime(), nullable=True))
    op.add_column('invitations', sa.Column('accepted_by_user_id', sa.Integer(), nullable=True))
    op.create_foreign_key(
        'fk_invitations_accepted_by_user_id_users',
        'invitations', 'users',
        ['accepted_by_user_id'], ['id']
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('fk_invitations_accepted_by_user_id_users', 'invitations', type_='foreignkey')
    op.drop_column('invitations', 'accepted_by_user_id')
    op.drop_column('invitations', 'accepted_at')

    op.drop_constraint('fk_invitations_approved_by_admin_id_users', 'invitations', type_='foreignkey')
    op.drop_column('invitations', 'approved_by_admin_id')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/835b07ae6f4e_add_approval_acceptance_to_invitations.py ---

================================================================================

--- START OF FILE: alembic/versions/0581da68b2ba_change_connection_status_to_enum.py ---

"""Change connection status to Enum

Revision ID: 0581da68b2ba
Revises: 7bd0250369dc
Create Date: 2025-04-29 09:13:58.949165

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '0581da68b2ba'
down_revision: Union[str, None] = '7bd0250369dc'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

# Define the new enum type for convenience
connectionstatus_enum = sa.Enum('PENDING', 'ACCEPTED', 'DECLINED', 'BLOCKED', name='connectionstatus')

def upgrade() -> None:
    """Upgrade schema using multi-step process."""
    # 1. Create the ENUM type
    connectionstatus_enum.create(op.get_bind(), checkfirst=False)
    
    # 2. Add a new temporary column with the ENUM type
    op.add_column('connections', sa.Column('status_new', connectionstatus_enum, nullable=True))
    
    # 3. Update the new column based on the old string column values
    op.execute("""
        UPDATE connections
        SET status_new = CASE status
            WHEN 'pending' THEN 'PENDING'::connectionstatus
            WHEN 'accepted' THEN 'ACCEPTED'::connectionstatus
            WHEN 'declined' THEN 'DECLINED'::connectionstatus
            WHEN 'blocked' THEN 'BLOCKED'::connectionstatus
            ELSE NULL -- Or handle unexpected values appropriately
        END
    """)
    
    # 4. Make the new column non-nullable (assuming all rows were updated)
    op.alter_column('connections', 'status_new', nullable=False)
    
    # 5. Drop the old VARCHAR status column
    op.drop_column('connections', 'status')
    
    # 6. Rename the new column to 'status'
    op.alter_column('connections', 'status_new', new_column_name='status')


def downgrade() -> None:
    """Downgrade schema using multi-step process."""
    # 1. Add back the old VARCHAR column (nullable temporarily)
    op.add_column('connections', sa.Column('status_old', sa.VARCHAR(), nullable=True))
    
    # 2. Update the old column based on the ENUM values
    op.execute("""
        UPDATE connections
        SET status_old = status::text -- Cast enum back to text
    """)
    
    # 3. Make the old column non-nullable
    op.alter_column('connections', 'status_old', nullable=False)
    
    # 4. Drop the ENUM status column
    op.drop_column('connections', 'status')
    
    # 5. Rename the old column back to 'status'
    op.alter_column('connections', 'status_old', new_column_name='status')
    
    # 6. Drop the ENUM type
    connectionstatus_enum.drop(op.get_bind(), checkfirst=False)


--- END OF FILE: alembic/versions/0581da68b2ba_change_connection_status_to_enum.py ---

================================================================================

--- START OF FILE: alembic/versions/8c3a5a32e14b_add_verification_token_table.py ---

"""Add verification token table

Revision ID: 8c3a5a32e14b
Revises: 6f81518f99df
Create Date: 2025-04-19 16:47:01.473034

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '8c3a5a32e14b'
down_revision: Union[str, None] = '6f81518f99df'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('verification_tokens',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('token', sa.String(), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_verification_tokens_id'), 'verification_tokens', ['id'], unique=False)
    op.create_index(op.f('ix_verification_tokens_token'), 'verification_tokens', ['token'], unique=True)
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('users', 'updated_at',
               existing_type=postgresql.TIMESTAMP(),
               type_=sa.DateTime(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('users', 'updated_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(timezone=True),
               type_=postgresql.TIMESTAMP(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.drop_index(op.f('ix_verification_tokens_token'), table_name='verification_tokens')
    op.drop_index(op.f('ix_verification_tokens_id'), table_name='verification_tokens')
    op.drop_table('verification_tokens')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/8c3a5a32e14b_add_verification_token_table.py ---

================================================================================

--- START OF FILE: alembic/versions/c5a8a53fefb7_add_revoked_fields_to_invitations.py ---

"""add_revoked_fields_to_invitations

Revision ID: c5a8a53fefb7
Revises: 835b07ae6f4e
Create Date: 2024-05-27 10:00:00.000000 # Placeholder, Alembic will update

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'c5a8a53fefb7'
down_revision: Union[str, None] = '835b07ae6f4e'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('invitations', sa.Column('revoked_at', sa.DateTime(), nullable=True))
    op.add_column('invitations', sa.Column('revoked_by_admin_id', sa.Integer(), nullable=True))
    op.create_foreign_key(
        'fk_invitations_revoked_by_admin_id_users',
        'invitations', 'users',
        ['revoked_by_admin_id'], ['id']
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('fk_invitations_revoked_by_admin_id_users', 'invitations', type_='foreignkey')
    op.drop_column('invitations', 'revoked_by_admin_id')
    op.drop_column('invitations', 'revoked_at')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/c5a8a53fefb7_add_revoked_fields_to_invitations.py ---

================================================================================

--- START OF FILE: alembic/versions/5294db0e7af9_add_hnsw_index_on_profile_vector.py ---

"""Add hnsw index on profile_vector

Revision ID: 5294db0e7af9
Revises: c92880be338c
Create Date: 2025-04-28 04:53:48.538629

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
# Add pgvector import if needed for types, though op.execute uses raw SQL
# from pgvector.sqlalchemy import Vector 


# revision identifiers, used by Alembic.
revision: str = '5294db0e7af9'
down_revision: Union[str, None] = 'c92880be338c' # Corrected previous migration ID
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.execute("CREATE INDEX ix_user_profiles_profile_vector_hnsw ON user_profiles USING hnsw (profile_vector vector_cosine_ops)")
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.execute("DROP INDEX ix_user_profiles_profile_vector_hnsw")
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/5294db0e7af9_add_hnsw_index_on_profile_vector.py ---

================================================================================

--- START OF FILE: alembic/versions/6584e07b26cc_add_space_id_to_users_table.py ---

"""Add space_id to users table

Revision ID: 6584e07b26cc
Revises: 362919f61f47
Create Date: 2025-04-26 11:42:14.838280

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6584e07b26cc'
down_revision: str | None = '362919f61f47'
branch_labels: str | None = None
depends_on: str | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Operation already handled by revision 362919f61f47
    # op.add_column('users', sa.Column('space_id', sa.Integer(), nullable=True))
    # op.create_index(op.f('ix_users_space_id'), 'users', ['space_id'], unique=False)
    # op.create_foreign_key('users_space_id_fkey', 'users', 'spacenodes', ['space_id'], ['id'])
    pass # Indicate no operation needed in this revision anymore
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Operation already handled by revision 362919f61f47
    # op.drop_constraint('users_space_id_fkey', 'users', type_='foreignkey')
    # op.drop_index(op.f('ix_users_space_id'), table_name='users')
    # op.drop_column('users', 'space_id')
    pass # Indicate no operation needed in this revision anymore
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/6584e07b26cc_add_space_id_to_users_table.py ---

================================================================================

--- START OF FILE: alembic/versions/4560944864bf_add_updated_at_is_deleted_to_chatmessage.py ---

"""add_updated_at_is_deleted_to_chatmessage

Revision ID: 4560944864bf
Revises: 61285376d591
Create Date: 2025-05-13 06:58:36.310140

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '4560944864bf'
down_revision: Union[str, None] = '61285376d591'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    op.add_column('chat_messages', sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True))
    op.add_column('chat_messages', sa.Column('is_deleted', sa.Boolean(), nullable=False, server_default=sa.false()))


def downgrade() -> None:
    """Downgrade schema."""
    op.drop_column('chat_messages', 'is_deleted')
    op.drop_column('chat_messages', 'updated_at')


--- END OF FILE: alembic/versions/4560944864bf_add_updated_at_is_deleted_to_chatmessage.py ---

================================================================================

--- START OF FILE: alembic/versions/a0ea2f0b7b3a_add_decline_fields_to_invitations.py ---

"""add_decline_fields_to_invitations

Revision ID: a0ea2f0b7b3a
Revises: c5a8a53fefb7
Create Date: 2024-05-27 12:00:00.000000 # Placeholder, Alembic will update

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'a0ea2f0b7b3a'
down_revision: Union[str, None] = 'c5a8a53fefb7'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('invitations', sa.Column('declined_at', sa.DateTime(), nullable=True))
    op.add_column('invitations', sa.Column('decline_reason', sa.Text(), nullable=True))
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('invitations', 'decline_reason')
    op.drop_column('invitations', 'declined_at')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/a0ea2f0b7b3a_add_decline_fields_to_invitations.py ---

================================================================================

--- START OF FILE: alembic/versions/99e4b0bb221a_add_company_and_startup_models.py ---

"""Add company and startup models

Revision ID: 99e4b0bb221a
Revises: 6e42b588d2b7
Create Date: 2025-04-26 02:12:04.722499

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '99e4b0bb221a'
down_revision: Union[str, None] = '6e42b588d2b7'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('companies',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('logo_url', sa.String(), nullable=True),
    sa.Column('industry_focus', sa.String(), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('website', sa.String(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_companies_id'), 'companies', ['id'], unique=False)
    op.create_index(op.f('ix_companies_name'), 'companies', ['name'], unique=False)
    op.create_table('startups',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('logo_url', sa.String(), nullable=True),
    sa.Column('industry_focus', sa.String(), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('mission', sa.Text(), nullable=True),
    sa.Column('website', sa.String(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_startups_id'), 'startups', ['id'], unique=False)
    op.create_index(op.f('ix_startups_name'), 'startups', ['name'], unique=False)
    op.add_column('users', sa.Column('company_id', sa.Integer(), nullable=True))
    op.add_column('users', sa.Column('startup_id', sa.Integer(), nullable=True))
    op.create_foreign_key(None, 'users', 'companies', ['company_id'], ['id'])
    op.create_foreign_key(None, 'users', 'startups', ['startup_id'], ['id'])
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'users', type_='foreignkey')
    op.drop_constraint(None, 'users', type_='foreignkey')
    op.drop_column('users', 'startup_id')
    op.drop_column('users', 'company_id')
    op.drop_index(op.f('ix_startups_name'), table_name='startups')
    op.drop_index(op.f('ix_startups_id'), table_name='startups')
    op.drop_table('startups')
    op.drop_index(op.f('ix_companies_name'), table_name='companies')
    op.drop_index(op.f('ix_companies_id'), table_name='companies')
    op.drop_table('companies')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/99e4b0bb221a_add_company_and_startup_models.py ---

================================================================================

--- START OF FILE: alembic/versions/96604f2f7de6_create_user_table.py ---

"""Create user table

Revision ID: 96604f2f7de6
Revises: 
Create Date: 2025-04-18 19:26:22.810819

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '96604f2f7de6'
down_revision: Union[str, None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(), nullable=False),
    sa.Column('hashed_password', sa.String(), nullable=False),
    sa.Column('full_name', sa.String(), nullable=True),
    sa.Column('role', sa.String(), nullable=False),
    sa.Column('status', sa.String(), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_index(op.f('ix_users_full_name'), 'users', ['full_name'], unique=False)
    op.create_index(op.f('ix_users_id'), 'users', ['id'], unique=False)
    op.create_index(op.f('ix_users_status'), 'users', ['status'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_users_status'), table_name='users')
    op.drop_index(op.f('ix_users_id'), table_name='users')
    op.drop_index(op.f('ix_users_full_name'), table_name='users')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/96604f2f7de6_create_user_table.py ---

================================================================================

--- START OF FILE: alembic/versions/a3cc12c29cbe_add_chat_models.py ---

"""Add chat models

Revision ID: a3cc12c29cbe
Revises: 01fcfe2512a6
Create Date: 2025-05-01 13:39:24.405039

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'a3cc12c29cbe'
down_revision: Union[str, None] = '01fcfe2512a6'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('chat_messages',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('sender_id', sa.Integer(), nullable=False),
    sa.Column('recipient_id', sa.Integer(), nullable=False),
    sa.Column('content', sa.Text(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('read_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['recipient_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['sender_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_chat_messages_id'), 'chat_messages', ['id'], unique=False)
    op.create_index(op.f('ix_chat_messages_recipient_id'), 'chat_messages', ['recipient_id'], unique=False)
    op.create_index(op.f('ix_chat_messages_sender_id'), 'chat_messages', ['sender_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_chat_messages_sender_id'), table_name='chat_messages')
    op.drop_index(op.f('ix_chat_messages_recipient_id'), table_name='chat_messages')
    op.drop_index(op.f('ix_chat_messages_id'), table_name='chat_messages')
    op.drop_table('chat_messages')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/a3cc12c29cbe_add_chat_models.py ---

================================================================================

--- START OF FILE: alembic/versions/a0f683693a70_create_invitations_table.py ---

"""create_invitations_table

Revision ID: a0f683693a70
Revises: 2a94457f8436
Create Date: 2024-05-24 10:00:00.000000 # Updated placeholder

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from app.models.invitation import InvitationStatus # Import for Enum values if needed by SAEnum

# revision identifiers, used by Alembic.
revision: str = 'a0f683693a70'
down_revision: Union[str, None] = '2a94457f8436' # Corrected previous revision
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('invitations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('email', sa.String(), nullable=False),
    sa.Column('startup_id', sa.Integer(), nullable=False),
    sa.Column('invitation_token', sa.String(), nullable=False),
    sa.Column('status', sa.Enum('PENDING', 'ACCEPTED', 'EXPIRED', name='invitationstatus'), nullable=False),
    sa.Column('expires_at', sa.DateTime(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=True, server_default=sa.text('now()')),
    sa.Column('updated_at', sa.DateTime(), nullable=True, server_default=sa.text('now()')),
    sa.ForeignKeyConstraint(['startup_id'], ['startups.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_invitations_email'), 'invitations', ['email'], unique=False)
    op.create_index(op.f('ix_invitations_id'), 'invitations', ['id'], unique=False)
    op.create_index(op.f('ix_invitations_invitation_token'), 'invitations', ['invitation_token'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_invitations_invitation_token'), table_name='invitations')
    op.drop_index(op.f('ix_invitations_id'), table_name='invitations')
    op.drop_index(op.f('ix_invitations_email'), table_name='invitations')
    op.drop_table('invitations')
    # Explicitly drop the ENUM type if it was created as a standalone type in PostgreSQL
    # This is often needed if the ENUM is not automatically dropped with the table.
    sa.Enum(name='invitationstatus').drop(op.get_bind(), checkfirst=False)
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/a0f683693a70_create_invitations_table.py ---

================================================================================

--- START OF FILE: alembic/versions/a2d9934e5db7_add_user_profiles_table_with_profile_.py ---

"""Add user_profiles table with profile_vector column

Revision ID: a2d9934e5db7
Revises: 6584e07b26cc
Create Date: 2025-04-26 17:15:19.976232

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import pgvector.sqlalchemy

# revision identifiers, used by Alembic.
revision: str = 'a2d9934e5db7'
down_revision: Union[str, None] = '6584e07b26cc'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('user_profiles',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('title', sa.String(), nullable=True),
    sa.Column('bio', sa.Text(), nullable=True),
    sa.Column('profile_vector', pgvector.sqlalchemy.Vector(dim=768), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_user_profiles_id'), 'user_profiles', ['id'], unique=False)
    op.create_index(op.f('ix_user_profiles_user_id'), 'user_profiles', ['user_id'], unique=True)

    # Drop constraints referencing the tables BEFORE dropping the tables
    op.drop_constraint('users_applied_promo_code_id_fkey', 'users', type_='foreignkey')
    op.drop_constraint('users_subscription_plan_id_fkey', 'users', type_='foreignkey')

    # Now drop the tables
    op.drop_index('ix_promocodes_code', table_name='promocodes')
    op.drop_index('ix_promocodes_id', table_name='promocodes')
    op.drop_table('promocodes')
    op.drop_index('ix_subscriptionplans_id', table_name='subscriptionplans')
    op.drop_index('ix_subscriptionplans_name', table_name='subscriptionplans')
    op.drop_table('subscriptionplans')

    # Other adjustments detected by autogenerate
    op.alter_column('spacenodes', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('spacenodes', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('users', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.drop_index('ix_users_referral_code', table_name='users')
    op.drop_index('ix_users_stripe_customer_id', table_name='users')
    op.drop_index('ix_users_stripe_subscription_id', table_name='users')
    op.create_index(op.f('ix_users_space_id'), 'users', ['space_id'], unique=False)
    op.drop_column('users', 'tools_technologies')
    op.drop_column('users', 'profile_vector')
    op.drop_column('users', 'stripe_customer_id')
    op.drop_column('users', 'skills_expertise')
    op.drop_column('users', 'linkedin_profile_url')
    op.drop_column('users', 'project_interests_goals')
    op.drop_column('users', 'stripe_subscription_id')
    op.drop_column('users', 'subscription_start_date')
    op.drop_column('users', 'title')
    op.drop_column('users', 'community_badge')
    op.drop_column('users', 'collaboration_preferences')
    op.drop_column('users', 'bio')
    op.drop_column('users', 'profile_picture_url')
    op.drop_column('users', 'subscription_status')
    op.drop_column('users', 'applied_promo_code_id')
    op.drop_column('users', 'contact_info_visibility')
    op.drop_column('users', 'industry_focus')
    op.drop_column('users', 'subscription_plan_id')
    op.drop_column('users', 'referral_code')
    op.drop_column('users', 'referral_credit_months')
    op.alter_column('workstations', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('workstations', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('workstations', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('workstations', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.add_column('users', sa.Column('referral_credit_months', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('referral_code', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('subscription_plan_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('industry_focus', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('contact_info_visibility', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('applied_promo_code_id', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('subscription_status', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('profile_picture_url', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('bio', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('collaboration_preferences', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('community_badge', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('title', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('subscription_start_date', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('stripe_subscription_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('project_interests_goals', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('linkedin_profile_url', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('skills_expertise', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('stripe_customer_id', sa.VARCHAR(), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('profile_vector', pgvector.sqlalchemy.Vector(dim=768), autoincrement=False, nullable=True))
    op.add_column('users', sa.Column('tools_technologies', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True))
    op.create_foreign_key('users_applied_promo_code_id_fkey', 'users', 'promocodes', ['applied_promo_code_id'], ['id'])
    op.create_foreign_key('users_subscription_plan_id_fkey', 'users', 'subscriptionplans', ['subscription_plan_id'], ['id'])
    op.drop_index(op.f('ix_users_space_id'), table_name='users')
    op.create_index('ix_users_stripe_subscription_id', 'users', ['stripe_subscription_id'], unique=True)
    op.create_index('ix_users_stripe_customer_id', 'users', ['stripe_customer_id'], unique=True)
    op.create_index('ix_users_referral_code', 'users', ['referral_code'], unique=True)
    op.alter_column('users', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('spacenodes', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
    op.alter_column('spacenodes', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.create_table('subscriptionplans',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('role_type', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('price_monthly', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('price_annual', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('features_list', sa.TEXT(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='subscriptionplans_pkey')
    )
    op.create_index('ix_subscriptionplans_name', 'subscriptionplans', ['name'], unique=False)
    op.create_index('ix_subscriptionplans_id', 'subscriptionplans', ['id'], unique=False)
    op.create_table('promocodes',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('code', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('description', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('discount_type', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('valid_until', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='promocodes_pkey')
    )
    op.create_index('ix_promocodes_id', 'promocodes', ['id'], unique=False)
    op.create_index('ix_promocodes_code', 'promocodes', ['code'], unique=True)
    op.drop_index(op.f('ix_user_profiles_user_id'), table_name='user_profiles')
    op.drop_index(op.f('ix_user_profiles_id'), table_name='user_profiles')
    op.drop_table('user_profiles')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/a2d9934e5db7_add_user_profiles_table_with_profile_.py ---

================================================================================

--- START OF FILE: alembic/versions/7bd0250369dc_create_notification_table.py ---

"""Create notification table

Revision ID: 7bd0250369dc
Revises: 9a0c9d66f8f4
Create Date: 2025-04-28 10:29:51.576320

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '7bd0250369dc'
down_revision: Union[str, None] = '9a0c9d66f8f4'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('notifications',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('type', sa.String(), nullable=False),
    sa.Column('related_entity_id', sa.Integer(), nullable=True),
    sa.Column('message', sa.String(), nullable=False),
    sa.Column('is_read', sa.Boolean(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_notifications_id'), 'notifications', ['id'], unique=False)
    op.create_index(op.f('ix_notifications_related_entity_id'), 'notifications', ['related_entity_id'], unique=False)
    op.create_index(op.f('ix_notifications_type'), 'notifications', ['type'], unique=False)
    op.create_index(op.f('ix_notifications_user_id'), 'notifications', ['user_id'], unique=False)
    op.drop_index('ix_user_profiles_profile_vector_hnsw', table_name='user_profiles', postgresql_using='hnsw')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index('ix_user_profiles_profile_vector_hnsw', 'user_profiles', ['profile_vector'], unique=False, postgresql_using='hnsw')
    op.drop_index(op.f('ix_notifications_user_id'), table_name='notifications')
    op.drop_index(op.f('ix_notifications_type'), table_name='notifications')
    op.drop_index(op.f('ix_notifications_related_entity_id'), table_name='notifications')
    op.drop_index(op.f('ix_notifications_id'), table_name='notifications')
    op.drop_table('notifications')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/7bd0250369dc_create_notification_table.py ---

================================================================================

--- START OF FILE: alembic/versions/43b26710d32d_update_invitationstatus_enum_and_values.py ---

"""update_invitationstatus_enum_and_values

Revision ID: 43b26710d32d
Revises: a0ea2f0b7b3a
Create Date: <will be filled by Alembic>

"""
from alembic import op
import sqlalchemy as sa

# revision identifiers, used by Alembic.
revision = '43b26710d32d'
down_revision = 'a0ea2f0b7b3a' # Previous migration that added declined_at/reason fields
branch_labels = None
depends_on = None

# Define enum names
table_name = 'invitations'
column_name = 'status'
enum_name = 'invitationstatus' # This is the actual name of the enum type in PostgreSQL
temp_enum_name = f'{enum_name}_old'

# Desired final lowercase values for the enum
new_enum_values = ('pending', 'accepted', 'expired', 'revoked', 'declined')

# Original uppercase values (assumed from migration a0f683693a70)
original_enum_values_uppercase = ('PENDING', 'ACCEPTED', 'EXPIRED')


def upgrade():
    # Rename the existing enum type
    op.execute(f"ALTER TYPE {enum_name} RENAME TO {temp_enum_name};")
    
    # Create the new enum type with all correct lowercase values
    new_enum_sa = sa.Enum(*new_enum_values, name=enum_name)
    new_enum_sa.create(op.get_bind(), checkfirst=False)
    
    # Alter the column to use the new enum type
    # This involves casting existing uppercase values to lowercase, then to the new enum type
    op.execute(
        f"ALTER TABLE {table_name} ALTER COLUMN {column_name} TYPE {enum_name} "
        f"USING LOWER({column_name}::text)::{enum_name};"
    )
    
    # Drop the old (renamed) enum type
    op.execute(f"DROP TYPE {temp_enum_name};")


def downgrade():
    # This downgrade reverts to the state where the enum was ('PENDING', 'ACCEPTED', 'EXPIRED') - uppercase.
    # Data for 'revoked' and 'declined' statuses will be mapped to 'EXPIRED' as they didn't exist.
    
    temp_new_enum_name = f'{enum_name}_temp_new'

    # Rename the current (new) enum type
    op.execute(f"ALTER TYPE {enum_name} RENAME TO {temp_new_enum_name};")
    
    # Recreate the original enum type with uppercase values
    original_enum_sa = sa.Enum(*original_enum_values_uppercase, name=enum_name)
    original_enum_sa.create(op.get_bind(), checkfirst=False)
    
    # Alter the column back to the old enum type
    # Map current lowercase values back to old uppercase ones.
    # 'revoked' and 'declined' will be mapped to 'EXPIRED'.
    # Other values (like 'pending') will be uppercased.
    op.execute(
        f"ALTER TABLE {table_name} ALTER COLUMN {column_name} TYPE {enum_name} "
        f"USING CASE "
        f"  WHEN LOWER({column_name}::text) = 'pending' THEN 'PENDING'::{enum_name} "
        f"  WHEN LOWER({column_name}::text) = 'accepted' THEN 'ACCEPTED'::{enum_name} "
        f"  WHEN LOWER({column_name}::text) = 'expired' THEN 'EXPIRED'::{enum_name} "
        f"  WHEN LOWER({column_name}::text) = 'revoked' THEN 'EXPIRED'::{enum_name} "
        f"  WHEN LOWER({column_name}::text) = 'declined' THEN 'EXPIRED'::{enum_name} "
        # Fallback for any values that might have been directly PENDING, ACCEPTED, EXPIRED (already uppercase)
        f"  WHEN {column_name}::text IN {original_enum_values_uppercase} THEN {column_name}::text::{enum_name} "
        f"  ELSE 'EXPIRED'::{enum_name} " # Default for any unexpected status
        f"END;"
    )
    
    # Drop the temporary new enum type
    op.execute(f"DROP TYPE {temp_new_enum_name};")


--- END OF FILE: alembic/versions/43b26710d32d_update_invitationstatus_enum_and_values.py ---

================================================================================

--- START OF FILE: alembic/versions/61285376d591_add_reference_and_link_to_notification.py ---

"""Add reference and link to Notification

Revision ID: 61285376d591
Revises: 08eced71251f
Create Date: 2025-05-13 05:52:58.429788

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '61285376d591'
down_revision: Union[str, None] = '08eced71251f'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('notifications', sa.Column('reference', sa.String(), nullable=True))
    op.add_column('notifications', sa.Column('link', sa.String(), nullable=True))
    op.create_index(op.f('ix_notifications_reference'), 'notifications', ['reference'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_notifications_reference'), table_name='notifications')
    op.drop_column('notifications', 'link')
    op.drop_column('notifications', 'reference')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/61285376d591_add_reference_and_link_to_notification.py ---

================================================================================

--- START OF FILE: alembic/versions/c92880be338c_add_missing_profile_fields_to_user_.py ---

"""Add missing profile fields to user_profiles table

Revision ID: c92880be338c
Revises: a2d9934e5db7
Create Date: 2025-04-27 10:31:50.326465

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'c92880be338c'
down_revision: Union[str, None] = 'a2d9934e5db7'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('ix_user_profile_id', table_name='user_profile')
    op.drop_index('ix_user_profile_user_id', table_name='user_profile')
    op.drop_table('user_profile')
    op.add_column('user_profiles', sa.Column('contact_info_visibility', sa.Enum('PRIVATE', 'CONNECTIONS', 'PUBLIC', name='contact_visibility_enum'), nullable=False))
    op.add_column('user_profiles', sa.Column('skills_expertise', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('user_profiles', sa.Column('industry_focus', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('user_profiles', sa.Column('project_interests_goals', sa.Text(), nullable=True))
    op.add_column('user_profiles', sa.Column('collaboration_preferences', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('user_profiles', sa.Column('tools_technologies', postgresql.ARRAY(sa.String()), nullable=True))
    op.add_column('user_profiles', sa.Column('linkedin_profile_url', sa.String(), nullable=True))
    op.add_column('user_profiles', sa.Column('profile_picture_url', sa.String(), nullable=True))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('user_profiles', 'profile_picture_url')
    op.drop_column('user_profiles', 'linkedin_profile_url')
    op.drop_column('user_profiles', 'tools_technologies')
    op.drop_column('user_profiles', 'collaboration_preferences')
    op.drop_column('user_profiles', 'project_interests_goals')
    op.drop_column('user_profiles', 'industry_focus')
    op.drop_column('user_profiles', 'skills_expertise')
    op.drop_column('user_profiles', 'contact_info_visibility')
    op.create_table('user_profile',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('title', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('bio', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('contact_info_visibility', postgresql.ENUM('PRIVATE', 'CONNECTIONS', 'PUBLIC', name='contact_visibility_enum'), autoincrement=False, nullable=False),
    sa.Column('skills_expertise', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True),
    sa.Column('industry_focus', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True),
    sa.Column('project_interests_goals', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('collaboration_preferences', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True),
    sa.Column('tools_technologies', postgresql.ARRAY(sa.VARCHAR()), autoincrement=False, nullable=True),
    sa.Column('linkedin_profile_url', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('profile_picture_url', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='user_profile_user_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='user_profile_pkey')
    )
    op.create_index('ix_user_profile_user_id', 'user_profile', ['user_id'], unique=True)
    op.create_index('ix_user_profile_id', 'user_profile', ['id'], unique=False)
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/c92880be338c_add_missing_profile_fields_to_user_.py ---

================================================================================

--- START OF FILE: alembic/versions/c421022fb1a2_add_space_workstation_management_models_.py ---

"""add_space_workstation_management_models_and_relations

Revision ID: c421022fb1a2
Revises: 4560944864bf
Create Date: 2025-05-20 07:48:53.925033

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from app.schemas.space import WorkstationStatus # For Enum values

# revision identifiers, used by Alembic.
revision: str = 'c421022fb1a2'
down_revision: Union[str, None] = '4560944864bf'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

# Define the Enum type for use in this migration
workstation_status_enum_type = sa.Enum(WorkstationStatus, name='workstation_status_enum')

def upgrade() -> None:
    """Upgrade schema."""
    # Create the ENUM type in PostgreSQL
    workstation_status_enum_type.create(op.get_bind(), checkfirst=True)

    # ### commands auto generated by Alembic - please adjust! ###
    # Modifications to 'spacenodes' table
    op.alter_column('spacenodes', 'location_description', new_column_name='address', existing_type=sa.VARCHAR(), nullable=True)
    op.add_column('spacenodes', sa.Column('company_id', sa.Integer(), nullable=True))
    op.create_foreign_key(op.f('fk_spacenodes_company_id_companies'), 'spacenodes', 'companies', ['company_id'], ['id'])
    
    # Attempt to drop total_workstations. If it was already dropped or renamed, this might cause an error.
    # It's safer to check if it exists or handle potential errors if this script is re-runnable.
    # For now, assume it exists based on previous model state.
    try:
        op.drop_column('spacenodes', 'total_workstations')
    except Exception as e:
        print(f"Could not drop total_workstations from spacenodes (may have been already dropped): {e}")


    # Modifications to 'workstations' table
    op.add_column('workstations', sa.Column('name', sa.String(), nullable=False, server_default='Workstation'))
    op.create_index(op.f('ix_workstations_name'), 'workstations', ['name'], unique=False)
    
    # Drop foreign key constraint associated with assigned_user_id if it exists
    # Alembic autogenerates FK names like: fk_workstations_assigned_user_id_users
    # We need to know the exact name or allow op.drop_column to handle it if the DB does.
    # Dropping the column often drops the FK if the DB supports it.
    # If a specific FK name needs to be dropped first:
    # op.drop_constraint('fk_workstations_assigned_user_id_users', 'workstations', type_='foreignkey')
    op.drop_column('workstations', 'assigned_user_id')
    
    op.drop_column('workstations', 'status') # Drop old string status
    op.add_column('workstations', sa.Column('status', workstation_status_enum_type, nullable=False, server_default=WorkstationStatus.AVAILABLE.value))
    op.create_index(op.f('ix_workstations_status'), 'workstations', ['status'], unique=False) # Recreate index for new status


    # Create 'workstation_assignments' table
    op.create_table('workstation_assignments',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('workstation_id', sa.Integer(), nullable=False),
    sa.Column('space_id', sa.Integer(), nullable=False),
    sa.Column('start_date', sa.DateTime(), nullable=False, server_default=sa.func.now()),
    sa.Column('end_date', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), server_default=sa.func.now(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), server_default=sa.func.now(), onupdate=sa.func.now(), nullable=False),
    sa.ForeignKeyConstraint(['space_id'], ['spacenodes.id'], name=op.f('fk_workstation_assignments_space_id_spacenodes')),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name=op.f('fk_workstation_assignments_user_id_users')),
    sa.ForeignKeyConstraint(['workstation_id'], ['workstations.id'], name=op.f('fk_workstation_assignments_workstation_id_workstations')),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_workstation_assignments'))
    )
    op.create_index(op.f('ix_workstation_assignments_id'), 'workstation_assignments', ['id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_workstation_assignments_id'), table_name='workstation_assignments')
    op.drop_table('workstation_assignments')

    # Revert 'workstations' table changes
    op.drop_index(op.f('ix_workstations_status'), table_name='workstations')
    op.drop_column('workstations', 'status') # Drop new enum status
    op.add_column('workstations', sa.Column('status', sa.String(), nullable=False, server_default='Available')) # Add back old string status
    # op.create_index if old status was indexed, which it was.
    op.create_index('ix_workstations_status', 'workstations', ['status'], unique=False)


    op.add_column('workstations', sa.Column('assigned_user_id', sa.Integer(), autoincrement=False, nullable=True))
    op.create_foreign_key('fk_workstations_assigned_user_id_users', 'workstations', 'users', ['assigned_user_id'], ['id'])
    
    op.drop_index(op.f('ix_workstations_name'), table_name='workstations')
    op.drop_column('workstations', 'name')

    # Revert 'spacenodes' table changes
    try:
        op.add_column('spacenodes', sa.Column('total_workstations', sa.INTEGER(), autoincrement=False, nullable=False, server_default="0"))
    except Exception as e:
         print(f"Could not add total_workstations to spacenodes (may not have been dropped cleanly or other issue): {e}")

    op.drop_constraint(op.f('fk_spacenodes_company_id_companies'), 'spacenodes', type_='foreignkey')
    op.drop_column('spacenodes', 'company_id')
    op.alter_column('spacenodes', 'address', new_column_name='location_description', existing_type=sa.VARCHAR(), nullable=True)

    # Drop the ENUM type
    workstation_status_enum_type.drop(op.get_bind(), checkfirst=True)
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/c421022fb1a2_add_space_workstation_management_models_.py ---

================================================================================

--- START OF FILE: alembic/versions/01fcfe2512a6_make_corporate_admin_id_nullable_in_.py ---

"""Make corporate_admin_id nullable in spacenodes

Revision ID: 01fcfe2512a6
Revises: 0581da68b2ba
Create Date: 2025-04-30 04:15:46.652205

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '01fcfe2512a6'
down_revision: Union[str, None] = '0581da68b2ba'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index(op.f('ix_connections_status'), 'connections', ['status'], unique=False)
    op.alter_column('spacenodes', 'corporate_admin_id',
               existing_type=sa.INTEGER(),
               nullable=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('spacenodes', 'corporate_admin_id',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.drop_index(op.f('ix_connections_status'), table_name='connections')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/01fcfe2512a6_make_corporate_admin_id_nullable_in_.py ---

================================================================================

--- START OF FILE: alembic/versions/2a94457f8436_add_space_id_to_startup_and_relationship.py ---

"""add_space_id_to_startup_and_relationship

Revision ID: 2a94457f8436
Revises: c421022fb1a2
Create Date: 2025-05-23 09:32:33.634894

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '2a94457f8436'
down_revision: Union[str, None] = 'c421022fb1a2'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('startups', sa.Column('space_id', sa.Integer(), nullable=False))
    op.create_index(op.f('ix_startups_space_id'), 'startups', ['space_id'], unique=False)
    op.create_foreign_key(
        'fk_startups_space_id_spacenodes',  # Constraint name
        'startups', 'spacenodes',
        ['space_id'], ['id']
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint('fk_startups_space_id_spacenodes', 'startups', type_='foreignkey')
    op.drop_index(op.f('ix_startups_space_id'), table_name='startups')
    op.drop_column('startups', 'space_id')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/2a94457f8436_add_space_id_to_startup_and_relationship.py ---

================================================================================

--- START OF FILE: alembic/versions/362919f61f47_add_space_node_and_workstation_models.py ---

"""Add space node and workstation models

Revision ID: 362919f61f47
Revises: 99e4b0bb221a
Create Date: 2025-04-26 08:56:42.644123

"""
from typing import Sequence, Union
from enum import Enum

from alembic import op
import sqlalchemy as sa
import pgvector.sqlalchemy


# revision identifiers, used by Alembic.
revision: str = '362919f61f47'
down_revision: Union[str, None] = '99e4b0bb221a'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None

# Define the Enum class directly in the migration script
class WorkstationStatusEnum(Enum):
    AVAILABLE = "AVAILABLE"
    OCCUPIED = "OCCUPIED"
    MAINTENANCE = "MAINTENANCE"

# Create an SQLAlchemy Enum type using the defined Enum
# create_type=True is default and will handle CREATE TYPE ... IF NOT EXISTS
workstation_status_sa_enum = sa.Enum(
    WorkstationStatusEnum, 
    name="workstation_status_enum", 
    create_type=True # Explicitly True, though it's the default
)

def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    
    # The sa.Enum in the table definition below will handle creating the type.
    # workstation_status_sa_enum.create(op.get_bind(), checkfirst=True) # REMOVED THIS LINE
    
    op.create_table('promocodes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('code', sa.String(), nullable=False),
    sa.Column('description', sa.String(), nullable=True),
    sa.Column('discount_type', sa.String(), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('valid_until', sa.DateTime(timezone=True), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_promocodes_code'), 'promocodes', ['code'], unique=True)
    op.create_index(op.f('ix_promocodes_id'), 'promocodes', ['id'], unique=False)
    op.create_table('spacenodes',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('location_description', sa.String(), nullable=True),
    sa.Column('corporate_admin_id', sa.Integer(), nullable=False),
    sa.Column('total_workstations', sa.Integer(), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['corporate_admin_id'], ['users.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_spacenodes_id'), 'spacenodes', ['id'], unique=False)
    op.create_index(op.f('ix_spacenodes_name'), 'spacenodes', ['name'], unique=False)
    op.create_table('subscriptionplans',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.String(), nullable=False),
    sa.Column('role_type', sa.String(), nullable=False),
    sa.Column('price_monthly', sa.Float(), nullable=True),
    sa.Column('price_annual', sa.Float(), nullable=True),
    sa.Column('features_list', sa.Text(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_subscriptionplans_id'), 'subscriptionplans', ['id'], unique=False)
    op.create_index(op.f('ix_subscriptionplans_name'), 'subscriptionplans', ['name'], unique=False)
    op.create_table('workstations',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('space_id', sa.Integer(), nullable=False),
    sa.Column('status', workstation_status_sa_enum, nullable=False),
    sa.Column('assigned_user_id', sa.Integer(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['assigned_user_id'], ['users.id'], ),
    sa.ForeignKeyConstraint(['space_id'], ['spacenodes.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_workstations_id'), 'workstations', ['id'], unique=False)
    op.create_index(op.f('ix_workstations_status'), 'workstations', ['status'], unique=False)
    op.add_column('users', sa.Column('title', sa.String(), nullable=True))
    op.add_column('users', sa.Column('bio', sa.String(), nullable=True))
    op.add_column('users', sa.Column('contact_info_visibility', sa.String(), nullable=True))
    op.add_column('users', sa.Column('skills_expertise', sa.ARRAY(sa.String()), nullable=True))
    op.add_column('users', sa.Column('industry_focus', sa.ARRAY(sa.String()), nullable=True))
    op.add_column('users', sa.Column('project_interests_goals', sa.String(), nullable=True))
    op.add_column('users', sa.Column('collaboration_preferences', sa.ARRAY(sa.String()), nullable=True))
    op.add_column('users', sa.Column('tools_technologies', sa.ARRAY(sa.String()), nullable=True))
    op.add_column('users', sa.Column('linkedin_profile_url', sa.String(), nullable=True))
    op.add_column('users', sa.Column('profile_picture_url', sa.String(), nullable=True))
    op.add_column('users', sa.Column('profile_vector', pgvector.sqlalchemy.Vector(dim=768), nullable=True))
    op.add_column('users', sa.Column('space_id', sa.Integer(), nullable=True))
    op.add_column('users', sa.Column('applied_promo_code_id', sa.Integer(), nullable=True))
    op.add_column('users', sa.Column('referral_code', sa.String(), nullable=True))
    op.add_column('users', sa.Column('community_badge', sa.String(), nullable=True))
    op.add_column('users', sa.Column('stripe_customer_id', sa.String(), nullable=True))
    op.add_column('users', sa.Column('stripe_subscription_id', sa.String(), nullable=True))
    op.add_column('users', sa.Column('subscription_status', sa.String(), nullable=True))
    op.add_column('users', sa.Column('subscription_plan_id', sa.Integer(), nullable=True))
    op.add_column('users', sa.Column('subscription_start_date', sa.DateTime(timezone=True), nullable=True))
    op.add_column('users', sa.Column('referral_credit_months', sa.Integer(), nullable=True))
    op.create_index(op.f('ix_users_referral_code'), 'users', ['referral_code'], unique=True)
    op.create_index(op.f('ix_users_stripe_customer_id'), 'users', ['stripe_customer_id'], unique=True)
    op.create_index(op.f('ix_users_stripe_subscription_id'), 'users', ['stripe_subscription_id'], unique=True)
    op.create_foreign_key(None, 'users', 'subscriptionplans', ['subscription_plan_id'], ['id'])
    op.create_foreign_key(None, 'users', 'spacenodes', ['space_id'], ['id'])
    op.create_foreign_key(None, 'users', 'promocodes', ['applied_promo_code_id'], ['id'])
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_constraint(None, 'users', type_='foreignkey')
    op.drop_constraint(None, 'users', type_='foreignkey')
    op.drop_constraint(None, 'users', type_='foreignkey')
    op.drop_index(op.f('ix_users_stripe_subscription_id'), table_name='users')
    op.drop_index(op.f('ix_users_stripe_customer_id'), table_name='users')
    op.drop_index(op.f('ix_users_referral_code'), table_name='users')
    op.drop_column('users', 'referral_credit_months')
    op.drop_column('users', 'subscription_start_date')
    op.drop_column('users', 'subscription_plan_id')
    op.drop_column('users', 'subscription_status')
    op.drop_column('users', 'stripe_subscription_id')
    op.drop_column('users', 'stripe_customer_id')
    op.drop_column('users', 'community_badge')
    op.drop_column('users', 'referral_code')
    op.drop_column('users', 'applied_promo_code_id')
    op.drop_column('users', 'space_id')
    op.drop_column('users', 'profile_vector')
    op.drop_column('users', 'profile_picture_url')
    op.drop_column('users', 'linkedin_profile_url')
    op.drop_column('users', 'tools_technologies')
    op.drop_column('users', 'collaboration_preferences')
    op.drop_column('users', 'project_interests_goals')
    op.drop_column('users', 'industry_focus')
    op.drop_column('users', 'skills_expertise')
    op.drop_column('users', 'contact_info_visibility')
    op.drop_column('users', 'bio')
    op.drop_column('users', 'title')
    op.drop_index(op.f('ix_workstations_status'), table_name='workstations')
    op.drop_index(op.f('ix_workstations_id'), table_name='workstations')
    op.drop_table('workstations')
    op.drop_index(op.f('ix_subscriptionplans_name'), table_name='subscriptionplans')
    op.drop_index(op.f('ix_subscriptionplans_id'), table_name='subscriptionplans')
    op.drop_table('subscriptionplans')
    op.drop_index(op.f('ix_spacenodes_name'), table_name='spacenodes')
    op.drop_index(op.f('ix_spacenodes_id'), table_name='spacenodes')
    op.drop_table('spacenodes')
    op.drop_index(op.f('ix_promocodes_id'), table_name='promocodes')
    op.drop_index(op.f('ix_promocodes_code'), table_name='promocodes')
    op.drop_table('promocodes')
    # The sa.Enum type should be dropped automatically when the last table using it is dropped,
    # or if create_type=False was used and it was managed entirely manually.
    # For safety with create_type=True, explicit drop in downgrade is okay if table drop doesn't manage it.
    # However, let's rely on SQLAlchemy's behavior first. If issues, can add: op.execute("DROP TYPE IF EXISTS workstation_status_enum;")
    # workstation_status_sa_enum.drop(op.get_bind(), checkfirst=True) # REMOVED THIS LINE
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/362919f61f47_add_space_node_and_workstation_models.py ---

================================================================================

--- START OF FILE: alembic/versions/bd906d8dba40_create_password_reset_tokens_table.py ---

"""Create password_reset_tokens table

Revision ID: bd906d8dba40
Revises: 8c3a5a32e14b
Create Date: 2025-04-20 04:37:24.676699

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'bd906d8dba40'
down_revision: Union[str, None] = '8c3a5a32e14b'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('password_reset_tokens',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('user_id', sa.Integer(), nullable=False),
    sa.Column('token', sa.String(), nullable=False),
    sa.Column('expires_at', sa.DateTime(timezone=True), nullable=False),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_password_reset_tokens_id'), 'password_reset_tokens', ['id'], unique=False)
    op.create_index(op.f('ix_password_reset_tokens_token'), 'password_reset_tokens', ['token'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_password_reset_tokens_token'), table_name='password_reset_tokens')
    op.drop_index(op.f('ix_password_reset_tokens_id'), table_name='password_reset_tokens')
    op.drop_table('password_reset_tokens')
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/bd906d8dba40_create_password_reset_tokens_table.py ---

================================================================================

--- START OF FILE: alembic/versions/6f81518f99df_create_user_table.py ---

"""Create user table

Revision ID: 6f81518f99df
Revises: 96604f2f7de6
Create Date: 2025-04-18 21:54:39.199538

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6f81518f99df'
down_revision: Union[str, None] = '96604f2f7de6'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('users', 'created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('users', 'updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('users', 'updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    op.alter_column('users', 'created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('now()'))
    # ### end Alembic commands ###


--- END OF FILE: alembic/versions/6f81518f99df_create_user_table.py ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/61285376d591_add_reference_and_link_to_notification.cpython-312.pyc ---



    :"h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zAdd reference and link to Notification

Revision ID: 61285376d591
Revises: 08eced71251f
Create Date: 2025-05-13 05:52:58.429788

    )SequenceUnion)opN61285376d591revision08eced71251f
down_revision
branch_labels
depends_onc                  V   t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  dt        j                         d             t        j
                  t        j                  d      ddgd       y	)
zUpgrade schema.
notifications	referenceT)nullablelinkix_notifications_referenceF)uniqueN)r   
add_columnsaColumnStringcreate_indexf     z/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/61285376d591_add_reference_and_link_to_notification.pyupgrader      sf     MM/299["))+PT#UVMM/299VRYY[4#PQOOBDD56+_der   c                      t        j                  t        j                  d      d       t        j                  dd       t        j                  dd       y)zDowngrade schema.r   r
   )
table_namer   r   N)r   
drop_indexr   drop_columnr   r   r   	downgrader!      s8     MM"$$34QNN?F+NN?K0r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r!   r   r   r   <module>r)      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2f1r   

--- END OF FILE: alembic/versions/__pycache__/61285376d591_add_reference_and_link_to_notification.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/c421022fb1a2_add_space_workstation_management_models_.cpython-312.pyc ---



    C,ht                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<    ej                   e	d
      ZddZddZy)zadd_space_workstation_management_models_and_relations

Revision ID: c421022fb1a2
Revises: 4560944864bf
Create Date: 2025-05-20 07:48:53.925033

    )SequenceUnion)opN)WorkstationStatusc421022fb1a2revision4560944864bf
down_revision
branch_labels
depends_onworkstation_status_enumnamec                  p	   t         j                  t        j                         d       t        j                  dddt        j                         d       t        j                  dt        j                  dt        j                         d             t        j                  t        j                  d	      dd
dgdg       	 t        j                  dd       t        j                  dt        j                  dt        j                         dd             t        j                   t        j                  d      ddgd       t        j                  dd       t        j                  dd       t        j                  dt        j                  dt         dt"        j$                  j&                               t        j                   t        j                  d      ddgd       t        j(                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j*                         dt
        j,                  j/                               t        j                  dt        j*                         d      t        j                  dt        j*                         t
        j,                  j/                         d       t        j                  d!t        j*                         t
        j,                  j/                         t
        j,                  j/                         d"      t        j0                  dgd#gt        j                  d$      %      t        j0                  dgd&gt        j                  d'      %      t        j0                  dgd(gt        j                  d)      %      t        j2                  dt        j                  d*      %      
       t        j                   t        j                  d+      ddgd       y# t        $ r} t        d
|         Y d} ~ d} ~ ww xY w),zUpgrade schema.T
checkfirst
spacenodeslocation_descriptionaddressnew_column_name
existing_typenullable
company_id)r   "fk_spacenodes_company_id_companies	companiesidtotal_workstationszSCould not drop total_workstations from spacenodes (may have been already dropped): Nworkstationsr   FWorkstationr   server_defaultix_workstations_nameuniqueassigned_user_idstatusix_workstations_statusworkstation_assignmentsuser_idworkstation_idspace_id
start_dateend_date
created_at)r"   r   
updated_at)r"   onupdater   z
spacenodes.id.fk_workstation_assignments_space_id_spacenodesr   zusers.id(fk_workstation_assignments_user_id_userszworkstations.id6fk_workstation_assignments_workstation_id_workstationspk_workstation_assignmentsix_workstation_assignments_id)workstation_status_enum_typecreater   get_bindalter_columnsaVARCHAR
add_columnColumnIntegercreate_foreign_keyfdrop_column	ExceptionprintStringcreate_indexr   	AVAILABLEvaluecreate_tableDateTimefuncnowForeignKeyConstraintPrimaryKeyConstraintes    |/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/c421022fb1a2_add_space_workstation_management_models_.pyupgraderR      s9    !''
$'G OOL"8)cecmcmcoz~MM,		,

t TU"$$CDlT_bnaorvqwx
i
|%9: MM."))FBIIK%`m"noOOBDD/0.6(SXY NN>#56NN>8,MM."))H6R]b  tE  tO  tO  tU  tU  #V  WOOBDD12NXJW\] OO-IIdBJJL51IIi6II

u=IIj"**,7IIlBKKME"''++-XIIj"++-$7IIlBKKM"''++-RWXIIlBKKM"''++-RTRYRYR]R]R_jopZL?*;"$$GwBxyYK*BDDAk<lm-.1B0C"$$  PH  KI  JDrtt,H'IJ
 OOBDD89;TW[V\ejkI  i
cdecfghhis   R 	R5R00R5c            
         t        j                  t        j                  d      d       t        j                  d       t        j                  t        j                  d      d       t        j                  dd       t        j
                  dt
        j                  dt
        j                         dd	             t        j                  dddgd
       t        j
                  dt
        j                  dt
        j                         dd
             t        j                  ddddgdg       t        j                  t        j                  d      d       t        j                  dd       	 t        j
                  dt
        j                  dt
        j                         ddd             t        j                  t        j                  d      dd       t        j                  dd       t        j                   dddt
        j"                         d       t$        j'                  t        j(                         d        y# t        $ r} t        d|         Y d} ~ d} ~ ww xY w)!zDowngrade schema.r6   r)   )
table_namer(   r   r'   F	Availabler!   r$   r&   T)
autoincrementr   &fk_workstations_assigned_user_id_usersusersr   r#   r   r   r   0)rV   r   r"   zcCould not add total_workstations to spacenodes (may not have been dropped cleanly or other issue): Nr   
foreignkey)type_r   r   r   r   r   )r   
drop_indexrA   
drop_tablerB   r=   r;   r>   rE   rF   r?   r@   INTEGERrC   rD   drop_constraintr:   r<   r7   dropr9   rO   s    rQ   	downgradera   O   s    MM"$$67D]^MM+, MM"$$/0^LNN>8,MM."))HbiikEbm"noOO,nxjQVW MM.")),>

\alp"qrBNT[^p]qtxsyzMM"$$-.>JNN>6*z


lBII.BBJJL`epu  GJ  %K  	L rtt@A<WcdNN<.OOL)=Scecmcmcoz~ !%%bkkm%E  z	tuvtwx	y	yzs   4A I 	I,I''I,)returnN)__doc__typingr   r   alembicr   
sqlalchemyr;   app.schemas.spacer   r   str__annotations__r
   r   r   Enumr7   rR   ra        rQ   <module>rm      s    #   / # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2  'rww'8?XY 4lpFrl   

--- END OF FILE: alembic/versions/__pycache__/c421022fb1a2_add_space_workstation_management_models_.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/bd906d8dba40_create_password_reset_tokens_table.cpython-312.pyc ---



    zh2                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)z}Create password_reset_tokens table

Revision ID: bd906d8dba40
Revises: 8c3a5a32e14b
Create Date: 2025-04-20 04:37:24.676699

    )SequenceUnion)opNbd906d8dba40revision8c3a5a32e14b
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                  d	      d      t        j                  dgd
gd      t        j                  d             t        j                  t        j                  d
      ddgd       t        j                  t        j                  d      ddgd       y)zUpgrade schema.password_reset_tokensidF)nullableuser_idtoken
expires_atT)timezonezusers.idCASCADE)ondeleteix_password_reset_tokens_id)uniqueix_password_reset_tokens_tokenN)r   create_tablesaColumnIntegerStringDateTimeForeignKeyConstraintPrimaryKeyConstraintcreate_indexf     v/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/bd906d8dba40_create_password_reset_tokens_table.pyupgrader&      s     OO+IIdBJJL51IIi6IIgryy{U3IIlBKK6GYK*	JD!
 OOBDD679PSWRXafgOOBDD9:<SV]U^gklr$   c                      t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r   r
   )
table_namer   N)r   
drop_indexr"   
drop_tabler#   r$   r%   	downgrader+   %   sC     MM"$$78E\]MM"$$45BYZMM)*r$   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r&   r+   r#   r$   r%   <module>r3      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2m +r$   

--- END OF FILE: alembic/versions/__pycache__/bd906d8dba40_create_password_reset_tokens_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/6f81518f99df_create_user_table.cpython-312.pyc ---



    Yh                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zlCreate user table

Revision ID: 6f81518f99df
Revises: 96604f2f7de6
Create Date: 2025-04-18 21:54:39.199538

    )SequenceUnion)opN)
postgresql6f81518f99dfrevision96604f2f7de6
down_revision
branch_labels
depends_onc            
      T   t        j                  ddt        j                  d      t	        j
                         dt	        j                  d             t        j                  ddt        j                  d      t	        j
                         dt	        j                  d             y)	zUpgrade schema.users
created_atTtimezonenow()
existing_typetype_existing_nullableexisting_server_default
updated_atN)r   alter_columnr   	TIMESTAMPsaDateTimetext     e/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/6f81518f99df_create_user_table.pyupgrader!      sr     OOG\'114@[[]!%')www'7	9
 OOG\'114@[[]!%')www'7	9r   c            
      T   t        j                  ddt        j                         t	        j
                  d      dt        j                  d             t        j                  ddt        j                         t	        j
                  d      dt        j                  d             y)	zDowngrade schema.r   r   Tr   r   r   r   N)r   r   r   r   r   r   r   r   r   r    	downgrader#   %   sr     OOG\[[]))48!%')www'7	9
 OOG\[[]))48!%')www'7	9r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   sqlalchemy.dialectsr   r   str__annotations__r
   r   r   r!   r#   r   r   r    <module>r,      su    #   * # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 29 9r   

--- END OF FILE: alembic/versions/__pycache__/6f81518f99df_create_user_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/08eced71251f_add_last_read_at_to_.cpython-312.pyc ---



    ]"h	                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zAdd last_read_at to ConversationParticipant

Revision ID: 08eced71251f
Revises: f6faaa54ca44
Create Date: 2025-05-13 05:49:17.342621

    )SequenceUnion)opN08eced71251frevisionf6faaa54ca44
down_revision
branch_labels
depends_onc            
          t        j                  dt        j                  dt        j                  d      t        j
                  d      d             t        j                  dt        j                  dt        j                  d      d             t        j                  d	dd
       t        j                  ddd
       t        j                  d
dddgdgd       t        j                  d
dddgdgd       y
)zUpgrade schema.conversation_participants	joined_atT)timezoneznow())server_defaultnullablelast_read_at)r   &conversation_participants_user_id_fkey
foreignkeytype_.conversation_participants_conversation_id_fkeyN
conversationsconversation_ididCASCADE)ondeleteusersuser_id)r   
add_columnsaColumnDateTimetextdrop_constraintcreate_foreign_key     h/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/08eced71251f_add_last_read_at_to_.pyupgrader)      s     MM-ryybkk[_F`qsqxqx  zA  rB  MQ  0R  SMM-ryy^bIcnr/st?A\dpqGIdlxy$ ;_O`Nadhcit}~$ ;WykTXSYdmnr'   c                  (   t        j                  ddd       t        j                  ddd       t        j                  ddddgdg       t        j                  d	dd
dgdg       t        j                  dd       t        j                  dd
       y)zDowngrade schema.Nr
   r   r   r   r   r   r   r   r   r   r   r   )r   r$   r%   drop_columnr&   r'   r(   	downgrader,   !   s     t8Mt8MJLgix  |M  {N  QU  PV  WBD_ahktjux|w}~NN.?NN.<r'   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr    r   str__annotations__r	   r
   r   r)   r,   r&   r'   r(   <module>r4      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2o=r'   

--- END OF FILE: alembic/versions/__pycache__/08eced71251f_add_last_read_at_to_.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/01fcfe2512a6_make_corporate_admin_id_nullable_in_.cpython-312.pyc ---



    h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zMake corporate_admin_id nullable in spacenodes

Revision ID: 01fcfe2512a6
Revises: 0581da68b2ba
Create Date: 2025-04-30 04:15:46.652205

    )SequenceUnion)opN01fcfe2512a6revision0581da68b2ba
down_revision
branch_labels
depends_onc                      t        j                  t        j                  d      ddgd       t        j                  ddt	        j
                         d	       y
)zUpgrade schema.ix_connections_statusconnectionsstatusF)unique
spacenodescorporate_admin_idT
existing_typenullableN)r   create_indexfalter_columnsaINTEGER     x/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/01fcfe2512a6_make_corporate_admin_id_nullable_in_.pyupgrader      s@     OOBDD01=8*UZ[OOL"6ZZ\r   c                      t        j                  ddt        j                         d       t        j                  t        j
                  d      d       y)	zDowngrade schema.r   r   Fr   r
   r   )
table_nameN)r   r   r   r   
drop_indexr   r   r   r   	downgrader"      s;     OOL"6ZZ\ MM"$$./MJr   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r"   r   r   r   <module>r*      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2Kr   

--- END OF FILE: alembic/versions/__pycache__/01fcfe2512a6_make_corporate_admin_id_nullable_in_.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/2a94457f8436_add_space_id_to_startup_and_relationship.cpython-312.pyc ---



    RA0h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zadd_space_id_to_startup_and_relationship

Revision ID: 2a94457f8436
Revises: c421022fb1a2
Create Date: 2025-05-23 09:32:33.634894

    )SequenceUnion)opN2a94457f8436revisionc421022fb1a2
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d             t        j
                  t        j                  d      ddgd       t        j                  ddddgd	g       y )
Nstartupsspace_idF)nullableix_startups_space_id)uniquefk_startups_space_id_spacenodes
spacenodesid)r   
add_columnsaColumnIntegercreate_indexfcreate_foreign_key     |/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/2a94457f8436_add_space_id_to_startup_and_relationship.pyupgrader      sa    MM*bii
BJJL5QROOBDD/0*zlSXY)L	tfr   c                      t        j                  ddd       t        j                  t        j                  d      d       t        j                  dd       y )Nr   r
   
foreignkey)type_r   )
table_namer   )r   drop_constraint
drop_indexr   drop_columnr   r   r   	downgrader'   !   s;    8*LYMM"$$-.:FNN:z*r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r'   r   r   r   <module>r/      sr    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2+r   

--- END OF FILE: alembic/versions/__pycache__/2a94457f8436_add_space_id_to_startup_and_relationship.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/a0ea2f0b7b3a_add_decline_fields_to_invitations.cpython-312.pyc ---



    z1h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zadd_decline_fields_to_invitations

Revision ID: a0ea2f0b7b3a
Revises: c5a8a53fefb7
Create Date: 2024-05-27 12:00:00.000000 # Placeholder, Alembic will update

    )SequenceUnion)opNa0ea2f0b7b3arevisionc5a8a53fefb7
down_revision
branch_labels
depends_onc                      t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  dt        j
                         d             y )Ninvitationsdeclined_atT)nullabledecline_reason)r   
add_columnsaColumnDateTimeText     u/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/a0ea2f0b7b3a_add_decline_fields_to_invitations.pyupgrader      sG    MM-="++-RV!WXMM-+;RWWYQU!VWr   c                  \    t        j                  dd       t        j                  dd       y )Nr
   r   r   )r   drop_columnr   r   r   	downgrader      s    NN="23NN=-0r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r   r   r   r   <module>r$      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2X1r   

--- END OF FILE: alembic/versions/__pycache__/a0ea2f0b7b3a_add_decline_fields_to_invitations.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/a2d9934e5db7_add_user_profiles_table_with_profile_.cpython-312.pyc ---



    
h*                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 ddl
ZdZe
ed<   dZee
df   ed	<   dZee
ee
   df   ed
<   dZee
ee
   df   ed<   ddZdd
Zy)zAdd user_profiles table with profile_vector column

Revision ID: a2d9934e5db7
Revises: 6584e07b26cc
Create Date: 2025-04-26 17:15:19.976232

    )SequenceUnion)opN)
postgresqla2d9934e5db7revision6584e07b26cc
down_revision
branch_labels
depends_onc            
      J   t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  d	t        j                  j                  d
      d      t        j                  dgdg      t        j                  d             t        j                  t        j                  d
      ddgd       t        j                  t        j                  d      ddgd       t        j                  ddd       t        j                  ddd       t        j                  dd       t        j                  dd       t        j                   d       t        j                  dd       t        j                  dd       t        j                   d       t        j"                  ddt%        j&                  d      t        j(                         dt        j*                  d              t        j"                  dd!t%        j&                  d      t        j(                         d"       t        j"                  ddt%        j&                  d      t        j(                         dt        j*                  d              t        j"                  dd!t%        j&                  d      t        j(                         dt        j*                  d              t        j                  d#d       t        j                  d$d       t        j                  d%d       t        j                  t        j                  d&      dd'gd       t        j,                  dd(       t        j,                  dd	       t        j,                  dd)       t        j,                  dd*       t        j,                  dd+       t        j,                  dd,       t        j,                  dd-       t        j,                  dd.       t        j,                  dd       t        j,                  dd/       t        j,                  dd0       t        j,                  dd       t        j,                  dd1       t        j,                  dd2       t        j,                  dd3       t        j,                  dd4       t        j,                  dd5       t        j,                  dd6       t        j,                  dd7       t        j,                  dd8       t        j"                  d9dt%        j&                  d      t        j(                         dt        j*                  d              t        j"                  d9d!t%        j&                  d      t        j(                         d"       y:);zUpgrade schema.
user_profilesidF)nullableuser_idtitleTbioprofile_vector   dimzusers.idix_user_profiles_iduniqueix_user_profiles_user_id users_applied_promo_code_id_fkeyusers
foreignkey)type_users_subscription_plan_id_fkeyix_promocodes_code
promocodes
table_nameix_promocodes_idix_subscriptionplans_idsubscriptionplansix_subscriptionplans_name
spacenodes
created_attimezonenow()
existing_typer   existing_nullableexisting_server_default
updated_atr/   r   r0   ix_users_referral_codeix_users_stripe_customer_idix_users_stripe_subscription_idix_users_space_idspace_idtools_technologiesstripe_customer_idskills_expertiselinkedin_profile_urlproject_interests_goalsstripe_subscription_idsubscription_start_datecommunity_badgecollaboration_preferencesprofile_picture_urlsubscription_statusapplied_promo_code_idcontact_info_visibilityindustry_focussubscription_plan_id
referral_codereferral_credit_monthsworkstationsN)r   create_tablesaColumnIntegerStringTextpgvector
sqlalchemyVectorForeignKeyConstraintPrimaryKeyConstraintcreate_indexfdrop_constraint
drop_index
drop_tablealter_columnr   	TIMESTAMPDateTimetextdrop_column     y/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/a2d9934e5db7_add_user_profiles_table_with_profile_.pyupgraderc      s    OOOIIdBJJL51IIi6IIgryy{T2IIeRWWY.II 3 3 : :s : CdSYK*8D! OOBDD./4&QVWOOBDD34o	{[_` 97,W8'V MM&<@MM$>MM,MM+8KLMM-:MNMM%& OOL,'114@[[]!%')www'7	9
 OOL,'114@[[]!%' OOG\'114@[[]!%')www'7	9
 OOG\'114@[[]!%')www'7	9
 MM*w?MM/GDMM3HOOBDD,-wUSNN701NN7,-NN701NN7./NN723NN756NN745NN756NN7G$NN7-.NN778NN7E"NN712NN712NN734NN756NN7,-NN723NN7O,NN745OONL'114@[[]!%')www'7	9
 OONL'114@[[]!%'ra   c                     t        j                  ddt        j                         t	        j
                  d      d       t        j                  ddt        j                         t	        j
                  d      dt        j                  d             t        j                  d	t        j                  d
t        j                         dd             t        j                  d	t        j                  d
t        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt	        j                  t        j                               dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt	        j                  t        j                               dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt	        j
                  d      dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt	        j                  t        j                               dd             t        j                  d	t        j                  dt        j                         dd             t        j                  d	t        j                  dt        j                  j                  d       dd             t        j                  d	t        j                  d!t	        j                  t        j                               dd             t        j                  d"d	d#dgd$g       t        j                  d%d	d&dgd$g       t        j                   t        j"                  d'      d	(       t        j$                  d)d	dgd*       t        j$                  d+d	dgd*       t        j$                  d,d	d
gd*       t        j                  d	dt        j                         t	        j
                  d      dt        j                  d             t        j                  d	dt        j                         t	        j
                  d      dt        j                  d             t        j                  d-dt        j                         t	        j
                  d      d       t        j                  d-dt        j                         t	        j
                  d      dt        j                  d             t        j&                  d&t        j                  d$t        j                         dd      t        j                  d.t        j                         dd      t        j                  d/t        j                         dd      t        j                  d0t        j(                  d12      dd      t        j                  d3t        j(                  d12      dd      t        j                  d4t        j*                         dd      t        j,                  d$d56             t        j$                  d7d&d.gd*       t        j$                  d8d&d$gd*       t        j&                  d#t        j                  d$t        j                         dd      t        j                  d9t        j                         dd      t        j                  d:t        j                         dd      t        j                  d;t        j                         dd      t        j                  d<t        j.                         dd      t        j                  d=t	        j
                  d      dd      t        j                  dt	        j
                  d      t        j                  d      dd>      t        j                  dt	        j
                  d      dd      t        j,                  d$d?6      
       t        j$                  d@d#d$gd*       t        j$                  dAd#d9gd*       t        j                   t        j"                  dB      dC(       t        j                   t        j"                  dD      dC(       t        j0                  dC       yE)FzDowngrade schema.rJ   r2   Tr+   r3   r*   r-   r.   r   rI   F)
autoincrementr   rH   rG   rF   rE   rD   rC   rB   r   rA   r@   r   r?   r>   r=   r<   r;   r:   r   r   r   r9   r   r"   r   r    r'   r7   r#   r6   r   r5   r4   r)   name	role_type
price_monthly5   )	precisionprice_annual
features_listsubscriptionplans_pkey)rf   r(   r&   codedescription
discount_type	is_activevalid_until)server_defaultre   r   promocodes_pkeyr%   r!   r   r   r   N)r   r[   rL   r]   r   r\   r^   
add_columnrM   INTEGERVARCHARARRAYrQ   rR   rS   create_foreign_keyrY   rW   rV   rK   DOUBLE_PRECISIONTEXTrU   BOOLEANrZ   r`   ra   rb   	downgrader}   i   s    OONL[[]))48!%' OONL[[]))48!%')www'7	9
 MM'299%=rzz|[`kopqMM'299_bjjlRWbfghMM'299%;RZZ\Y^imnoMM'299%5z7G7G

7Uejuyz{MM'299%>

\alpqrMM'299%<bjjlZ_jnopMM'299%:BJJLX]hlmnMM'299%:BJJLX]hlmnMM'299UBJJLX\]^MM'299%@*BRBRSUS]S]S_B`pu  AE  F  GMM'299%6

TYdhijMM'299Wbjjl%Z^_`MM'299%>
@T@T^b@csx  DH  I  JMM'299%=rzz|[`kopqMM'299%>

\alpqrMM'299%;RZZ\Y^imnoMM'299%79I9I"**,9Wglw{|}MM'299%92::<W\gklmMM'299%5x7J7J7Q7QVY7Q7Zjoz~  AMM'299%9:;K;KBJJL;Yiny}~<g|VmUnqupvw;WFY\r[svzu{|MM"$$*+@OO5wAY@ZcghOO17=Q<R[_`OO,g7HQUVOOG\[[]))48!%')www'7	9
 OOG\[[]))48!%')www'7	9
 OOL,[[]))48!%' OOL,[[]))48!%')www'7	9
 OO'IIdBJJLuEIIfbjjl%%HIIk2::<uuMIIor22R@PU`deIInb11B?u_cdIIorwwyMD'?@ OO/1DvhW\]OO-/BTFSXYOOLIIdBJJLuEIIfbjjl%%HIImRZZ\NIIorzz|55QIIk2::<utLIImZ114@PU`deIIlJ00$?PRPWPWX_P`pu  AE  FIIlJ00$?u_cdD'89
 OO&tfUKOO(,NMM"$$12OMM"$$,-/JMM/"ra   )returnN)__doc__typingr   r   alembicr   rR   rL   sqlalchemy.dialectsr   pgvector.sqlalchemyrQ   r   str__annotations__r
   r   r   rc   r}   r`   ra   rb   <module>r      s{    #   *  # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2O'fS#ra   

--- END OF FILE: alembic/versions/__pycache__/a2d9934e5db7_add_user_profiles_table_with_profile_.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/7bd0250369dc_create_notification_table.cpython-312.pyc ---



    Xh
	                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)ztCreate notification table

Revision ID: 7bd0250369dc
Revises: 9a0c9d66f8f4
Create Date: 2025-04-28 10:29:51.576320

    )SequenceUnion)opN7bd0250369dcrevision9a0c9d66f8f4
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  d	t        j
                         d      t        j                  d
t        j                         d      t        j                  dt        j                  d      t        j                  d
      d      t        j                  dgdg      t        j                  d      
       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  ddd       y)zUpgrade schema.
notificationsidF)nullableuser_idtyperelated_entity_idTmessageis_read
created_at)timezoneznow())server_defaultr   zusers.idix_notifications_id)unique"ix_notifications_related_entity_idix_notifications_typeix_notifications_user_id$ix_user_profiles_profile_vector_hnsw
user_profileshnsw)
table_namepostgresql_usingN)r   create_tablesaColumnIntegerStringBooleanDateTimetextForeignKeyConstraintPrimaryKeyConstraintcreate_indexf
drop_index     m/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/7bd0250369dc_create_notification_table.pyupgrader2      sp    OOOIIdBJJL51IIi6IIfbiikE2II!2::<$?IIiu5IIi6IIlBKK6rwwwGWbfgYK*8D!
 OOBDD./4&QVWOOBDD=>ReQfotuOOBDD01?VHUZ[OOBDD34o	{[`aMM8_gmnr0   c                     t        j                  dddgdd       t        j                  t        j                  d      d	       t        j                  t        j                  d
      d	       t        j                  t        j                  d      d	       t        j                  t        j                  d      d	       t        j                  d       y
)zDowngrade schema.r   r   profile_vectorFr   )r   r!   r   r
   )r    r   r   r   N)r   r,   r.   r-   
drop_tabler/   r0   r1   	downgrader6   +   s     OO:ON^M_hm  AG  HMM"$$12OMM"$$./OLMM"$$;<YMM"$$,-/JMM/"r0   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr#   r   str__annotations__r	   r
   r   r2   r6   r/   r0   r1   <module>r>      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2o,#r0   

--- END OF FILE: alembic/versions/__pycache__/7bd0250369dc_create_notification_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/c5a8a53fefb7_add_revoked_fields_to_invitations.cpython-312.pyc ---



    t1h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zadd_revoked_fields_to_invitations

Revision ID: c5a8a53fefb7
Revises: 835b07ae6f4e
Create Date: 2024-05-27 10:00:00.000000 # Placeholder, Alembic will update

    )SequenceUnion)opNc5a8a53fefb7revision835b07ae6f4e
down_revision
branch_labels
depends_onc                  2   t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  dt        j
                         d             t        j                  ddddgdg       y )	Ninvitations
revoked_atT)nullablerevoked_by_admin_id(fk_invitations_revoked_by_admin_id_usersusersid)r   
add_columnsaColumnDateTimeIntegercreate_foreign_key     u/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/c5a8a53fefb7_add_revoked_fields_to_invitations.pyupgrader      sg    MM-<QU!VWMM-+@"**,Y]!^_2w	$r   c                      t        j                  ddd       t        j                  dd       t        j                  dd       y )Nr   r
   
foreignkey)type_r   r   )r   drop_constraintdrop_columnr   r   r   	downgrader#   !   s3    A=XdeNN="78NN=,/r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r#   r   r   r   <module>r+      sr    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 20r   

--- END OF FILE: alembic/versions/__pycache__/c5a8a53fefb7_add_revoked_fields_to_invitations.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/0581da68b2ba_change_connection_status_to_enum.cpython-312.pyc ---



    yh'
                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<    ej                  ddd
dd      ZddZddZy)z{Change connection status to Enum

Revision ID: 0581da68b2ba
Revises: 7bd0250369dc
Create Date: 2025-04-29 09:13:58.949165

    )SequenceUnion)opN0581da68b2barevision7bd0250369dc
down_revision
branch_labels
depends_onPENDINGACCEPTEDDECLINEDBLOCKEDconnectionstatus)namec                  l   t         j                  t        j                         d       t        j                  dt        j                  dt         d             t        j                  d       t        j                  ddd       t        j                  dd       t        j                  ddd	       y
)z(Upgrade schema using multi-step process.F
checkfirstconnections
status_newTnullablea  
        UPDATE connections
        SET status_new = CASE status
            WHEN 'pending' THEN 'PENDING'::connectionstatus
            WHEN 'accepted' THEN 'ACCEPTED'::connectionstatus
            WHEN 'declined' THEN 'DECLINED'::connectionstatus
            WHEN 'blocked' THEN 'BLOCKED'::connectionstatus
            ELSE NULL -- Or handle unexpected values appropriately
        END
    statusnew_column_nameN)
connectionstatus_enumcreater   get_bind
add_columnsaColumnexecutealter_columndrop_column     t/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/0581da68b2ba_change_connection_status_to_enum.pyupgrader(      s       5 A MM-<9NY]!^_ JJ 	 		 OOM<%@ NN=(+ OOM<Jr&   c                     t        j                  dt        j                  dt        j                         d             t        j
                  d       t        j                  ddd       t        j                  dd       t        j                  ddd       t        j                  t        j                         d	       y
)z*Downgrade schema using multi-step process.r   
status_oldTr   z`
        UPDATE connections
        SET status_old = status::text -- Cast enum back to text
    Fr   r   r   N)r   r   r    r!   VARCHARr"   r#   r$   r   dropr   r%   r&   r'   	downgrader-   5   s     MM-<PT!UV JJ  	 OOM<%@ NN=(+ OOM<J r{{}?r&   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr    r   str__annotations__r	   r
   r   Enumr   r(   r-   r%   r&   r'   <module>r6      s    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2  	:z9Sef K<@r&   

--- END OF FILE: alembic/versions/__pycache__/0581da68b2ba_change_connection_status_to_enum.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/c92880be338c_add_missing_profile_fields_to_user_.cpython-312.pyc ---



    h'                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zAdd missing profile fields to user_profiles table

Revision ID: c92880be338c
Revises: a2d9934e5db7
Create Date: 2025-04-27 10:31:50.326465

    )SequenceUnion)opN)
postgresqlc92880be338crevisiona2d9934e5db7
down_revision
branch_labels
depends_onc                     t        j                  dd       t        j                  dd       t        j                  d       t        j                  dt	        j
                  dt	        j                  ddd	d
      d
             t        j                  dt	        j
                  dt        j                  t	        j                               d
             t        j                  dt	        j
                  dt        j                  t	        j                               d
             t        j                  dt	        j
                  dt	        j                         d
             t        j                  dt	        j
                  dt        j                  t	        j                               d
             t        j                  dt	        j
                  dt        j                  t	        j                               d
             t        j                  dt	        j
                  dt	        j                         d
             t        j                  dt	        j
                  dt	        j                         d
             y)zUpgrade schema.ix_user_profile_iduser_profile)
table_nameix_user_profile_user_id
user_profilescontact_info_visibilityPRIVATECONNECTIONSPUBLICcontact_visibility_enumnameF)nullableskills_expertiseTindustry_focusproject_interests_goalscollaboration_preferencestools_technologieslinkedin_profile_urlprofile_picture_urlN)r   
drop_index
drop_table
add_columnsaColumnEnumr   ARRAYStringText     w/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/c92880be338c_add_missing_profile_fields_to_user_.pyupgrader.      s    MM&>BMM+GMM.!MM/299-FPY[hjr  zS  IT  _d  $e  fMM/299-?AQAQRTR[R[R]A^im#noMM/299-=z?O?OPRPYPYP[?\gk#lmMM/299-F	\`#abMM/299-H*JZJZ[][d[d[fJgrv#wxMM/299-A:CSCSTVT]T]T_C`ko#pqMM/299-CRYY[[_#`aMM/299-BBIIKZ^#_`r,   c                     t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd	       t        j                  d
t        j                  dt        j
                         dd
      t        j                  dt        j
                         d
d
      t        j                  dt        j                         d
d      t        j                  dt        j                         d
d      t        j                  d	t        j                  dddd      d
d
      t        j                  dt        j                  t        j                               d
d      t        j                  dt        j                  t        j                               d
d      t        j                  dt        j                         d
d      t        j                  dt        j                  t        j                               d
d      t        j                  dt        j                  t        j                               d
d      t        j                  dt        j                         d
d      t        j                  dt        j                         d
d      t        j                  dgdgd      t        j                  dd             t        j                  dd
dgd       t        j                  dd
dgd
       y)zDowngrade schema.r   r!   r    r   r   r   r   r   r   r   idTF)
autoincrementr   user_idtitlebior   r   r   r   r   zusers.iduser_profile_user_id_fkeyuser_profile_pkeyr   )uniquer   N)r   drop_columncreate_tabler%   r&   INTEGERVARCHARTEXTr   ENUMr(   ForeignKeyConstraintPrimaryKeyConstraintcreate_indexr+   r,   r-   	downgraderA   &   sU    NN?$9:NN?$:;NN?$89NN?$?@NN?$=>NN?$45NN?$67NN?$=>OONIIdBJJLuEIIiUUKIIgrzz|54HIIeRWWYedCII'MS[b{)|  MR  ]b  cII *"2"22::<"@PU`deII
 0 0 >e^bcII'%RVWII):+;+;BJJL+IY^imnII"J$4$4RZZ\$BRWbfgII$bjjl%RVWII#RZZ\QUVYK*<WXD':;  OO-~	{SWXOO(.4&Or,   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr%   sqlalchemy.dialectsr   r   str__annotations__r
   r   r   r.   rA   r+   r,   r-   <module>rJ      sw    #   * # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2
a"Pr,   

--- END OF FILE: alembic/versions/__pycache__/c92880be338c_add_missing_profile_fields_to_user_.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/96604f2f7de6_create_user_table.cpython-312.pyc ---



    6h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d<   dZ
ee	ee	   df   e
d	<   dd
ZddZy)
z`Create user table

Revision ID: 96604f2f7de6
Revises: 
Create Date: 2025-04-18 19:26:22.810819

    )SequenceUnion)opN96604f2f7de6revision
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  d	t        j
                         d      t        j                  d
t        j
                         d      t        j                  dt        j                         d      t        j                  dt        j                  d
      t        j                  d      d      t        j                  dt        j                  d
      t        j                  d      d      t        j                  d             t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      dd
gd       y)zUpgrade schema.usersidF)nullableemailhashed_password	full_nameTrolestatus	is_active
created_at)timezoneznow())server_defaultr   
updated_atix_users_email)uniqueix_users_full_nameix_users_idix_users_statusN)r   create_tablesaColumnIntegerStringBooleanDateTimetextPrimaryKeyConstraintcreate_indexf     e/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/96604f2f7de6_create_user_table.pyupgrader,      s~    OOGIIdBJJL51IIgryy{U3IIu=IIk299;6IIfbiikE2IIh		e4IIk2::<$7IIlBKK6rwwwGWbfgIIlBKK6rwwwGWbfgD! OOBDD)*GgYtLOOBDD-.+uUOOBDD'4&GOOBDD*+WxjOr*   c                  ~   t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r   r   )
table_namer   r   r   N)r   
drop_indexr(   
drop_tabler)   r*   r+   	downgrader1   +   so     MM"$$()g>MM"$$}%':MM"$$+,AMM"$$'(W=MM'r*   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r   r	   r
   r,   r1   r)   r*   r+   <module>r9      ss    #   # "&
uS$Y &15
uS(3--. 5.2
E#x}d*+ 2P,r*   

--- END OF FILE: alembic/versions/__pycache__/96604f2f7de6_create_user_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/a9db281d289d_add_attachment_fields_to_chat_messages_.cpython-312.pyc ---



    h                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zAdd attachment fields to chat_messages and conversation models

Revision ID: a9db281d289d
Revises: 25802b79acda
Create Date: 2025-05-09 11:17:48.347454

    )SequenceUnion)opN)
postgresqla9db281d289drevision25802b79acda
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  d             t        j                  t        j                  d      ddgd       t        j                  d	t        j                  d
t        j                         d      t        j                  dt        j                         d      t        j                  d
gdg      t        j                  dgd
g      t        j                  d
d             t        j                  dt        j                  d
t        j                         d             t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  dt        j                         d             t        j                  ddt        j                         d       t        j                  ddt        j                  d      t        j
                         dt        j                   d             t        j                  ddt        j                  d      t        j
                         d       t        j"                  ddd       t        j"                  ddd       t        j$                  dddd
gdg       y)zUpgrade schema.
conversationsidF)nullable
created_atTix_conversations_iduniqueconversation_participantsconversation_iduser_idzconversations.idzusers.id
chat_messagesattachment_urlattachment_filenameattachment_mimetyperecipient_id
existing_typer   timezonenow()r   type_r   existing_server_defaultread_atr   r#   existing_nullableix_chat_messages_recipient_id)
table_name	if_existsix_chat_messages_sender_id.fk_chat_messages_conversation_id_conversationsN)r   create_tablesaColumnIntegerDateTimePrimaryKeyConstraintcreate_indexfForeignKeyConstraint
add_columnStringalter_columnINTEGERr   	TIMESTAMPtext
drop_indexcreate_foreign_key     {/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/a9db281d289d_add_attachment_fields_to_chat_messages_.pyupgraderA      sM    OOOIIdBJJL51IIlBKKMD9D!
 OOBDD./4&QVWOO/II>IIi6./2D1EHYK*8-y9 MM/299->

W[#\]MM/299-=ryy{UY#Z[MM/299-BBIIKZ^#_`MM/299-BBIIKZ^#_`OOO^ZZ\ OOO\'114@[[]')www'7	9
 OOOY'114@[[]!%' MM1oY]^MM.?VZ[JO]l  pA  oB  EI  DJ  Kr?   c            
      r   t        j                  ddd       t        j                  dddgd       t        j                  d	dd
gd       t        j                  ddt	        j
                         t
        j                  d
      d       t        j                  ddt	        j
                         t
        j                  d
      dt	        j                  d             t        j                  dd
t	        j                         d       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  d       t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r,   r   
foreignkey)r#   r+   	sender_idFr   r(   r   r%   Tr   r&   r   r!   r"   r   r   r   r   r   r   r   r   )r)   N)r   drop_constraintr3   r8   r.   r1   r   r:   r;   r9   drop_column
drop_tabler<   r4   r>   r?   r@   	downgraderH   ;   s4    G`lmOO0/K=Y^_OO3_~FV_deOOOY[[]))48!%' OOO\[[]))48')www'7	9
 OOO^ZZ\ NN?$9:NN?$9:NN?$45NN?$56MM-.MM"$$,-/JMM/"r?   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr.   sqlalchemy.dialectsr   r   str__annotations__r
   r   r   rA   rH   r>   r?   r@   <module>rQ      sw    #   * # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2"KL#r?   

--- END OF FILE: alembic/versions/__pycache__/a9db281d289d_add_attachment_fields_to_chat_messages_.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/835b07ae6f4e_add_approval_acceptance_to_invitations.cpython-312.pyc ---



    q1h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zadd_approval_acceptance_to_invitations

Revision ID: 835b07ae6f4e
Revises: a0f683693a70
Create Date: 2024-05-26 12:00:00.000000 # Placeholder, will be updated by Alembic

    )SequenceUnion)opN835b07ae6f4erevisiona0f683693a70
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d             t        j
                  ddddgdg       t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  d	t        j                         d             t        j
                  d
ddd	gdg       y )Ninvitationsapproved_by_admin_idT)nullable)fk_invitations_approved_by_admin_id_usersusersidaccepted_ataccepted_by_user_id(fk_invitations_accepted_by_user_id_users)r   
add_columnsaColumnIntegercreate_foreign_keyDateTime     z/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/835b07ae6f4e_add_approval_acceptance_to_invitations.pyupgrader      s    MM-+A2::<Z^!_`3w	 4& MM-="++-RV!WXMM-+@"**,Y]!^_2w	$r   c                      t        j                  ddd       t        j                  dd       t        j                  dd       t        j                  ddd       t        j                  dd       y )	Nr   r
   
foreignkey)type_r   r   r   r   )r   drop_constraintdrop_columnr   r   r   	downgrader%   (   sV    A=XdeNN="78NN=-0BMYefNN="89r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r%   r   r   r   <module>r-      sr    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2&:r   

--- END OF FILE: alembic/versions/__pycache__/835b07ae6f4e_add_approval_acceptance_to_invitations.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/25802b79acda_add_message_reaction_table.cpython-312.pyc ---



    h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zuAdd message_reaction table

Revision ID: 25802b79acda
Revises: a3cc12c29cbe
Create Date: 2025-05-09 08:20:58.573890

    )SequenceUnion)opN25802b79acdarevisiona3cc12c29cbe
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                         d	      t        j                  dgd
g      t        j                  dgdg      t        j                  d      t        j                  dddd
      
       t        j                  t        j                  d      ddgd       y)zUpgrade schema.message_reactionsidF)nullableuser_id
message_id
emoji_char
created_atTzchat_messages.idzusers.id_user_message_emoji_uc)nameix_message_reactions_id)uniqueN)r   create_tablesaColumnIntegerStringDateTimeForeignKeyConstraintPrimaryKeyConstraintUniqueConstraintcreate_indexf     n/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/25802b79acda_add_message_reaction_table.pyupgrader&      s     OO'IIdBJJL51IIi6IIlBJJL59IIlBIIK%8IIlBKKMD9\N-?,@CYK*8D!	<D\]
 OOBDD235H4&Y^_r$   c                      t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r   r
   )
table_nameN)r   
drop_indexr"   
drop_tabler#   r$   r%   	downgrader+   '   s*     MM"$$01>QRMM%&r$   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r&   r+   r#   r$   r%   <module>r3      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2`$'r$   

--- END OF FILE: alembic/versions/__pycache__/25802b79acda_add_message_reaction_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/a0f683693a70_create_invitations_table.cpython-312.pyc ---



    
a1h-	                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zcreate_invitations_table

Revision ID: a0f683693a70
Revises: 2a94457f8436
Create Date: 2024-05-24 10:00:00.000000 # Updated placeholder

    )SequenceUnion)opN)InvitationStatusa0f683693a70revision2a94457f8436
down_revision
branch_labels
depends_onc                  |   t        j                  dt        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                  d	d
dd
      d      t        j                  dt        j                         d      t        j                  dt        j                         dt        j                  d            t        j                  dt        j                         dt        j                  d            t        j                  dgdg      t        j                  d             t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       y )NinvitationsidF)nullableemail
startup_idinvitation_tokenstatusPENDINGACCEPTEDEXPIREDinvitationstatusname
expires_at
created_atTznow())r   server_default
updated_atzstartups.idix_invitations_email)uniqueix_invitations_idix_invitations_invitation_token)
r   create_tablesaColumnIntegerStringEnumDateTimetextForeignKeyConstraintPrimaryKeyConstraintcreate_indexf     l/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/a0f683693a70_create_invitations_table.pyupgrader2      sf   OOMIIdBJJL51IIgryy{U3IIlBJJL59II "))+>IIh	:yGYZejkIIlBKKME:IIlBKKMDQXIYZIIlBKKMDQXIYZ\N]O>D! OOBDD/0-'SXYOOBDD,-}tfUSOOBDD:;]M_L`imnr0   c                     t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  d       t	        j
                  d      j
                  t        j                         d	       y )
Nr"   r   )
table_namer!   r   r   r   F)
checkfirst)r   
drop_indexr.   
drop_tabler$   r(   dropget_bindr/   r0   r1   	downgrader:   )   s{    MM"$$89mTMM"$$*+
FMM"$$-.=IMM-  GG#$))"++-E)Jr0   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr$   app.models.invitationr   r   str__annotations__r
   r   r   r2   r:   r/   r0   r1   <module>rC      sw    #   2 # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2o(Kr0   

--- END OF FILE: alembic/versions/__pycache__/a0f683693a70_create_invitations_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/5294db0e7af9_add_hnsw_index_on_profile_vector.cpython-312.pyc ---



    h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)z{Add hnsw index on profile_vector

Revision ID: 5294db0e7af9
Revises: c92880be338c
Create Date: 2025-04-28 04:53:48.538629

    )SequenceUnion)opN5294db0e7af9revisionc92880be338c
down_revision
branch_labels
depends_onc                  .    t        j                  d       y )NzpCREATE INDEX ix_user_profiles_profile_vector_hnsw ON user_profiles USING hnsw (profile_vector vector_cosine_ops)r   execute     t/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/5294db0e7af9_add_hnsw_index_on_profile_vector.pyupgrader      s    JJ  B  Cr   c                  .    t        j                  d       y )Nz/DROP INDEX ix_user_profiles_profile_vector_hnswr
   r   r   r   	downgrader      s    JJ@Ar   )returnN)__doc__typingr   r   alembicr   
sqlalchemysar   str__annotations__r	   r
   r   r   r   r   r   r   <module>r      st    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2CBr   

--- END OF FILE: alembic/versions/__pycache__/5294db0e7af9_add_hnsw_index_on_profile_vector.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/6e42b588d2b7_add_user_profile_table_and_relationship.cpython-312.pyc ---



    $h~                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zAdd user profile table and relationship

Revision ID: 6e42b588d2b7
Revises: bd906d8dba40
Create Date: 2025-04-20 16:44:58.310022

    )SequenceUnion)opN)
postgresql6e42b588d2b7revisionbd906d8dba40
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  d	t        j                  d
ddd
      d      t        j                  dt        j                  t        j
                               d      t        j                  dt        j                  t        j
                               d      t        j                  dt        j                         d      t        j                  dt        j                  t        j
                               d      t        j                  dt        j                  t        j
                               d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  dgdg      t        j                  d             t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       y)zUpgrade schema.user_profileidF)nullableuser_idtitleTbiocontact_info_visibilityPRIVATECONNECTIONSPUBLICcontact_visibility_enum)nameskills_expertiseindustry_focusproject_interests_goalscollaboration_preferencestools_technologieslinkedin_profile_urlprofile_picture_urlzusers.idix_user_profile_id)uniqueix_user_profile_user_idN)r   create_tablesaColumnIntegerStringTextEnumr   ARRAYForeignKeyConstraintPrimaryKeyConstraintcreate_indexf     {/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/6e42b588d2b7_add_user_profile_table_and_relationship.pyupgrader3      s    OONIIdBJJL51IIi6IIgryy{T2IIeRWWY.II'M8Zs)t  @E  FII *"2"2299;"?$OII
 0 0 =MII'TBII):+;+;BIIK+HSWXII"J$4$4RYY[$ADQII$biikDAII#RYY[4@YK*8D!  OOBDD-.uUOOBDD23^i[Y]^r1   c                      t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r#   r   )
table_namer!   N)r   
drop_indexr/   
drop_tabler0   r1   r2   	downgrader8   -   s@     MM"$$01nMMM"$$+,HMM.!r1   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr%   sqlalchemy.dialectsr   r   str__annotations__r
   r   r   r3   r8   r0   r1   r2   <module>rA      sv    #   * # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2_0"r1   

--- END OF FILE: alembic/versions/__pycache__/6e42b588d2b7_add_user_profile_table_and_relationship.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/99e4b0bb221a_add_company_and_startup_models.cpython-312.pyc ---



    @h6                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zyAdd company and startup models

Revision ID: 99e4b0bb221a
Revises: 6e42b588d2b7
Create Date: 2025-04-26 02:12:04.722499

    )SequenceUnion)opN99e4b0bb221arevision6e42b588d2b7
down_revision
branch_labels
depends_onc                  F	   t        j                  dt        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  d	t        j                         d      t        j                  d
t        j
                         d      t        j                  dt        j                  d      t        j                  d
      d      t        j                  dt        j                  d      d      t        j                  d      
       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  dt        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  d	t        j                         d      t        j                  dt        j                         d      t        j                  d
t        j
                         d      t        j                  dt        j                  d      t        j                  d
      d      t        j                  dt        j                  d      d      t        j                  d             t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  dt        j                  dt        j                         d             t        j                  dt        j                  dt        j                         d             t        j                  ddddgdg       t        j                  ddddgdg       y)zUpgrade schema.	companiesidF)nullablenamelogo_urlTindustry_focusdescriptionwebsite
created_at)timezoneznow())server_defaultr   
updated_atix_companies_id)uniqueix_companies_namestartupsmissionix_startups_idix_startups_nameusers
company_id
startup_idN)r   create_tablesaColumnIntegerStringTextDateTimetextPrimaryKeyConstraintcreate_indexf
add_columncreate_foreign_key     r/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/99e4b0bb221a_add_company_and_startup_models.pyupgrader3      s    OOKIIdBJJL51IIfbiikE2IIj"))+5II		d;IImRWWY6IIit4IIlBKK6rwwwGWbfgIIlBKK6FD!
 OOBDD*+[4&OOOBDD,-{VHUSOOJIIdBJJL51IIfbiikE2IIj"))+5II		d;IImRWWY6IIiT2IIit4IIlBKK6rwwwGWbfgIIlBKK6FD! OOBDD)*JuMOOBDD+,j6(5QMM'299\2::<$OPMM'299\2::<$OP$|ntfM$l^dVLr1   c                  `   t        j                  ddd       t        j                  ddd       t        j                  dd       t        j                  dd       t        j                  t        j                  d      d	       t        j                  t        j                  d
      d	       t        j
                  d       t        j                  t        j                  d      d	       t        j                  t        j                  d
      d	       t        j
                  d       y)zDowngrade schema.Nr    
foreignkey)type_r"   r!   r   r   )
table_namer   r   r
   r   )r   drop_constraintdrop_column
drop_indexr-   
drop_tabler0   r1   r2   	downgrader<   :   s     tWL9tWL9NN7L)NN7L)MM"$$)*zBMM"$$'(Z@MM*MM"$$*+DMM"$$()kBMM+r1   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr$   r   str__annotations__r	   r
   r   r3   r<   r0   r1   r2   <module>rD      st    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2!MJr1   

--- END OF FILE: alembic/versions/__pycache__/99e4b0bb221a_add_company_and_startup_models.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/362919f61f47_add_space_node_and_workstation_models.cpython-312.pyc ---



    ü-h%                         U d Z ddlmZmZ ddlmZ ddlmZ ddlZ	ddl
ZdZe
ed<   dZee
df   ed	<   dZee
ee
   df   ed
<   dZee
ee
   df   ed<    G d d
e      Z e	j
                  edd      ZddZddZy)zAdd space node and workstation models

Revision ID: 362919f61f47
Revises: 99e4b0bb221a
Create Date: 2025-04-26 08:56:42.644123

    )SequenceUnion)Enum)opN362919f61f47revision99e4b0bb221a
down_revision
branch_labels
depends_onc                       e Zd ZdZdZdZy)WorkstationStatusEnum	AVAILABLEOCCUPIEDMAINTENANCEN)__name__
__module____qualname__r   r   r        y/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/362919f61f47_add_space_node_and_workstation_models.pyr   r      s    IHKr   r   workstation_status_enumT)namecreate_typec                  ~   t        j                  d       t        j                  dt        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  d	t        j                         d      t        j                  d
t        j                         d      t        j                  dt        j                  d      d      t        j                  d
t        j                  d      t        j                  d      d      t        j                  dt        j                  d      d      t        j                  d      
       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  dt        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j
                         d      t        j                  d
t        j                  d      t        j                  d      d      t        j                  dt        j                  d      d      t        j                  dgdg      t        j                  d      
       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  dt        j                  dt        j
                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  d t        j                         d      t        j                  d             t        j                  t        j                  d!      ddgd       t        j                  t        j                  d"      ddgd       t        j                  d#t        j                  dt        j
                         d      t        j                  d$t        j
                         d      t        j                  d%t         d      t        j                  d&t        j
                         d      t        j                  d
t        j                  d      t        j                  d      d      t        j                  dt        j                  d      d      t        j                  d&gdg      t        j                  d$gd'g      t        j                  d      
       t        j                  t        j                  d(      d#dgd       t        j                  t        j                  d)      d#d%gd       t        j"                  d*t        j                  d+t        j                         d             t        j"                  d*t        j                  d,t        j                         d             t        j"                  d*t        j                  d-t        j                         d             t        j"                  d*t        j                  d.t        j$                  t        j                               d             t        j"                  d*t        j                  d/t        j$                  t        j                               d             t        j"                  d*t        j                  d0t        j                         d             t        j"                  d*t        j                  d1t        j$                  t        j                               d             t        j"                  d*t        j                  d2t        j$                  t        j                               d             t        j"                  d*t        j                  d3t        j                         d             t        j"                  d*t        j                  d4t        j                         d             t        j"                  d*t        j                  d5t&        j(                  j+                  d67      d             t        j"                  d*t        j                  d$t        j
                         d             t        j"                  d*t        j                  d8t        j
                         d             t        j"                  d*t        j                  d9t        j                         d             t        j"                  d*t        j                  d:t        j                         d             t        j"                  d*t        j                  d;t        j                         d             t        j"                  d*t        j                  d<t        j                         d             t        j"                  d*t        j                  d=t        j                         d             t        j"                  d*t        j                  d>t        j
                         d             t        j"                  d*t        j                  d?t        j                  d      d             t        j"                  d*t        j                  d@t        j
                         d             t        j                  t        j                  dA      d*d9gd       t        j                  t        j                  dB      d*d;gd       t        j                  t        j                  dC      d*d<gd       t        j,                  dDd*dd>gdg       t        j,                  dDd*dd$gdg       t        j,                  dDd*dd8gdg       yD)EzUpgrade schema.z&CREATE EXTENSION IF NOT EXISTS vector;
promocodesidF)nullablecodedescriptionT
discount_type	is_activevalid_until)timezone
created_atznow())server_defaultr   
updated_atix_promocodes_code)uniqueix_promocodes_id
spacenodesr   location_descriptioncorporate_admin_idtotal_workstationszusers.idix_spacenodes_idix_spacenodes_namesubscriptionplans	role_type
price_monthlyprice_annual
features_listix_subscriptionplans_idix_subscriptionplans_nameworkstationsspace_idstatusassigned_user_idz
spacenodes.idix_workstations_idix_workstations_statususerstitlebiocontact_info_visibilityskills_expertiseindustry_focusproject_interests_goalscollaboration_preferencestools_technologieslinkedin_profile_urlprofile_picture_urlprofile_vectori   )dimapplied_promo_code_id
referral_codecommunity_badgestripe_customer_idstripe_subscription_idsubscription_statussubscription_plan_idsubscription_start_datereferral_credit_monthsix_users_referral_codeix_users_stripe_customer_idix_users_stripe_subscription_idN)r   executecreate_tablesaColumnIntegerStringBooleanDateTimetextPrimaryKeyConstraintcreate_indexfForeignKeyConstraintFloatTextworkstation_status_sa_enum
add_columnARRAYpgvector
sqlalchemyVectorcreate_foreign_keyr   r   r   upgraderm   $   s    JJ78
 OOLIIdBJJL51IIfbiikE2IImRYY[48IIoryy{U;IIk2::<$7IImR[[$7$GIIlBKK6rwwwGWbfgIIlBKK6FD!
 OOBDD-.vhtTOOBDD+,lTF5QOOLIIdBJJL51IIfbiikE2II$biikDAII"BJJL5AII"BJJL5AIIlBKK6rwwwGWbfgIIlBKK6F12ZLCD!
 OOBDD+,lTF5QOOBDD-.vhuUOO'IIdBJJL51IIfbiikE2IIk299;7IIorxxzD9IInbhhj48IIorwwy48D! OOBDD235H4&Y^_OOBDD457JVH]bcOONIIdBJJL51IIj"**,7IIh2UCII "**,>IIlBKK6rwwwGWbfgIIlBKK6F/0:,AZL?*;>D!
 OOBDD-.uUOOBDD12NXJW\]MM'299WbiikDIJMM'299UBIIK$GHMM'299%>		VZ[\MM'299%7"))+9NY]^_MM'299%5rxx		7LW[\]MM'299%>		VZ[\MM'299%@"((299;BWbfghMM'299%9288BIIK;P[_`aMM'299%;RYY[SWXYMM'299%:BIIKRVWXMM'299%5x7J7J7Q7QVY7Q7ZeijkMM'299ZMNMM'299%<bjjlUYZ[MM'299_biikDQRMM'299%6		dSTMM'299%9299;QUVWMM'299%=ryy{UYZ[MM'299%:BIIKRVWXMM'299%;RZZ\TXYZMM'299%>UY@ZeijkMM'299%=rzz|VZ[\OOBDD12Go=NW[\OOBDD67CWBXaefOOBDD:;WG_F`imn$)<?U>VY]X^_$
|dVL$8O7PSWRXYr   c                  t   t        j                  ddd       t        j                  ddd       t        j                  ddd       t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  dd	       t        j                  dd
       t        j                  dd       t        j                  dd       t        j                  dd
       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  dd       t        j                  t        j                  d      d       t        j                  t        j                  d       d       t        j
                  d       t        j                  t        j                  d!      d"       t        j                  t        j                  d#      d"       t        j
                  d"       t        j                  t        j                  d$      d%       t        j                  t        j                  d&      d%       t        j
                  d%       t        j                  t        j                  d'      d(       t        j                  t        j                  d)      d(       t        j
                  d(       y)*zDowngrade schema.Nr>   
foreignkey)type_rV   )
table_namerU   rT   rS   rR   rQ   rP   rO   rN   rM   rL   rK   r9   rI   rH   rG   rF   rE   rD   rC   rB   rA   r@   r?   r=   r8   r<   r7   r1   r6   r0   r+   r/   r*   r   r(   )r   drop_constraint
drop_indexrb   drop_column
drop_tabler   r   r   	downgraderv   |   s    tWL9tWL9tWL9MM"$$89gNMM"$$45'JMM"$$/0WENN745NN756NN723NN712NN745NN701NN7-.NN7O,NN734NN7J'NN7,-NN712NN723NN701NN778NN756NN7,-NN7./NN756NN7E"NN7G$MM"$$/0^LMM"$$+,HMM.!MM"$$23@STMM"$$01>QRMM%&MM"$$+,FMM"$$)*|DMM,MM"$$)*|DMM"$$+,FMM,r   )returnN)__doc__typingr   r   enumr   alembicr   rj   rY   pgvector.sqlalchemyri   r   str__annotations__r
   r   r   r   rf   rm   rv   r   r   r   <module>r      s    #     # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2 D   %RWW	" TZp) r   

--- END OF FILE: alembic/versions/__pycache__/362919f61f47_add_space_node_and_workstation_models.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/8c3a5a32e14b_add_verification_token_table.cpython-312.pyc ---



    h<
                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zwAdd verification token table

Revision ID: 8c3a5a32e14b
Revises: 6f81518f99df
Create Date: 2025-04-19 16:47:01.473034

    )SequenceUnion)opN)
postgresql8c3a5a32e14brevision6f81518f99df
down_revision
branch_labels
depends_onc            
      *   t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                  d	      d      t        j                  d
t        j                  d	      d      t        j                  dgdg      t        j                  d             t        j                  t        j                  d      ddgd
       t        j                  t        j                  d      ddgd
       t        j                  dd
t        j                         t        j                  d	      dt        j                  d             t        j                  ddt        j                         t        j                  d	      dt        j                  d             y)zUpgrade schema.verification_tokensidF)nullableuser_idtoken
expires_atTtimezone
created_atzusers.idix_verification_tokens_id)uniqueix_verification_tokens_tokenusersnow()
existing_typetype_existing_nullableexisting_server_default
updated_atN)r   create_tablesaColumnIntegerStringDateTimeForeignKeyConstraintPrimaryKeyConstraintcreate_indexfalter_columnr   	TIMESTAMPtext     p/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/8c3a5a32e14b_add_verification_token_table.pyupgrader2      s]    OO)IIdBJJL51IIi6IIgryy{U3IIlBKK6GIIlBKK6FYK*8D! OOBDD457Ltf]bcOOBDD78:ORYQZcghOOG\'113[[$/!%')www'7	9
 OOG\'113[[$/!%')www'7	9r0   c            
      &   t        j                  ddt        j                  d      t	        j
                         dt        j                  d             t        j                  ddt        j                  d      t	        j
                         dt        j                  d             t        j                  t        j                  d      d	
       t        j                  t        j                  d      d	
       t        j                  d	       y)
zDowngrade schema.r   r!   Tr   r   r   r   r   r   )
table_namer   N)
r   r,   r#   r'   r   r-   r.   
drop_indexr+   
drop_tabler/   r0   r1   	downgrader7   0   s     OOG\[[$7))+!%')www'7	9
 OOG\[[$7))+!%')www'7	9
 MM"$$56CXYMM"$$23@UVMM'(r0   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr#   sqlalchemy.dialectsr   r   str__annotations__r
   r   r   r2   r7   r/   r0   r1   <module>r@      su    #   * # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 296)r0   

--- END OF FILE: alembic/versions/__pycache__/8c3a5a32e14b_add_verification_token_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/a3cc12c29cbe_add_chat_models.cpython-312.pyc ---



    yhq                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zjAdd chat models

Revision ID: a3cc12c29cbe
Revises: 01fcfe2512a6
Create Date: 2025-05-01 13:39:24.405039

    )SequenceUnion)opNa3cc12c29cberevision01fcfe2512a6
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                  d	
      t        j                  d      d      t        j                  d
t        j                  d	
      d	      t        j                  dgdg      t        j                  dgdg      t        j                  d      
       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       y)zUpgrade schema.
chat_messagesidF)nullable	sender_idrecipient_idcontent
created_atT)timezoneznow())server_defaultr   read_atzusers.idix_chat_messages_id)uniqueix_chat_messages_recipient_idix_chat_messages_sender_idN)r   create_tablesaColumnIntegerTextDateTimetextForeignKeyConstraintPrimaryKeyConstraintcreate_indexf     c/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/a3cc12c29cbe_add_chat_models.pyupgrader)      s?    OOOIIdBJJL51IIk2::<%8IInbjjlU;IIiU3IIlBKK6rwwwGWbghIIid3dC^,zl=[MJ<:D!
 OOBDD./4&QVWOOBDD89?^L\ejkOOBDD56+_der'   c                  *   t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r   r
   )
table_namer   r   N)r   
drop_indexr%   
drop_tabler&   r'   r(   	downgrader.   )   sX     MM"$$34QMM"$$67OTMM"$$,-/JMM/"r'   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r)   r.   r&   r'   r(   <module>r6      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2f(#r'   

--- END OF FILE: alembic/versions/__pycache__/a3cc12c29cbe_add_chat_models.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/f6faaa54ca44_add_message_reactions_table.cpython-312.pyc ---



    K hZ                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
eedf   ed	<   dZeeee   df   ed
<   dZeeee   df   ed<   ddZdd
Zy)zvadd message reactions table

Revision ID: f6faaa54ca44
Revises: a9db281d289d
Create Date: 2025-05-11 07:04:29.275231

    )SequenceUnion)opN)
postgresqlf6faaa54ca44revisiona9db281d289d
down_revision
branch_labels
depends_onc            	         t        j                  ddt        j                         dt	        j
                  d             t        j                  dt	        j                  dt	        j                         d	             t        j                  d
dd       t        j                  d
dg d       t        j                  dd       y)zUpgrade schema.
chat_messages
created_atTnow()
existing_typenullableexisting_server_defaultmessage_reactionsemojiF)r   _user_message_emoji_ucuniquetype__message_user_emoji_uc)
message_iduser_idr   
emoji_charN)r   alter_columnr   	TIMESTAMPsatext
add_columnColumnStringdrop_constraintcreate_unique_constraintdrop_column     o/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/f6faaa54ca44_add_message_reactions_table.pyupgrader,      s     OOO\'113')www'79 MM%ryy"))+PU'VW/1DHU 8:MOqrNN&5r*   c            	         t        j                  dt        j                  dt        j                         dd             t        j
                  ddd       t        j                  ddg d	       t        j                  dd
       t        j                  ddt        j                         dt        j                  d
             y)zDowngrade schema.r   r   F)
autoincrementr   r   r   r   r   )r   r   r   r   r   r   r   r   N)r   r#   r!   r$   VARCHARr&   r'   r(   r   r   r    r"   r)   r*   r+   	downgrader0   #   s     MM%ryyrzz|[`kp'qr/1DHU 8:MOvwNN&0OOO\'113')www'79r*   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr!   sqlalchemy.dialectsr   r   str__annotations__r
   r   r   r,   r0   r)   r*   r+   <module>r9      su    #   * # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2
6
9r*   

--- END OF FILE: alembic/versions/__pycache__/f6faaa54ca44_add_message_reactions_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/9a0c9d66f8f4_create_connection_table.cpython-312.pyc ---



    2h                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zrCreate connection table

Revision ID: 9a0c9d66f8f4
Revises: 5294db0e7af9
Create Date: 2025-04-28 05:09:39.143766

    )SequenceUnion)opN9a0c9d66f8f4revision5294db0e7af9
down_revision
branch_labels
depends_onc                     t        j                  dt        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j                         d      t        j                  dt        j
                         d      t        j                  dt        j                         d	      t        j                  d
t        j                         d	      t        j                  dgdg      t        j                  dgdg      t        j                  d      t        j                  ddd
             t        j                  t        j                  d      ddgd       t        j                  t        j                  d      ddgd       y)zUpgrade schema.connectionsidF)nullablerequester_idrecipient_idstatus
created_atT
updated_atzusers.id_requester_recipient_uc)nameix_connections_id)uniqueix_connections_statusN)r   create_tablesaColumnIntegerStringDateTimeForeignKeyConstraintPrimaryKeyConstraintUniqueConstraintcreate_indexf     k/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/9a0c9d66f8f4_create_connection_table.pyupgrader(      s     OOMIIdBJJL51IInbjjlU;IInbjjlU;IIh		e4IIlBKKMD9IIlBKKMD9^,zl=^,zl=D!=VW OOBDD,-}tfUSOOBDD01=8*UZ[r&   c                      t        j                  t        j                  d      d       t        j                  t        j                  d      d       t        j                  d       y)zDowngrade schema.r   r
   )
table_namer   N)r   
drop_indexr$   
drop_tabler%   r&   r'   	downgrader-   *   s@     MM"$$./MJMM"$$*+
FMM- r&   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r(   r-   r%   r&   r'   <module>r5      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2\*!r&   

--- END OF FILE: alembic/versions/__pycache__/9a0c9d66f8f4_create_connection_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/4560944864bf_add_updated_at_is_deleted_to_chatmessage.cpython-312.pyc ---



    W"hk                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zadd_updated_at_is_deleted_to_chatmessage

Revision ID: 4560944864bf
Revises: 61285376d591
Create Date: 2025-05-13 06:58:36.310140

    )SequenceUnion)opN4560944864bfrevision61285376d591
down_revision
branch_labels
depends_onc            
      &   t        j                  dt        j                  dt        j                  d      d             t        j                  dt        j                  dt        j
                         dt        j                                      y	)
zUpgrade schema.
chat_messages
updated_atT)timezone)nullable
is_deletedF)r   server_defaultN)r   
add_columnsaColumnDateTimeBooleanfalse     |/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/4560944864bf_add_updated_at_is_deleted_to_chatmessage.pyupgrader      sV    MM/299\2;;PT;U`d#efMM/299\2::<RWhjhphphr#str   c                  \    t        j                  dd       t        j                  dd       y)zDowngrade schema.r
   r   r   N)r   drop_columnr   r   r   	downgrader      s    NN?L1NN?L1r   )returnN)__doc__typingr   r   alembicr   
sqlalchemyr   r   str__annotations__r	   r
   r   r   r   r   r   r   <module>r'      ss    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2u2r   

--- END OF FILE: alembic/versions/__pycache__/4560944864bf_add_updated_at_is_deleted_to_chatmessage.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/43b26710d32d_update_invitationstatus_enum_and_values.cpython-312.pyc ---



    i2h<                         U d Z ddlmZmZ ddlmZ ddlZdZe	e
d<   dZee	df   e
d<   dZee	ee	   df   e
d	<   dZ
ee	ee	   df   e
d
<   d
dZd
dZy)zupdate_invitationstatus_enum_and_values

Revision ID: 43b26710d32d
Revises: a0ea2f0b7b3a
Create Date: 2025-05-25 08:51:30.539663

    )SequenceUnion)opN43b26710d32drevisiona0ea2f0b7b3a
down_revision
branch_labels
depends_onc                       y)zUpgrade schema.N r
       {/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/43b26710d32d_update_invitationstatus_enum_and_values.pyupgrader          r   c                       y)zDowngrade schema.Nr
   r
   r   r   	downgrader      r   r   )returnN)__doc__typingr   r   alembicr   
sqlalchemysar   str__annotations__r	   r
   r   r   r   r
   r   r   <module>r      sr    #   # "0
uS$Y 015
uS(3--. 5.2
E#x}d*+ 2	
	r   

--- END OF FILE: alembic/versions/__pycache__/43b26710d32d_update_invitationstatus_enum_and_values.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/versions/__pycache__/6584e07b26cc_add_space_id_to_users_table.cpython-312.pyc ---



    	
h                         U d Z ddlmZmZ ddlmZ ddlZddlm	Z	 dZ
eed<   dZ
edz  ed	<   dZedz  ed
<   dZedz  ed<   ddZdd
Zy)zvAdd space_id to users table

Revision ID: 6584e07b26cc
Revises: 362919f61f47
Create Date: 2025-04-26 11:42:14.838280

    )SequenceUnion)opN)
postgresql6584e07b26ccrevision362919f61f47
down_revision
branch_labels
depends_onc                       y)zUpgrade schema.N r       o/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/versions/6584e07b26cc_add_space_id_to_users_table.pyupgrader           	r   c                       y)zDowngrade schema.Nr   r   r   r   	downgrader       r   r   )returnN)__doc__typingr   r   alembicr   
sqlalchemysasqlalchemy.dialectsr   r   str__annotations__r
   r   r   r   r   r   r   r   <module>r      sX    #   * # *
sTz * 
sTz  
C$J 		r   

--- END OF FILE: alembic/versions/__pycache__/6584e07b26cc_add_space_id_to_users_table.cpython-312.pyc ---

================================================================================

--- START OF FILE: alembic/__pycache__/env.cpython-312.pyc ---



    -g2h                        d dl Z d dlZd dlZd dlmZ d dlmZ  e        d dlmZ d dl	m
Z
 d dlmZ ej                  j                  ej                  j                  ej                  j!                  e      d             d dlmZ d d	lmZ d d
lmZ d dlmZmZ d dlmZ d d
lmZmZm Z  d dl!m"Z" d dl#m$Z$ d dl%m&Z& d dl'm(Z( d dl)m*Z* ejV                  Z+ ejX                  dd      j[                         dk(  Z.dZ/ e0ejb                        Z2e.r= e3de2        de2v r"e2ji                  dde/ d      Z2 e3de2        n e3de2        n e3de2        e+jk                  de2       e+jl                   ee+jl                         ejn                  Z8d"dZ9d  Z:d"d!Z; ejx                         r e9        y e jz                   e;              y)#    N)
fileConfig)load_dotenv)pool)create_async_engine)contextz..)settings)Base)User)CompanyStartup)UserProfile)	SpaceNodeWorkstationWorkstationAssignment)
Connection)Notification)VerificationToken)PasswordResetToken)
InvitationALEMBIC_USE_DB_IPfalsetruez
172.18.0.2z:ALEMBIC_INFO: ALEMBIC_USE_DB_IP is true. Original DB_URL: z@db:@:z+ALEMBIC_INFO: Modified DB_URL for Alembic: zUALEMBIC_WARNING: Could not find '@db:' in DB_URL to replace with IP. Using original: zLALEMBIC_INFO: ALEMBIC_USE_DB_IP is false or not set. Using original DB_URL: sqlalchemy.urlc                      t        j                  t        j                  d      t        dddi       t        j
                         5  t        j                          ddd       y# 1 sw Y   yxY w)aF  Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    r   T
paramstylenamed)urltarget_metadata
literal_bindsdialect_optsN)r   	configureconfigget_main_optionr    begin_transactionrun_migrations     A/home/marcel/ShareYourSpace/shareyourspace-backend/alembic/env.pyrun_migrations_offliner+   N   s^     ""#34'"G,	 
	"	"	$ ! ! ! !s   A%%A.c                     t        j                  | t               t        j                         5  t        j                          d d d        y # 1 sw Y   y xY w)N)
connectionr    )r   r#   r    r&   r'   )r-   s    r*   do_run_migrationsr.   g   s?    _M		"	"	$ ! ! ! !s   AAc                  ^  K   t        t        j                  d      t        j                        } | j                         4 d{   }|j
                  t               d{    ddd      d{    | j                          d{    y7 J7 /7 !# 1 d{  7  sw Y   1xY w7  w)zRun migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    r   )	poolclassN)	r   r$   r%   r   NullPoolconnectrun_syncr.   dispose)connectabler-   s     r*   run_migrations_onliner6   m   s      &/0--K
 ""$ 5 5
!!"34445 5 


	545 5 5 5  sf   AB-BB-	B"B#B'B-2B3B-
B+B-BB-B(BB($B-)returnN)>asyncioossyslogging.configr   dotenvr   
sqlalchemyr   sqlalchemy.ext.asyncior   alembicr   pathappendjoindirname__file__app.core.configr   app.db.base_classr	   app.models.userr
   app.models.organizationr   r   app.models.profiler
   app.models.spacer   r   r   app.models.connectionr   app.models.notificationr   app.models.verification_tokenr   app.models.password_reset_tokenr   app.models.invitationr   r$   getenvlowerr   
DB_IP_ADDRESSstrDATABASE_URL
db_url_strprintreplaceset_main_optionconfig_file_namemetadatar    r+   r.   r6   is_offline_moderunr(   r)   r*   <module>r]      s    	 
 %  
  6  RWW__X6= > % " ! 4 * J J , 0 ; > ,
 
 BII17;AACvM  

&&
'
	Fzl
ST
''!M?!0DE

;J<HI
efpeqrs	XYcXd
ef
   ' 4 
&v&&' --!2! 2 7 GKK%'(r)   

--- END OF FILE: alembic/__pycache__/env.cpython-312.pyc ---

================================================================================

